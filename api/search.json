[{"id":"09303d998ed7337d46bfa9387efc032e","title":"操作系统基础","content":"计算机系统概论\n操作系统的基本概念\n【考纲内容】\n(一）操作系统的概念、特征、功能和提供的服务\n(二）操作系统的发展与分类\n(三）操作系统的运行环境\n内核态与用户态;中断、异常;系统调用\n(四）操作系统体系结构\n【知识框架】\n概论\n\n\n特征\n\n并发(最基本)\n共享(最基本)\n虚拟\n同步\n\n\n\n目标和功能\n\n计算机系统资源的管理者\n用户与计算机系统之间的接口\n\n命令接口\n程序接口\nGUI\n\n\n扩充机器\n\n\n\n发展——批处理操作系统——分时操作系统——实时操作系统——网络和分布式操作系统\n\n\n运行机制\n\n中断和异常\n系统调用\n\n\n\n体系结构\n\n大内核\n微内核\n\n\n\n操作系统的概念\n​\t在信息化时代，软件是计算机系统的灵魂，而作为软件核心的操作系统，已与现代计算机系统密不可分、融为一体。计算机系统自下而上可大致分为 4 部分:硬件、操作系统、应用程序和用户(这里的划分与计算机组成原理中的分层不同)。操作系统管理各种计算机硬件，为应用程序提供基础，并充当计算机硬件与用户之间的中介。\n硬件如中央处理器、内存、输入/输出设备等，提供基本的计算资源。应用程序如字处理程序、电子制表软件、编译器、网络浏览器等，规定按何种方式使用这些资源来解决用户的计算问题。操作系统控制和协调各用户的应用程序对硬件的分配与使用。\n在计算机系统的运行过程中，操作系统提供了正确使用这些资源的方法。\n综上所述，操作系统(Operating System，OS）是指控制和管理整个计算机系统的硬件与软件资源，合理地组织、调度计算机的工作与资源的分配，进而为用户和其他软件提供方便接口与环境的程序集合。操作系统是计算机系统中最基本的系统软件。\n操作系统的特征\n操作系统是一种系统软件，但与其他系统软件和应用软件有很大的不同，它有自己的特殊性即基本特征。操作系统的基本特征包括并发、共享、虚拟和异步。这些概念对理解和掌握操作系统的核心至关重要，将一直贯穿于各个章节中。\n并发(Concurrence)\n并发是指两个或多个事件在同一时间间隔内发生。操作系统的并发性是指计算机系统中同时存在多个运行的程序，因此它具有处理和调度多个程序同时执行的能力。在操作系统中，引入进程的目的是使程序能并发执行。\n注意同一时间间隔（并发）和同一时刻（并行）的区别。在多道程序环境下，一段时间内，宏观上有多道程序在同时执行，而在每个时刻，单处理机环境下实际仅能有一道程序执行，因此微观上这些程序仍是分时交替执行的。操作系统的并发性是通过分时得以实现的。\n注意，并行性是指系统具有同时进行运算或操作的特性，在同一时刻能完成两种或两种以上的工作。并行性需要有相关硬件的支持，如多流水线或多处理机硬件环境。\n\n\n\n\n\n\n\n\n\n我们以现实生活中的直观例子来认识并发和并行的区别。例如，如果你在 9:00 ～ 9:10 仅吃面包，在 9:10 ～ 9:20 仅写字，在 9:20 ～ 9:30 仅吃面包，在 9:30 ～ 10:00 仅写字，那么在 9:00 ～ 10:00 吃面包和写字这两种行为就是并发执行的;再如，如果你在 9:00 ～ 10:00 右手写字，左手同时拿着面包吃，那么这两个动作就是并行执行的。\n共享(Sharing)\n资源共享即共享，是指系统中的资源可供内存中多个并发执行的进程共同使用。共享可分为以下两种资源共享方式。\n(1）互斥共享方式\n系统中的某些资源，如打印机、磁带机，虽然可供多个进程使用，但为使得所打印或记录的结果不致造成混淆，应规定在一段时间内只允许一个进程访问该资源。\n为此，当进程 A 访问某个资源时，必须先提出请求，若此时该资源空闲，则系统便将之分配给进程 A 使用，此后有其他进程也要访问该资源时（只要 A 未用完）就必须等待。仅当进程 A 访问完并释放该资源后，才允许另一个进程对该资源进行访问。我们把这种资源共享方式称为互斥式共享，而把在一段时间内只允许一个进程访问的资源称为临界资源或独占资源。计算机系统中的大多数物理设备及某些软件中所用的栈、变量和表格，都属于临界资源，它们都要求被互斥地共享。\n(2）同时访问方式\n系统中还有另一类资源，这类资源允许在一段时间内由多个进程“同时”访问。这里所说的“同时”通常是宏观上的，而在微观上，这些进程可能是交替地对该资源进行访问即“分时共享”的。可供多个进程“同时”访问的典型资源是磁盘设备，一些用重入码编写的文件也可被“同时”共享，即允许若干个用户同时访问该文件。\n注意，互斥共享要求一种资源在一段时间内（哪怕是一段很小的时间）只能满足一个请求，否则就会出现严重的问题，(你能想象打印机第一行打印 A 文档的内容、第二行打印 B 文档的内容的效果吗?）而同时访问共享通常要求一个请求分几个时间片段间隔地完成，其效果与连续完成的效果相同。\n并发和共享是操作系统两个最基本的特征，两者之间互为存在的条件:① 资源共享是以程序的并发为条件的，若系统不允许程序并发执行，则自然不存在资源共享问题;② 若系统不能对资源共享实施有效的管理，则必将影响到程序的并发执行，甚至根本无法并发执行。\n虚拟(Virtual)\n虚拟是指把一个物理上的实体变为若干逻辑上的对应物。物理实体（前者）是实的，即实际存在的;而后者是虚的，是用户感觉上的事物。用于实现虚拟的技术，称为虚拟技术。操作系统中利用了多种虚拟技术来实现虚拟处理器、虚拟内存和虚拟外部设备等。\n虚拟处理器技术是通过多道程序设计技术，采用让多道程序并发执行的方法，来分时使用一个处理器的。此时，虽然只有一个处理器，但它能同时为多个用户服务，使每个终端用户都感觉有一个中央处理器(CPU)在专门为它服务。利用多道程序设计技术把一个物理上的 CPU 虚拟为多个逻辑上的 CPU，称为虚拟处理器。\n类似地，可以采用虚拟存储器技术将一台机器的物理存储器变为虚拟存储器，以便从逻辑上扩充存储器的容量。当然，这时用户所感觉到的内存容量是虚的。我们把用户感觉到（但实际不存在)的存储器称为虚拟存储器。\n还可采用虚拟设备技术将一台物理 IO 设备虚拟为多台逻辑上的 I/O 设备，并允许每个用户占用一台逻辑上的 IO 设备，使原来仅允许在一段时间内由一个用户访问的设备（即临界资源)变为在一段时间内允许多个用户同时访问的共享设备。\n因此，操作系统的虚拟技术可归纳为:时分复用技术，如处理器的分时共享;空分复用技术，如虚拟存储器。\n异步(Asynchronism)\n多道程序环境允许多个程序并发执行，但由于资源有限，进程的执行并不是一贯到底的，而是走走停停的，它以不可预知的速度向前推进，这就是进程的异步性。\n异步性使得操作系统运行在一种随机的环境下，可能导致进程产生与时间有关的错误（就像对全局变量的访问顺序不当会导致程序出错一样)。然而，只要运行环境相同，操作系统就须保证多次运行进程后都能获得相同的结果。\n操作系统的目标和功能\n为了给多道程序提供良好的运行环境，操作系统应具有以下几方面的功能:处理机管理、存储器管理、设备管理和文件管理。为了方便用户使用操作系统，还必须向用户提供接口。同时，操作系统可用来扩充机器，以提供更方便的服务、更高的资源利用率。\n我们用一个直观的例子来理解这种情况。例如，用户是雇主，操作系统是工人（用来操作机器)，计算机是机器（由处理机、存储器、设备、文件几个部件构成)，工人有熟练的技能，能够控制和协调各个部件的工作，这就是操作系统对资源的管理;同时，工人必须接收雇主的命令，这就是“接口”;有了工人，机器就能发挥更大的作用，因此工人就成了“扩充机器”。\n操作系统作为计算机系统资源的管理者\n处理机管理\n在多道程序环境下，处理机的分配和运行都以进程（或线程）为基本单位，因而对处理机的管理可归结为对进程的管理。并发是指在计算机内同时运行多个进程，因此进程何时创建、何时撤销、如何管理、如何避免冲突、合理共享就是进程管理的最主要的任务。进程管理的主要功能包括进程控制、进程同步、进程通信、死锁处理、处理机调度等。\n存储器管理\n存储器管理是为了给多道程序的运行提供良好的环境，方便用户使用及提高内存的利用率，主要包括内存分配与回收、地址映射、内存保护与共享和内存扩充等功能。\n文件管理\n计算机中的信息都是以文件的形式存在的，操作系统中负责文件管理的部分称为文件系统。文件管理包括文件存储空间的管理、目录管理及文件读写管理和保护等。\n设备管理\n设备管理的主要任务是完成用户的 IO 请求，方便用户使用各种设备，并提高设备的利用率，主要包括缓冲管理、设备分配、设备处理和虚拟设备等功能。\n这些工作都由“工人”负责，“雇主”无须关注。\n操作系统作为用户与计算机硬件系统之间的接口\n为了让用户方便、快捷、可靠地操纵计算机硬件并运行自己的程序，操作系统还提供了用户接口。操作系统提供的接口主要分为两类:一类是命令接口，用户利用这些操作命令来组织和控制作业的执行;另一类是程序接口，编程人员可以使用它们来请求操作系统服务。\n命令接口\n使用命令接口进行作业控制的主要方式有两种，即联机控制方式和脱机控制方式。按作业控制方式的不同，可将命令接口分为联机命令接口和脱机命令接口。\n联机命令接口又称交互式命令接口，适用于分时或实时系统的接口。它由一组键盘操作命令组成。用户通过控制台或终端输入操作命令，向系统提出各种服务要求。用户每输入一条命令，控制权就转给操作系统的命令解释程序，然后由命令解释程序解释并执行输入的命令，完成指定的功能。之后，控制权转回控制台或终端，此时用户又可输入下一条命令。联机命令接口可以这样理解:“雇主”说一句话，“工人”做一件事，并做出反馈，这就强调了交互性。\n脱机命令接口又称批处理命令接口，适用于批处理系统，它由一组作业控制命令组成。脱机用户不能直接干预作业的运行，而应事先用相应的作业控制命令写成一份作业操作说明书，连同作业一起提交给系统。系统调度到该作业时，由系统中的命令解释程序逐条解释执行作业说明书上的命令，从而间接地控制作业的运行。脱机命令接口可以这样理解:“雇主”把要“工人”做的事写在清单上，“工人”按照清单命令逐条完成这些事，这就是批处理。\n\n\n\n\n\n\n\n\n\n联机和脱机可以理解为「联接机器」的「联」不是「联网」的「联」;交互的状态不就是连接着机器的吗\n程序接口\n程序接口由一组系统调用（也称广义指令）组成。用户通过在程序中使用这些系统调用来请求操作系统为其提供服务，如使用各种外部设备、申请分配和回收内存及其他各种要求。\n当前最为流行的是图形用户界面(GUI),即图形接口。GUI 最终是通过调用程序接口实现的，用户通过鼠标和键盘在图形界面上单击或使用快捷键，就能很方便地使用操作系统。严格来说，图形接口不是操作系统的一部分，但图形接口所调用的系统调用命令是操作系统的一部分。\n操作系统用作扩充机器\n没有任何软件支持的计算机称为裸机，它仅构成计算机系统的物质基础，而实际呈现在用户面前的计算机系统是经过若干层软件改造的计算机。裸机在最里层，其外面是操作系统。操作系统所提供的资源管理功能和方便用户的各种服务功能，将裸机改造成功能更强、使用更方便的机器;因此，我们通常把覆盖了软件的机器称为扩充机器或虚拟机。\n“工人”操作机器，机器就有更大的作用，于是“工人”便成了“扩充机器”。\n注意，本课程所关注的内容是操作系统如何控制和协调处理机、存储器、设备和文件，而不关注接口和扩充机器，后两者读者只需要有个印象，能理解即可。\n操作系统的发展与分类\n手工操作阶段（此阶段无操作系统)\n用户在计算机上算题的所有工作都要人工干预，如程序的装入、运行、结果的输出等。随着计算机硬件的发展，人机矛盾（速度和资源利用）越来越大，必须寻求新的解决办法。\n手工操作阶段有两个突出的缺点:① 用户独占全机，虽然不会出现因资源已被其他用户占用而等待的现象，但资源利用率低。②CPU 等待手工操作，CPU 的利用不充分。\n唯一的解决办法就是用高速的机器代替相对较慢的手工操作来对作业进行控制。\n批处理阶段(操作系统开始出现）\n为了解决人机矛盾及 CPU 和 IO 设备之间速度不匹配的矛盾，出现了批处理系统。按发展历程又分为单道批处理系统、多道批处理系统（多道程序设计技术出现以后)。·\n单道批处理系统\n系统对作业的处理是成批进行的，但内存中始终保持一道作业。单道批处理系统是在解决人机矛盾及 CPU 和 IO 设备速率不匹配的矛盾中形成的。单道批处理系统的主要特征如下:\n\n\n自动性。在顺利的情况下，磁带上的一批作业能自动地逐个运行，而无须人工干预\n\n\n顺序性。磁带上的各道作业顺序地进入内存，各道作业的完成顺序与它们进入内存的顺序在正常情况下应完全相同，亦即先调入内存的作业先完成。\n\n\n单道性。内存中仅有一道程序运行，即监督程序每次从磁带上只调入一道程序进入内存运行，当该程序完成或发生异常情况时，才换入其后继程序进入内存运行。\n\n\n此时面临的问题是:每次主机内存中仅存放一道作业，每当它在运行期间（注意这里是“运行时”而不是“完成后”)发出输入/输出请求后，高速的 CPU 便处于等待低速的 IO 完成的状态。为了进一步提高资源的利用率和系统的吞吐量，引入了多道程序技术。\n多道批处理系统\n多道程序设计技术允许多个程序同时进入内存并允许它们在 CPU 中交替地运行，这些程序共享系统中的各种硬/软件资源。当一道程序因 I/O 请求而暂停运行时，CPU 便立即转去运行另一道程序。它不采用某些机制来提高某一技术方面的瓶颈问题，而让系统的各个组成部分都尽量去“忙”，因此切换任务所花费的时间很少，可实现系统各部件之间的并行工作，使其整体在单位时间内的效率翻倍。\n当然，多道批处理系统的设计和实现要比单道系统复杂很多，因为要充分利用各种资源，就要涉及各种资源的调度问题。\n多道程序设计的特点是多道、宏观上并行、微观上串行。\n\n\n多道。计算机内存中同时存放多道相互独立的程序。\n\n\n宏观上并行。同时进入系统的多道程序都处于运行过程中，即它们先后开始各自的运行，但都未运行完毕。\n\n\n微观上串行。内存中的多道程序轮流占有 CPU，交替执行。\n\n\n多道程序设计技术的实现需要解决下列问题:\n\n\n如何分配处理器。\n\n\n多道程序的内存分配问题。\n\n\nIO 设备如何分配。\n\n\n如何组织和存放大量的程序和数据，以方便用户使用并保证其安全性与一致性。\n\n\n​\t在批处理系统中采用多道程序设计技术就形成了多道批处理操作系统。该系统把用户提交的作业成批地送入计算机内存，然后由作业调度程序自动地选择作业运行。\n​\t优点:资源利用率高，多道程序共享计算机资源，从而使各种资源得到充分利用;系统吞吐量大，CPU 和其他资源保持“忙碌”状态。缺点:用户响应的时间较长;不提供人机交互能力，用户既不能了解自己的程序的运行情况，又不能控制计算机。\n分时操作系统\n​\t所谓分时技术，是指把处理器的运行时间分成很短的时间片，按时间片轮流把处理器分配给各联机作业使用。若某个作业在分配给它的时间片内不能完成其计算，则该作业暂时停止运行，把处理器让给其他作业使用，等待下一轮再继续运行。由于计算机速度很快，作业运行轮转得也很快，因此给每个用户的感觉就像是自己独占一台计算机。\n​\t分时操作系统是指多个用户通过终端同时共享一台主机，这些终端连接在主机上，用户可以同时与主机进行交互操作而互不干扰。因此，实现分时系统最关键的问题是如何使用户能与自己的作业进行交互，即当用户在自己的终端上键入命令时，系统应能及时接收并及时处理该命令，再将结果返回用户。分时系统也是支持多道程序设计的系统，但它不同于多道批处理系统多道批处理是实现作业自动控制而无须人工干预的系统，而分时系统是实现人机交互的系统，这使得分时系统具有与批处理系统不同的特征。分时系统的主要特征如下:\n\n\n同时性。同时性也称多路性，指允许多个终端用户同时使用一台计算机，即一台计算机与若干台终端相连接，终端上的这些用户可以同时或基本同时使用计算机。\n\n\n交互性。用户能够方便地与系统进行人机对话，即用户通过终端采用人机对话的方式直接控制程序运行，与同程序进行交互。\n\n\n独立性。系统中多个用户可以彼此独立地进行操作，互不干扰，单个用户感觉不到别人也在使用这台计算机，好像只有自己单独使用这台计算机一样。\n\n\n及时性。用户请求能在很短时间内获得响应。分时系统采用时间片轮转方式使一台计算机同时为多个终端服务，使用户能够对系统的及时响应感到满意。\n\n\n虽然分时操作系统较好地解决了人机交互问题，但在一些应用场合，需要系统能对外部的信息在规定的时间（比时间片的时间还短）内做出处理（比如飞机订票系统或导弹制导系统)，因此，实时操作系统应运而生。\n实时操作系统\n​\t为了能在某个时间限制内完成某些紧急任务而不需要时间片排队，诞生了实时操作系统。这里的时间限制可以分为两种情况:若某个动作必须绝对地在规定的时刻（或规定的时间范围）发生，则称为硬实时系统，如飞行器的飞行自动控制系统，这类系统必须提供绝对保证，让某个特定的动作在规定的时间内完成。若能够接受偶尔违反时间规定且不会引起任何永久性的损害，则称为软实时系统，如飞机订票系统、银行管理系统。\n在实时操作系统的控制下，计算机系统接收到外部信号后及时进行处理，并在严格的时限内处理完接收的事件。实时操作系统的主要特点是 及时性 和 可靠性 。\n网络操作系统和分布式计算机系统\n​\t网络操作系统把计算机网络中的各台计算机有机地结合起来，提供一种统一、经济而有效的使用各台计算机的方法，实现各台计算机之间数据的互相传送。网络操作系统最主要的特点是网络中各种资源的共享及各台计算机之间的通信。\n​\t分布式计算机系统是由多台计算机组成并满足下列条件的系统:系统中任意两台计算机通过通信方式交换信息;系统中的每台计算机都具有同等的地位，即没有主机也没有从机;每台计算机上的资源为所有用户共享;系统中的任意台计算机都可以构成一个子系统，并且还能重构;任何工作都可以分布在几台计算机上，由它们并行工作、协同完成。用于管理分布式计算机系统的操作系统称为分布式计算机系统。该系统的主要特点是:分布性和并行性。分布式操作系统与网络操作系统的本质不同是，分布式操作系统中的若干计算机相互协同完成同一任务。\n个人计算机操作系统\n个人计算机操作系统是目前使用最广泛的操作系统，它广泛应用于文字处理、电子表格、游戏中，常见的有 Windows、Linux 和 Macintosh 等。操作系统的发展历程如图 1.1 所示。\\\n\n此外，还有嵌入式操作系统、服务器操作系统、智能手机操作系统等。\n操作系统的运行环境\n操作系统的运行机制\n\n\n\n\n\n\n\n\n\n初学者需要弄清楚一个问题，即计算机“指令”和高级语言的“代码”是不同的。我们一般所说的“编写代码”指的是用高级语言〈如 C、Java 等）来编写程序。但 CPU 看不懂这些高级语言程序的含义，为了让这些程序能够顺利执行，就需要把它们“翻译”成 CPU 能懂的机器语言，即一条条“指令”(这个“翻译”的过程称为“编译”)。所谓执行程序，其实就是 CPU 根据一条条指令的指示来执行一个个具体的操作。\n​\t计算机系统中，通常 CPU 执行两种不同性质的程序:一种是操作系统内核程序;另一种是用户自编程序（即系统外层的应用程序，或简称“应用程序”)。对操作系统而言，这两种程序的作用不同，前者是后者的管理者，因此“管理程序”(即内核程序）要执行一些特权指令，而“被管理程序”(即用户自编程序）出于安全考虑不能执行这些指令。所谓特权指令，是指计算机中不允许用户直接使用的指令，如 IO 指令、置中断指令，存取用于内存保护的寄存器、送程序状态字到程序状态字寄存器等的指令。在具体实现上，将 CPU 的状态划分为用户态(目态）和核心态（又称管态、内核态)。可以理解为 CPU 内部有一个小开关，当小开关为 1 时，CPU 处于核心态，此时 CPU 可以执行特权指令;当小开关为 0 时，CPU 处于用户态，此时 CPU 只能执行非特权指令。用户自编程序运行在用户态，操作系统内核程序运行在核心态。\n​\t在软件工程思想和结构化程序设计方法影响下诞生的现代操作系统，几乎都是层次式的结构。操作系统的各项功能分别被设置在不同的层次上。一些与硬件关联较紧密的模块，如时钟管理、中断处理、设备驱动等处于最低层。其次是运行频率较高的程序，如进程管理、存储器管理和设备管理等。这两部分内容构成了操作系统的内核。这部分内容的指令操作工作在核心态。\n内核是计算机上配置的底层软件，是计算机功能的延伸。不同系统对内核的定义稍有区别，大多数操作系统的内核包括 4 方面的内容。\n时钟管理\n​\t在计算机的各种部件中，时钟是最关键的设备。时钟的第一功能是计时，操作系统需要通过时钟管理，向用户提供标准的系统时间。另外，通过时钟中断的管理，可以实现进程的切换。例如，在分时操作系统中采用时间片轮转调度，在实时系统中按截止时间控制运行，在批处理系统中通过时钟管理来衡量一个作业的运行程度等。因此，系统管理的方方面面无不依赖于时钟。\n中断机制\n​\t引入中断技术的初衷是提高多道程序运行环境中 CPU 的利用率，而且主要是针对外部设备的。后来逐步得到发展，形成了多种类型，成为操作系统各项操作的基础。例如，键盘或鼠标信息的输入、进程的管理和调度、系统功能的调用、设备驱动、文件访问等，无不依赖于中断机制。可以说，现代操作系统是靠中断驱动的软件。\n中断机制中，只有一小部分功能属于内核，它们负责保护和恢复中断现场的信息，转移控制权到相关的处理程序。这样可以减少中断的处理时间，提高系统的并行处理能力。\n原语\n​\t按层次结构设计的操作系统，底层必然是一些可被调用的公用小程序，它们各自完成一个规定的操作。它们的特点如下:\n\n\n处于操作系统的最低层，是最接近硬件的部分。\n\n\n这些程序的运行具有原子性，其操作只能一气呵成(主要从系统安全性和便于管理考虑)。\n\n\n这些程序的运行时间都较短，而且调用频繁。\n\n\n通常把具有这些特点的程序称为原语(Atomic Operation)。定义原语的直接方法是关闭中断，让其所有动作不可分割地完成后再打开中断。\n系统中的设备驱动、CPU 切换、进程通信等功能中的部分操作都可定义为原语，使它们成为内核的组成部分。\n系统控制的数据结构及处理\n​\t系统中用来登记状态信息的数据结构很多，如作业控制块、进程控制块(PCB)、设备控制块、各类链表、消息队列、缓冲区、空闲区登记表、内存分配表等。为了实现有效的管理,系统需要一些基本的操作，常见的操作有以下 3 种:\n\n\n进程管理。进程状态管理、进程调度和分派、创建与撤销进程控制块等。\n\n\n存储器管理。存储器的空间分配和回收、内存信息保护程序、代码对换程序等。\n\n\n设备管理。缓冲区管理、设备分配和回收等。\n\n\n从上述内容可以了解，核心态指令实际上包括系统调用类指令和一些针对时钟、中断和原语的操作指令。\n中断和异常的概念\n\n\n\n\n\n\n\n\n\n建议结合《计算机组成原理考研复习指导》第 7 章学习，那里的讲解更详细。\n​\t在操作系统中引入核心态和用户态这两种工作状态后，就需要考虑这两种状态之间如何切换。操作系统内核工作在核心态，而用户程序工作在用户态。系统不允许用户程序实现核心态的功能，而它们又必须使用这些功能。因此，需要在核心态建立一些“门”，以便实现从用户态进入核心态。在实际操作系统中，CPU 运行上层程序时唯一能进入这些“门”的途径就是通过中断或异常。发生中断或异常时，运行用户态的 CPU 会立即进入核心态，这是通过硬件实现的(例如,用一个特殊寄存器的一位来表示 CPU 所处的工作状态，0 表示核心态，1 表示用户态。若要进入核心态，则只需将该位置 0 即可)。中断是操作系统中非常重要的一个概念，对一个运行在计算机上的实用操作系统而言，缺少了中断机制，将是不可想象的。原因是，操作系统的发展过程大体上就是一个想方设法不断提高资源利用率的过程，而提高资源利用率就需要在程序并未使用某种资源时，把它对那种资源的占有权释放，而这一行为就需要通过中断实现。\n中断和异常的定义\n​\t中断(Interruption)也称外中断，指来自 CPU 执行指令以外的事件的发生，如设备发出的 IO 结束中断，表示设备输入/输出处理已经完成，希望处理机能够向设备发下一个输入/输出请求，同时让完成输入/输出后的程序继续运行。时钟中断，表示一个固定的时间片已到，让处理机处理计时、启动定时运行的任务等。这一类中断通常是与当前指令执行无关的事件，即它们与当前处理机运行的程序无关。\n\n异常（Exception）也称内中断、例外或陷入(trap)，指源自 CPU 执行指令内部的事件,如程序的非法操作码、地址越界、算术溢出、虚存系统的缺页及专门的陷入指令等引起的事件。对异常的处理一般要依赖于当前程序的运行现场，而且异常不能被屏蔽，一旦出现应立即处理。关于内中断和外中断的联系与区别如图 1.2 所示。\n中断处理的过程\n​\t不同计算机的中断(指外中断)处理过程各具特色，就其多数而论，中断处理流程如图 1.3 所示。各阶段处理流程的描述如下:\n\n\n\n关中断。CPU 响应中断后，首先要保护程序的现场状态，在保护现场的过程中，CPU 不应响应更高级中断源的中断请求。否则，若现场保存不完整，在中断服务程序结束后，也就不能正确地恢复并继续执行现行程序。\n\n\n保存断点。为保证中断服务程序执行完毕后能正确地返回到原来的程序，必须将原来的程序的断点（即程序计数器 PC）保存起来。\n\n\n中断服务程序寻址。其实质是取出中断服务程序的入口地址送入程序计数器 PC。\n\n\n保存现场和屏蔽字。进入中断服务程序后，首先要保存现场，现场信息一般是指程序状态字寄存器 PSWR 和某些通用寄存器的内容。\n\n\n开中断。允许更高级中断请求得到响应。\n\n\n执行中断服务程序。这是中断请求的目的。\n\n\n关中断。保证在恢复现场和屏蔽字时不被中断。\n\n\n恢复现场和屏蔽字。将现场和屏蔽字恢复到原来的状态。\n\n\n开中断、中断返回。中断服务程序的最后一条指令通常是一条中断返回指令，使其返回到原程序的断点处，以便继续执行原程序。\n\n\n其中，1 ~ 3 步是在 CPU 进入中断周期后，由硬件自动（中断隐指令）完成的;4 ~ 9 步由中断服务程序完成。恢复现场是指在中断返回前，必须将寄存器的内容恢复到中断处理前的状态，这部分工作由中断服务程序完成。中断返回由中断服务程序的最后一条中断返回指令完成。\n系统调用\n​\t所谓系统调用，是指用户在程序中调用操作系统所提供的一些子功能，系统调用可视为特殊的公共子程序。系统中的各种共享资源都由操作系统统一掌管，因此在用户程序中，凡是与资源有关的操作（如存储分配、进行 IO 传输及管理文件等)，都必须通过系统调用方式向操作系统提出服务请求，并由操作系统代为完成。通常，一个操作系统提供的系统调用命令有几十条乃至上百条之多。这些系统调用按功能大致可分为如下几类。\n\n\n设备管理。完成设备的请求或释放，以及设备启动等功能。文件管理。完成文件的读、写、创建及删除等功能。\n\n\n进程控制。完成进程的创建、撤销、阻塞及唤醒等功能。\n\n\n进程通信。完成进程之间的消息传递或信号传递等功能。\n\n\n内存管理。完成内存的分配、回收以及获取作业占用内存区大小及始址等功能。\n\n\n显然，系统调用相关功能涉及系统资源管理、进程管理之类的操作，对整个系统的影响非常大，因此必定需要使用某些特权指令才能完成，所以系统调用的处理需要由操作系统内核程序负责完成，要运行在核心态。用户程序可以执行陷入指令(又称访管指令或 trap 指令）来发起系统调用，请求操作系统提供服务。可以这么理解，用户程序执行“陷入指令”，相当于把 CPU 成低用权主动交给操作系统内核程序（CPU 状态会从用户态进入核心态)，之后操作系统内核程序再对系统调用请求做出相应处理。处理完成后，操作系统内核程序又会把 CPU 的使用权还给用户程序(即 CPU 状态会从核心态回到用户态)。这么设计的目的是:用户程序不能直接执行对系统影响非常大的操作，必须通过系统调用的方式请求操作系统代为执行，以便保证系统的稳定性和安全性，防止用户程序随意更改或访问重要的系统资源，影响其他进程的运行。\n​\t这样，操作系统的运行环境就可以理解为:用户通过操作系统运行上层程序（如系统提供的命令解释程序或用户自编程序)，而这个上层程序的运行依赖于操作系统的底层管理程序提供服务支持，当需要管理程序服务时，系统则通过硬件中断机制进入核心态，运行管理程序;也可能是程序运行出现异常情况，被动地需要管理程序的服务，这时就通过异常处理来进入核心态。管理程序运行结束时，用户程序需要继续运行，此时通过相应的保存的程序现场退出中断处理程序或异常处理程序，返回断点处继续执行，如图 1.4 所示。\n\n在操作系统这一层面上，我们关心的是系统核心态和用户态的软件实现与切换，对于硬件层面的具体理解，可以结合“计算机组成原理”课程中有关中断的内容进行学习。\n下面列举一些由用户态转向核心态的例子:\n\n\n用户程序要求操作系统的服务，即系统调用。\n\n\n发生一次中断。\n\n\n用户程序中产生了一个错误状态。\n\n\n用户程序中企图执行一条特权指令。\n\n\n从核心态转向用户态由一条指令实现，这条指令也是特权命令，一般是中断返回指令。\n\n\n\n\n\n\n\n\n\n\n\n注意:由用户态进入核心态，不仅状态需要切换，而且所用的堆栈也可能需要由用户堆栈切换为系统堆栈，但这个系统堆栈也是属于该进程的。\n若程序的运行由用户态转到核心态，则会用到访管指令，访管指令是在用户态使用的，所以它不可能是特权指令。\n操作系统的体系结构\n大内核和微内核\n​\t操作系统的体系结构是一个开放的问题。如上文所述，操作系统在核心态为应用程序提供公共的服务，那么操作系统在核心态应该提供什么服务、怎样提供服务﹖有关这一问题的回答形成了两种主要的体系结构:大内核和微内核。\n​\t大内核系统将操作系统的主要功能模块都作为一个紧密联系的整体运行在核心态，从而为应用提供高性能的系统服务。因为各管理模块之间共享信息，能有效利用相互之间的有效特性.所以具有无可比拟的性能优势。\n​\t但随着体系结构和应用需求的不断发展，需要操作系统提供的服务越来越多，而且接口形式越来越复杂，操作系统的设计规模急剧增长，操作系统也面临着“软件危机”困境。为此，操作系统设计人员试图按照复杂性、时间常数、抽象级别等因素，将操作系统内核分成基本进程管理、虚存、IO 与设备管理、IPC、文件系统等几个层次，继而定义层次之间的服务结构，提高操作系统内核设计上的模块化。但是，由于层次之间的交互关系错综复杂，定义清晰的层次间接口非常困难，复杂的交互关系也使得层次之间的界限极其模糊。\n​\t为解决操作系统的内核代码难以维护的问题，提出了微内核的体系结构。它将内核中最基本的功能（如进程管理等）保留在内核，而将那些不需要在核心态执行的功能移到用户态执行,从而降低了内核的设计复杂性。那些移出内核的操作系统代码根据分层的原则被划分成若干服务程序，它们的执行相互独立，交互则都借助于微内核进行通信。\n​\t微内核结构有效地分离了内核与服务、服务与服务，使得它们之间的接口更加清晰，维护的代价大大降低，各部分可以独立地优化和演进，从而保证了操作系统的可靠性。\n​\t微内核结构的最大问题是性能问题，因为需要频繁地在核心态和用户态之间进行切换，操作系统的执行开销偏大。因此有的操作系统将那些频繁使用的系统服务又移回内核，从而保证系统性能。但相当多的实验数据表明，体系结构不是引起性能下降的主要因素，体系结构带来的性能提升足以弥补切换开销带来的缺陷。为减少切换开销，也有人提出将系统服务作为运行库链接到用户程序的一种解决方案，这样的体系结构称为库操作系统。\n本章疑难点\n并行性与并发性的区别和联系\n​\t\t并行性和并发性是既相似又有区别的两个概念。并行性是指两个或多个事件在同一时刻发生，并发性是指两个或多个事件在同一时间间隔内发生。\n​\t在多道程序环境下，并发性是指在一段时间内，宏观上有多个程序同时运行，但在单处理器系统中每个时刻却仅能有一道程序执行，因此微观上这些程序只能分时地交替执行。若在计算机系统中有多个处理器，则这些可以并发执行的程序便被分配到多个处理器上，实现并行执行，即利用每个处理器来处理一个可并发执行的程序。\n\n\n\n\n\n\n\n\n\n咬文嚼字一下，并行依靠多处理器支持，如果两个任务挂在到两个不同的处理器那么就能并行执行考虑 java 的线程机制，一个继承了 thread 的线程，在调用 start 的时候启动启动一个线程，那么就实现了并发发(发车，启动)java run 和 start 的区别\n特权指令与非特权指令\n​\t所谓特权指令，是指有特殊权限的指令，由于这类指令的权限最大，使用不当将导致整个系统崩溃，如清内存、置时钟、分配系统资源、修改虚存的段表或页表、修改用户的访问权限等。若所有程序都能使用这些指令，则系统一天死机 n 次就不足为奇。为保证系统安全，这类指令只能用于操作系统或其他系统软件，不直接提供给用户使用。因此，特权指令必须在核心态执行。实际上，CPU 在核心态下可以执行指令系统的全集。形象地说，特权指令是那些儿童不宜的东西，而非特权指令是老少皆宜的东西。\n​\t为了防止用户程序中使用特权指令，用户态下只能使用非特权指令，核心态下可以使用全部指令。在用户态下使用特权指令时，将产生中断以阻止用户使用特权指令。所以把用户程序放在用户态下运行，而操作系统中必须使用特权指令的那部分程序在核心态下运行，保证了计算机系统的安全可靠。从用户态转换为核心态的唯一途径是中断或异常。\n访管指令与访管中断\n​\t访管指令是一条可以在用户态下执行的指令。在用户程序中，因要求操作系统提供服务而有意识地使用访管指令，从而产生一个中断事件（自愿中断)，将操作系统转换为核心态，称为访管中断。访管中断由访管指令产生，程序员使用访管指令向操作系统请求服务。\n​\t为什么要在程序中引入访管指令呢?这是因为用户程序只能在用户态下运行。若用户程序想要完成在用户态下无法完成的工作，该怎么办﹖解决这个问题要靠访管指令。访管指令本身不是特权指令，其基本功能是让程序拥有“自愿进管”的手段，从而引起访管中断。\n​\t处于用户态的用户程序使用访管指令时，系统根据访管指令的操作数执行访管中断处理程序，访管中断处理程序将按系统调用的操作数和参数转到相应的例行子程序。完成服务功能后，退出中断，返回到用户程序断点继续执行。\n进程管理\n进程与线程\n【考纲内容】\n(一）进程与线程\n\n\n进程与 线程 的基本概念\n\n\n进程/线程的状态与转换\n\n\n线程的实现 （内核支持的线程，线程库支持的线程）\n\n\n进程与 线程的组织与控制\n\n\n进程间的通信（共享内存，消息传递，管道）\n\n\n(二）CPU调度与上下文切换\n\n\n调度的基本概念\n\n\n调度的目标调度的目标\n\n\n调度的实现 （ 调度器/调度程序 （scheduler），调度的时机与调度方式（抢占式/非抢占式），闲逛进程 ， 内核级线程与用户级线程调度 ）\n\n\n典型调度算法（先来先服务调度算法；短作业（短进程、短线程)优先调度算法;时间片轮转调度算法;优先级调度算法;高响应比优先调度算法; 多级队列调度算法 ;多级反馈队列调度算法。）\n\n\n上下文及其切换机制\n\n\n(三）进程同步\n\n\n进程同步的基本概念\n\n\n基本实现方法（软件方法，硬件方法）\n\n\n锁\n\n\n信号量\n\n\n条件变量\n\n\n经典同步问题（生产者-消费者问题；读者-写者问题；哲学家进餐问题）\n\n\n(四）死锁\n\n\n死锁的概念\n\n\n死锁处理策略\n\n\n死锁预防\n\n\n死锁避免\n\n\n死锁的检测和解除\n\n\n【知识框架】\n\n\n进程\n\n概念:与程序的区别\n特征:动态性、并发性、独立性、异步性、结构性\n状态:运行、就绪、阻塞、创建、结束\n控制:创建、终止、阻塞和唤醒、切换\n组织:进程控制块PCB、程序段、数据段\n通信:共享存储、消息传递、管道通信\n\n\n\n线程\n\n概念、与进程的比较、属性\n线程的实现方式\n\n\n\n处理机调度\n\n概念、三级调度:作业调度、中级调度、进程调度调度方式:剥夺式、非剥夺式\n调度准则:CPU利用率、吞吐量、周转时间、等待时间、响应时间\n算法:先来先服务、短作业(SJF）优先、优先级、高响应比优先、时间片轮转、多级反馈队列\n\n\n\n进程同步\n\n概念:临界资源、同步、互斥\n实现方法:软件实现的几种算法、硬件实现\n信号量:整型、记录型\n经典问题:生产者-消费者问题、读者-写者问题、哲学家进餐问题、吸烟者问题\n\n\n\n死锁\n\n定义\n原因:系统资源竞争、进程推进顺序非法\n条件:互斥、不剥夺、请求和保持、循环等待\n策略:预防死锁、避免死锁、死锁的检测与解除\n\n\n\n进程的概念和特征\n进程的概念\n​\t在多道程序环境下，允许多个程序并发执行，此时它们将失去封闭性，并具有间断性及不可再现性的特征。为此引入了进程（Process）的概念，以便更好地描述和控制程序的并发执行，实现操作系统的并发性和共享性（最基本的两个特性)。\n​\t为了使参与并发执行的程序（含数据）能独立地运行，必须为之配置一个专门的数据结构，称为进程控制块（Process Control Block，PCB)。系统利用 PCB 来描述进程的基本情况和运行状态，进而控制和管理进程。相应地，由程序段、相关数据段和 PCB 三部分构成了进程映像（进程实体)。**所谓创建进程，实质上是创建进程映像中的 PCB;而撤销进程,实质上是撤销进程的 PCB。**值得注意的是，进程映像是静态的，进程则是动态的。\n\n\n\n\n\n\n\n\n\n注意:PCB 是进程存在的唯一标志!\n从不同的角度，进程可以有不同的定义，比较典型的定义有:\n\n\n进程是程序的一次执行过程。\n\n\n进程是一个程序及其数据在处理机上顺序执行时所发生的活动。\n\n\n进程是具有独立功能的程序在一个数据集合上运行的过程，它是系统进行资源分配和调度的一个独立单位。\n\n\n​\t引入进程实体的概念后，我们可以把传统操作系统中的进程定义为:“进程是进程实体的运行过程，是系统进行资源分配和调度的一个独立单位。”\n​\t读者要准确理解这里说的系统资源。它指处理机、存储器和其他设备服务于某个进程的“时间”，例如把处理机资源理解为处理机的时间片才是准确的。因为进程是这些资源分配和调度的独立单位，即“时间片”分配的独立单位，这就决定了进程一定是一个动态的、过程性的概念。\n进程的特征\n进程是由多道程序的并发执行而引出的，它和程序是两个截然不同的概念。进程的基本特征是对比单个程序的顺序执行提出的，也是对进程管理提出的基本要求。\n\n\n动态性。进程是程序的一次执行，它有着创建、活动、暂停、终止等过程，具有一定的生命周期，是动态地产生、变化和消亡的。动态性是进程最基本的特征。\n\n\n并发性。指多个进程实体同时存于内存中，能在一段时间内同时运行。并发性是进程的重要特征，同时也是操作系统的重要特征。引入进程的目的就是使程序能与其他进程的程序并发执行，以提高资源利用率。\n\n\n独立性。指进程实体是一个能独立运行、独立获得资源和独立接受调度的基本单位。凡未建立 PCB 的程序，都不能作为一个独立的单位参与运行。\n\n\n异步性。由于进程的相互制约，使得进程具有执行的间断性，即进程按各自独立的、不可预知的速度向前推进。异步性会导致执行结果的不可再现性，为此在操作系统中必须配置相应的进程同步机制。\n\n\n结构性。每个进程都配置一个 PCB 对其进行描述。从结构上看，进程实体是由程序段、数据段和进程控制块三部分组成的。\n\n\n通常不会直接考查进程有什么特性，所以读者对上面的 5 个特性不求记忆，只求理解。\n进程的状态与转换\n​\t进程在其生命周期内，由于系统中各进程之间的相互制约关系及系统的运行环境的变化，使得进程的状态也在不断地发生变化(一个进程会经历若干不同状态)。通常进程有以下 5 种状态，前 3 种是进程的基本状态。\n\n\n运行态。进程正在处理机上运行。在单处理机环境下，每个时刻最多只有一个进程处于运行态。\n\n\n就绪态。进程获得了除处理机外的一切所需资源，一旦得到处理机，便可立即运行。系统中处于就绪状态的进程可能有多个，通常将它们排成一个队列，称为就绪队列。\n\n\n阻塞态，又称等待态。进程正在等待某一事件而暂停运行，如等待某资源为可用（不包括处理机）或等待输入/输出完成。即使处理机空闲，该进程也不能运行。\n\n\n创建态。进程正在被创建，尚未转到就绪态。创建进程通常需要多个步骤:首先申请一个空白的 PCB，并向 PCB 中填写一些控制和管理进程的信息;然后由系统为该进程分配运行时所必需的资源;最后把该进程转入就绪态。\n\n\n结束态。进程正从系统中消失，可能是进程正常结束或其他原因中断退出运行。进程需要结束运行时，系统首先必须将该进程置为结束态，然后进一步处理资源释放和回收等工作。\n\n\n​\t注意区别就绪态和等待态:就绪态是指进程仅缺少处理机，只要获得处理机资源就立即运行;而等待态是指进程需要其他资源（除了处理机）或等待某一事件。之所以把处理机和其他资源划分开，是因为在分时系统的时间片轮转机制中，每个进程分到的时间片是若干毫秒。也就是说，进程得到处理机的时间很短且非常频繁，进程在运行过程中实际上是频繁地转换到就绪态的;而其他资源（如外设）的使用和分配或某一事件的发生（如 IO 操作的完成）对应的时间相对来说很长，进程转换到等待态的次数也相对较少。这样来看，就绪态和等待态是进程生命周期中两个完全不同的状态，显然需要加以区分。\n图 2.1 说明了 5 种进程状态的转换，而 3 种基本状态之间的转换如下:\n\n\n就绪态 → 运行态:处于就绪态的进程被调度后，获得处理机资源（分派处理机时间片)，于是进程由就绪态转换为运行态。\n\n\n运行态 → 就绪态:处于运行态的进程在时间片用完后，不得不让出处理机，从而进程由运行态转换为就绪态。此外，在可剥夺的操作系统中，当有更高优先级的进程就绪时，调度程序将正在执行的进程转换为就绪态，让更高优先级的进程执行。\n\n\n运行态 → 阻塞态:进程请求某一资源（如外设）的使用和分配或等待某一事件的发生(如 I/O 操作的完成）时，它就从运行态转换为阻塞态。进程以系统调用的形式请求操作系统提供服务，这是一种特殊的、由运行用户态程序调用操作系统内核过程的形式。\n\n\n阻塞态 → 就绪态:进程等待的事件到来时，如 IO 操作结束或中断结束时，中断处理程序必须把相应进程的状态由阻塞态转换为就绪态。\n\n\n\n需要注意的是，一个进程从运行态变成阻塞态是主动的行为，而从阻塞态变成就绪态是被动的行为，需要其他相关进程的协助。\n拓展:引入挂起的五状态模型\n​\t而在这些状态之外还存在着一个状态，我们称之为挂起状态，它既可以是我们客户主动使得进程挂起，也可以是操作系统因为某些原因使得进程挂起。总而言之引入挂起状态的原因有以下几种：\n用户的请求：可能是在程序运行期间发现了可疑的问题，需要暂停进程。\n\n\n父进程的请求：考察，协调，或修改子进程。\n\n\n操作系统的需要：对运行中资源的使用情况进行检查和记账。\n\n\n负载调节的需要：有一些实时的任务非常重要，需要得到充足的内存空间(将进程PCB等相关内容调入外存)，这个时候我们需要把非实时的任务进行挂起，优先使得实时任务执行。\n\n\n定时任务：一个进程可能会周期性的执行某个任务，那么在一次执行完毕后挂起而不是阻塞，这样可以节省内存。\n\n\n安全：系统有时可能会出现故障或者某些功能受到破坏，这是就需要将系统中正在进行的进程进行挂起，当系统故障消除以后，对进程的状态进行恢复。\n\n\n\n挂起状态和阻塞状态有什么区别?\n有以下几个方面的区别：\n\n\n是否释放CPU：阻塞（pend）就是任务释放CPU，其他任务可以运行，一般在等待某种资源或信号量的时候出现。挂起（suspend）不释放CPU，如果任务优先级高就永远轮不到其他任务运行。一般挂起用于程序调试中的条件中断，当出现某个条件的情况下挂起，然后进行单步调试。\n\n\n是否主动：显然阻塞是一种被动行为，其发生在磁盘，网络IO，wait，lock等要等待某种事件的发生的操作之后。因为拿不到IO资源，所以阻塞时会放弃 CPU的占用。而挂起是主动的，因为挂起后还要受到CPU的监督（等待着激活），所以挂起不释放CPU，比如sleep函数，占着CPU不使用。\n\n\n与调度器是否相关：任务调度是操作系统来实现的，任务调度时，直接忽略挂起状态的任务，但是会顾及处于pend下的任务，当pend下的任务等待的资源就绪后，就可以转为ready了。ready只需要等待CPU时间，当然，任务调度也占用开销，但是不大，可以忽略。可以这样理解，只要是挂起状态，操作系统就不在管理这个任务了。\n\n\n进程控制\n进程控制的主要功能是对系统中的所有进程实施有效的管理，它具有创建新进程、撤销已有进程、实现进程状态转换等功能。在操作系统中，一般把进程控制用的程序段称为原语，原语的特点是执行期间不允许中断，它是一个不可分割的基本单位。\n进程的创建\n​\t允许一个进程创建另一个进程。此时创建者称为父进程，被创建的进程称为子进程。子进程可以继承父进程所拥有的资源。当子进程被撤销时，应将其从父进程那里获得的资源归还给程。此外，在撤销父进程时，必须同时撤销其所有的子进程。\n在操作系统中，终端用户登录系统、作业调度、系统提供服务、用户程序的应用请求等都会引起进程的创建。操作系统创建一个新进程的过程如下（创建原语):\n\n\n为新进程分配一个唯一的进程标识号，并申请一个空白的 PCB (PCB 是有限的)。若申请失败，则创建失败。\n\n\n为进程分配资源，为新进程的程序和数据及用户栈分配必要的内存空间（在 PCB 中体现)。注意，若资源不足（如内存空间)，则并不是创建失败，而是处于阻塞态，等待内存资源。\n\n\n初始化 PCB，主要包括初始化标志信息、初始化处理机状态信息和初始化处理机控制信息，以及设置进程的优先级等。\n\n\n若进程就绪队列能够接纳新进程，则将新进程插入就绪队列，等待被调度运行。\n\n\n进程的终止\n​\t引起进程终止的事件主要有:① 正常结束，表示进程的任务已完成并准备退出运行。② 异常结束，表示进程在运行时，发生了某种异常事件，使程序无法继续运行，如存储区越界、保护错、非法指令、特权指令错、运行超时、算术运算错、I/O 故障等。③ 外界干预，指进程应外界的请求而终止运行，如操作员或操作系统干预、父进程请求和父进程终止。\n操作系统终止进程的过程如下（撤销原语):\n\n\n根据被终止进程的标识符，检索 PCB，从中读出该进程的状态。\n\n\n若被终止进程处于执行状态，立即终止该进程的执行，将处理机资源分配给其他进程。\n\n\n若该进程还有子孙进程，则应将其所有子孙进程终止。\n\n\n将该进程所拥有的全部资源，或归还给其父进程，或归还给操作系统。\n\n\n将该 PCB 从所在队列（链表）中删除。\n\n\n进程的阻塞和唤醒\n​\t正在执行的进程，由于期待的某些事件未发生，如请求系统资源失败、等待某种操作的完成、新数据尚未到达或无新工作可做等，由系统自动执行阻塞原语（Block)，使自己由运行态变为阻塞态。可见，进程的阻塞是进程自身的一种主动行为，也因此只有处于运行态的进程(获得 CPU 才可能将其转为阻塞态。阻塞原语的执行过程如下:\n\n\n找到将要被阻塞进程的标识号对应的 PCB。\n\n\n若该进程为运行态，则保护其现场，将其状态转为阻塞态，停止运行。\n\n\n把该 PCB 插入相应事件的等待队列，将处理机资源调度给其他就绪进程。\n\n\n当被阻塞进程所期待的事件出现时,如它所启动的 IO 操作已完成或其所期待的数据已到达，由有关进程（比如，释放该 IO 设备的进程，或提供数据的进程）调用唤醒原语（Wakeup)，将等待该事件的进程唤醒。唤醒原语的执行过程如下:\n\n\n在该事件的等待队列中找到相应进程的 PCB。\n\n\n将其从等待队列中移出，并置其状态为就绪态。\n\n\n把该 PCB 插入就绪队列，等待调度程序调度。\n\n\n需要注意的是，Block 原语和 Wakeup 原语是一对作用刚好相反的原语，必须成对使用。Block 原语是由被阻塞进程自我调用实现的，而 Wakeup 原语则是由一个与被唤醒进程合作或被其他相关的进程调用实现的。\n进程切换\n​\t对于通常的进程而言，其创建、撤销及要求由系统设备完成的 I/O 操作，都是利用系统调用而进入内核，再由内核中的相应处理程序予以完成的。进程切换同样是在内核的支持下实现的，因此可以说，任何进程都是在操作系统内核的支持下运行的，是与内核紧密相关的。\n进程切换是指处理机从一个进程的运行转到另一个进程上运行，在这个过程中，进程的运行环境产生了实质性的变化。进程切换的过程如下:\n\n\n保存处理机上下文，包括程序计数器和其他寄存器。\n\n\n更新 PCB 信息。\n\n\n把进程的 PCB 移入相应的队列，如就绪、在某事件阻塞等队列。\n\n\n选择另一个进程执行，并更新其 PCB。\n\n\n更新内存管理的数据结构。\n\n\n恢复处理机上下文。\n\n\n\n\n\n\n\n\n\n\n\n注意，进程切换与处理机模式切换是不同的，模式切换时，处理机逻辑上可能还在同一进程中运行。若进程因中断或异常进入核心态运行，执行完后又回到用户态刚被中断的程序运行，则操作系统只需恢复进程进入内核时所保存的 CPU 现场，而无须改变当前进程的环境信息。但若要切换进程，当前运行进程改变了，则当前进程的环境信息也需要改变。\n进程的组织\n​\t进程是一个独立的运行单位，也是操作系统进行资源分配和调度的基本单位。它由以下三部分组成，其中最核心的是进程控制（PCB)。\n进程控制块\n​\t进程创建时，操作系统为它新建一个 PCB，该结构之后常驻内存，任意时刻都可以存取，并在进程结束时删除。PCB 是进程实体的一部分，是进程存在的唯一标志。\n​\t进程执行时，系统通过其 PCB 了解进程的现行状态信息，以便对其进行控制和管理;进程结束时，系统收回其 PCB，该进程随之消亡。操作系统通过 PCB 表来管理和控制进程。\n​\t当操作系统欲调度某进程运行时，要从该进程的 PCB 中查出其现行状态及优先级;在调度到某进程后，要根据其 PCB 中所保存的处理机状态信息，设置该进程恢复运行的现场，并根据其 PCB 中的程序和数据的内存始址，找到其程序和数据;进程在运行过程中，当需要和与之合作的进程实现同步、通信或访问文件时，也需要访问 PCB;当进程由于某种原因而暂停运行时，又需将其断点的处理机环境保存在 PCB 中。可见，在进程的整个生命期中，系统总是通过 PCB 对进程进行控制的，亦即系统唯有通过进程的 PCB 才能感知到该进程的存在。\n表 2.1 是一个 PCB 的实例。PCB 主要包括进程描述信息、进程控制和管理信息、资源分配清单和处理机相关信息等。各部分的主要说明如下:\n\n\n\n进程描述信息。进程标识符:标志各个进程，每个进程都有一个唯一的标识号。用户标识符:进程归属的用户，用户标识符主要为共享和保护服务。\n\n\n进程控制和管理信息。进程当前状态:描述进程的状态信息，作为处理机分配调度的依据。进程优先级:描述进程抢占处理机的优先级，优先级高的进程可优先获得处理机。\n\n\n资源分配清单，用于说明有关内存地址空间或虚拟地址空间的状况，所打开文件的列表和所使用的输入/输出设备信息。\n\n\n处理机相关信息，主要指处理机中各寄存器的值，当进程被切换时，处理机状态信息都必须保存在相应的 PCB 中，以便在该进程重新执行时，能从断点继续执行。\n\n\n在一个系统中，通常存在着许多进程的 PCB，有的处于就绪态，有的处于阻塞态，而且阻塞的原因各不相同。为了方便进程的调度和管理，需要将各进程的 PCB 用适当的方法组织起来。目前，常用的组织方式有链接方式和索引方式两种。链接方式将同一状态的 PCB 链接成一个队列,不同状态对应不同的队列，也可把处于阻塞态的进程的 PCB，根据其阻塞原因的不同，排成多个阻塞队列。索引方式将同一状态的进程组织在一个索引表中，索引表的表项指向相应的 PCB，不同状态对应不同的索引表，如就绪索引表和阻塞索引表等。\n程序段\n程序段就是能被进程调度程序调度到 CPU 执行的程序代码段。注意，程序可被多个进程共享，即多个进程可以运行同一个程序。\n数据段\n一个进程的数据段，可以是进程对应的程序加工处理的原始数据，也可以是程序执行时产生的中间或最终结果。\n进程的通信\n进程通信是指进程之间的信息交换。PV 操作是低级通信方式，高级通信方式是指以较高的效率传输大量数据的通信方式。高级通信方法主要有以下三类。\n共享存储\n在通信的进程之间存在一块可直接访问的共享空间,通过对这片共享空间进行写/读操作实现进程之间的信息交换，如图 2.2 所示。在对共享空间进行写/读操作时，需要使用同步互斥工具(如 Р 操作、V 操作)，对共享空间的写/读进行控制。共享存储又分为两种:低级方式的共享是基于数据结构的共享;高级方式的共享则是基于存储区的共享。操作系统只负责为通信进程提供可共享使用的存储空间和同步互斥工具，而数据交换则由用户自己安排读/写指令完成。\n注意，用户进程空间一般都是独立的，进程运行期间一般不能访问其他进程的空间，要想让两个用户进程共享空间，必须通过特殊的系统调用实现，而进程内的线程是自然共享进程空间的。\n简单理解就是，甲和乙中间有一个大布袋，甲和乙交换物品是通过大布袋进行的，甲把物品放在大布袋里，乙拿走。但乙不能直接到甲的手中拿东西，甲也不能直接到乙的手中拿东西。\n消息传递\n在消息传递系统中，进程间的数据交换是以格式化的消息（Message）为单位的。若通信的进程之间不存在可直接访问的共享空间，则必须利用操作系统提供的消息传递方法实现进程通信。进程通过系统提供的发送消息和接收消息两个原语进行数据交换。\n\n\n直接通信方式。发送进程直接把消息发送给接收进程，并将它挂在接收进程的消息缓冲队列上，接收进程从消息缓冲队列中取得消息，如图 2.3 所示。\n\n\n\n\n\n间接通信方式。发送进程把消息发送到某个中间实体，接收进程从中间实体取得消息。\n\n\n这种中间实体一般称为信箱，这种通信方式又称信箱通信方式。该通信方式广泛应用于计算机网络中，相应的通信系统称为电子邮件系统。简单理解就是，甲要告诉乙某些事情，就要写信，然后通过邮差送给乙。直接通信就是邮差把信直接送到乙的手上;间接通信就是乙家门口有一个邮箱，邮差把信放到邮箱里。\n管道通信\n管道通信是消息传递的一种特殊方式（见图 2.4)。所谓“管道”，是指用于连接一个读进程和一个写进程以实现它们之间的通信的一个共享文件，又名 pipe 文件。向管道(共享文件)提供输入的发送进程（即写进程)，以字符流形式将大量的数据送入(写）管道;而接收管道输出的接收进程（即读进程）则从管道中接收（读）数据。为了协调双方的通信，管道机制必须提供以下三方面的协调能力:互斥、同步和确定对方的存在。\n\n下面以 Linux 中的管道为例进行说明。在 Linux 中，管道是一种使用非常频繁的通信机制。从本质上说，管道也是一种文件，但它又和一般的文件有所不同，管道可以克服使用文件进行通信的两个问题，具体表现如下:\n\n\n限制管道的大小。实际上，管道是一个固定大小的缓冲区。在 Linux 中，该缓冲区的大小为 4KB，这使得它的大小不像文件那样不加检验地增长。使用单个固定缓冲区也会带来问题，比如在写管道时可能变满，这种情况发生时，随后对管道的 write()调用将默认地被阻塞，等待某些数据被读取，以便腾出足够的空间供 write()调用写。\n\n\n读进程也可能工作得比写进程快。当所有当前进程数据已被读取时，管道变空。当这种情况发生时，一个随后的 read()调用将默认地被阻塞,等待某些数据被写入,这解决了 read()调用返回文件结束的问题。\n\n\n\n\n\n\n\n\n\n\n\n注意:从管道读数据是一次性操作，数据一旦被读取，它就从管道中被抛弃，释放空间以便写更多的数据。管道只能采用半双工通信，即某一时刻只能单向传输。要实现父子进程双方互动通信，需要定义两个管道。\n管道可以理解为共享存储的优化和发展,因为在共享存储中，若某进程要访问共享存储空间则必须没有其他进程在该共享存储空间中进行写操作，否则访问行为就会被阻塞。而管道通信中存储空间进化成了缓冲区，缓冲区只允许一边写入、另一边读出，因此只要缓冲区中有数据，进程就能从缓冲区中读出，而不必担心会因为其他进程在其中进行写操作而遭到阻塞，因为写进程会先把缓冲区写满，然后才让读进程读，当缓冲区中还有数据时，写进程不会往缓冲区写数据。当然，这也决定了管道通信必然是半双工通信。\n线程概念和多线程模型\n线程的基本概念\n​\t引入进程的目的是更好地使多道程序并发执行，提高资源利用率和系统吞吐量;而引入线程的目的则是减小程序在并发执行时所付出的时空开销，提高操作系统的并发性能。\n​\t线程最直接的理解就是“轻量级进程”，它是一个基本的 CPU 执行单元，也是程序执行流的最小单元，由线程 ID、程序计数器、寄存器集合和堆栈组成。线程是进程中的一个实体，是被系统独立调度和分派的基本单位，线程自己不拥有系统资源，只拥有一点儿在运行中必不可少的资源，但它可与同属一个进程的其他线程共享进程所拥有的全部资源。一个线程可以创建和撤销另一个线程，同一进程中的多个线程之间可以并发执行。由于线程之间的相互制约，致使线程在运行中呈现出间断性。线程也有就绪、阻塞和运行三种基本状态。\n​\t引入线程后，进程的内涵发生了改变，进程只作为除 CPU 外的系统资源的分配单元，而线程则作为处理机的分配单元。由于一个进程内部有多个线程，若线程的切换发生在同一个进程内部，则只需要很少的时空开销。\n线程与进程的比较\n\n\n调度。在传统的操作系统中，拥有资源和独立调度的基本单位都是进程。在引入线程的操作系统中，线程是独立调度的基本单位，进程是拥有资源的基本单位。在同一进程中,线程的切换不会引起进程切换。在不同进程中进行线程切换，如从一个进程内的线程切换到另一个进程中的线程时，会引起进程切换。\n\n\n拥有资源。不论是传统操作系统还是设有线程的操作系统，进程都是拥有资源的基本单位，而线程不拥有系统资源（也有一点儿必不可少的资源)，但线程可以访问其隶属进程的系统资源。要知道，若线程也是拥有资源的单位，则切换线程就需要较大的时空开销，线程这个概念的提出就没有意义。\n\n\n并发性。在引入线程的操作系统中，不仅进程之间可以并发执行，而且多个线程之间也可以并发执行，从而使操作系统具有更好的并发性，提高了系统的吞吐量。\n\n\n系统开销。由于创建或撤销进程时，系统都要为之分配或回收资源，如内存空间、IO 设备等，因此操作系统所付出的开销远大于创建或撤销线程时的开销。类似地，在进行进程切换时，涉及当前执行进程 CPU 环境的保存及新调度到进程 CPU 环境的设置，而线程切换时只需保存和设置少量寄存器内容，开销很小。此外，由于同一进程内的多个线程共享进程的地址空间，因此这些线程之间的同步与通信非常容易实现，甚至无须操作系统的干预。\n\n\n地址空间和其他资源（如打开的文件)。进程的地址空间之间互相独立，同一进程的各线程间共享进程的资源，某进程内的线程对于其他进程不可见。\n\n\n通信方面。进程间通信（IPC）需要进程同步和互斥手段的辅助，以保证数据的一致性，而线程间可以直接读/写进程数据段（如全局变量）来进行通信。\n\n\n线程的属性\n多线程操作系统把线程作为独立运行（或调度）的基本单位，此时的进程已不再是一个基本的可执行实体，但它仍具有与执行相关的状态。所谓进程处于“执行”状态，实际上是指该进程中的某线程正在执行。线程的主要属性如下:\n\n\n线程是一个轻型实体，它不拥有系统资源，但每个线程都应有一个唯一的标识符和一个线程控制块，线程控制块记录了线程执行的寄存器和栈等现场状态。\n\n\n不同的线程可以执行相同的程序，即同一个服务程序被不同的用户调用时，操作系统把它们创建成不同的线程。\n\n\n同一进程中的各个线程共享该进程所拥有的资源。\n\n\n线程是处理机的独立调度单位，多个线程是可以并发执行的。在单 CPU 的计算机系统中，各线程可交替地占用 CPU;在多 CPU 的计算机系统中，各线程可同时占用不同的 CPU,若各个 CPU 同时为一个进程内的各线程服务，则可缩短进程的处理时间。\n\n\n一个线程被创建后，便开始了它的生命周期，直至终止。线程在生命周期内会经历阻塞态、就绪态和运行态等各种状态变化。\n\n\n为什么线程的提出有利于提高系统并发性?可以这样来理解:由于有了线程，线程切换时，有可能会发生进程切换，也有可能不发生进程切换，平均而言每次切换所需的开销就变小了，因此能够让更多的线程参与并发，而不会影响到响应时间等问题。\n线程的实现方式\n​\t线程的实现可以分为两类:用户级线程(User-Level Thread，ULT)和内核级线程(Kernel-LevelThread，KLT)。内核级线程又称内核支持的线程。\n在用户级线程中，有关线程管理（线程的创建、撤销和切换等）的所有工作都由应用程序完成，内核意识不到线程的存在。应用程序可以通过使用线程库设计成多线程程序。通常，应用程序从单线程开始，在该线程中开始运行，在其运行的任何时刻，可以通过调用线程库中的派生例程创建一个在相同进程中运行的新线程。图 2.5(a)说明了用户级线程的实现方式。\n在内核级线程中，线程管理的所有工作由内核完成，应用程序没有进行线程管理的代码，只有一个到内核级线程的编程接口。内核为进程及其内部的每个线程维护上下文信息，调度也在内核基于线程架构的基础上完成。图 2.5(b)说明了内核级线程的实现方式。\n有些系统中使用组合方式的多线程实现。线程创建完全在用户空间中完成，线程的调度和同步也在应用程序中进行。一个应用程序中的多个用户级线程被映射到一些(小于等于用户级线程的数目）内核级线程上。图 2.5©说明了用户级与内核级的组合实现方式。\n\n多线程模型\n有些系统同时支持用户线程和内核线程，由此产生了不同的多线程模型，即实现用户级线程和内核级线程的连接方式。\n\n\n多对一模型。将多个用户级线程映射到一个内核级线程，线程管理在用户空间完成。此模式中，用户级线程对操作系统不可见（即透明)。\n\n\n优点:线程管理是在用户空间进行的，因而效率比较高。\n缺点:一个线程在使用内核服务时被阻塞，整个进程都会被阻塞;多个线程不能并行地运行在多处理机上。\n\n\n一对一模型。将每个用户级线程映射到一个内核级线程。\n\n\n优点:当一个线程被阻塞后，允许另一个线程继续执行，所以并发能力较强。\n缺点:每创建一个用户级线程都需要创建一个内核级线程与其对应，这样创建线程的开销比较大，会影响到应用程序的性能。\n\n\n多对多模型。将 n 个用户级线程映射到 m 个内核级线程上，要求 m≤n。\n\n\n特点:多对多模型是多对一模型和一对一模型的折中，既克服了多对一模型并发度不高的缺点，又克服了一对一模型的一个用户进程占用太多内核级线程而开销太大的缺点。\n此外，还拥有多对一模型和一对一模型各自的优点，可谓集两者之所长。\n本节小结\n为什么要引入进程?\n在多道程序同时运行的背景下，进程之间需要共享系统资源，因此会导致各程序在执行过程中出现相互制约的关系，程序的执行会表现出间断性的特征。这些特征都是在程序的执行过程中发生的，是动态的过程，而传统的程序本身是一组指令的集合，是一个静态的概念，无法描述程序在内存中的执行情况，即我们无法从程序的字面上看出它何时执行、何时停顿，也无法看出它与其他执行程序的关系，因此，程序这个静态概念已不能如实反映程序并发执行过程的特征。为了深刻描述程序动态执行过程的性质乃至更好地支持和管理多道程序的并发执行，人们引入了进程的概念。\n什么是进程?进程由什么组成?\n进程是一个具有独立功能的程序关于某个数据集合的一次运行活动。它可以申请和拥有系统资源，是一个动态的概念，是一个活动的实体。它不只是程序的代码本身，还包括当前的活动，通过程序计数器的值和处理寄存器的内容来表示。\n一个进程实体由程序段、相关数据段和 PCB 三部分构成，其中 PCB 是标志一个进程存在的唯一标识，程序段是进程运行的程序的代码，数据段则存储程序运行过程中相关的一些数据。\n处理机调度\n调度的概念\n调度的基本概念\n​\t在多道程序系统中，进程的数量往往多于处理机的个数，因此进程争用处理机的情况在所难免。处理机调度是对处理机进行分配，即从就绪队列中按照一定的算法（公平、高效）选择一个进程并将处理机分配给它运行，以实现进程并发地执行。\n处理机调度是多道程序操作系统的基础，是操作系统设计的核心问题。\n调度的层次\n一个作业从提交开始直到完成，往往要经历以下三级调度，如图 2.6 所示。\n\n\n作业调度。又称高级调度，其主要任务是按一定的原则从外存上处于后备状态的作业中挑选一个(或多个）作业，给它（们）分配内存、输入/输出设备等必要的资源，并建立相应的进程，以使它（们）获得竞争处理机的权利。简言之，作业调度就是内存与辅存之间的调度。对于每个作业只调入一次、调出一次。多道批处理系统中大多配有作业调度，而其他系统中通常不需要配置作业调度。作业调度的执行频率较低，通常为几分钟一次。\n\n\n中级调度 。又称内存调度，其作用是提高内存利用率和系统吞吐量。为此，应将那些暂时不能运行的进程调至外存等待，把此时的进程状态称为挂起态。当它们已具备运行条件且内存又稍有空闲时，由中级调度来决定把外存上的那些已具备运行条件的就绪进程再重新调入内存，并修改其状态为就绪态，挂在就绪队列上等待。\n\n\n进程调度 。又称低级调度，其主要任务是按照某种方法和策略从就绪队列中选取一个进程，将处理机分配给它。进程调度是操作系统中最基本的一种调度，在一般的操作系统中都必须配置进程调度。进程调度的频率很高，一般几十毫秒一次。\n\n\n\n三级调度的联系\n作业调度从外存的后备队列中选择一批作业进入内存，为它们建立进程，这些进程被送入就绪队列，进程调度从就绪队列中选出一个进程，并把其状态改为运行态，把 CPU 分配给它。中级调度是为了提高内存的利用率，系统将那些暂时不能运行的进程挂起来。当内存空间宽松时，通过中级调度选择具备运行条件的进程，将其唤醒。\n\n\n作业调度为进程活动做准备，进程调度使进程正常活动起来，中级调度将暂时不能运行的进程挂起，中级调度处于作业调度和进程调度之间。\n\n\n作业调度次数少，中级调度次数略多，进程调度频率最高。\n\n\n进程调度是最基本的，不可或缺。\n\n\n调度的时机、切换与过程\n进程调度和切换程序是操作系统内核程序。请求调度的事件发生后，才可能运行进程调度程序，调度了新的就绪进程后，才会进行进程间的切换。理论上这三件事情应该顺序执行，但在实际设计中，操作系统内核程序运行时，若某时发生了引起进程调度的因素，则不一定能够马上进行调度与切换。\n现代操作系统中，不能进行进程的调度与切换的情况有以下几种:\n\n\n处理中断的过程中。中断处理过程复杂，在实现上很难做到进程切换，而且中断处理是系统工作的一部分，逻辑上不属于某一进程，不应被剥夺处理机资源。\n\n\n进程在操作系统内核程序临界区中。进入临界区后，需要独占式地访问共享数据，理论上必须加锁，以防止其他并行程序进入，在解锁前不应切换到其他进程运行，以加快该共享数据的释放。\n\n\n其他需要完全屏蔽中断的原子操作过程中。如加锁、解锁、中断现场保护、恢复等原子操作。在原子过程中，连中断都要屏蔽，更不应该进行进程调度与切换。\n\n\n若在上述过程中发生了引起调度的条件，则不能马上进行调度和切换，应置系统的请求调度标志，直到上述过程结束后才进行相应的调度与切换。\n应该进行进程调度与切换的情况如下:\n\n\n发生引起调度条件且当前进程无法继续运行下去时，可以马上进行调度与切换。若操作系统只在这种情况下进行进程调度，则是 非剥夺调度 。\n\n\n中断处理结束或自陷处理结束后，返回被中断进程的用户态程序执行现场前，若置上请求调度标志，即可马上进行进程调度与切换。若操作系统支持这种情况下的运行调度程序，则实现了剥夺方式的调度。\n\n\n进程切换往往在调度完成后立刻发生，它要求保存原进程当前切换点的现场信息，恢复被调度进程的现场信息。现场切换时，操作系统内核将原进程的现场信息推入当前进程的内核堆栈来保存它们，并更新堆栈指针。内核完成从新进程的内核栈中装入新进程的现场信息、更新当前运行进程空间指针、重设 PC 寄存器等相关工作之后，开始运行新的进程。\n进程调度方式\n所谓进程调度方式，是指当某个进程正在处理机上执行时，若有某个更为重要或紧迫的进程需要处理，即有优先权更高的进程进入就绪队列，此时应如何分配处理机。\n通常有以下两种进程调度方式:\n\n\n非剥夺调度方式，又称非抢占方式。非剥夺调度方式是指当一个进程正在处理机上执行时，即使有某个更为重要或紧迫的进程进入就绪队列，仍然让正在执行的进程继续执行直到该进程完成或发生某种事件而进入阻塞态时，才把处理机分配给更为重要或紧迫的进程。\n\n\n在非剥夺调度方式下，一旦把 CPU 分配给一个进程，该进程就会保持 CPU 直到终止或转换到等待态。这种方式的优点是实现简单、系统开销小，适用于大多数的批处理系统但它不能用于分时系统和大多数的实时系统。\n\n\n剥夺调度方式，又称抢占方式。剥夺调度方式是指当一个进程正在处理机上执行时，若有某个更为重要或紧迫的进程需要使用处理机，则立即暂停正在执行的进程，将处理机分配给这个更为重要或紧迫的进程。\n\n\n采用剥夺式的调度，对提高系统吞吐率和响应效率都有明显的好处。但“剥夺”不是一种任意性行为，必须遵循一定的原则，主要有优先权、短进程优先和时间片原则等。\n调度的基本准则\n不同的调度算法具有不同的特性，在选择调度算法时，必须考虑算法的特性。为了比较处理机调度算法的性能，人们提出了很多评价准则，下面介绍其中主要的几种:\n\n\nCPU 利用率 。CPU 是计算机系统中最重要和昂贵的资源之一，所以应尽可能使 CPU 保持“忙”状态，使这一资源利用率最高。\n\n\n系统吞吐量。表示单位时间内 CPU 完成作业的数量。长作业需要消耗较长的处理机时间,因此会降低系统的吞吐量。而对于短作业，它们所需要消耗的处理机时间较短，因此能提高系统的吞吐量。调度算法和方式的不同，也会对系统的吞吐量产生较大的影响。\n\n\n周转时间 。周转时间是指从作业提交到作业完成所经历的时间，是作业等待、在就绪队列中排队、在处理机上运行及进行输入/输出操作所花费时间的总和。\n\n\n作业的周转时间可用公式表示如下:\n周转时间=作业完成时间-作业提交时间\n平均周转时间是指多个作业周转时间的平均值:\n平均周转时间=（作业 1 的周转时间+…+作业 n 的周转时间）/ n\n带权周转时间是指作业周转时间与 作业实际运行时间的比值:\n带权周转时间=作业周转时间/作业实际运行时间\n平均带权周转时间是指多个作业带权周转时间的平均值:\n平均带权周转时间=（作业 1 的带权周转时间+…+作业 n 的带权周转时间）/ n\n\n\n等待时间。等待时间指进程处于等处理机状态的时间之和，等待时间越长，用户满意度越低。处理机调度算法实际上并不影响作业执行或输入/输出操作的时间，只影响作业在就绪队列中等待所花的时间。因此，衡量一个调度算法的优劣，常常只需简单地考察等待时间。\n\n\n响应时间。响应时间指从用户提交请求到系统首次产生响应所用的时间。在交互式系统中，周转时间不可能是最好的评价准则，一般采用响应时间作为衡量调度算法的重要准则之一。从用户角度来看，调度策略应尽量降低响应时间，使响应时间处在用户能接受的范围之内。\n\n\n要想得到一个满足所有用户和系统要求的算法几乎是不可能的。设计调度程序，一方面要满足特定系统用户的要求（如某些实时和交互进程的快速响应要求)，另一方面要考虑系统整体效率（如减少整个系统的进程平均周转时间)，同时还要考虑调度算法的开销。\n典型的调度算法\n先来先服务(FCFS)调度算法\nFCFS 调度算法是一种最简单的调度算法，它既可用于作业调度，又可用于进程调度。在作业调度中，算法每次从后备作业队列中选择最先进入该队列的一个或几个作业，将它们调入内存，分配必要的资源，创建进程并放入就绪队列。\n在进程调度中，FCFS 调度算法每次从就绪队列中选择最先进入该队列的进程，将处理机分配给它，使之投入运行，直到完成或因某种原因而阻塞时才释放处理机。\n下面通过一个实例来说明 FCFS 调度算法的性能。假设系统中有 4 个作业，它们的提交时间分别是 8,8.4,8.8,9，运行时间依次是 2,1,0.5,0.2，系统采用 FCFS 调度算法，这组作业的平均等待时间、平均周转时间和平均带权周转时间见表 2.2。\n\nFCFS 调度算法属于不可剥夺算法。从表面上看，它对所有作业都是公平的，但若一个长作业先到达系统，就会使后面的许多短作业等待很长时间，因此它不能作为分时系统和实时系统的主要调度策略。但它常被结合在其他调度策略中使用。例如，在使用优先级作为调度策略的系统中，往往对多个具有相同优先级的进程按 FCFS 原则处理。\nFCFS 调度算法的特点是算法简单，但效率低;对长作业比较有利，但对短作业不利（相对 SJF 和高响应比);有利于 CPU 繁忙型作业，而不利于 I/O 繁忙型作业。\n短作业优先(SJF)调度算法\n​\t短作业（进程）优先调度算法是指对短作业（进程）优先调度的算法。短作业优先（SJF)调度算法从后备队列中选择一个或若干估计运行时间最短的作业，将它们调入内存运行;短进程优先(SPF）调度算法从就绪队列中选择一个估计运行时间最短的进程，将处理机分配给它，使之立即执行，直到完成或发生某事件而阻塞时，才释放处理机。\n例如，考虑表 2.2 中给出的一组作业，若系统采用短作业优先调度算法，其平均等待时间、平均周转时间和平均带权周转时间见表 2.3。\n\nSJF 调度算法也存在不容忽视的缺点:\n\n\n该算法对长作业不利，由表 2.2 和表 2.3 可知，SJF 调度算法中长作业的周转时间会增加更严重的是，若有一长作业进入系统的后备队列，由于调度程序总是优先调度那些（E 使是后进来的）短作业，将导致长作业长期不被调度（“饥饿”现象，注意区分“死锁”后者是系统环形等待，前者是调度策略问题)。\n\n\n该算法完全未考虑作业的紧迫程度，因而不能保证紧迫性作业会被及时处理。\n\n\n由于作业的长短只是根据用户所提供的估计执行时间而定的，而用户又可能会有意或无意地缩短其作业的估计运行时间，致使该算法不一定能真正做到短作业优先调度。\n\n\n\n\n\n\n\n\n\n\n\n注意，SJF 调度算法的平均等待时间、平均周转时间最少。\n优先级调度算法\n​\t优先级调度算法又称优先权调度算法，它既可用于作业调度，又可用于进程调度。该算法中的优先级用于描述作业运行的紧迫程度。\n在作业调度中，优先级调度算法每次从后备作业队列中选择优先级最高的一个或几个作业，将它们调入内存，分配必要的资源，创建进程并放入就绪队列。在进程调度中，优先级调度算法每次从就绪队列中选择优先级最高的进程，将处理机分配给它，使之投入运行。\n根据新的更高优先级进程能否抢占正在执行的进程，可将该调度算法分为如下两种:\n\n\n非剥夺式优先级调度算法非剥夺式优先级调度算法 。当一个进程正在处理机上运行时，即使有某个更为重要或紧迫的进程进入就绪队列，仍然让正在运行的进程继续运行，直到由于其自身的原因而主动让出处理机时（任务完成或等待事件)，才把处理机分配给更为重要或紧迫的进程。\n\n\n剥夺式优先级调度算法剥夺式优先级调度算法 。当一个进程正在处理机上运行时，若有某个更为重要或紧迫的进程进入就绪队列，则立即暂停正在运行的进程，将处理机分配给更重要或紧迫的进程。\n\n\n而根据进程创建后其优先级是否可以改变，可以将进程优先级分为以下两种:\n\n\n静态优先级 。优先级是在创建进程时确定的，且在进程的整个运行期间保持不变。确定静态优先级的主要依据有进程类型、进程对资源的要求、用户要求。\n\n\n动态优先级 。在进程运行过程中，根据进程情况的变化动态调整优先级。动态调整优先级的主要依据有进程占有 CPU 时间的长短、就绪进程等待 CPU 时间的长短。\n\n\n一般来说，进程优先级的设置可以参照以下原则:\n\n\n系统进程 &gt; 用户进程 。系统进程作为系统的管理者，理应拥有更高的优先级。\n\n\n交互型进程 &gt; 非交互型进程 （或前台进程&gt;后台进程)。大家平时在使用手机时，在前台运行的正在和你交互的进程应该更快速地响应你，因此自然需要被优先处理，即要有更高的优先级。\n\n\nI/O 型进程 &gt; 计算型进程计算型进程 。所谓 IO 型进程，是指那些会频繁使用 IO 设备的进程，而计算型进程是那些频繁使用 CPU 的进程（很少使用 I/O 设备)。我们知道，IO 设备（如打印机）的处理速度要比 CPU 慢得多，因此若将 IO 型进程的优先级设置得更高，就更有可能让 IO 设备尽早开始工作，进而提升系统的整体效率。\n\n\n高响应比优先调度算法\n高响应比优先调度算法主要用于作业调度，是对 FCFS 调度算法和 SJF 调度算法的一种综合平衡，同时考虑了每个作业的等待时间和估计的运行时间。在每次进行作业调度时，先计算后备作业队列中每个作业的响应比，从中选出响应比最高的作业投入运行。\n响应比的变化规律可描述为\n响应比Rp=等待时间+要求服务时间/要求服务时间\n根据公式可知：\n\n\n作业的等待时间相同时，要求服务时间越短，响应比越高，有利于 短作业 。\n\n\n要求服务时间相同时，作业的响应比由其等待时间决定，等待时间越长，其响应比越高,因而它实现的是 先来先服务 。\n\n\n对于长作业，作业的响应比可以随等待时间的增加而提高，等待时间足够长时，其响应比便可升到很高，从而也可获得处理机。因此，克服了饥饿状态 ，兼顾了长作业。\n\n\n时间片轮转调度算法\n​\t时间片轮转调度算法主要适用于分时系统。在这种算法中，系统将所有就绪进程按到达时间的先后次序排成一个队列，进程调度程序总是选择就绪队列中的第一个进程执行，即先来先服务的原则，但仅能运行一个时间片，如 100ms。在使用完一个时间片后，即使进程并未完成其运行，它也必须释放出（被剥夺）处理机给下一个就绪的进程，而被剥夺的进程返回到就绪队列的末尾重新排队，等候再次运行。\n​\t在时间片轮转调度算法中，时间片的大小对系统性能的影响很大。若时间片足够大，以至于所有进程都能在一个时间片内执行完毕，则时间片轮转调度算法就退化为先来先服务调度算法。若时间片很小，则处理机将在进程间过于频繁地切换，使处理机的开销增大，而真正用于运行用户进程的时间将减少。因此，时间片的大小应选择适当。\n​\t时间片的长短通常由以下因素确定:系统的响应时间、就绪队列中的进程数目和系统的处理能力。\n多级反馈队列调度算法（融合了前几种算法的优点）\n​\t多级反馈队列调度算法是时间片轮转调度算法和优先级调度算法的综合与发展，如图 2.7 所示。通过动态调整进程优先级和时间片大小,多级反馈队列调度算法可以兼顾多方面的系统目标。例如，为提高系统吞吐量和缩短平均周转时间而照顾短进程;为获得较好的 IO 设备利用率和缩短响应时间而照顾 IO 型进程;同时，也不必事先估计进程的执行时间。\n\n多级反馈队列调度算法的实现思想如下:\n\n\n设置多个就绪队列，并为各个队列赋予不同的优先级，第 1 级队列的优先级最高，第 2 级队列次之，其余队列的优先级逐次降低。\n\n\n赋予各个队列中进程执行时间片的大小各不相同。在优先级越高的队列中，每个进程的运行时间片越小。例如，第 2 级队列的时间片要比第 1 级队列的时间片长 1 倍……第 i +1 级队列的时间片要比第 i 级队列的时间片长 1 倍。\n\n\n一个新进程进入内存后，首先将它放入第 1 级队列的末尾，按 FCFS 原则排队等待调度当轮到该进程执行时，如它能在该时间片内完成，便可准备撤离系统;若它在一个时间片结束时尚未完成，调度程序便将该进程转入第 2 级队列的末尾，再同样按 FCFS 原则等待调度执行;若它在第 2 级队列中运行一个时间片后仍未完成，再以同样的方法放入第 3 级队列……如此下去，当一个长进程从第 1 级队列依次降到第 n 级队列后，在第 n 级队列中便采用时间片轮转的方式运行。\n\n\n仅当第 1 级队列为空时，调度程序才调度 2 级队列中的进程运行;仅当第 1~( i -1)级队列均为空时，才会调度第 i 级队列中的进程运行。若处理机正在执行第 i 级队列中的某进程，这时又有新进程进入优先级较高的队列〔第 1 ～( i -1)中的任何一个队列]，则此时新进程将抢占正在运行进程的处理机,即由调度程序把正在运行的进程放回第 i 级队列的末尾，把处理机分配给新到的更高优先级的进程。\n\n\n多级反馈队列的优势有以下几点:\n\n\n终端型作业用户:短作业优先。\n\n\n短批处理作业用户:周转时间较短。\n\n\n长批处理作业用户:经过前面几个队列得到部分执行，不会长期得不到处理。\n\n\n本章小结\n本节开头提出的问题的参考答案如下。\n为什么要进行处理机调度?\n​\t若没有处理机调度，同意味着要等到当前运行的进程执行完毕后，下一个进程才能执行，而实际情况中，进程时常需要等待一些外部设备的输入，而外部设备的速度与处理机相比是非常缓慢的，若让处理机总是等待外部设备，则对处理机的资源是极大的浪费。而引进处理机调度后，可在运行进程等待外部设备时，把处理机调度给其他进程，从而提高处理机的利用率。用一句简单的话说，就是为了合理地处理计算机的软/硬件资源。\n调度算法有哪几种?结合第 1 章学习的分时操作系统和实时操作系统，思考有没有哪种调度算法比较适合这两种操作系统。\n​\t本节介绍的调度算法有先来先服务调度算法、短作业优先调度算法、优先级调度算法、高响应比优先调度算法、时间片轮转调度算法、多级反馈队列调度算法 6 种。\n​\t先来先服务算法和短作业优先算法无法保证及时地接收和处理问题，因此无法保证规定时时间间隔内响应每个用户的需求，也同样无法达到实时操作系统的实时性,对于更紧急的任务给予更高的优先级，适合实时操作系统。\n​\t高响应比优先调度算法、时间片轮转调度算法、多级反馈队列调度算法都能保证每个任务在一定时间内分配到时间片，并轮流占用 CPU，适合分时操作系统。\n本节主要介绍了处理机调度的概念。操作系统主要管理处理机、内存、文件、设备几种资源，只要对资源的请求大于资源本身的数量，就会涉及调度。例如，在单处理机系统中，处理机只有一个，而请求服务的进程却有多个，所以就有处理机调度的概念出现。而出现调度的概念后，又有了一个问题，即如何调度、应该满足谁、应该让谁等待，这是调度算法所回答的问题;而应该满足谁、应该让谁等待，要遵循一定的准则，即调度的准则。调度这一概念贯穿于操作系统的始终，读者在接下来的学习中，将接触到几种资源的调度问题和相应的调度算法。将它们与处理机调度的内容相对比，将会发现它们有异曲同工之妙。\n进程同步\n用 PV 操作解决进程之间的同步互斥问题是这一节的重点，考试已经多次考查过这一内容，读者务必多加练习，掌握好求解问题的方法。\n\n\n大题中遇到相关的题目，信号量的类型直接定义为 semaphore\n\n\n进程同步的基本概念\n​\t在多道程序环境下，进程是并发执行的，不同进程之间存在着不同的相互制约关系。为了协调进程之间的相互制约关系，引入了进程同步的概念。下面举一个简单的例于米帮大豕理解赵个概念。例如，让系统计算 1+2x3，假设系统产生两个进程:一个是加法进程，一个是乘法进程。要让计算结果是正确的，一定要让加法进程发生在乘法进程之后，但实际上操作系统具有异步性，若不加以制约，加法进程发生在乘法进程之前是绝对有可能的，因此要制定一定的机制去约束加法进程，让它在乘法进程完成之后才发生，而这种机制就是本节要讨论的内容。\n临界资源\n虽然多个进程可以共享系统中的各种资源，但其中许多资源一次只能为一个进程所用，我们将一次仅允许一个进程使用的资源称为临界资源。许多物理设备都属于临界资源，如打印机等。此外，还有许多变量、数据等都可以被若干进程共享，也属于临界资源。\n对临界资源的访问，必须互斥地进行，在每个进程中，访问临界资源的那段代码称为临界区。为了保证临界资源的正确使用，可把临界资源的访问过程分成 4 个部分:\n\n\n进入区 。为了进入临界区使用临界资源，在进入区要检查可否进入临界区，若能进入临界区，则应设置正在访问临界区的标志，以阻止其他进程同时进入临界区。\n\n\n临界区 。进程中访问临界资源的那段代码，又称临界段。\n\n\n退出区 。将正在访问临界区的标志清除。\n\n\n剩余区 。代码中的其余部分。\n\n\ndo&#123;\n  entry section; //进入区\n  critical section; //临界区\n  exit section;//退出区\n  remainder section;//剩余区\n&#125; while (true)\n\n同步\n​\t同步亦称直接制约关系，是指为完成某种任务而建立的两个或多个进程，这些进程因为需要在某些位置上协调它们的工作次序而等待、传递信息所产生的制约关系。进程间的直接制约关系源于它们之间的相互合作。\n​\t例如，输入进程 A 通过单缓冲向进程 B 提供数据。当该缓冲区空时，进程 B 不能获得所需数据而阻塞，一旦进程 A 将数据送入缓冲区，进程 B 就被唤醒。反之，当缓冲区满时，进程 A 被阻塞，仅当进程 B 取走缓冲数据时，才唤醒进程 A。\n互斥\n互斥也称间接制约关系。当一个进程进入临界区使用临界资源时，另一个进程必须等待，当占用临界资源的进程退出临界区后，另一进程才允许去访问此临界资源。\n例如，在仅有一台打印机的系统中，有两个进程 A 和进程 B，若进程 A 需要打印时，系统已将打印机分配给进程 B，则进程 A 必须阻塞。一旦进程 B 将打印机释放，系统便将进程唤醒，并将其由阻塞态变为就绪态。\n为禁止两个进程同时进入临界区，同步机制应遵循以下准则:\n\n\n空闲让进。临界区空闲时，可以允许一个请求进入临界区的进程立即进入临界区。\n\n\n忙则等待 。当已有进程进入临界区时，其他试图进入临界区的进程必须等待。\n\n\n有限等待 。对请求访问的进程，应保证能在有限时间内进入临界区。\n\n\n让权等待 。当进程不能进入临界区时，应立即释放处理器，防止进程忙等待。\n\n\n实现临界区互斥的基本方法\n软件实现方法\n在进入区设置并检查一些标志来标明是否有进程在临界区中，若已有进程在临界区，则在进入区通过循环检查进行等待，进程离开临界区后则在退出区修改标志。\n\n\n算法一:单标志法。该算法设置一个公用整型变量 turn，用于指示被允许进入临界区的进程编号，即若 turn=0，则允许 P0 进程进入临界区。该算法可确保每次只允许一个进程进入临界区。但两个进程必须交替进入临界区，若某个进程不再进入临界区，则另一个进程也将无法进入临界区（违背“空闲让进”)。这样很容易造成资源利用不充分。若 P0 顺利进入临界区并从临界区离开，则此时临界区是空闲的，但 P1 并没有进入临界区的打算，turn=1 一直成立， P0 就无法再次进入临界区（一直被 while 死循环困住)。\n\n\n\n\n\n算法二:双标志法先检查。该算法的基本思想是在每个进程访问临界区资源之前，先查看临界资源是否正被访问，若正被访问，该进程需等待;否则，进程才进入自己的临界区。为此，设置一个数据 flag[i]，如第 i 个元素值为 FALSE，表示 Pi 进程未进入临界区，值为 TRUE，表示 P 进程进入临界区。\n\n\n\n优点:不用交替进入，可连续使用;缺点: Pi 和 Pj ,可能同时进入临界区。按序列 ①② ③③ ④④ 执行时，会同时进入临界区（违背“忙则等待”)。即在检查对方的 flag 后和切换自己的 flag 前有一段时间，结果都检查通过。这里的问题出在检查和修改操作不能一次进行。\n\n\n算法三:双标志法后检查。算法二先检测对方的进程状态标志，再置自己的标志，由在检测和放置中可插入另一个进程到达时的检测操作，会造成两个进程在分别检测后同时进入临界区。为此，算法三先将自己的标志设置为 TRUE，再检测对方的状态标志，若对方标志为 TRUE，则进程等待;否则进入临界区。\n\n\n\n两个进程几乎同时都想进入临界区时，它们分别将自己的标志值 flag 设置为 TRUE，并且同时检测对方的状态（执行 while 语句)，发现对方也要进入临界区时，双方互相谦让，结果谁也进不了临界区，从而导致“饥饿”现象。\n\n\n算法四:Peterson’s Algorithm。为了防止两个进程为进入临界区而无限期等待，又设置变量 turn，每个进程在先设置自己的标志后再设置 turn 标志。这时，再同时检测另一个进程状态标志和不允许进入标志，以便保证两个进程同时要求进入临界区时，只允许个进程进入临界区。\n\n\n\n具体如下:考虑进程 PI ，一旦设置 flag[ i ] = true，就表示它想要进入临界区，同时 turn =j,此时若进程 Pj 已在临界区中，符合进程 Pi 中的 while 循环条件，则 Pi 不能进入临界区。若 Pj 不想要进入临界区，即 flag[ j ] = false，循环条件不符合，则 Pi 可以顺利进入，反之亦然。本算法的基本思想是算法一和算法三的结合。利用 flag 解决临界资源的互斥访问，而利用 turn 解决“饥饿”现象。\n理解 Peterson’s Algorithm 的最好方法就是手动模拟。\n硬件实现方法\n理解本节介绍的硬件实现，对学习后面的信号量很有帮助。计算机提供了特殊的硬件指令，允许对一个字中的内容进行检测和修正，或对两个字的内容进行交换等。通过硬件支持实现临界段问题的方法称为低级方法，或称元方法。\n中断屏蔽方法\n当一个进程正在使用处理机执行它的临界区代码时，防止其他进程进入其临界区进行访问的最简方法是，禁止一切中断发生，或称之为屏蔽中断、关中断。因为 CPU 只在发生中断时引起进程切换，因此屏蔽中断能够保证当前运行的进程让临界区代码顺利地执行完，进而保证互斥的正确实现，然后执行开中断。其典型模式为\n\n这种方法限制了处理机交替执行程序的能力，因此执行的效率会明显降低。对内核来说，在它执行更新变量或列表的几条指令期间，关中断是很方便的，但将关中断的权力交给用户则很不明智，若一个进程关中断后不再开中断，则系统可能会因此终止。\n硬件指令方法\nTestAndSet 指令:这条指令是原子操作，即执行该代码时不允许被中断。其功能是读出指定标志后把该标志设置为真。指令的功能描述如下:\n\n可以为每个临界资源设置一个共享布尔变量 lock，表示资源的两种状态: true 表示正被占用，初值为 false。在进程访问临界资源之前，利用 TestAndSet 检查和修改标志 lock;若有进程在临界区，则重复检查，直到进程退出。利用该指令实现进程互斥的算法描述如下:\n\nSwap 指令:该指令的功能是交换两个字（字节）的内容。其功能描述如下:\n\n\n\n\n\n\n\n\n\n\n注意:以上对 TestAndSet 和 Swap 指令的描述仅是功能实现，而并非软件实现的定义。事实上，它们是由硬件逻辑直接实现的，不会被中断。\n应为每个临界资源设置一个共享布尔变量 lock，初值为 false;在每个进程中再设置一个局部布尔变量 key，用于与 lock 交换信息。在进入临界区前，先利用 Swap 指令交换 lock 与 key 的内容，然后检查 key 的状态;有进程在临界区时，重复交换和检查过程，直到进程退出。利用 Swap 指令实现进程互斥的算法描述如下:\n\n硬件方法的优点:适用于任意数目的进程，而不管是单处理机还是多处理机;简单、容易验证其正确性。可以支持进程内有多个临界区，只需为每个临界区设立一个布尔变量。\n硬件方法的缺点:进程等待进入临界区时要耗费处理机时间，不能实现让权等待。从等待进程中随机选择一个进入临界区，有的进程可能一直选不上，从而导致“饥饿”现象。\n无论是软件实现方法还是硬件实现方法，读者只需理解它的执行过程即可，关键是软件实现方法。实际练习和考试中很少让读者写出某种软件和硬件实现方法，因此读者并不需要默写或记忆。以上的代码实现与我们平时在编译器上写的代码意义不同，以上的代码实现是为了表述进程实现同步和互斥的过程，并不是说计算机内部实现同步互斥的就是这些代码。\n信号量\n​\t信号量机制是一种功能较强的机制，可用来解决互斥与同步问题，它只能被两个标准的 原语原语 wait(S)和 signal(S)访问，也可记为“P 操作”和“V 操作”。\n​\t原语是指完成某种功能且不被分割、不被中断执行的操作序列，通常可由硬件来实现。例如,前述的 Test-and-Set 和 Swap 指令就是由硬件实现的原子操作。原语功能的不被中断执行特性在单处理机上可由软件通过屏蔽中断方法实现。\n​\t原语之所以不能被中断执行，是因为原语对变量的操作过程若被打断，可能会去运行另一个对同一变量的操作过程，从而出现临界段问题。若能够找到一种解决临界段问题的元方法，就可以实现对共享变量操作的原子性。\n整型信号量\n整型信号量被定义为一个用于表示资源数目的整型量 S，wait 和 signal 操作可描述为\n\nwait 操作中，只要信号量 S≤0，就会不断地测试。因此，该机制并未遵循“让权等待”的准则，而是使进程处于“忙等”的状态。\n记录型信号量\n记录型信号量是不存在“忙等”现象的进程同步机制。除需要一个用于代表资源数目的整型变量 value 外，再增加一个进程链表 L，用于链接所有等待该资源的进程。记录型信号量得名于采用了记录型的数据结构。记录型信号量可描述为\n\n相应的 wait(S)和 signal(S)的操作如下:\n\nwait 操作，S.value–表示进程请求一个该类资源，当 S.value &lt;0 时，表示该类资源已分配完毕，因此进程应调用 block 原语，进行自我阻塞，放弃处理机，并插入该类资源的等待队列 S.L，可见该机制遵循了“让权等待”的准则。\n\nsignal 操作,表示进程释放一个资源,使系统中可供分配的该类资源数增 1,因此有 S.value ++。若加 1 后仍是 S.value≤0，则表示在 S.L 中仍有等待该资源的进程被阻塞，因此还应调用 wakeup 原语，将 S.L 中的第一个等待进程唤醒。\n利用信号量实现同步\n信号量机制能用于解决进程间的各种同步问题。设 S 为实现进程 P1 , P2 同步的公共信号量，初值为 0。进程 P2 中的语句 y 要使用进程 P1 中语句 x 的运行结果，所以只有当语句 x 执行完成之后语句 y 才可以执行。其实现进程同步的算法如下:\n\n若 P2 先执行到 P(S)时，S 为 0，执行 Р 操作会把进程 P2 阻塞，并放入阻塞队列;当进程 P1 中的 x 执行完后，执行 V 操作，把 P2 从阻塞队列中放回就绪队列，当 P2 得到处理机时，就得以继续执行。\n利用信号量实现进程互斥\n信号量机制也能很方便地解决进程互斥问题。设 S 为实现进程 P1 , P2 互斥的信号量，由于每次只允许一个进程进入临界区﹐所以 S 的初值应为 1(即可用资源数为 1)。只需把临界区置于 P(S)和 V(S)之间，即可实现两个进程对临界资源的互斥访问。其算法如下:\n\n当没有进程在临界区时，任意一个进程要进入临界区，就要执行 Р 操作，把 S 的值减为 0，然后进入临界区;当有进程存在于临界区时，S 的值为 0，再有进程要进入临界区，执行 Р 操作时将会被阻塞，直至在临界区中的进程退出，这样便实现了临界区的互斥。\n互斥是不同进程对同一信号量进行 P,V 操作实现的，一个进程成功对信号量执行了 Р 操作后进入临界区，并在退出临界区后，由该进程本身对该信号量执行 V 操作，表示当前没有进程进入临界区，可以让其他进程进入。\n下面简单总结一下 PV 操作在同步互斥中的应用:在同步问题中，若某个行为要用到某种资源，则在这个行为前面 Р 这种资源一下;若某个行为会提供某种资源，则在这个行为后面 V 这种资源一下。在互斥问题中，P, V 操作要紧夹使用互斥资源的那个行为，中间不能有其他冗余代码。\n利用信号量实现前驱关系\n\n信号量也可用来描述程序之间或语句之间的前驱关系。图 2.8 给出了一个前驱图，其中 P1 , P2 , P3 ,… , P6 是最简单的程序段(只有一条语句)。为使各程序段能正确执行，应设置若干初始值为“0”的信号量。例如，为保证 P1 → P2 , P1 → P3 的前驱关系，应分别设置信号量 al, a2。同样，为保证 P2 → P4 , P2 → P5 , P5 → P6 , P4 → P6 , P5 → P6 ，应设置信号量 b1, b2,c, d,e。\n\n分析进程同步和互斥问题的方法步骤\n\n\n关系分析。找出问题中的进程数，并分析它们之间的同步和互斥关系。同步、互斥、前驱关系直接按照上面例子中的经典范式改写。\n\n\n整理思路。找出解决问题的关键点，并根据做过的题目找出求解的思路。根据进程的操作流程确定 Р 操作、V 操作的大致顺序。\n\n\n设置信号量。根据上面的两步，设置需要的信号量，确定初值，完善整理。\n\n\n这是一个比较直观的同步问题，以 S2 为例，它是 S1 的后继，所以要用到 S1 的资源，在前面的简单总结中我们说过，在同步问题中，要用到某种资源，就要在行为（题中统一抽象成 L)前面 Р 这种资源一下。 S2 是 S4 ， S5 的前驱，给 S4 ， S5 ,提供资源，所以要在 L 行为后面 V 由 S4 和 S5 代表的资源一下。\n管程\n​\t在信号量机制中，每个要访问临界资源的进程都必须自备同步的 PV 操作，大量分散的同步操作给系统管理带来了麻烦，且容易因同步操作不当而导致系统死锁。于是，便产生了一种新的进程同步工具-管程。管程的特性保证了进程互斥，无须程序员自己实现互斥，从而降低了死锁发生的可能性。同时管程提供了条件变量，可以让程序员灵活地实现进程同步。\n管程的定义\n​\t系统中的各种硬件资源和软件资源，均可用数据结构抽象地描述其资源特性，即用少量信息和对资源所执行的操作来表征该资源，而忽略它们的内部结构和实现细节。\n​\t利用共享数据结构抽象地表示系统中的共享资源，而把对该数据结构实施的操作定义为一组过程。进程对共享资源的申请、释放等操作，都通过这组过程来实现，这组过程还可以根据资源情况，或接受或阻塞进程的访问，确保每次仅有一个进程使用共享资源，这样就可以统一管理对共享资源的所有访问，实现进程互斥。这个代表共享资源的数据结构，以及由对该共享数据结构实施操作的一组过程所组成的资源管理程序，称为管程( monitor )。管程定义了一个数据结构和能为并发进程所执行(在该数据结构上)的一组操作，这组操作能同步进程和改变管程中的数据。\n由上述定义可知，管程由 4 部分组成:\n① 管程的名称;\n② 局部于管程内部的共享结构数据说明;\n③ 对该数据结构进行操作的一组过程(或函数);\n④ 对局部于管程内部的共享数据设置初始值的语句。\n管程的定义描述举例如下:\n\n熟悉面向对象程序设计的读者看到管程的组成后，会立即联想到管程很像一个类(class)。\n\n\n管程把对共享资源的操作封装起来，管程内的共享数据结构只能被管程内的过程所访问。一个进程只有通过调用管程内的过程才能进入管程访问共享资源。对于上例，外部进程只能通过调用 take_away()过程来申请一个资源;归还资源也一样。\n\n\n每次仅允许一个进程进入管程，从而实现进程互斥。若多个进程同时调用 take_away(),give_back()，则只有某个进程运行完它调用的过程后，下个进程才能开始运行它调用的过程。也就是说，各个进程只能串行执行管程内的过程，这一特性保证了进程“互斥”访问共享数据结构 S。\n\n\n条件变量\n​\t当一个进程进入管程后被阻塞，直到阻塞的原因解除时，在此期间，如果该进程不释放管程，那么其他进程无法进入管程。为此，将阻塞原因定义为条件变量 condition。通常，一个进程被阻塞的原因可以有多个，因此在管程中设置了多个条件变量。每个条件变量保存了一个等待队列，用于记录因该条件变量而阻塞的所有进程，对条件变量只能进行两种操作，即 wait 和 signal。\nx.wait:当 x 对应的条件不满足时，正在调用管程的进程调用 x.wait 将自己插入 x 条件的等待队列，并释放管程。此时其他进程可以使用该管程。\nx.signal: x 对应的条件发生了变化，则调用 x.signal，唤醒一个因 x 条件而阻塞的进程。下面给出条件变量的定义和使用:\n\n条件变量和信号量的比较:\n相似点:条件变量的 wait/signal 操作类似于信号量的 P/V 操作，可以实现进程的阻塞/唤醒。\n不同点:条件变量是“没有值”的，仅实现了“排队等待”功能;而信号量是“有值”的，信号量的值反映了剩余资源数，而在管程中，剩余资源数用共享数据结构记录。\n经典同步问题\n生产者-消费者问题\n问题描述:一组生产者进程和一组消费者进程共享一个初始为空、大小为 n 的缓冲区，只有缓冲区没满时，生产者才能把消息放入缓冲区，否则必须等待;只有缓冲区不空时，消费者才能从中取出消息，否则必须等待。由于缓冲区是临界资源，它只允许一个生产者放入消息，或一个消费者从中取出消息。\n问题分析:\n1）关系分析。生产者和消费者对缓冲区互斥访问是互斥关系，同时生产者和消费者又是个相互协作的关系，只有生产者生产之后，消费者才能消费，它们也是同步关系。\n2）整理思路。这里比较简单，只有生产者和消费者两个进程，正好是这两个进程存在着互斥关系和同步关系。那么需要解决的是互斥和同步 PV 操作的位置。\n3）信号量设置。信号量 mutex 作为互斥信号量，用于控制互斥访问缓冲池，互斥信号量初值为 1;信号量 full 用于记录当前缓冲池中的“满”缓冲区数，初值为 0。信号量 empty 用于记录当前缓冲池中的“空”缓冲区数，初值为 n。\n我们对同步互斥问题的介绍是一个循序渐进的过程。上面介绍了一个同步问题的例子和一个互斥问题的例子，下面来看生产者-消费者问题的例子是什么样的。\n生产者-消费者进程的描述如下:\n\n该类问题要注意对缓冲区大小为 n 的处理，当缓冲区中有空时，便可对 empty 变量执行 Р 操作，一旦取走一个产品便要执行 V 操作以释放空闲区。对 empty 和 full 变量的 Р 操作必须放在对 mutex 的 P 操作之前。若生产者进程先执行 P(mutex)，然后执行 P(empty)，消费者执行 P(mutex),然后执行 P(full)，这样可不可以﹖答案是否定的。设想生产者进程已将缓冲区放满，消费者进程并没有取产品，即 empty =0，当下次仍然是生产者进程运行时，它先执行 P(mutex)封锁信号量,再执行 P(empty)时将被阻塞，希望消费者取出产品后将其唤醒。轮到消费者进程运行时，它先执行 P(mutex)，然而由于生产者进程已经封锁 mutex 信号量，消费者进程也会被阻塞，这样一来生产者、消费者进程都将阻塞，都指望对方唤醒自己，因此陷入了无休止的等待。同理，若消费者进程已将缓冲区取空，即 full = 0，下次若还是消费者先运行，也会出现类似的死锁。不过生产者释放信号量时，mutex, full 先释放哪一个无所谓，消费者先释放 mutex 或 empty 都可以。\n根据对同步互斥问题的简单总结，我们发现，其实生产者-消费者问题只是一个同步互斥问题的综合而已。\n下面再看一个较为复杂的生产者-消费者问题。\n问题描述:桌子上有一个盘子，每次只能向其中放入一个水果。爸爸专向盘子中放苹果，妈妈专向盘子中放橘子，儿子专等吃盘子中的橘子，女儿专等吃盘子中的苹果。只有盘子为空时，爸爸或妈妈才可向盘子中放一个水果;仅当盘子中有自己需要的水果时，儿子或女儿可以从盘子中取出。\n问题分析:\n1）关系分析。这里的关系要稍复杂一些。由每次只能向其中放入一只水果可知，爸爸和妈妈是互斥关系。爸爸和女儿、妈妈和儿子是同步关系，而且这两对进程必须连起来，儿子和女儿之间没有互斥和同步关系，因为他们是选择条件执行，不可能并发，如图 2.9 所示。\n2）整理思路。这里有 4 个进程，实际上可抽象为两个生产者和两个消费者被连接到大小为 1 的缓冲区上。\n3）信号量设置。首先将信号量 plate 设置互斥信号量，表示是否允许向盘子放入水果，初值为 1 表示允许放入，且只允许放入一个。信号量 apple 表示盘子中是否有苹果，初值为 0 表示盘子为空，不许取，apple = 1 表示可以取。信号量 orange 表示盘子中是否有橘子，初值为 0 表示盘子为空，不许取，orange =1 表示可以取。\n\n解决该问题的代码如下:\n\n进程间的关系如图 2.9 所示。dad()和 daughter()、mom()和 son()必须连续执行，正因为如此，也只能在女儿拿走苹果后或儿子拿走橘子后才能释放盘子，即 V(plate)操作。\n读者-写者问题\n问题描述:有读者和写者两组并发进程，共享一个文件，当两个或以上的读进程同时访问共享数据时不会产生副作用，但若某个写进程和其他进程（读进程或写进程）同时访问共享数据时则可能导致数据不一致的错误。因此要求:① 允许多个读者可以同时对文件执行读操作;② 只允许一个写者往文件中写信息;③ 任一写者在完成写操作之前不允许其他读者或写者工作;④ 写者执行写操作前，应让已有的读者和写者全部退出。\n问题分析:\n1）关系分析。由题目分析读者和写者是互斥的，写者和写者也是互斥的，而读者和读者不存在互斥问题。\n2）整理思路。两个进程，即读者和写者。写者是比较简单的，它和任何进程互斥，用互斥信号量的 Р 操作、V 操作即可解决。读者的问题比较复杂，它必须在实现与写者互斥的同时，实现与其他读者的同步，因此简单的一对 Р 操作、V 操作是无法解决问题的。这里用到了一个计数器，用它来判断当前是否有读者读文件。当有读者时，写者是无法写文件的，此时读者会一直占用文件，当没有读者时，写者才可以写文件。同时，这里不同读者对计数器的访问也应该是互斥的。\n3）信号量设置。首先设置信号量 count 为计数器，用于记录当前读者的数量，初值为 0;设置 mutex 为互斥信号量，用于保护更新 count 变量时的互斥;设置互斥信号量 rw，用于保证读者和写者的互斥访问。\n代码如下:\n\n在上面的算法中，读进程是优先的，即当存在读进程时，写操作将被延迟，且只要有一个读进程活跃，随后而来的读进程都将被允许访问文件。这样的方式会导致写进程可能长时间等待，且存在写进程“饿死”的情况。\n若希望写进程优先，即当有读进程正在读共享文件时，有写进程请求访问，这时应禁止后续读进程的请求，等到已在共享文件的读进程执行完毕，立即让写进程执行，只有在无写进程执行的情况下才允许读进程再次运行。为此，增加一个信号量并在上面程序的 writer()和 reader()函数中各增加一对 PV 操作，就可以得到写进程优先的解决程序。\n\n这里的写进程优先是相对而言的，有些书上把这个算法称为读写公平法，即读写进程具有-一样的优先级。当一个写进程访问文件时，若先有一些读进程要求访问文件，后有另一个写进程要求访问文件，则当前访问文件的进程结束对文件的写操作时，会是一个读进程而不是一个写进程占用文件(在信号量 w 的阻塞队列上，因为读进程先来，因此排在阻塞队列队首，而 V 操作唤醒进程时唤醒的是队首进程)，所以说这里的写优先是相对的，想要了解如何做到真正写者优先，\n可参考其他相关资料。\n读者-写者问题有一个关键的特征，即有一个互斥访问的计数器 count，因此遇到一个不太好解决的同步互斥问题时，要想一想用互斥访问的计数器 count 能否解决问题。\n哲学家进餐问题\n\n问题描述:一张圆桌边上坐着 5 名哲学家，每两名哲学家之间的桌上摆一根筷子，两根筷子中间是一碗米饭，如图 2.10 所示。哲学家们倾注毕生精力用于思考和进餐，哲学家在思考时，并不影响他人。只有当哲学家饥饿时，才试图拿起左、右两根筷子(一根一根地拿起)。若筷子已在他人手上，则需要等待。饥饿的哲学家只有同时拿到了两根筷子才可以开始进餐，进餐完毕后，放下筷子继续思考。\n问题分析:\n\n\n关系分析。5 名哲学家与左右邻居对其中间筷子的访问是互斥关系。\n\n\n整理思路。显然，这里有 5 个进程。本题的关键是如何让一名哲学家拿到左右两根筷子而不造成死锁或饥饿现象。解决方法有两个:一是让他们同时拿两根筷子;二是对每名哲学家的动作制定规则，避免饥饿或死锁现象的发生。\n\n\n信号量设置。定义互斥信号量数组 chopstick[ 5 ]={1,1,1,1,1}，用于对 5 个筷子的互斥访问。哲学家按顺序编号为 0 ～ 4，哲学家 i 左边筷子的编号为 i，哲学家右边筷子的编号为(i +1)%5。\n\n\n\n该算法存在以下问题:当 5 名哲学家都想要进餐并分别拿起左边的筷子时（都恰好执行完 wait(chopstick[ i]);）筷子已被拿光,等到他们再想拿右边的筷子时（执行 wait(chopstick[(i + 1)%5]);）就全被阻塞，因此出现了死锁。为防止死锁发生，可对哲学家进程施加一些限制条件，比如至多允许 4 名哲学家同时进餐;仅当一名哲学家左右两边的筷子都可用时，才允许他抓起筷子;对哲学家顺序编号，要求奇数号哲学家先拿左边的筷子，然后拿右边的筷子，而偶数号哲学家刚好相反。\n制定的正确规则如下:假设采用第二种方法，当一名哲学家左右两边的筷子都可用时，才允许他抓起筷子。\n\n此外，还可采用 AND 型信号量机制来解决哲学家进餐问题，有兴趣的读者可以查阅相关资料，自行思考。\n熟悉 ACM 或有过相关训练的读者都应知道贪心算法，哲学家进餐问题的思想其实与贪心算法的思想截然相反，贪心算法强调争取眼前认为最好的，而不考虑后续会有什么后果。若哲学家进餐问题用贪心算法来解决，即只要眼前有筷子能拿起就拿起的话，就会出现死锁。然而,若不仅考虑眼前的一步，而且考虑下一步，即不因为有筷子能拿起就拿起，而考虑能不能一次拿起两根筷子才做决定的话，就会避免死锁问题，这就是哲学家进餐问题的思维精髓。\n大部分练习题和真题用消费者-生产者模型或读者-写者问题就能解决，但对于哲学家进餐问题和吸烟者问题仍然要熟悉。考研复习的关键在于反复多次和全面，“偷工减料”是要吃亏的。\n吸烟者问题\n问题描述:假设一个系统有三个抽烟者进程和一个供应者进程。每个抽烟者不停地卷烟并抽掉它，但要卷起并抽掉一支烟，抽烟者需要有三种材料:烟草、纸和胶水。三个抽烟者中,第一个拥有烟草，第二个拥有纸，第三个拥有胶水。供应者进程无限地提供三种材料，供应者每次将两种材料放到桌子上，拥有剩下那种材料的抽烟者卷一根烟并抽掉它，并给供应者一个信号告诉已完成，此时供应者就会将另外两种材料放到桌上，如此重复（让三个抽烟者轮流地抽烟）。\n问题分析:\n\n\n关系分析。供应者与三个抽烟者分别是同步关系。由于供应者无法同时满足两个或以上的抽烟者，三个抽烟者对抽烟这个动作互斥（或由三个抽烟者轮流抽烟得知)。\n\n\n整理思路。显然这里有 4 个进程。供应者作为生产者向三个抽烟者提供材料。\n\n\n信号量设置。信号量 offer1, offer2, offer3 分别表示烟草和纸组合的资源、烟草和胶水组合的资源、纸和胶水组合的资源。信号量 finish 用于互斥进行抽烟动作。\n\n\n代码如下:\n\n本节小结\n本节开头提出的问题的参考答案如下。\n为什么要引入进程同步的概念?\n在多道程序共同执行的条件下，进程与进程是并发执行的，不同进程之间存在不同的相互制约关系。为了协调进程之间的相互制约关系，引入了进程同步的概念。\n不同的进程之间会存在什么关系?\n进程之间存在同步与互斥的制约关系。\n同步是指为完成某种任务而建立的两个或多个进程，这些进程因为需要在某些位置上协调它们的工作次序而等待、传递信息所产生的制约关系。\n互斥是指当一个进程进入临界区使用临界资源时，另一个进程必须等待，当占用临界资源的进程退出临界区后，另一进程才允许去访问此临界资源。\n当单纯用本节介绍的方法解决这些问题时会遇到什么新的问题吗?\n当两个或两个以上的进程在执行过程中，因占有一些资源而又需要对方的资源时，会因为争夺资源而造成一种互相等待的现象，若无外力作用，它们都将无法推进下去。这种现象称为死锁，具体介绍和解决方案请参考下一节。\n死锁\n在学习本节时，请读者思考以下问题:\n1）为什么会产生死锁?产生死锁有什么条件?\n2）有什么办法可以解决死锁问题?\n学完本节，读者应了解死锁的由来、产生条件及基本解决方法，区分死锁的避免和死锁的预防。\n死锁的概念\n死锁的定义\n​\t在多道程序系统中，由于多个进程的并发执行，改善了系统资源的利用率并提高了系统的处理能力。然而，多个进程的并发执行也带来了新的问题–死锁。所谓死锁，是指多个进程因竞争资源而造成的一种僵局（互相等待)，若无外力作用，这些进程都将无法向前推进。\n下面通过一些实例来说明死锁现象。\n先看生活中的一个实例。在一条河上有一座桥，桥面很窄，只能容纳一辆汽车通行。若有两辆汽车分别从桥的左右两端驶上该桥，则会出现下述冲突情况:此时，左边的汽车占有桥面左边的一段，要想过桥还需等待右边的汽车让出桥面右边的一段;右边的汽车占有桥面右边的一段，要想过桥还需等待左边的汽车让出桥面左边的一段。此时，若左右两边的汽车都只能向前行驶，则两辆汽车都无法过桥。\n在计算机系统中也存在类似的情况。例如，某计算机系统中只有一台打印机和一台输入设备，进程 P1 正占用输入设备，同时又提出使用打印机的请求，但此时打印机正被进程 P2 所占用，而 P2 在未释放打印机之前，又提出请求使用正被 P1 占用的输入设备。这样，两个进程相互无休止地等待下去，均无法继续执行，此时两个进程陷入死锁状态。\n死锁产生的原因\n系统资源的竞争\n​\t通常系统中拥有的不可剥夺资源，其数量不足以满足多个进程运行的需要，使得进程在运行过程中，会因争夺资源而陷入僵局，如磁带机、打印机等。只有对不可剥夺资源的竞争才可能产生死锁，对可剥夺资源的竞争是不会引起死锁的。\n进程推进顺序非法\n​\t进程在运行过程中，请求和释放资源的顺序不当，也同样会导致死锁。例如，并发进程 P1 , P2 分别保持了资源 R1 , R2 ，而进程 P1 申请资源 R2 、进程 P2 申请资源 R1 时，两者都会因为所需资源被占用而阻塞。\n​\t信号量使用不当也会造成死锁。进程间彼此相互等待对方发来的消息，也会使得这些进程间无法继续向前推进。例如，进程 A 等待进程 B 发的消息，进程 B 又在等待进程 A 发的消息，可以看出进程 A 和 B 不是因为竞争同一资源，而是在等待对方的资源导致死锁。\n死锁产生的必要条件\n产生死锁必须同时满足以下 4 个条件，只要其中任意一个条件不成立，死锁就不会发生。\n互斥条件:进程要求对所分配的资源（如打印机）进行排他性控制，即在一段时间内某资源仅为一个进程所占有。此时若有其他进程请求该资源，则请求进程只能等待。\n不剥夺条件:进程所获得的资源在未使用完之前，不能被其他进程强行夺走，即只能由获得该资源的进程自己来释放（只能是主动释放)。\n请求并保持条件:进程已经保持了至少一个资源，但又提出了新的资源请求，而该资源已被其他进程占有，此时请求进程被阻塞，但对自己已获得的资源保持不放。\n循环等待条件:存在一种进程资源的循环等待链，链中每个进程已获得的资源同时被链中下一个进程所请求。即存在一个处于等待态的进程集合{ P1 , P2 ,…, Pn }，其中 Pi 等待的资源被Pi+1 ( i =0,1,… , n -1）占有， Pn 等待的资源被 P0 占有，如图 2.11 所示。\n直观上看，循环等待条件似乎和死锁的定义一样，其实不然。按死锁定义构成等待环所要求的条件更严，它要求 Pi 等待的资源必须由 Pi+1 来满足，而循环等待条件则无此限制。例如，系统中有两台输出设备， P0 占有一台， PK 占有另一台，且 K 不属于集合{0,1，…, n}。 Pn 等待一台输出设备，它可从 P0 获得，也可能从 PK 获得。因此，虽然 Pn , P0 和其他一些进程形成了循环等待圈,但 PK 不在圈内，若 PK 释放了输出设备，则可打破循环等待，如图 2.12 所示。因此循环等待只是死锁的必要条件。\n\n资源分配图含圈而系统又不一定有死锁的原因是，同类资源数大于 1。但若系统中每类资源都只有一个资源，则资源分配图含圈就变成了系统出现死锁的充分必要条件。\n要注意区分不剥夺条件与请求并保持条件。下面用一个简单的例子进行说明:若你手上拿着一个苹果（即便你不打算吃)，别人不能把你手上的苹果拿走，则这就是不剥夺条件;若你左手拿着一个苹果，允许你右手再去拿一个苹果，则这就是请求并保持条件。\n死锁的处理策略\n为使系统不发生死锁，必须设法破坏产生死锁的 4 个必要条件之一，或允许死锁产生，但当死锁发生时能检测出死锁，并有能力实现恢复。\n\n\n预防和避免的区别：参考文献\n\n\n死锁预防\n设置某些限制条件，破坏产生死锁的 4 个必要条件中的一个或几个，以防止发生死锁。\n避免死锁\n在资源的动态分配过程中，用某种方法防止系统进入不安全状态，从而避免死锁。\n死锁的检测及解除\n无须采取任何限制性措施，允许进程在运行过程中发生死锁。通过系统的检测机构及时地检测出死锁的发生，然后采取某种措施解除死锁。\n预防死锁和避免死锁都属于事先预防策略，预防死锁的限制条件比较严格，实现起来较为简单，但往往导致系统的效率低，资源利用率低;避免死锁的限制条件相对宽松，资源分配后需要通过算法来判断是否进入不安全状态，实现起来较为复杂。\n死锁的几种处理策略的比较见表 2.4。\n\n死锁预防\n防止死锁的发生只需破坏死锁产生的 4 个必要条件之一即可。\n破坏互斥条件\n若允许系统资源都能共享使用，则系统不会进入死锁状态。但有些资源根本不能同时访问，如打印机等临界资源只能互斥使用。所以，破坏互斥条件而预防死锁的方法不太可行，而且在有的场合应该保护这种互斥性。\n破坏不剥夺条件\n当一个已保持了某些不可剥夺资源的进程请求新的资源而得不到满足时，它必须释放已经保持的所有资源，待以后需要时再重新申请。这意味着，一个进程已占有的资源会被暂时释放，或者说是被剥夺，或从而破坏了不剥夺条件。\n该策略实现起来比较复杂，释放已获得的资源可能造成前一阶段工作的失效，反复地申请和释放资源会增加系统开销,降低系统吞吐量。这种方法常用于状态易于保存和恢复的资源,如 CPU 的寄存器及内存资源，一般不能用于打印机之类的资源。\n破坏请求并保持条件\n采用预先静态分配方法，即进程在运行前一次申请完它所需要的全部资源，在它的资源未满足前，不把它投入运行。一旦投入运行，这些资源就一直归它所有，不再提出其他资源请求，这样就可以保证系统不会发生死锁。\n这种方式实现简单，但缺点也显而易见，系统资源被严重浪费，其中有些资源可能仅在运行初期或运行快结束时才使用，甚至根本不使用。而且还会导致“饥饿”现象，由于个别资源长期被其他进程占用时，将致使等待该资源的进程迟迟不能开始运行。\n破坏循环等待条件\n为了破坏循环等待条件，可采用顺序资源分配法。首先给系统中的资源编号，规定每个进程必须按编号递增的顺序请求资源，同类资源一次申请完。也就是说，只要进程提出申请分配资源 Ri，则该进程在以后的资源申请中就只能申请编号大于Ri 的资源。\n这种方法存在的问题是，编号必须相对稳定，这就限制了新类型设备的增加;尽管在为资源编号时已考虑到大多数作业实际使用这些资源的顺序，但也经常会发生作业使用资源的顺序与系统规定顺序不同的情况，造成资源的浪费;此外，这种按规定次序申请资源的方法，也必然会给用户的编程带来麻烦。\n死锁避免\n避免死锁同样属于事先预防策略，但并不是事先采取某种限制措施破坏死锁的必要条件，而是在资源动态分配过程中，防止系统进入不安全状态，以避免发生死锁。这种方法所施加的限制条件较弱，可以获得较好的系统性能。\n系统安全状态\n避免死锁的方法中，允许进程动态地申请资源，但系统在进行资源分配之前，应先计算此次分配的安全性。若此次分配不会导致系统进入不安全状态，则允许分配;否则让进程等待。\n所谓安全状态，是指系统能按某种进程推进顺序( P1 , P2 ,…, Pn )为每个进程 Pi 分配其所需的资源，直至满足每个进程对资源的最大需求，使每个进程都可顺序完成。此时称 Pi ， P2 .…， Pn 为安全序列。若系统无法找到一个安全序列，则称系统处于不安全状态。\n假设系统中有三个进程 P1 , P2 ,和 P3 ，共有 12 台磁带机。进程 P1 共需要 10 台磁带机， P2 和 P3 分别需要 4 台和 9 台。假设在 P0 时刻，进程 P1 ， P2 和 P3 已分别获得 5 台、2 台和 2 台，尚有 3 台未分配，见表 2.5。\n\n在 P0 时刻是安全的，因为存在一个安全序列 P2 , P1 , P3 ，只要系统按此进程序列分配资源，那么每个进程都能顺利完成。也就是说，当前可用磁带机为 3 台，先把 3 台磁带机分配给 РР2 以满足其最大需求， P2 结束并归还资源后，系统有 5 台磁带机可用;接下来给 P1 分配 5 台磁带机以满足其最大需求， P1 结束并归还资源后，剩余 10 台磁带机可用;最后分配 7 台磁带机给 P3 ，这样 P3 也能顺利完成。\n若在 P0 时刻后，系统分配 1 台磁带机给 P3 ，系统剩余可用资源数为 2，此时系统进入不安全状态，因为此时已无法再找到一个安全序列。当系统进入不安全状态后，便可能导致死锁。例如，把剩下的 2 台磁带机分配给 P2 这样， P2 完成后只能释放 4 台磁带机，既不能满足 P1 又不能满足 P3 ，致使它们都无法推进到完成，彼此都在等待对方释放资源，陷入僵局，即导致死锁。\n并非所有的不安全状态都是死锁状态，但当系统进入不安全状态后，便可能进入死锁状态;反之，只要系统处于安全状态，系统便可避免进入死锁状态。\n银行家算法\n银行家算法是最著名的死锁避免算法，其思想是:把操作系统视为银行家，操作系统管理的资源相当于银行家管理的资金，进程向操作系统请求分配资源相当于用户向银行家贷款。操作系统按照银行家制定的规则为进程分配资源。进程运行之前先声明对各种资源的最大需求量，当进程在执行中继续申请资源时，先测试该进程已占用的资源数与本次申请的资源数之和是否超过该进程声明的最大需求量。若超过则拒绝分配资源，若未超过则再测试系统现存的资源能否满足该进程尚需的最大资源量，若能满足则按当前的申请量分配资源，否则也要推迟分配。\n数据结构描述\n可利用资源向量 Available:含有 m 个元素的数组，其中每个元素代表一类可用的资源数目。Available[ j ]=K 表示系统中现有 Rj 类资源 K 个。\n最大需求矩阵 Max: n×m 矩阵，定义系统中 n 个进程中的每个进程对 m 类资源的最大需求。简单来说，一行代表一个进程，一列代表一类资源。Max[ i,j ]=K 表示进程 i 需要 Rj 类资源的最大数目为 K。\n分配矩阵 Allocation: n×m 矩阵，定义系统中每类资源当前已分配给每个进程的资源数。Allocation[ i,j ]=K 表示进程 i 当前已分得 Rj 类资源的数目为 K。初学者容易混淆 Available 向量和 Allocation 矩阵，在此特别提醒。\n需求矩阵 Need: n×m 矩阵，表示每个进程接下来最多还需要多少资源。Need[ i,j ]=K 表示进程 i 还需要 Rj 类资源的数目为 K。\n上述三个矩阵间存在下述关系:\nNeed=Max−AllocationNeed= Max- Allocation\nNeed=Max−Allocation\n一般情况下，在银行家算法的题目中，Max 矩阵和 Allocation 矩阵是已知条件，而求出 Need 矩阵是解题的第一步。\n银行家算法描述\n\n安全性算法举例\n\n银行家算法举例\n\n死锁检测和解除\n​\t前面介绍的死锁预防和避免算法，都是在为进程分配资源时施加限制条件或进行检测，若系统为进程分配资源时不采取任何措施，则应该提供死锁检测和解除的手段。\n资源分配图\n​\t系统死锁可利用资源分配图来描述。如图 2.13 所示，用圆圈代表一个进程，用框代表一类资源。由于一种类型的资源可能有多个，因此用框中的一个圆代表一类资源中的一个资源。从进程到资源的有向边称为请求边 ，表示该进程申请一个单位的该类资源;从资源到进程的边称为分配边 ，表示该类资源已有一个资源分配给了该进程。\n在图 2.13 所示的资源分配图中，进程 P1 已经分得了两个 R1 资源，并又请求一个 R2 资源;进程 P2 ,分得了一个 R1 资源和一个 R2 资源，并又请求一个 R1 资源。\n\n死锁定理\n简化资源分配图可检测系统状态 S 是否为死锁状态。简化方法如下:\n\n\n在资源分配图中，找出既不阻塞又不孤点的进程 Pi (即找出一条有向边与它相连，且该有向边对应资源的申请数量小于等于系统中己有的空闲资源数量，如在图 2.13 中， R1 没有空闲资源， R2 有一个空闲资源。若所有连接该进程的边均满足上述条件，则这个进程能继续运行直至完成，然后释放它所占有的所有资源)。消去它所有的请求边和分配边，使之成为孤立的结点。在图 2.14(a)中， P1 是满足这一条件的进程结点，将 P 的所有边消去，便得到图 2.14(b)所示的情况。\n\n\n\n\n\n\n\n\n\n\n\n这里要注意一个问题，判断某种资源是否有空间，应用它的资源数量减去它在资源分配图中的出度，例如在图 2.13 中， R1 的资源数为 3，而出度也为 3，所以 R1 没有空闲资源, R2 的资源数为 2，出度为 1，所以 R2 有一个空闲资源。\n\n\n进程 Pi 所释放的资源，可以唤醒某些因等待这些资源而阻塞的进程，原来的阻塞进程可能变为非阻塞进程。在图 2.13 中，进程 P2 就满足这样的条件。根据 1)中的方法进行一系列简化后，若能消去图中所有的边，则称该图是可完全简化的，如图 2.14©所示。\n\n\n\nS 为死锁的条件是当且仅当 S 状态的资源分配图是不可完全简化的，该条件为死锁定理 。\n死锁解除\n一旦检测出死锁，就应立即采取相应的措施来解除死锁。死锁解除的主要方法有:\n\n\n资源剥夺法 。挂起某些死锁进程，并抢占它的资源，将这些资源分配给其他的死锁进程。但应防止被挂起的进程长时间得不到资源而处于资源匮乏的状态。\n\n\n撤销进程法 。强制撤销部分甚至全部死锁进程并剥夺这些进程的资源。撤销的原则可以按进程优先级和撤销进程代价的高低进行。\n\n\n进程回退法 。让一（或多〉个进程回退到足以回避死锁的地步，进程回退时自愿释放资源而非被剥夺。要求系统保持进程的历史信息，设置还原点。\n\n\n本节小结\n本节开头提出的问题的参考答案如下。\n\n\n为什么会产生死锁?产生死锁有什么条件?\n\n\n由于系统中存在一些不可剥夺资源，当两个或两个以上的进程占有自身的资源并请求对方的资源时，会导致每个进程都无法向前推进，这就是死锁。死锁产生的必要条件有 4 个，分别是互斥条件、不剥夺条件、请求并保持条件和循环等待条件。\n互斥条件是指进程要求分配的资源是排他性的，即最多只能同时供一个进程使用。\n不剥夺条件是指进程在使用完资源之前，资源不能被强制夺走。\n请求并保持条件是指进程占有自身本来拥有的资源并要求其他资源。\n循环等待条件是指存在一种进程资源的循环等待链。\n\n\n有什么办法可以解决死锁问题?\n\n\n死锁的处理策略可以分为预防死锁、避免死锁及死锁的检测与解除。\n死锁的预防是指通过设立一些限制条件，破坏死锁的一些必要条件，让死锁无法发生。\n死锁的避免是指在动态分配资源的过程中，用一些算法防止系统进入不安全状态，从而避免死锁。\n死锁的检测和解除是指在死锁产生前不采取任何措施，只检测当前系统有没有发生死锁，若有，则采取一些措施解除死锁。\n本章疑难点\n进程与程序的区别与联系\n\n\n进程是程序及其数据在计算机上的一次运行活动，是一个动态的概念。进程的运行实体是程序，离开程序的进程没有存在的意义。从静态角度看，进程是由程序、数据和进程控制块（PCB）三部分组成的。而程序是一组有序的指令集合，是一种静态的概念。\n\n\n进程是程序的一次执行过程，它是动态地创建和消亡的，具有一定的生命周期，是暂时存在的;而程序则是一组代码的集合，是永久存在的，可长期保存。\n\n\n一个进程可以执行一个或几个程序，一个程序也可构成多个进程。进程可创建进程，而程序不可能形成新的程序。\n\n\n进程与程序的组成不同。进程的组成包括程序、数据和 PCB。\n\n\n死锁与饥饿\n​\t具有等待队列的信号量的实现可能导致这样的情况:两个或多个进程无限地等待一个事件，而该事件只能由这些等待进程之一来产生。这里的事件是 V 操作的执行（即释放资源)。出现这样的状态时，这些进程称为死锁(Deadlocked)。\n为加以说明，考虑一个由两个进程 P0 和P1 组成的系统，每个进程都访问两个信号量 S 和 Q,这两个信号量的初值均为 1。\n\n假设进程 P0 执行 P(S)，接着进程 P1 执行 P(Q)。当进程 P0 执行 P(Q)时，它必须等待，直到进程 P1 执行 V(Q)。类似地，当进程 P1 执行 P(S)时，它必须等待，直到进程 P0 执行 V(S)。由于这两个 V 操作都不能执行，因此进程 P0 和进程 P1 就死锁了。\n一组进程处于死锁状态是指组内的每个进程都在等待一个事件，而该事件只可能由组内的另一个进程产生。这里所关心的主要是事件是资源的获取和释放。\n​\t与死锁相关的另一个问题是无限期阻塞（Indefinite Blocking）或饥饿(Starvation)，即进程在信号量内无穷等待的情况。\n产生饥饿的主要原因是:在一个动态系统中，对于每类系统资源，操作系统需要确定一个分配策略，当多个进程同时申请某类资源时，由分配策略确定资源分配给进程的次序。有时资源分配策略可能是不公平的，即不能保证等待时间上界的存在。在这种情况下，即使系统没有发生死锁，某些进程也可能会长时间等待。当等待时间给进程推进和响应带来明显影响时，称发生了进程“饥饿”，当“饥饿”到一定程度的进程所赋予的任务即使完成也不再具有实际意义时，称该进程被“饿死”。\n例如，当有多个进程需要打印文件时，若系统分配打印机的策略是最短文件优先，则长文件的打印任务将由于短文件的源源不断到来而被无限期推迟，导致最终“饥饿”甚至“饿死”。\n“饥饿”并不表示系统一定会死锁，但至少有一个进程的执行被无限期推迟。“饥饿”与死锁的主要差别如下:\n\n\n进入“饥饿”状态的进程可以只有一个，而因循环等待条件而进入死锁状态的进程却必须大于等于两个。\n\n\n处于“饥饿”状态的进程可以是一个就绪进程，如静态优先权调度算法时的低优先权进程，而处于死锁状态的进程则必定是阻塞进程。\n\n\n银行家算法的工作原理\n​\t银行家算法的主要思想是避免系统进入不安全状态。在每次进行资源分配时，它首先检查系统是否有足够的资源满足要求，若有则先进行分配，并对分配后的新状态进行安全性检查。若新状态安全，则正式分配上述资源，否则拒绝分配上述资源。这样，它保证系统始终处于安全状态，从而避免了死锁现象的发生。\n进程同步、互斥的区别和联系\n​\t并发进程的执行会产生相互制约的关系:一种是进程之间竞争使用临界资源，只能让它们逐个使用，这种现象称为互斥，是一种竞争关系;另一种是进程之间协同完成任务，在关键点上等待另一个进程发来的消息，以便协同一致，是一种协作关系。\n作业和进程的关系\n​\t进程是系统资源的使用者，系统的资源大部分都是以进程为单位分配的。而用户使用计算机是为了实现一串相关的任务，通常把用户要求计算机完成的这一串任务称为作业。\n批处理系统中作业与进程的关系（进程组织)\n​\t批处理系统可以通过磁记录设备或卡片机向系统提交批作业，由系统的 SPOOLing 输入进程将作业放入磁盘的输入井，作为后备作业。作业调度程序（一般也作为独立的进程运行）每当选择一道后备作业运行时，首先为该作业创建一个进程（称为该作业的根进程)。该进程将执行作业控制语言解释程序，解释该作业的作业说明书。父进程在运行过程中可以动态地创建一个或多个子进程，执行说明书中的语句。例如，对一条编译的语句，该进程可以创建一个子进程执行编译程序对用户源程序进行编译。类似地，子进程也可继续创建子进程去完成指定的功能。因此,一个作业就动态地转换成了一组运行实体—进程族。当父进程遇到作业说明书中的“撤出作业”语句时，将该作业从运行态改变为完成态，将作业及相关结果送入磁盘上的输出井。作业终止进程负责将输出井中的作业利用打印机输出，回收作业所占用的资源，删除作业有关的数据结构,删除作业在磁盘输出井中的信息等。作业终止进程撤除一道作业后，可向作业调度进程请求进行新的作业调度。至此，一道进入系统运行的作业全部结束。\n分时系统中作业与进程的关系\n​\t在分时系统中，作业的提交方法、组织形式均与批处理作业有很大差异。分时系统的用户通过命令语言逐条与系统应合八把武大系体自动时，系统为每个终端设备建立一个进程（称为终端统内部对应一个(以右 T 经程序，命令解释程序从终端设备读入俞令，解藉疯令是一茶后台命进程)，该进程执仃类令 n 可以创建一个子进程去具体执行。若当 HPN 根据需要创建子孙进程。条命令。对于每条终端命令，可以创建一个子进程去具体执行。若当前的终端命令是一条后台命令，则可以和下一条终端命令并行处理。各子进程在运行过程中完全可以根据需要创建子孙进程。终端命令所对应的进程结束后，命令的功能也相应处理完毕。用户本次上机完毕，用户通过一条登出命令即结束上机过程。\n​\t分时系统的作业就是用户的一次上机交互过程，可以认为终端进程的创建是一个交互作业的开始，登出命令运行结束代表用户交互作业的终止。\n​\t命令解释程序流程扮演着批处理系统中作业控制语言解释程序的角色，只不过命令解释程序是从用户终端接收命令。\n交互地提交批作业\n​\t在同时支持交互和批处理的操作系统中，人们可以用交互的方式准备好批作业的有关程序、数据及作业控制说明书。比如，可用交互式系统提供的全屏幕编辑命令编辑好自编的一个天气预报程序，用编译及装配命令将程序变成可执行文件，用调试命令进行程序调试。调试成功后，用户每天都要做如下工作:准备原始天气数据，运行天气预报执行文件处理原始数据，把结果打印出来等。这时，用交互系统提供的全屏幕编辑命令编辑好将要提交的作业控制说明书文件，如 Windows 系统的 bat 文件和 Linux 系统的 sh 文件。然后用一条作业提交命令将作业提交到系统作业队列中。系统有专门的作业调度进程负责从作业队列中选择作业，为被选取的作业创建一个父进程运行命令解释程序，解释执行作业控制说明书文件中的命令。\n内存管理\n【考纲内容】\n(一）内存管理基础\n\n\n内存管理概念（逻辑地址与物理地址空间，地址变换， 内存共享内存共享 ，内存保护，内存分配与回收）\n\n\n连续分配管理方式\n\n\n非连续分配管理方式:\n\n\n分页管理方式\n\n\n分段管理方式\n\n\n段页式管理方式\n\n\n(二）虚拟内存管理\n\n\n虚拟内存的基本概念\n\n\n请求分页管理方式\n\n\n页框分配\n\n\n页面置换算法\n\n\n内存映射文件内存映射文件 （Memory-Mapped Files）\n\n\n虚拟存储器性能的影响因素及改进方式\n\n\n【知识框架】\n\n\n程序执行过程\n\n编译、连接、装入\n逻辑地址和物理地址\n\n\n\n扩充内存————覆盖与变换\n\n\n连续分配\n\n单一连续分配\n固定分区分配————内部碎片\n动态分区分配\n\n外部碎片\n分配算法：首次、最佳、最坏、邻近适应\n\n\n\n\n\n非连续分配\n\n页式存储管理\n\n概念:页面、地址结构、页表\n地址变化机构及变换过程\n快表\n\n\n段式存储管理————段表、地址变换机构、段的共享与保护\n段式存储管理————段表、页表\n\n\n\n虚拟内存\n\n概念\n\n局部性原理\n特征:多次性、对换性、虚拟性\n\n\n请求分页\n\n组成：页表机构、缺页中断机构、地址变换机构\n页面置换算法\n\n最佳置换(OPT)\n先进先出(FIFO)————Belady 异常\n最近最久未使用(LRU)\n时钟(CLOCK)算法\n\n\n页面分配策略\n抖动、工作集\n\n\n\n\n\n【复习提示】\n内存管理和进程管理是操作系统的核心内容，需要重点复习。本章围绕分页机制展开:通过分页管理方式在物理内存大小的基础上提高内存的利用率，再进一步引入请求分页管理方式，实现虚拟内存，使内存脱离物理大小的限制，从而提高处理器的利用率。\n\n\n需要注意：编译，链接，装入，执行，各个阶段的任务\n\n\n内存管理概念\n在学习本节时，请读者思考以下问题:\n1）为什么要进行内存管理?\n2）页式管理中每个页表项大小的下限如何决定?\n3）多级页表解决了什么问题?又会带来什么问题?\n在学习经典的管理方法前，同样希望读者先思考，自己给出一些内存管理的想法，并在学习过程中和经典方案进行比较。注意本节给出的内存管理是循序渐进的，后一种方法通常会解决前一种方法的不足。希望读者多多思考，比较每种方法的异同，着重掌握页式管理。\n内存管理的基本原理和要求\n​\t内存管理(Memory Management）是操作系统设计中最重要和最复杂的内容之一。虽然计算机硬件技术一直在飞速发展，内存容量也在不断增大，但仍然不可能将所有用户进程和系统所需要的全部程序与数据放入主存，因此操作系统必须对内存空间进行合理的划分和有效的动态分配。操作系统对内存的划分和动态分配，就是内存管理的概念。\n​\t有效的内存管理在多道程序设计中非常重要，它不仅可以方便用户使用存储器、提高内存利用率，还可以通过虚拟技术从逻辑上扩充存储器。\n内存管理的功能有:\n\n\n内存空间的分配与回收 。由操作系统完成主存储器空间的分配和管理，使程序员摆脱存储分配的麻烦，提高编程效率。\n\n\n地址转换 。在多道程序环境下，程序中的逻辑地址与内存中的物理地址不可能一致，因此存储管理必须提供地址变换功能，把逻辑地址转换成相应的物理地址。\n\n\n内存空间的扩充 。利用虚拟存储技术或自动覆盖技术，从逻辑上扩充内存。\n\n\n存储保护 。保证各道作业在各自的存储空间内运行，互不干扰。\n\n\n在进行具体的内存管理之前，需要了解进程运行的基本原理和要求。\n程序装入和链接\n创建进程首先要将程序和数据装入内存。将用户源程序变为可在内存中执行的程序，通常需要以下几个步骤:\n\n\n编译 。由编译程序将用户源代码编译成若干目标模块。\n\n\n链接 。由链接程序将编译后形成的一组目标模块及所需的库函数链接在一起，形成一个完整的装入模块。\n\n\n装入 。由装入程序将装入模块装入内存运行。\n\n\n这三步过程如图 3.1 所示。\n\n程序的链接有以下三种方式。\n\n\n静态链接 。在程序运行之前，先将各目标模块及它们所需的库函数链接成一个完整的可执行程序，以后不再拆开。\n\n\n装入时动态链接 。将用户源程序编译后所得到的一组目标模块，在装入内存时，采用边装入边链接的方式。\n\n\n运行时动态链接 。对某些目标模块的链接，是在程序执行中需要该目标模块时才进行的。其优点是便于修改和更新，便于实现对目标模块的共享。\n\n\n内存的装入模块在装入内存时，同样有以下三种方式:\n\n\n绝对装入 。在编译时，若知道程序将驻留在内存的某个位置，则编译程序将产生绝对地址的目标代码。绝对装入程序按照装入模块中的地址，将程序和数据装入内存。由于程序中的逻辑地址与实际内存地址完全相同，因此不需对程序和数据的地址进行修改。绝对装入方式只适用于单道程序环境。另外，程序中所用的绝对地址，可在编译或汇编时给出，也可由程序员直接赋予。而通常情况下在程序中采用的是符号地址，编译或汇编时再转换为绝对地址。\n\n\n可重定位装入 。在多道程序环境下，多个目标模块的起始地址（简称 始址始址 ）通常都从 0 开始，程序中的其他地址都是相对于始址的，此时应采用可重定位装入方式。根据内存的当前情况，将装入模块装入内存的适当位置。装入时对目标程序中指令和数据的修改﹒过程称为 重定位重定位 ,地址变换通常是在装入时一次完成的,所以又称静态重定位,如图 3.2(a)所示。\n\n\n\n\n\n\n\n\n\n\n\n静态重定位的特点是，一个作业装入内存时，必须给它分配要求的全部内存空间，若没有足够的内存，则不能装入该作业。此外，作业一旦进入内存，整个运行期间就不能在内存中移动，也不能再申请内存空间。\n\n\n动态运行时装入 ，也称动态重定位。程序在内存中若发生移动，则需要采用动态的装入方式。装入程序把装入模块装入内存后，并不立即把装入模块中的相对地址转换为绝对地址，而是把这种地址转换推迟到程序真正要执行时才进行。因此，装入内存后的所有地址均为相对地址。这种方式需要一个重定位寄存器的支持，如图 3.2(b)所示。\n\n\n\n\n\n\n\n\n\n\n\n动态重定位的特点如下:可以将程序分配到不连续的存储区中;在程序运行之前可以只装入它的部分代码即可投入运行，然后在程序运行期间，根据需要动态申请分配内存;便于程序段的共享，可以向用户提供一个比存储空间大得多的地址空间。\n\n逻辑地址空间与物理地址空间\n​\t编译后,每个目标模块都从 0 号单元开始编址,这称为该目标模块的相对地址(或逻辑地址)。当链接程序将各个模块链接成一个完整的可执行目标程序时，链接程序顺序依次按各个模块的相对地址构成统一的从 0 号单元开始编址的逻辑地址空间。用户程序和程序员只需知道逻辑地址，而内存管理的具体机制则是完全透明的，只有系统编程人员才会涉及内存管理的具体机制。不同进程可以有相同的逻辑地址，因为这些相同的逻辑地址可以映射到主存的不同位置。\n​\t物理地址空间是指内存中物理单元的集合，它是地址转换的最终地址，进程在运行时执行指令和访问数据，最后都要通过物理地址从主存中存取。当装入程序将可执行代码装入内存时，必须通过地址转换将逻辑地址转换成物理地址，这个过程称为地址重定位 。\n\n\n\n\n\n\n\n\n\n内存中的地址被称为物理地址，而外存（辅助存储器）中的地址被称为逻辑地址或虚拟地址。\n内存保护\n内存分配前，需要保护操作系统不受用户进程的影响，同时保护用户进程不受其他用户进程的影响。内存保护可采取两种方法:\n\n\n在 CPU 中设置一对上、下限寄存器，存放用户作业在主存中的下限和上限地址，每当 CPU 要访问一个地址时，分别和两个寄存器的值相比，判断有无越界。\n\n\n采用重定位寄存器 （或基址寄存器）和 界地址寄存器 （又称限长寄存器）来实现这种保护。重定位寄存器含最小的物理地址值，界地址寄存器含逻辑地址的最大值。每个逻辑地址值必须小于界地址寄存器;内存管理机构动态地将逻辑地址与界地址寄存器进行比较，若未发生地址越界，则加上重定位寄存器的值后映射成物理地址，再送交内存单元,如图 3.3 所示。\n\n\n\n实现内存保护需要重定位寄存器和界地址寄存器，因此要注意两者的区别。重定位寄存器是用来“加”的，逻辑地址加上重定位寄存器中的值就能得到物理地址;界地址寄存器是用来“比”的，通过比较界地址寄存器中的值与逻辑地址的值来判断是否越界。\n*覆盖与交换\n覆盖与交换技术是在多道程序环境下用来扩充内存的两种方法。\n覆盖\n​\t早期的计算机系统中，主存容量很小，虽然主存中仅存放一道用户程序，但存储空间放不下用户进程的现象也经常发生，这一矛盾可以用覆盖技术来解决。\n​\t覆盖的基本思想如下:由于程序运行时并非任何时候都要访问程序及数据的各个部分（尤其是大程序)，因此可把用户空间分成一个固定区和若干覆盖区。将经常活跃的部分放在固定区，其余部分按调用关系分段。首先将那些即将要访问的段放入覆盖区，其他段放在外存中，在需要调用前，系统再将其调入覆盖区，替换覆盖区中原有的段。\n​\t覆盖技术的特点是，打破了必须将一个进程的全部信息装入主存后才能运行的限制，但当同时运行程序的代码量大于主存时仍不能运行，此外，内存中能够更新的地方只有覆盖区的段，不在覆盖区中的段会常驻内存。\n交换\n​\t交换（对换）的基本思想是，把处于等待状态（或在 CPU 调度原则下被剥夺运行权利）的程序从内存移到辅存，把内存空间腾出来，这一过程又称换出;把准备好竞争 CPU 运行的程序从辅存移到内存，这一过程又称换入。第 2 章介绍的中级调度采用的就是交换技术。\n​\t例如，有一个 CPU 采用时间片轮转调度算法的多道程序环境。时间片到，内存管理器将刚刚执行过的进程换出，将另一进程换入刚刚释放的内存空间。同时，CPU 调度器可以将时间片分配给其他已在内存中的进程。每个进程用完时间片都与另一进程交换。在理想情况下，内存管理器的交换过程速度足够快，总有进程在内存中可以执行。\n有关交换，需要注意以下几个问题:\n\n\n交换需要备份存储，通常是快速磁盘。它必须足够大，并提供对这些内存映像的直接访问。\n\n\n为了有效使用 CPU，需要使每个进程的执行时间比交换时间长，而影响交换时间的主要是转移时间。转移时间与所交换的内存空间成正比。\n\n\n若换出进程，则必须确保该进程完全处于空闲状态。\n\n\n交换空间通常作为磁盘的一整块，且独立于文件系统，因此使用起来可能很快。\n\n\n交换通常在有许多进程运行且内存空间吃紧时开始启动，而在系统负荷降低时就暂停。\n\n\n普通的交换使用不多，但交换策略的某些变体在许多系统(如 UNIX 系统)中仍发挥作用。\n\n\n​\t交换技术主要在不同进程（或作业)之间进行，而覆盖则用于同一个程序或进程中。由于覆盖技术要求给出程序段之间的覆盖结构，使得其对用户和程序员不透明，所以对于主存无法存放用户程序的矛盾，现代操作系统是通过虚拟内存技术来解决的，覆盖技术则已成为历史;而交换技术在现代操作系统中仍具有较强的生命力。\n连续分配管理方式\n​\t连续分配方式是指为一个用户程序分配一个连续的内存空间，譬如某用户需要 1GB 的内存空间，连续分配方式就在内存空间中为用户分配一块连续的 1GB 空间。连续分配方式主要包括 单一连续分配 、固定分区分配 、动态分区分配 。\n单一连续分配\n​\t内存在此方式下分为系统区 和 用户区 ，系统区仅供操作系统使用，通常在低地址部分;用户区是为用户提供的、除系统区之外的内存空间。这种方式无须进行内存保护。因为内存中永远只有一道程序，因此肯定不会因为访问越界而干扰其他程序。\n​\t这种方式的优点是简单、无外部碎片，可以采用覆盖技术，不需要额外的技术支持。缺点是只能用于单用户、单任务的操作系统中，有内部碎片，存储器的利用率极低。\n固定分区分配\n​\t固定分区分配是最简单的一种多道程序存储管理方式，它将用户内存空间划分为若干固定大小的区域，每个分区只装入一道作业。当有空闲分区时，便可再从外存的后备作业队列中选择适当大小的作业装入该分区，如此循环。\n固定分区分配在划分分区时有两种不同的方法，如图 3.4 所示。\n\n​\t为便于内存分配,通常将分区按大小排队，并为之建立一张分区说明表，其中各表项包括每个分区的始址、大小及状态（是否已分配)，如图 3.5(a)所示。当有用户程序要装入时，便检索该表，以找到合适的分区给予分配并将其状态置为“已分配”，未找到合适分区时，则拒绝为该用户程序分配内存。存储空间的分配情况如图 3.5(b)所示。\n\n​\t这种分区方式存在两个问题:一是程序可能太大而放不进任何一个分区中，这时用户不得不使用覆盖技术来使用内存空间;二是主存利用率低，当程序小于固定分区大小时，也占用一个完整的内存分区空间，这样分区内部就存在空间浪费，这种现象称为内部碎片(内零头)。\n​\t固定分区是可用于多道程序设计的最简单的存储分配，无外部碎片(外零头)，但不能实现多进程共享一个主存区，所以存储空间利用率低。固定分区分配很少用于现在通用的操作系统中，但在某些用于控制多个相同对象的控制系统中仍发挥着一定的作用。\n动态分区分配\n​\t动态分区分配又称可变分区分配，是一种动态划分内存的分区方法。这种分区方法不预先划分内存，而是在进程装入内存时，根据进程的大小动态地建立分区，并使分区的大小正好适合进程的需要。因此，系统中分区的大小和数目是可变的。\n​\t如图 3.6 所示，系统有 64MB 内存空间，其中低 8MB 固定分配给操作系统，其余为用户可用内存。开始时装入前三个进程，它们分别分配到所需的空间后，内存只剩下 4MB，进程 4 无法装入。在某个时刻，内存中没有一个就绪进程，CPU 出现空闲，操作系统就换出进程 2，换入进程 4。由于进程 4 比进程 2 小，这样在主存中就产生了一个 6MB 的内存块。之后 CPU 又出现空闲，而主存无法容纳进程 2，操作系统就换出进程 1，换入进程 2。\n\n​\t动态分区在开始分配时是很好的，但之后会导致内存中出现许多小的内存块。随着时间的推移，内存中会产生越来越多的碎片(（图 3.6 中最后的 4MB 和中间的 6MB，且随着进程的换入/换出，很可能会出现更多、更小的内存块)，内存的利用率随之下降。这些小的内存块称为外部碎片，指在所有分区外的存储空间会变成越来越多的碎片，这与固定分区中的内部碎片正好相对。克服外部碎片可以通过紧凑(Compaction）技术来解决，即操作系统不时地对进程进行移动和整理。但这需要动态重定位寄存器的支持，且相对费时。紧凑的过程实际上类似于 Windows 系统中的磁盘整理程序，只不过后者是对外存空间的紧凑。\n​\t在进程装入或换入主存时，若内存中有多个足够大的空闲块，则操作系统必须确定分配哪个内存块给进程使用，这就是动态分区的分配策略。考虑以下几种算法:\n\n\n首次适应 (First Fit）算法。空闲分区以地址递增的次序链接。分配内存时顺序查找，找到大小能满足要求的第一个空闲分区。\n\n\n最佳适应 （Best Fit）算法。空闲分区按容量递增的方式形成分区链，找到第一个能满足要求的空闲分区。\n\n\n最坏适应 (Worst Fit）算法。又称最大适应（Largest Fit）算法，空闲分区以容量递减的次序链接，找到第一个能满足要求的空闲分区，即挑选出最大的分区。\n\n\n邻近适应 (Next Fit）算法。又称循环首次适应算法，由首次适应算法演变而成。不同之处是，分配内存时从上次查找结束的位置开始继续查找。\n\n\n​\t在这几种方法中，首次适应算法不仅是最简单的，而且通常也是最好和最快的。在 UNIX 系统的最初版本中，就是使用首次适应算法为进程分配内存空间的，它使用数组的数据结构（而非链表）来实现。不过，首次适应算法会使得内存的低地址部分出现很多小的空闲分区，而每次分配查找时，都要经过这些分区，因此增加了查找的开销。\n​\t邻近适应算法试图解决这个问题。但实际上，它常常导致在内存的末尾分配空间（因为在一遍扫描中，内存前面部分使用后再释放时，不会参与分配）分裂成小碎片。它通常比首次适应算法的结果要差。\n​\t最佳适应算法虽然称为“最佳”，但是性能通常很差，因为每次最佳的分配会留下很小的难以利用的内存块，会产生最多的外部碎片。\n​\t最坏适应算法与最佳适应算法相反，它选择最大的可用块，这看起来最不容易产生碎片，但是却把最大的连续内存划分开，会很快导致没有可用的大内存块，因此性能也非常差。\n​\tKnuth 和 Shore 分别就前三种方法对内存空间的利用情况做了模拟实验，结果表明:首次适应算法可能比最佳适应法效果好，而它们两者一定比最大适应法效果好。另外要注意，在算法实现时，分配操作中最佳适应法和最大适应法需要对可用块进行排序或遍历查找，而首次适应法和邻近适应法只需要简单查找;在回收操作中，当回收的块与原来的空闲块相邻时（有三种相邻的情况，比较复杂)，需要将这些块合并。在算法实现时，使用数组或链表进行管理。除了内存的利用率，这里的算法开销也是操作系统设计需要考虑的一个因素。\n三种内存分区管理方式的比较见表 3.1。\n\n以上三种内存分区管理方法有一个共同特点，即用户进程（或作业）在主存中都是连续存放的。这里对它们进行比较和总结。\n非连续分配管理方式\n​\t非连续分配允许一个程序分散地装入不相邻的内存分区。在连续分配管理方式中，我们发现，即使内存有超过 1GB 的空闲空间，但若没有连续的 1GB 空间，则需要 1GB 空间的作业仍然是无法运行的;但若采用非连续分配管理方式，则作业所要求的 1GB 内存空间可以分散地分配在内存的各个区域，当然，这也需要额外的空间去存储它们（分散区域）的索引，使得非连续分配方式的存储密度低于连续存储方式的。\n​\t非连续分配管理方式根据分区的大小是否固定，分为分页存储管理方式 和分段存储管理方式 。\n在分页存储管理方式中，又根据运行作业时是否要把作业的所有页面都装入内存才能运行，分为 基本分页存储管理方式 请求分页存储管理方式 。下面介绍基本分页存储管理方式。\n基本分页存储管理方式\n​\t固定分区会产生内部碎片，动态分区会产生外部碎片,这两种技术对内存的利用率都比较低。我们希望内存的使用能尽量避免碎片的产生，这就引入了分页的思想:把主存空间划分为大小相等且固定的块，块相对较小，作为主存的基本单位。每个进程也以块为单位进行划分，进程在执行时，以块为单位逐个申请主存中的块空间。\n​\t分页的方法从形式上看，像分区相等的固定分区技术，分页管理不会产生外部碎片。但它又有本质的不同点:块的大小相对分区要小很多，而且进程也按照块进行划分，进程运行时按块申请主存可用空间并执行。这样，进程只会在为最后一个不完整的块申请一个主存块空间时，才产生主存碎片，所以尽管会产生内部碎片，但这种碎片相对于进程来说也是很小的，每个进程平均只产生半个块大小的内部碎片（也称页内碎片)。\n分页存储的几个基本概念\n​\t① 页面和页面大小 。进程中的块称为 页 (Page)，内存中的块称为 页框 (Page Frame，或页帧)。外存也以同样的单位进行划分，直接称为 块 （Block)。进程在执行时需要申请主存空间，即要为每个页面分配主存中的可用页框，这就产生了页和页框的一一对应。为方便地址转换，页面大小应是 2 的整数幂。同时页面大小应该适中，页面太小会使进程的页面数过多，这样页表就会过长，占用大量内存，而且也会增加硬件地址转换的开销，降低页面换入/换出的效率;页面过大又会使页内碎片增多，降低内存的利用率。所以页面的大小应该适中，要在空间效率和时间效率之间权衡。\n​\t② 地址结构 。分页存储管理的逻辑地址结构如图 3.7 所示。\n\n​\t地址结构包含两部分:前一部分为页号 P，后一部分为页内偏移量 W。地址长度为 32 位，其中 0 ～ 11 位为页内地址，即每页大小为 4KB;12~31 位为页号，地址空间最多允许 220 页。\n\n\n\n\n\n\n\n\n\n注意，地址结构决定了虚拟内存的寻址空间有多大。在实际问题中，页号、页内偏移、逻辑地址大多都是用十进制数给出的。题目用二进制地址的形式给出时，读者要会转换。\n​\t③ 页表。为了便于在内存中找到进程的每个页面所对应的物理块，系统为每个进程建立张页表，它记录页面在内存中对应的物理块号，页表一般存放在内存中。页表是由页表项组成的，初学者容易混淆页表项与地址结构，页表项与地址都由两部构成，而且第一部分都是页号，但页表项的第二部分是物理内存中的块号，而地址的;二部分是页内偏移;页表项的第二部分与地址的第二部分共同组成物理地址。在配置页表后，进程执行时，通过查找该表，即可找到每页在内存中的物理块号。可见页表的作用是实现从页号到物理块号的地址映射，如图 3.8 所示。\n\n基本地址变换机构\n​\t地址变换机构的任务是将逻辑地址转换为内存中的物理地址。地址变换是借助于页表实现的。图 3.9 给出了分页存储管理系统中的地址变换机构。\n\n在系统中通常设置一个页表寄存器（PTR)，存放页表在内存的起始地址 F 和页表长度 M。进程未执行时，页表的始址和长度存放在进程控制块中，当进程执行时，才将页表始址和长度存入页表寄存器。设页面大小为 L，逻辑地址 A 到物理地址 E 的变换过程如下（逻辑地址、页号、每页的长度都是十进制数):\n​\t① 计算页号 P(P=AIL）和页内偏移量 W(W=A%L)。\n​\t② 比较页号 Р 和页表长度 M，若 P≥M，则产生越界中断，否则继续执行。\n​\t③ 页表中页号 Р 对应的页表项地址=页表始址 F ＋页号 Px 页表项长度，取出该页表项内容 b，即为物理块号。要注意区分页表长度和页表项长度。页表长度的值是指一共有多少页，页表项长度是指页地址占多大的存储空间。\n​\t④ 计算 E=b×L ＋ W，用得到的物理地址 E 去访问内存。\n以上整个地址变换过程均是由硬件自动完成的。例如，若页面大小 L 为 1KB，页号 2 对应的物理块为 b=8，计算逻辑地址 A=2500 的物理地址 E 的过程如下:P=2500/1K=2，W = 2500%1K=452，查找得到页号 2 对应的物理块的块号为 8，E=8×1024+452=8644。\n\n\n\n\n\n\n\n\n\n要再次提醒读者的是，题目中条件用十进制数给出和用二进制数给出的处理过程会稍有不同。同时读者会发现，页式管理只需给出一个整数就能确定对应的物理地址，因为页面大小 L 是固定的。因此，页式管理中地址空间是 一维的 。\n页表项的大小不是随意规定的，而是有所约束的。如何确定页表项的大小?\n​\t页表项的作用是找到该页在内存中的位置。以 32 位逻辑地址空间、字节编址单位、一页 4KB 为例，地址空间内一共有 232 B/4KB= 1M 页，因此需要 log21M = 20 位才能保证表示范围能容纳所有页面，又因为以字节作为编址单位，即页表项的大小 ≥ ⌈20/81⌉ =3B。所以在这个条件下，为了保证页表项能够指向所有页面，页表项的大小应该大于 3B，当然，也可选择更大的页表项让一个页面能够正好容下整数个页表项,进而方便存储(如取成 4B，一页正好可以装下 1K 个页表项)，或增加一些其他信息。\n下面讨论分页管理方式存在的两个主要问题:① 每次访存操作都需要进行逻辑地址到物理地址的转换，地址转换过程必须足够快，否则访存速度会降低;② 每个进程引入页表，用于存储映射机制，页表不能太大，否则内存利用率会降低。\n具有快表的地址变换机构\n​\t由上面介绍的地址变换过程可知，若页表全部放在内存中，则存取一个数据或一条指令至少要访问两次内存:第一次是访问页表，确定所存取的数据或指令的物理地址;第二次是根据该地址存取数据或指令。显然，这种方法比通常执行指令的速度慢了一半。\n​\t为此，在地址变换机构中增设一个具有并行查找能力的高速缓冲存储器—快表，又称相联存储器(TLB)，用来存放当前访问的若干页表项，以加速地址变换的过程。与此对应，主存中的页表常称为慢表。具有快表的地址变换机构如图 3.10 所示。\n\n在具有快表的分页机制中，地址的变换过程如下:\n① CPU 给出逻辑地址后，由硬件进行地址转换，将页号送入高速缓存寄存器，并将此页号与快表中的所有页号进行比较。\n② 若找到匹配的页号，说明所要访问的页表项在快表中，则直接从中取出该页对应的页框号，与页内偏移量拼接形成物理地址。这样，存取数据仅一次访存便可实现。\n③ 若未找到匹配的页号，则需要访问主存中的页表，在读出页表项后，应同时将其存入快表，以便后面可能的再次访问。但若快表已满，则必须按照一定的算法对旧的页表项进行替换。\n\n\n\n\n\n\n\n\n\n注意:有些处理机设计为快表和慢表同时查找，若在快表中查找成功则终止慢表的查找。\n一般快表的命中率可达 90%以上，这样分页带来的速度损失就可降低至 10%以下。快表的有效性基于著名的局部性原理，后面讲解虚拟内存时将会具体讨论它。\n两级页表\n​\t由于引入了分页管理，进程在执行时不需要将所有页调入内存页框，而只需将保存有映射关系的页表调入内存。但是，我们仍然需要考虑页表的大小。以 32 位逻辑地址空间、页面大小 4KB、页表项大小 4B 为例，若要实现进程对全部逻辑地址空间的映射，则每个进程需要 220 即约 100 万个页表项。也就是说，每个进程仅页表这一项就需要 4MB 主存空间，这显然是不切实际的。即便不考虑对全部逻辑地址空间进行映射的情况，一个逻辑地址空间稍大的进程，其页表大小也可能是过大的。以一个 40MB 的进程为例，页表项共 40KB (40MB/4KBx4B)，若将所有页表项内容保存在内存中，则需要 10 个内存页框来保存整个页表。整个进程大小约为 1 万个页面，而实际执行时只需要几十个页面进入内存页框就可运行，但若要求 10 个页面大小的页表必须全部进入内存，则相对实际执行时的几十个进程页面的大小来说，肯定降低了内存利用率;从另一方面来说，这 10 页的页表项也并不需要同时保存在内存中，因为在大多数情况下，映射所需要的页表项都在页表的同一个页面中。\n​\t为了压缩页表，我们进一步延伸页表映射的思想，就可得到二级分页，即使用层次结构的页表:将页表的 10 页空间也进行地址映射，建立上一级页表，用于存储页表的映射关系。这里对页表的 10 个页面进行映射只需要 10 个页表项，所以上一级页表只需要 1 页就已足够（可以存储 210=1024 个页表项)。在进程执行时，只需要将这一页的上一级页表调入内存即可，进程的页表和进程本身的页面可在后面的执行中再调入内存。根据上面提到的条件（32 位逻辑地址空间、页面大小 4KB、页表项大小 4B，以字节为编址单位)，我们来构造一个适合的页表结构。页面大小为 4KB，页内偏移地址为 log24K =12 位，页号部分为 20 位，若不采用分级页表，则仅页表就要占用 220 ×4B/4KB = 1024 页，这大大超过了许多进程自身需要的页面，对于内存来说是非常浪费资源的，而且查询页表工作也会变得十分不便、试想若把这些页表放在连续的空间内，查询对应页的物理页号时可以通过页表首页地址＋页号 ×4B 的形式得到，而这种方法查询起来虽然相对方便，但连续的 1024 页对于内存的要求实在太高，并且上面也说到了其中大多数页面都是不会用到的，所以这种方法并不具有可行性。若不把这些页表放在连续的空间里，则需要一张索引表来告诉我们第几张页表该上哪里去找，这能解决页表的查询问题，且不用把所有的页表都调入内存，只在需要它时才调入(下节介绍的虚拟存储器思想)，因此能解决占用内存空间过大的问题。读者也许发现这个方案就和当初引进页表机制的方式一模一样，实际上就是构造一个页表的页表，也就是二级页表。为查询方便，顶级页表最多只能有 1 个页面(一定要记住这个规定)，因此顶级页表总共可以容纳 4KB/4B= 1K 个页表项，它占用的地址位数为 log21K = 10 位，而之前已经计算出页内偏移地址占用了 12 位，因此一个 32 位的逻辑地址空间就剩下了 10 位，正好使得二级页表的大小在一页之内，这样就得到了逻辑地址空间的格式，如图 3.11 所示。\n\n二级页表实际上是在原有页表结构上再加上一层页表，示意结构如图 3.12 所示。\n\n建立多级页表的目的在于建立索引，以便不用浪费主存空间去存储无用的页表项，也不用盲目地顺序式查找页表项。\n基本分段存储管理方式\n分页管理方式是从计算机的角度考虑设计的,目的是提高内存的利用率，提升计算机的性能。分页通过硬件机制实现，对用户完全透明。分段管理方式的提出则考虑了用户和程序员，以满足方便编程、信息保护和共享、动态增长及动态链接等多方面的需要。\n\n\n分段。段式管理方式按照用户进程中的自然段划分逻辑空间。例如，用户进程由主程序、两个子程序、栈和一段数据组成，于是可以把这个用户进程划分为 5 段，每段从 0 开始编址，并分配一段连续的地址空间（段内要求连续，段间不要求连续，因此整个作业的地址空间是二维的)，其逻辑地址由段号 S 与段内偏移量 w 两部分组成。\n\n\n在图 3.13 中，段号为 16 位，段内偏移量为 16 位，因此一个作业最多有 216 =65536 段,最大段长为 64KB。\n\n在页式系统中，逻辑地址的页号和页内偏移量对用户是透明的，但在段式系统中，段号和段内偏移量必须由用户显式提供，在高级程序设计语言中，这个工作由编译程序完成。\n\n\n段表。每个进程都有一张逻辑空间与内存空间映射的段表，其中每个段表项对应进程的一段，段表项记录该段在内存中的始址和长度。段表的内容如图 3.14 所示。\n\n\n\n配置段表后，执行中的进程可通过查找段表，找到每段所对应的内存区。可见，段表用于实现从逻辑段到物理内存区的映射，如图 3.15 所示。\n\n\n地址变换机构。分段系统的地址变换过程如图 3.16 所示。为了实现进程从逻辑地址到物理地址的变换功能，在系统中设置了段表寄存器，用于存放段表始址 F 和段表长度 M。从逻辑地址 A 到物理地址 E 之间的地址变换过程如下:\n\n\n\n\n​\t① 从逻辑地址 A 中取出前几位为段号 S，后几位为段内偏移量 W，注意在段式存储管理的题目中，逻辑地址一般以二进制数给出，而在页式存储管理中，逻辑地址一般以十进制数给出，读者要具体问题具体分析。\n​\t② 比较段号 S 和段表长度 M，若 S≥M，则产生越界中断，否则继续执行。\n​\t③ 段表中段号 S 对应的段表项地址=段表始址 F ＋段号 S× 段表项长度，取出该段表项的前几位得到段长 C。若段内偏移量 ≥C，则产生越界中断，否则继续执行。从这句话我们可以看出，段表项实际上只有两部分，前几位是段长，后几位是始址。\n​\t④ 取出段表项中该段的始址 b，计算 E=b ＋ W，用得到的物理地址 E 去访问内存。\n\n\n段的共享与保护。在分段系统中，段的共享是通过两个作业的段表中相应表项指向被共享的段的同一个物理副本来实现的。当一个作业正从共享段中读取数据时，必须防止另一个作业修改此共享段中的数据。不能修改的代码称为纯代码或可重入代码（它不属于临界资源)，这样的代码和不能修改的数据可以共享，而可修改的代码和数据不能共享。\n\n\n与分页管理类似，分段管理的保护方法主要有两种:一种是存取控制保护，另一种是地址越界保护。地址越界保护将段表寄存器中的段表长度与逻辑地址中的段号比较，若段号大于段表长度，则产生越界中断;再将段表项中的段长和逻辑地址中的段内偏移进行比较，若段内偏移大于段长，也会产生越界中断。分页管理中的地址越界保护只需要判断页号是否越界，页内偏移是不可能越界的。\n与页式管理不同，段式管理不能通过给出一个整数便确定对应的物理地址，因为每段的长度是不固定的，无法通过整数除法得出段号，无法通过求余得出段内偏移，所以段号和段内偏移一定要显式给出（段号，段内偏移)，因此分段管理的地址空间是二维的 。\n段页式管理方式\n​\t页式存储管理能有效地提高内存利用率，而分段存储管理能反映程序的逻辑结构并有利于段的共享。将这两种存储管理方法结合起来，便形成了段页式存储管理方式。\n​\t在段页式系统中，作业的地址空间首先被分成若干逻辑段，每段都有自己的段号，然后将每段分成若干大小固定的页。对内存空间的管理仍然和分页存储管理一样，将其分成若干和页面大小相同的存储块，对内存的分配以存储块为单位，如图 3.17 所示。\n在段页式系统中，作业的逻辑地址分为三部分:段号、页号和页内偏移量，如图 3.18 所示。\n\n为了实现地址变换，系统为每个进程建立一张段表，每个分段有一张页表。段表表项中至少包括段号、页表长度和页表始址，页表表项中至少包括页号和块号。此外，系统中还应有一个段表寄存器，指出作业的段表始址和段表长度（段表寄存器和页表寄存器的作用都有两个，一是在段表或页表中寻址，二是判断是否越界)。\n\n\n\n\n\n\n\n\n\n注意:在一个进程中，段表只有 一个一个 ，而页表可能有 多个多个 。\n在进行地址变换时，首先通过段表查到页表始址，然后通过页表找到页帧号，最后形成物理地址。如图 3.19 所示，进行一次访问实际需要三次访问主存，这里同样可以使用快表来加快查找速度，其关键字由段号、页号组成，值是对应的页帧号和保护码。\n\n结合上面对段式管理和页式管理的地址空间的分析，可以得出结论:段页式管理的地址空间是二维的 。\n本节小结\n本节开头提出的问题的参考答案如下。\n为什么要进行内存管理?\n​\t在单道批处理系统阶段，一个系统在一个时间段内只执行一个程序，内存的分配极其简单，即仅分配给当前运行的进程。引入多道程序的并发执行后，进程之间共享的不仅仅是处理机，还有主存储器。然而，共享主存会形成一些特殊的挑战。若不对内存进行管理，则容易导致内存数据的混乱，以至于限制进程的并发执行。因此，为了更好地支持多道程序并发执行，必须进行内存管理。\n页式管理中每个页表项大小的下限如何决定?\n页表项的作用是找到该页在内存中的位置。以 32 位逻辑地址空间、字节编址单位、一页 4KB 为例，地址空间内共含有 232 B/4KB= 1M 页，需要 log21M = 20 位才能保证表示范围能容纳所有页面，又因为以字节作为编址单位，即页表项的大小 ≥ ⌈20/8⌉ =3B。所以在这个条件下，为了保证页表项能够指向所有页面，页表项的大小应该大于 3B;当然，也可选择更大的页表项大小，让一个页面能够正好容下整数个页表项，以方便存储（例如取成 4B，一页正好可以装下 1K 个页表项)，或增加一些其他信息。\n多级页表解决了什么问题?又会带来什么问题?\n多级页表解决了当逻辑地址空间过大时，页表的长度会大大增加的问题。而采用多级页表时，一次访盘需要多次访问内存甚至磁盘，会大大增加一次访存的时间。\n不少读者表示本节的内容难以掌握，实际上本节的内容并不难，只要抓住下列几个关键的线索，本节的所有知识点就能了然于胸。\n无论是段式管理、页式管理还是段页式管理，读者都只需要关注三个问题:① 逻辑地址结构，② 表项结构，③ 寻址过程。搞清楚这三个问题，就相当于搞清楚了上面几种存储管理方式。再次提醒读者区分逻辑地址结构和表项结构。\n虚拟内存管理\n在学习本节时，请读者思考以下问题:\n1）为什么要引入虚拟内存?\n2）虚拟内存空间的大小由什么因素决定?\n3）虚拟内存是怎么解决问题的?会带来什么问题?\n读者要掌握虚拟内存解决问题的思想，并了解几种替换算法的优劣，熟练掌握虚实地址的变换方法。\n虚拟内存的基本概念\n传统存储管理方式的特征\n3.1 节讨论的各种内存管理策略都是为了同时将多个进程保存在内存中，以便允叶进仃多道程序设计。它们都具有以下两个共同的特征:\n\n\n一次性 。作业必须一次性全部装入内存后，才能开始运行。这会导致两种情况:① 当作业很大而不能全部被装入内存时，将使该作业无法运行;② 当大量作业要求运行时，由于内存不足以容纳所有作业，只能使少数作业先运行，导致多道程序度的下降。\n\n\n驻留性 。作业被装入内存后，就一直驻留在内存中，其任何部分都不会被换出，直至作业运行结束。运行中的进程会因等待 IO 而被阻塞，可能处于长期等待状态。\n\n\n由以上分析可知，许多在程序运行中不用或暂时不用的程序（数据)占据了大量的内存空间，而一些需要运行的作业又无法装入运行，显然浪费了宝贵的内存资源。\n局部性原理\n​\t要真正理解虚拟内存技术的思想，首先须了解著名的局部性原理。Bill Joy (SUN 公司 CEO)说过:“在研究所时，我经常开玩笑地说高速缓存是计算机科学中唯一重要的思想。事实上，高速缓存技术确实极大地影响了计算机系统的设计。”快表、页高速缓存及虚拟内存技术从广义上讲，都属于高速缓存技术。这个技术所依赖的原理就是局部性原理。局部性原理既适用于程序结构，又适用于数据结构（更远地讲，Dijkstra 关于“goto 语句有害”的著名论文也出于对程序局部性原理的深刻认识和理解)。\n局部性原理表现在以下两个方面:\n\n\n时间局部性 。程序中的某条指令一旦执行，不久后该指令可能再次执行;某数据被访问过，不久后该数据可能再次被访问。产生时间局部性的典型原因是程序中存在着大量的循环操作。\n\n\n空间局部性 。一旦程序访问了某个存储单元，在不久后，其附近的存储单元也将被访问，即程序在一段时间内所访问的地址，可能集中在一定的范围之内，因为指令通常是顺序存放、顺序执行的，数据也一般是以向量、数组、表等形式簇聚存储的。\n\n\n时间局部性通过将近来使用的指令和数据保存到高速缓冲存储器中，并使用高速缓存的层次结构实现。空间局部性通常使用较大的高速缓存，并将预取机制集成到高速缓存控制逻辑中实现。虚拟内存技术实际上建立了“内存-外存”的两级存储器结构，利用局部性原理实现高速缓存。\n虚拟存储器的定义和特征\n​\t基于局部性原理，在程序装入时，将程序的一部分装入内存，而将其余部分留在外存，就可启动程序执行。在程序执行过程中，当所访问的信息不在内存时，由操作系统将所需要的部分调入内存，然后继续执行程序。另一方面，操作系统将内存中暂时不使用的内容换出到外存上，从而腾出空间存放将要调入内存的信息。这样，系统好像为用户提供了一个比实际内存大得多的存储器，称为 虚拟存储器 。\n​\t之所以将其称为虚拟存储器，是因为这种存储器实际上并不存在，只是由于系统提供了部分装入、请求调入和置换功能后（对用户完全透明)，给用户的感觉是好像存在一个比实际物理内存大得多的存储器。虚拟存储器的大小由计算机的地址结构决定，并不是内存和外存的简单相加。虚拟存储器有以下三个主要特征:\n1） 多次性 。多次性是指无须在作业运行时一次性地全部装入内存，而允许被分成多次调入内存运行。\n2） 对换性 。对换性是指无须在作业运行时一直常驻内存，而允许在作业的运行过程中，进行换进和换出。\n3） 虚拟性 。虚拟性是指从逻辑上扩充内存的容量，使用户所看到的内存容量远大于实际的内存容量。\n虚拟内存技术的实现\n​\t虚拟内存技术允许将一个作业分多次调入内存。采用连续分配方式时，会使相当一部分内存空间都处于暂时或“永久”的空闲状态，造成内存资源的严重浪费，而且也无法从逻辑上扩大内存容量。因此，虚拟内存的实现需要建立在离散分配的内存管理方式的基础上。\n虚拟内存的实现有以下三种方式:\n\n\n请求分页存储管理。\n\n\n请求分段存储管理。\n\n\n请求段页式存储管理。\n\n\n不管哪种方式，都需要有一定的硬件支持。一般需要的支持有以下几个方面:\n\n\n一定容量的 内存 和 外存 。\n\n\n页表机制 （或段表机制)，作为主要的数据结构。\n\n\n中断机构 ，当用户程序要访问的部分尚未调入内存时，则产生中断。\n\n\n地址变换机构 ，逻辑地址到物理地址的变换。\n\n\n请求分页管理方式\n​\t请求分页系统建立在基本分页系统基础之上，为了支持虚拟存储器功能而增加了请求调页功能和页面置换功能。请求分页是目前最常用的一种实现虚拟存储器的方法。\n​\t在请求分页系统中，只要求将当前需要的一部分页面装入内存，便可以启动作业运行。在作业执行过程中，当所要访问的页面不在内存中时，再通过调页功能将其调入，同时还可通过置换功能将暂时不用的页面换出到外存上，以便腾出内存空间。\n​\t为了实现请求分页，系统必须提供一定的硬件支持。除了需要一定容量的内存及外存的计算机系统，还需要有页表机制、缺页中断机构和地址变换机构。\n页表机制\n​\t请求分页系统的页表机制不同于基本分页系统，请求分页系统在一个作业运行之前不要求全部一次性调入内存，因此在作业的运行过程中，必然会出现要访问的页面不在内存中的情况，如何发现和处理这种情况是请求分页系统必须解决的两个基本问题。为此，在请求页表项中增加了 4 个字段，如图 3.20 所示。\n\n增加的 4 个字段说明如下:\n\n\n状态位 P。用于指示该页是否已调入内存，供程序访问时参考。\n\n\n访问字段 A。用于记录本页在一段时间内被访问的次数，或记录本页最近已有多长时间未被访问，供置换算法换出页面时参考。\n\n\n修改位 M。标识该页在调入内存后是否被修改过。\n\n\n外存地址。用于指出该页在外存上的地址，通常是物理块号，供调入该页时参考。\n\n\n缺页中断机构\n​\t在请求分页系统中，每当所要访问的页面不在内存中时，便产生一个缺页中断，请求操作系统将所缺的页调入内存。此时应将缺页的进程阻塞（调页完成唤醒)，若内存中有空闲块,则分配一个块，将要调入的页装入该块，并修改页表中的相应页表项，若此时内存中没有空闲块，则要淘汰某页（若被淘汰页在内存期间被修改过，则要将其写回外存)。\n​\t缺页中断作为中断，同样要经历诸如保护 CPU 环境、分析中断原因、转入缺页中断处理程序、恢复 CPU 环境等几个步骤。但与一般的中断相比，它有以下两个明显的区别:\n\n\n在指令执行期间而非一条指令执行完后产生和处理中断信号，属于内部中断。\n\n\n一条指令在执行期间，可能产生多次缺页中断。\n\n\n地址变换机构\n​\t请求分页系统中的地址变换机构，是在分页系统地址变换机构的基础上，为实现虚拟内存，又增加了某些功能而形成的。\n如图 3.21 所示，在进行地址变换时，先检索快表:\n\n\n\n若找到要访问的页，则修改页表项中的访问位（写指令还需要重置修改位)，然后利用页表项中给出的物理块号和页内地址形成物理地址。\n\n\n若未找到该页的页表项，则应到内存中去查找页表，再对比页表项中的状态位 P，看该页是否已调入内存，未调入则产生缺页中断，请求从外存把该页调入内存。\n\n\n页面置换算法（决定应该换入哪页、换出哪页)\n​\t进程运行时，若其访问的页面不在内存中而需将其调入，但内存已无空闲空间时，就需要从内存中调出一页程序或数据，送入磁盘的对换区。\n​\t选择调出页面的算法就称为页面置换算法。好的页面置换算法应有较低的页面更换频率也就是说，应将以后不会再访问或以后较长时间内不会再访问的页面先调出。\n常见的置换算法有以下 4 种。\n最佳(OPT)置换算法\n​\t最佳(Optimal，OPT)置换算法选择的被淘汰页面是以后永不使用的页面，或是在最长时间内不再被访问的页面，以便保证获得最低的缺页率。然而，由于人们目前无法预知进程在内存下的若干页面中哪个是未来最长时间内不再被访问的，因而该算法无法实现。\n​\t最佳置换算法可用来评价其他算法。假定系统为某进程分配了三个物理块，并考虑有页面号引用7,0,1,2,0,3,0,4,2,3,0,3,2,1,2,0,1,7,0,1。进程运行时，先将 7,0,1 三个页面依次装入内存。进程要访问页面 2 时，产生缺页中断，根据最佳置换算法，选择将第 18 次访问才需调入的页面 7 淘汰。然后，访问页面 0 时，因为它已在内存中，所以不必产生缺页中断。访问页面 3 时，又会根据最佳置换算法将页面 1 淘汰……以此类推，如图 3.22 所示，从图中可以看出采用最佳置换算法时的情况。\n\n最长时间不被访问和以后被访问次数最小是不同的概念，初学者在理解 OPT 算法时千万不要混淆。\n可以看到，发生缺页中断的次数为 9，页面置换的次数为 6。\n先进先出(FIFO)页面置换算法\n​\t优先淘汰最早进入内存的页面，即在内存中驻留时间最久的页面。该算法实现简单，只需把调入内存的页面根据先后次序链接成队列，设置一个指针总指向最早的页面。但该算法与进程实际运行时的规律不适应，因为在进程中，有的页面经常被访问。\n​\t这里仍用上面的实例采用 FIFO 算法进行页面置换。进程访问页面 2 时，把最早进入内存的页面 7 换出。然后访问页面 3 时，把 2,0,1 中最先进入内存的页面 0 换出。由图 3.23 可以看出，利用 FIFO 算法时进行了 12 次页面置换，比最佳置换算法正好多一倍。\n​\tFIFO 算法还会产生所分配的物理块数增大而页故障数不减反增的异常现象，这由 Belady 于 1969 年发现，因此称为 Belady 异常。只有 FIFO 算法可能出现Belady 异常 ，LRU 和 OPT 算法永远不会出现 Belady 异常。\n\n如图 3.24 所示，页面访问顺序为 3,2,1,0,3,2,4,3,2,1,0,4。若采用 FIFO 置换算法，当分配的物理块为 3 个时，缺页次数为 9 次;当分配的物理块为 4 个时，缺页次数为 10 次。分配给进程的物理块增多，但缺页次数不减反增。\n\n最近最久未使用(LRU)置换算法\n​\t选择最近最长时间未访问过的页面予以淘汰，它认为过去一段时间内未访问过的页面，在最近的将来可能也不会被访问。该算法为每个页面设置一个访问字段，来记录页面自上次被访问以来所经历的时间，淘汰页面时选择现有页面中值最大的予以淘汰。\n再对上面的实例采用 LRU 算法进行页面置换，如图 3.25 所示。进程第一次对页面 2 访问时，将最近最久未被访问的页面 7 置换出去。然后在访问页面 3 时，将最近最久未使用的页面 1 换出。\n\n在图 3.25 中，前 5 次置换的情况与最佳置换算法相同，但两种算法并无必然联系。实际上，LRU 算法根据各页以前的情况，是“向前看”的，而最佳置换算法则根据各页以后的使用情况，是“向后看”的。\nLRU 算法的性能较好，但需要寄存器和栈的硬件支持。LRU 是堆栈类的算法。理论上可以证明， 堆栈类算法堆栈类算法 不可能出现 Belady 异常。FIFO 算法基于队列实现，不是堆栈类算法。\n时钟(CLOCK)置换算法\n​\tLRU 算法的性能接近于 OPT 算法，但实现起来比较困难，且开销大;FIFO 算法实现简单，但性能差。因此，操作系统的设计者尝试了很多算法，试图用比较小的开销接近 LRU 算法的性能，这类算法都是 CLOCK 算法的变体。因为算法要循环扫描缓冲区，像时钟的指针一样转动，所以称为 CLOCK 算法。\n​\t简单的 CLOCK 算法给每帧关联一个附加位，称为 使用位使用位 。当某页首次装入主存时，将该帧的使用位设置为 1;当该页随后再被访问到时，其使用位也被置为 1。对于页替换算法，用于替换的候选帧集合可视为一个循环缓冲区，并有一个指针与之相关联。当某一页被替换时，该指针被设置成指向缓冲区中的下一帧。当需要替换一页时，操作系统扫描缓冲区，以查找使用位被置为 0 的一帧。每当遇到一个使用位为 1 的帧时，操作系统就将该位重新置为 0;若在这个过程开始时，缓冲区中所有帧的使用位均为 0，则选择遇到的第一个帧替换;若所有帧的使用位均为 1,则指针在缓冲区中完整地循环一周，把所有使用位都置为 0，并停留在最初的位置上，替换该帧中的页。由于该算法循环检查各页面的情况，因此称 算法 CLOCK 算法 ，又称 最近未用 (Not RecentlyUsed，NRU）算法。\n​\tCLOCK 算法的性能比较接近 LRU 算法，而通过增加使用的位数目，可以使得 CLOCK 算法更加高效。在使用位的基础上再增加一个修改位，则得到改进型 CLOCK 置换算法。这样，每帧都处于以下 4 种情况之一:\n\n\n最近未被访问，也未被修改（u = 0,m = 0)\n\n\n最近被访问，但未被修改(u = 1,m = 0)\n\n\n最近未被访问，但被修改（u = 0, m = 1)\n\n\n最近被访问，被修改(u = 1, m= 1)\n\n\n算法执行如下操作步骤:\n\n\n从指针的当前位置开始，扫描帧缓冲区。在这次扫描过程中，对使用位不做任何修改。选择遇到的第一个帧（u =0, m = 0）用于替换。\n\n\n若第 1）步失败，则重新扫描，查找(u=0,m= 1)的帧。选择遇到的第一个这样的帧用于替换。在这个扫描过程中，对每个跳过的帧，把它的使用位设置成 0。\n\n\n若第 2）步失败，则指针将回到它的最初位置，且集合中所有帧的使用位均为 0。重复第 1）步，并且若有必要，重复第 2）步，以便可以找到供替换的帧。\n\n\n改进型 CLOCK 算法优于简单 CLOCK 算法的地方在于替换时首选没有变化的页。由于修改过的页在被替换之前必须写回，因而这样做会节省时间。\n有些读者会认为 CLOCK 算法和改进型 CLOCK 算法记忆起来不易。为方便记忆，我们将其总结如下。\n操作系统中任何经过优化而有效的页面置换算法都有一个原则，即尽可能保留曾经使用过的页面，而淘汰未使用的页面，认为这样可以在总体上减少换页次数。CLOCK 算法只考虑到是否被访问过，因此被访问过的当然尽可能留下，未使用过的就淘汰;而改进型 CLOCK 算法对使用过的页面又做了细分，分为使用过但未修改过和使用过且修改过。因此，若有未使用过的页面，则当然首先把它换出，若全部页面都使用过，则当然优先把未修改过的页面换出。\n\n\n替换优先级（在前面的优先被替换）： 未修改 &gt; 未使用 &gt; 修改\n\n\n为帮助读者理解，这里举一个例子。假设系统给某进程分配了 5 个页框，刚开始，进程依次访问 1,3,4,2,5 号页面，系统会将这些页面连成一个循环队列，刚开始扫描指针指向第一个被访问的页面(即 1 号页)，如图 3.26 所示。\n\n图 3.26 中，小括号内的数字就是使用位。接下来，若进程请求访问 6 号页面，则由于此时分配给进程的 5 个页框都被使用，因此必须选择一个页面置换出去。按照 CLOCK 置换算法的规则，在第一轮扫描中，指针扫过的页面的使用位应置为 0。第一轮扫描的过程如图 3.27 所示。\n\n第一轮扫描中，未找到使用位为 0 的页面，因此需要进行第二轮扫描。第二轮扫描中，1 号页面的使用位为 0，因此将 1 号页面换出，将 6 号页面换入，将 6 号页的访问位设置为 1，并将扫描指针后移（若下次需要换出页面，则从 3 号页面开始扫描)，如图 3.28 所示。\n注意一个小细节:假设 1 号页面原先占有的是 x 号物理块(页框)，则 6 号页面换入内存后也放在 x 号物理块中。\n\n页面分配策略\n驻留集大小\n对于分页式的虚拟内存，在进程准备执行时，不需要也不可能把一个进程的所有页都读入主存。因此，操作系统必须决定读取多少页，即决定给特定的进程分配几个页框。给一个进程分配的物理页框的集合就是这个进程的驻留集 。需要考虑以下几点:\n\n\n分配给一个进程的存储量越小，任何时候驻留在主存中的进程数就越多，从而可以提高处理机的时间利用效率。\n\n\n若一个进程在主存中的页数过少，则尽管有局部性原理，页错误率仍然会相对较高。\n\n\n若页数过多，则由于局部性原理，给特定的进程分配更多的主存空间对该进程的错误率没有明显的影响。\n\n\n基于这些因素，现代操作系统通常采用三种策略:\n\n\n固定分配局部置换 。它为每个进程分配一定数目的物理块，在整个运行期间都不改变。若进程在运行中发生缺页，则只能从该进程在内存中的页面中选出一页换出，然后调入需要的页面。实现这种策略时，难以确定应为每个进程分配的物理块数目:太少会频繁出现缺页中断，太多又会使 CPU 和其他资源利用率下降。\n\n\n可变分配全局置换 。这是最易于实现的物理块分配和置换策略，它为系统中的每个进程分配一定数目的物理块，操作系统自身也保持一个空闲物理块队列。当某进程发生缺页时，系统从空闲物理块队列中取出一个物理块分配给该进程，并将欲调入的页装入其中。这种方法比固定分配局部置换更加灵活，可以动态增加进程的物理块，但也存在弊端如它会盲目地给进程增加物理块，从而导致系统多道程序的并发能力下降。\n\n\n可变分配局部置换 。它为每个进程分配一定数目的物理块，当某个进程发生缺页时，只允许从该进程在内存的页面中选出一页换出，因此不会影响其他进程的运行。若进程在运行中频繁地缺页，则系统再为该进程分配若干物理块，直至该进程缺页率趋于适当程度;反之，若进程运行中的缺页率特别低，则可适当减少分配给该进程的物理块。比起可变分配全局置换，这种方法不仅可以动态增加进程物理块的数量，还能动态减少进程物理块的数量，在保证进程不会过多地调页的同时，也保持了系统的多道程序并发能力。当然它需要更复杂的实现，也需要更大的开销，但对比频繁地换入/换出所浪费的计算机资源，这种牺牲是值得的。\n\n\n\n\n\n\n\n\n\n\n\n页面分配策略在 2015 年的统考选择题中出现过，考查的是这三种策略的名称。往年很多读者看到这里时，由于认为不是重点，复习时便一带而过，最后在考试中失分。在这种基础题上失分是十分可惜的。再次提醒读者，考研成功的秘诀在于“反复多次”和“全面”。\n调入页面的时机\n为确定系统将进程运行时所缺的页面调入内存的时机，可采取以下两种调页策略:\n\n\n预调页策略。根据局部性原理，一次调入若干相邻的页可能会比一次调入一页更高效。但若调入的一批页面中大多数都未被访问，则又是低效的。因此，需要采用以预测为基础的预调页策略，将预计在不久之后便会被访问的页面预先调入内存。但目前预调页的成功率仅约 50%。因此这种策略主要用于进程的首次调入，由程序员指出应先调入哪些页。\n\n\n请求调页策略。进程在运行中需要访问的页面不在内存而提出请求，由系统将所需页面调入内存。由这种策略调入的页一定会被访问，且这种策略比较易于实现，因此在目前的虚拟存储器中大多采用此策略。它的缺点是每次只调入一页，调入/调出页面数多时会花费过多的 IO 开销。\n\n\n预调入实际上就是运行前的调入，请求调页实际上就是运行期间调入。一般情况下，两种调页策略会同时使用。\n从何处调入页面\n请求分页系统中的外存分为两部分:用于存放文件的文件区和用于存放对换页面的对换区。对换区通常采用连续分配方式，而文件区采用离散分配方式，因此对换区的磁盘 IO 速度比文件区的更快。这样，从何处调入页面就存在三种情况:\n\n\n系统拥有足够的对换区空间。可以全部从对换区调入所需页面，以提高调页速度。为此，在进程运行前，需将与该进程有关的文件从文件区复制到对换区。\n\n\n系统缺少足够的对换区空间。凡不会被修改的文件都直接从文件区调入;而当换出这些页面时，由于它们未被修改而不必再将它们换出。但对于那些可能被修改的部分，在将它们换出时须调到对换区，以后需要时再从对换区调入（因为读的速度比写的速度快)\n\n\nUNIX 方式。与进程有关的文件都放在文件区，因此未运行过的页面都应从文件区调入曾经运行过但又被换出的页面，由于放在对换区，因此下次调入时应从对换区调入。进程请求的共享页面若被其他进程调入内存，则无须再从对换区调入。\n\n\n抖动\n​\t在页面置换过程中，一种最糟糕的情形是，刚刚换出的页面马上又要换入主存，刚刚换入的页面马上又要换出主存，这种频繁的页面调度行为称为抖动或颠簸。若一个进程在换页上用的时间多于执行时间，则这个进程就在颠簸。\n​\t频繁发生缺页中断(抖动）的主要原因是，某个进程频繁访问的页面数目高于可用的物理页帧数目。虚拟内存技术可在内存中保留更多的进程以提高系统效率。在稳定状态，几乎主存的所有空间都被进程块占据，处理机和操作系统可以直接访问到尽可能多的进程。然而，如果管理不当，那么处理机的大部分时间都将用于交换块，即请求调入页面的操作，而不是执行进程的指令，因此会大大降低系统效率。\n工作集\n工作集是指在某段时间间隔内，进程要访问的页面集合。基于局部性原理，可以用最近访问过的页面来确定工作集。一般来说，工作集 W 可由时间 t 和工作集窗口大小 △ 来确定。例如，某进程对页面的访问次序如下:\n\n地址翻译\n本小节引入一个实例来说明虚实地址的变换过程，考虑到统考试题近来出现了学科综合的趋势，这里结合“计算机组成原理”中的 Cache 部分进行讲解。对于不参加统考的读者，可以看到翻译出实地址为止，对于参加统考却还没有复习计算机组成原理的读者，可在复习完“计算机组成原理”后，再回来看本章的内容。\n设某系统满足以下条件:\n\n本章小结\n为什么要引入虚拟内存?\n上一节提到过，多道程序并发执行不仅使进程之间共享了处理器，而且同时共享了主存。然而，随着对处理器需求的增长，进程的执行速度会以某种合理平滑的方式慢下来。但是，若同时运行的进程太多，则需要很多的内存，当一个程序没有内存空间可用时，那么它甚至无法运行。所以，在物理上扩展内存相对有限的条件下，应尝试以一些其他可行的方式在逻辑上扩充内存。\n虚拟内存（虚存）空间的大小由什么因素决定?\n虚存的容量要满足以下两个条件:\n​\t① 虚存的实际容量 ≤ 内存容量和外存容量之和，这是硬件的硬性条件规定的，若虚存的实际容量超过了这个容量，则没有相应的空间来供虚存使用。\n​\t② 虚存的最大容量 ≤ 计算机的地址位数能容纳的最大容量。假设地址是 32 位的，按字节编址，一个地址代表 1B 存储空间，则虚存的最大容量 ≤4GB( 232 B)。这是因为若虚存的最大容量超过 4GB，则 32 位的地址将无法访问全部虚存，也就是说 4GB 以后的空间被浪费了，相当于没有一样，没有任何意义。\n实际虚存的容量是取条件 ① 和 ② 的交集，即两个条件都要满足，仅满足一个条件是不行的。\n虚拟内存是怎么解决问题的?会带来什么问题?\n​\t虚拟内存使用外存上的空间来扩充内存空间，通过一定的换入/换出，使得整个系统在逻辑上能够使用一个远远超出其物理内存大小的内存容量。因为虚拟内存技术调换页面时需要访问外存，会导致平均访存时间增加，若使用了不合适的替换算法，则会大大降低系统性能。\n​\t本节学习了 4 种页面置换算法，要把它们与处理机调度算法区分开。当然，这些调度算法之间也是有联系的，它们都有一个共同点，即通过一定的准则决定资源的分配对象。在处理机调度算法中这些准则比较多，有优先级、响应比、时间片等，而在页面调度算法中就比较简单，即是否被用到过或近段时间内是否经常使用。在操作系统中，几乎每类资源都会有相关的调度算法，读者通过将这些调度算法作为线索，可把整个操作系统的课程连成一个整体。\n本章疑难点\n分页管理方式和分段管理方式在很多地方是相似的，比如在内存中都是不连续的、都有地址变换机构来进行地址映射等。但两者也存在许多区别，表 3.7 列出了分页管理方式和分段管理方式各方面的对比。\n\n文件管理\n【考纲内容】\n(一）文件系统基础\n\n\n文件的概念\n\n\n文件的逻辑结构: 文件元数据文件元数据 和索引节点（inode）\n\n\n文件的操作（建立，删除，打开，关闭，读，写）\n\n\n文件的保护\n\n\n文件的逻辑结构\n\n\n文件的物理结构\n\n\n(二）目录\n\n\n目录的基本概念\n\n\n树形目录\n\n\n目录的操作目录的操作\n\n\n硬链接和软链接\n\n\n(二）文件系统\n\n\n文件系统的全局结构文件系统的全局结构 (layout)（文件系统在外存中的结构，文件系统在内存中的结构）\n\n\n外存空闲空间管理办法\n\n\n虚拟文件系统虚拟文件系统\n\n\n文件系统挂载文件系统挂载 (mounting)\n\n\n\n\n概念——定义、属性、基本操作、打开与关闭\n\n\n文件逻辑结构\n\n无结果文件（流式文件）\n有结构文件(记录式文件)\n\n顺序文件\n索引文件\n索引顺序文件\n\n\n\n\n\n目录结构\n\n文件控制块（FCB）、索引结点\n单级目录结构、两级目录结构、树形目录结构、图形目录结构\n\n\n\n文件共享\n\n基于索引结点（硬链接)\n利用符号链实现(软链接)\n\n\n\n文件保护————访问类型、访问控制\n\n\n实现\n\n层次结构\n目录实现————线性列表、哈希表\n文件分配\n\n连续分配\n链接分配\n索引分配————索引链接、多层索引、混合索引\n\n\n文件存储空间管理\n\n空闲表法\n空闲链表法\n位示图法成组链接法\n\n\n\n\n\n磁盘\n\n访问时间——寻道时间、延迟时间、传输时间\n调度算法\n\n先来先服务（FCFS)————公平\n最短寻找时间优先(SSTF)————“饥饿”现象\n扫描算法(SCAN)\n循环扫描(C-SCAN)\n\n\n磁盘的管理————初始化、引导块、坏块\n\n\n\n【复习提示】\n本章内容较为具体，要注意对概念的理解。重点掌握文件系统的结构及其实现、磁盘的相关知识点等。要掌握文件系统的文件控制块、物理分配方法、索引结构，以及磁盘特性和结构、磁盘调度算法，能分析磁盘相关的性能等。这些都是综合题易考查的内容。\n文件系统基础\n在学习本节时，请读者思考以下问题:\n1）什么是文件?什么是文件系统?\n2）文件系统要完成哪些功能?\n本节内容较为抽象，对于初学者，推荐配合相关教材的相关章节进行学习。学习过程中要注意区分文件的逻辑结构和物理结构，不要把二者混为一谈。在读者的学习过程中，可尝试以上面的两个问题为线索，构建整个文件系统的概念，先思考有什么方法可以实现文件的共享和保护，再将自己的方法与书上的方法相比较。\n在前面的学习中，曾经提醒过读者不要忽略对基本概念的理解。操作系统这门课程在统考中算是比较容易得分的一门课程，从历年的情况来看，大部分同学对进程管理、内存管理有较好的掌握，但对于文件管理及下一章的 IO 管理，往往理解不太深入，记忆不太牢固，在考试中，即使面对一些关于本章内容的基本问题也容易失分，这十分可惜。主要原因还是对概念的理解不够全面和透彻，希望各位读者能够关注这个问题。\n文件的概念\n文件的定义\n​\t文件(File）是操作系统中的一个重要概念。文件是以计算机硬盘为载体的存储在计算机上的信息集合，文件可以是文本文档、图片、程序等。在系统运行时，计算机以进程为基本单位进行资源的调度和分配;而在用户进行的输入、输出中，则以文件为基本单位。大多数应用程序的输入都是通过文件来实现的，其输出也都保存在文件中，以便信息的长期存储及将来的访问。当用户将文件用于应用程序的输入、输出时，还希望可以访问文件、修改文件和保存文件等，实现对文件的维护管理，这就需要系统提供一个文件管理系统，操作系统中的 文件系统文件系统 (File System)就是用于实现用户的这些管理要求的。\n​\t要清晰地理解文件的概念，就要了解文件究竟由哪些东西组成。\n​\t首先，文件中肯定包括一块存储空间，更准确地说，是存储空间中的数据;其次，由于操作系统要管理成千上万的数据，因此必定需要对这些数据进行划分，然后贴上“标签”，以便于分类和索引，所以文件必定包含分类和索引的信息;最后，不同的用户拥有对数据的不同访问权限，因此文件中一定包含一些关于访问权限的信息。\n​\n​\t再举生活中的一个直观例子来类比文件，相信读者了解这个例子后会更深入地了解文件。这个例子就是图书馆中的书，可以认为，计算机中的一个文件相当于图书馆中的一本书，操作系统管理文件，相当于图书管理员管理图书馆中的书。\n​\t首先，一本书的主体一定是书中的内容，相当于文件中的数据;其次，不同类别的书需要放在不同的书库，然后加上编号，再把编号登记在图书管理系统中，方便读者查阅，相当于文件的分类和查找;最后，有些已经绝版或价格比较高的外文书籍，只能借给 VIP 会员或权限比较高的其他读者，而有些普通的书籍可供任何人借阅，这就是文件中的访问权限。\n​\t所举的例子与实际操作系统中的情形并不绝对等价，读者应能找出类比中的不严谨之处，但对于某些关键的属性，图书馆管理图书和操作系统管理文件的思想却有相一致的地方，因此通过这种类比可使初学者快速认识陌生的概念。\n​\t从用户的角度看，文件系统是操作系统的重要部分之一。用户关心的是如何命名、分类和查找文件，如何保证文件数据的安全性及对文件可以进行哪些操作等。而对其中的细节，如文件如何存储在辅存上、如何管理文件辅存区域等关心甚少。\n​\t文件系统提供了与二级存储相关的资源的抽象，让用户能在不了解文件的各种属性、文件存储介质的特征及文件在存储介质上的具体位置等情况下，方便快捷地使用文件。\n​\t用户通过文件系统建立文件，提供应用程序的输入、输出，对资源进行管理。首先了解文件的结构，我们通过自底向上的方式来定义。\n\n\n数据项。数据项是文件系统中最低级的数据组织形式，可分为以下两种类型:\n\n\n基本数据项。用于描述一个对象的某种属性的一个值，如姓名、日期或证件号等，是数据中可命名的最小逻辑数据单位，即原子数据。\n\n\n组合数据项。由多个基本数据项组成。\n\n\n\n\n记录。记录是一组相关的数据项的集合，用于描述一个对象在某方面的属性，如一名考生的报名记录包括考生姓名、出生日期、报考学校代号、身份证号等一系列域。\n\n\n文件。文件是指由创建者所定义的一组相关信息的集合，逻辑上可分为有结构文件和无结构文件两种。在有结构文件中，文件由一组相似的记录组成，如报考某学校的所有考生的报考信息记录，又称记录式文件;而无结构文件则被视为一个字符流，比如一个二进制文件或字符文件，又称流式文件。\n\n\n​\t虽然上面给出了结构化的表达，它使用了NJ大#制代码来表示文件的基本访问单元，这个基本访问单元可以是字节、行或程序和数据组织成文件。文件可以被定位、读取和修改，并且支持可控制的进程间共享访问，允许多个进程共同操作。这些文件可以被组织成记录，允许对数据进行结构化处理。文件可以长期存储于硬盘或其他二级存储器中\n文件的属性\n文件具有一定的属性，系统不同，属性也会有所不同，但通常都包括如下属性。\n\n\n名称 。文件名称唯一，以容易读取的形式保存。\n\n\n标识符 。标识文件系统内文件的唯一标签，通常为数字，是对人不可读的一种内部名称。\n\n\n类型 。被支持不同类型的文件系统所使用。\n\n\n位置 。指向设备和设备上文件的指针。\n\n\n大小 。文件当前大小（用字节、字或块表示)，也可包含文件允许的最大值。\n\n\n保护 。对文件进行保护的访问控制信息。\n\n\n时间、日期和用户标识 。文件创建、上次修改和上次访问的相关信息，用于保护和跟踪文件的使用。\n\n\n所有文件的信息都保存在目录结构中，而目录结构保存在外存上。文件信息在需要时才调入内存。通常，目录条目包括文件名称及其唯一的标识符，而标识符定位其他属性的信息。\n文件的基本操作\n文件属于抽象数据类型。为了恰当地定义文件，需要考虑有关文件的操作。操作系统提供系统调用，它对文件进行创建、写、读、重定位、删除和截断等操作。\n\n\n创建文件 。创建文件有两个必要步骤:一是在文件系统中为文件找到空间;二是在目录中为新文件创建条目，该条目记录文件名称、在文件系统中的位置及其他可能的信息。\n\n\n写文件 。为了写文件，执行一个系统调用，指明文件名称和要写入文件的内容。对于给定文件名称，系统搜索目录以查找文件位置。系统必须为该文件维护一个写位置的指针。每当发生写操作时，便更新写指针。\n\n\n读文件 。为了读文件，执行一个系统调用，指明文件名称和要读入文件块的内存位置。同样，需要搜索目录以找到相关目录项，系统维护一个读位置的指针。每当发生读操作时，更新读指针。一个进程通常只对一个文件读或写，因此当前操作位置可作为每个进程当前文件位置的指针。由于读和写操作都使用同一指针，因此节省了空间，也降低了系统复杂度。\n\n\n文件重定位 (文件寻址)。按某条件搜索目录，将当前文件位置设为给定值，并且不会读、写文件。\n\n\n删除文件 。先从目录中找到要删除文件的目录项，使之成为空项，然后回收该文件所占用的存储空间。\n\n\n截断文件 。允许文件所有属性不变，并删除文件内容，即将其长度设为 0 并释放其空间。这 6 个基本操作可以组合起来执行其他文件操作。例如，一个文件的复制，可以创建新文件、从旧文件读出并写入新文件。\n\n\n这 6 个基本操作可以组合起来执行其他文件操作。例如，一个文件的复制，可以创建新文件、从旧文件读出并写入新文件。\n文件的打开与关闭\n​\t因为许多文件操作都涉及为给定文件搜索相关目录条目，因此许多系统要求在首次使用文件时，使用系统调用 open 将指明文件的属性 (包括该文件在外存上的物理位置)从外存复制到内存打开文件表的一个表目中，并将该表目的编号（也称索引）返回给用户。操作系统维护一个包含所有打开文件信息的表(打开文件表，open-file table)。当用户需要一个文件操作时，可通过该表的一个索引指定文件，因此省略了搜索环节。当文件不再使用时，进程可以关闭它，操作系统从打开文件表中删除这一条目。\n​\t大部分操作系统要求在文件使用之前就被显式地打开。操作 open 会根据文件名搜索目录，并将目录条目复制到打开文件表。若调用 open 的请求（创建、只读、读写、添加等）得到允许，则进程就可打开文件，而 open 通常返回一个指向打开文件表中的一个条目的指针。通过使用该指针（而非文件名）进行所有 IO 操作，以简化步骤并节省资源。\n\n\n\n\n\n\n\n\n\n注意，在 open 调用完成后，操作系统对该文件的任何操作都不再需要文件名，而只需要 open 调用返回的指针。\n​\t整个系统表包含进程相关信息，如文件在磁盘的位置、访问日期和大小。一个进程打开一个文件，系统打开文件表就会为打开的文件增加相应的条目。当另一个进程执行 open 时，只不过是在其进程打开表中增加一个条目，并指向整个系统表的相应条目。通常，系统打开文件表的每个文件时，还用一个文件打开计数器（Open Count)，以记录多少进程打开了该文件。每个关闭操作 close 使 count 递减，当打开计数器为 0 时，表示该文件不再被使用，系统将回收分配给该文件的内存空间等资源。若文件被修改过，则将文件写回外存，并将系统打开文件表中的相应条目删除，最后释放文件的文件控制块（File Control Block，FCB)。\n每个打开文件都有如下关联信息:\n\n\n文件指针。系统跟踪上次的读写位置作为当前文件位置的指针，这种指针对打开文件的某个进程来说是唯一的，因此必须与磁盘文件属性分开保存。\n\n\n文件打开计数。文件关闭时，操作系统必须重用其打开文件表条目，否则表内空间会不够用。因为多个进程可能打开同一个文件，所以系统在删除打开文件条目之前，必须等待最后一个进程关闭文件。计数器跟踪打开和关闭的数量，计数为 0 时，系统关闭文件，删除该条目。\n\n\n文件磁盘位置。绝大多数文件操作都要求系统修改文件数据。该信息保存在内存中，以免为每个操作都从磁盘中读取。\n\n\n访问权限。每个进程打开文件都需要有一个访问模式（创建、只读、读写、添加等)。该信息保存在进程的打开文件表中，以便操作系统能够允许或拒绝之后的 I/O 请求。\n\n\n文件的逻辑结构\n​\t文件的逻辑结构是从用户观点出发看到的文件的组织形式。文件的物理结构(又称文件的存储结构，见 4.2.1 节）是从实现观点出发看到的文件在外存上的存储组织形式。文件的逻辑结构与存储介质特性无关，但文件的物理结构与存储介质的特性有很大关系。文件的逻辑结构实际上是指在文件的内部，数据逻辑上是如何组织起来的。\n按逻辑结构，文件可划分为无结构文件和有结构文件两种。\n无结构文件（流式文件)\n​\t无结构文件是最简单的文件组织形式。无结构文件将数据按顺序组织成记录并积累、保存，它是有序相关信息项的集合，以字节(Byte）为单位。由于无结构文件没有结构，因而对记录的访问只能通过穷举搜索的方式，因此这种文件形式对大多数应用不适用。但字符流的无结构文件管理简单，用户可以方便地对其进行操作。所以，那些对基本信息单位操作不多的文件较适于采用字符流的无结构方式，如源程序文件、目标代码文件等。\n有结构文件（记录式文件)\n有结构文件按记录的组织形式可以分为如下几种:\n\n\n顺序文件。文件中的记录一个接一个地顺序排列，记录通常是定长的，可以顺序存储或以链表形式存储，在访问时需要顺序搜索文件。顺序文件有以下两种结构:第一种是串结构，记录之间的顺序与关键字无关。通常的办法是由时间决定，即按存入时间的先后排列，最先存入的记录作为第 1 条记录，其次存入的为第 2 条记录，以此类推。第二种是顺序结构，指文件中的所有记录按关键字顺序排列。\n\n\n在对记录进行批量操作，即每次要读或写一大批记录时，顺序文件的效率是所有逻辑文件中最高的;此外，也只有顺序文件才能存储在磁带上，并能有效地工作，但顺序文件对查找、修改、增加或删除单条记录的操作比较困难。\n\n\n索引文件。索引文件示意图如图 4.1 所示。对于定长记录文件，要查找第 i 条记录,可直接根据下式计算得到第 i 条记录相对于第 1 条记录的地址:\n\n\nA_i=i×L\n\n然而，对于可变长记录的文件，要查找第 i 条记录，必须顺序地查找前 i –1 条记录，从而获得相应记录的长度 L，进而按下式计算出第 � 条记录的首址:\nAi=∑i=0i−1Li+1A_i = \\sum_{i=0}^{i-1} L_i + 1\nA​i​​=​i=0​∑​i−1​​L​i​​+1\n注意:假定每条记录前用一个字节指明该记录的长度。\n​\t变长记录文件只能顺序查找，系统开销较大。为此，可以建立一张索引表以加快检索速度，索引表本身是定长记录的顺序文件。在记录很多或访问要求高的文件中，需要引入索引以提供有效的访问。实际中，通过索引可以成百上千倍地提高访问速度。\n\n\n\n索引顺序文件。索引顺序文件是顺序和索引两种组织形式的结合。索引顺序文件将顺序文件中的所有记录分为若干组，为顺序文件建立一张索引表，在索引表中为每组中的第一条记录建立一个索引项，其中含有该记录的关键字值和指向该记录的指针。\n\n\n如图 4.2 所示，主文件名包含姓名和其他数据项。姓名为关键字，索引表中为每组的第一条记录（不是每条记录）的关键字值，用指针指向主文件中该记录的起始位置。索引表只包含关键字和指针两个数据项，所有姓名关键字递增排列。主文件中记录分组排列，同一个组中的关键字可以无序，但组与组之间的关键字必须有序。查找一条记录时，首先通过索引表找到其所在的组，然后在该组中使用顺序查找，就能很快地找到记录。\n\n对于含有 N 条记录的顺序文件，查找某关键字值的记录时，平均需要查找 N/2 次。在索引顺序文件中，假设 N 条记录分为 N\\sqrt{N}√​N​​​组，索引表中有N\\sqrt{N}√​N​​​个表项，每组有N\\sqrt{N}√​N​​​条记录,在查找某关键字值的记录时，先顺序查找索引表，需要查找 N2\\frac{\\sqrt{N}}{2}​2​​√​N​​​​​次，然后在主文件中对应的组中顺序查找，也需要查找 N2\\frac{\\sqrt{N}}{2}​2​​√​N​​​​​ 次，因此共需查找N2\\frac{\\sqrt{N}}{2}​2​​√​N​​​​​+N2\\frac{\\sqrt{N}}{2}​2​​√​N​​​​​=N\\sqrt{N}√​N​​​ 次。显然，索引顺序文件提高了查找效率，若记录数很多，则可采用两级或多级索引。\n索引文件和索引顺序文件都提高了存取的速度，但因为配置索引表而增加了存储空间。\n\n\n直接文件或散列文件（Hash File)。给定记录的键值或通过散列函数转换的键值直接决定记录的物理地址。这种映射结构不同于顺序文件或索引文件，没有顺序的特性。\n\n\n散列文件有很高的存取速度，但是会引起冲突，即不同关键字的散列函数值相同。\n复习了数据结构的读者读到这里时，会有这样的感觉:有结构文件逻辑上的组织，是为在文件中查找数据服务的（顺序查找、索引查找、索引顺序查找、哈希查找)。\n目录结构\n​\t与文件管理系统和文件集合相关联的是文件目录，它包含有关文件的信息如属性、位置和所有权等，这些信息主要由操作系统进行管理。首先我们来看目录管理的基本要求:从用户的角度看，目录在用户(应用程序）所需要的文件名和文件之间提供一种映射，所以目录管理要实现“按名存取”;目录存取的效率直接影响到系统的性能，所以要提高对目录的检索速度;在共享系统中，目录还需要提供用于控制访问文件的信息。此外，文件允许重名也是用户的合理和必然要求,目录管理通过树形结构来解决和实现。\n​\t前面介绍了文件内部的逻辑结构，下面介绍多个文件之间在逻辑上是如何组织的，这实际上是文件“外部”的逻辑结构的问题。\n文件控制块和索引结点\n​\t与进程管理一样，为实现目录管理，操作系统中引入了文件控制块的数据结构。\n\n\n文件控制块。文件控制块（FCB）是用来存放控制文件需要的各种信息的数据结构以实现“按名存取”。FCB 的有序集合称为文件目录，一个 FCB 就是一个文件目录项为了创建一个新文件，系统将分配一个 FCB 并存放在文件目录中，成为目录项。\n\n\nFCB 主要包含以下信息:\n\n\n基本信息，如文件名、文件的物理位置、文件的逻辑结构、文件的物理结构等。\n\n\n存取控制信息，如文件存取权限等。\n\n\n使用信息，如文件建立时间、修改时间等。\n\n\n\n\n索引结点。在检索目录文件的过程中，只用到了文件名，仅当找到一个目录项（查找文件名与目录项中文件名匹配）时，才需要从该目录项中读出该文件的物理地址。也就是说，在检索目录时，文件的其他描述信息不会用到，也不需要调入内存。因此，有的系统（如 UNIX，见表 4.1）采用了文件名和文件描述信息分开的方法，文件描述信息单独形成一个称为索引结点的数据结构，简称 i 结点。在文件目录中的每个目录项仅由文件名和指向该文件所对应的 i 结点的指针构成。\n\n\n\n一个 FCB 的大小是 64B，盘块大小是 1KB，因此在每个盘块中可以存放 16 个 FCB(注意，FCB 必须连续存放)。而在 UNIX 系统中，一个目录项仅占 16B，其中 14B 是文件名，2B 是 i 结点指针。在 1KB 的盘块中可存放 64 个目录项。这样，就可使查找文件时的平均启动磁盘次数减少到原来的 1/4，大大节省了系统开销。\n存放在磁盘上的索引结点称为磁盘索引结点，UNIX 中的每个文件都有一个唯一的磁盘索引结点，主要包括以下几个方面:\n\n\n文件主标识符 ，拥有该文件的个人或小组的标识符。\n\n\n文件类型 ，包括普通文件、目录文件或特别文件。文件存取权限，各类用户对该文件的存取权限。\n\n\n文件物理地址 ，每个索引结点中含有 13 个地址项，即 iaddr(O)一 iaddr(12)，它们以直接或间接方式给出数据文件所在盘块的编号。\n\n\n文件长度 ，以字节为单位。\n\n\n文件链接计数 ，在本文件系统中所有指向该文件的文件名的指针计数。\n\n\n文件存取时间 ，本文件最近被进程存取的时间、最近被修改的时间及索引结点最近被修改的时间。\n\n\n文件被打开时，磁盘索引结点复制到内存的索引结点中，以便于使用。在内存索引结点中又增加了以下内容:\n\n\n索引结点编号，用于标识内存索引结点。\n\n\n状态，指示 i 结点是否上锁或被修改。\n\n\n访问计数，每当有一进程要访问此 i 结点时，计数加 1，访问结束减 1。\n\n\n逻辑设备号，文件所属文件系统的逻辑设备号。\n\n\n链接指针，设置分别指向空闲链表和散列队列的指针。\n\n\nFCB 或索引结点相当于图书馆中图书的索书号，我们可以在图书馆网站上找到图书的索书号，然后根据索书号找到想要的书本。\n目录结构\n在理解一个文件系统的需求前，我们首先考虑在目录这个层次上所需要执行的操作，这有助于后面文件系统的整体理解。\n\n\n搜索。当用户使用一个文件时，需要搜索目录，以找到该文件的对应目录项。\n\n\n创建文件。当创建一个新文件时，需要在目录中增加-个目录项。\n\n\n删除文件。当删除一个文件时，需要在目录中删除相应的目录项。\n\n\n显示目录。用户可以请求显示目录的内容，如显示该用户目录中的所有文件及属性。\n\n\n修改目录。某些文件属性保存在目录中，因而这些属性的变化需要改变相应的目录项。操作时，考虑以下几种目录结构:\n\n\n操作时，考虑以下几种目录结构:\n\n\n单级目录结构单级目录结构 。在整个文件系统中只建立一张目录表，每个文件占一个目录项，如图 4.3 所示。\n\n\n\n​\t当访问一个文件时，先按文件名在该目录中查找到相应的 FCB，经合法性检查后执行相应的操作。当建立一个新文件时，必须先检索所有目录项以确保没有“重名”的情况，然后在该目录中增设一项，把 FCB 的全部信息保存在该项中。当删除一个文件时，先从该目录中找到该文件的目录项，回收该文件所占用的存储空间，然后清除该目录项。\n​\t单级目录结构实现了“按名存取”，但是存在查找速度慢、文件不允许重名、不便于文件共享等缺点，而且对于多用户的操作系统显然是不适用的。\n\n\n两级目录结构。单级目录很容易造成文件名称的混淆，因此可以考虑采用两级方案,将文件目录分成主文件目录(Master File Directory，MFD）和用户文件目录（User FileDirectory, UFD)两级，如图 4.4 所示。\n\n\n​\t主文件目录项记录用户名及相应用户文件目录所在的存储位置。用户文件目录项记录该用户文件的 FCB 信息。当某用户欲对其文件进行访问时，只需搜索该用户对应的 UFD，这既解决了不同用户文件的“重名”问题，又在一定程度上保证了文件的安全。\n​\t两级目录结构可以解决多用户之间的文件重名问题，文件系统可以在目录上实现访问限制。但是两级目录结构缺乏灵活性，不能对文件分类。\n\n\n\n多级目录结构（树形目录结构)。将两级目录结构的层次关系加以推广，就形成了多级目录结构，即树形目录结构，如图 4.5 所示。\n\n\n​\t用户要访问某个文件时，用文件的路径名标识文件，文件路径名是个字符串，由从根目录出发到所找文件通路上所有目录名与数据文件名用分隔符“/”链接而成。从根目录出发的路径称为绝对路径。当层次较多时，每次从根目录查询会浪费时间，于是加入了当前目录(又称工作目录)，进程对各文件的访问都是相对于当前目录进行的。当用户要访问某个文件时，使用相对路径标识文件，相对路径由从当前目录出发到所找文件通路上所有目录名与数据文件名用分隔符“/”链接而成。\n\n图 4.5 是 Linux 操作系统的目录结构,”/dev/hda”就是一个绝对路径。若当前目录为“/bin”,则“./1s”就是一个相对路径，其中符号“.”表示当前工作目录。\n​\t通常，每个用户都有各自的“当前目录”，登录后自动进入该用户的“当前目录”。操作系统提供一条专门的系统调用，供用户随时改变“当前目录”。例如，在 UNIX 系统中，”/etc/passwd”文件就包含有用户登录时默认的“当前目录”，可用 cd 命令改变“当前目录”。\n​\t树形目录结构可以很方便地对文件进行分类，层次结构清晰，也能够更有效地进行文件的管理和保护。但是，在树形目录中查找一个文件时，需要按路径名逐级访问中间结点，这就增加了磁盘访问次数，无疑将影响查询速度。\n\n\n无环图目录结构。树形目录结构能便于实现文件分类，但不便于实现文件共享，为此在树形目录结构的基础上增加了一些指向同一结点的有向边，使整个目录成为一个有向无环图。引入无环图目录结构是为了实现文件共享，如图 4.6 所示。\n\n\n\n当某用户要求删除一个共享结点时，若系统只是简单地将它删除，则当另一共享用户需要访问时，会因无法找到这个文件而发生错误。为此，可为每个共享结点设置一个共享计数器，每当图中增加对该结点的共享链时，计数器加 1;每当某用户提出删除该结点时,计数器减 1。仅当共享计数器为 0 时，才真正删除该结点，否则仅删除请求用户的共享链。共享文件（或目录）不同于文件拷贝(副本)。若有两个文件拷贝，则每个程序员看到的是拷贝而不是原件;然而，若一个文件被修改，则另一个程序员的拷贝不会改变。对于共享文件，只存在一个真正的文件，任何改变都会为其他用户所见。\n无环图目录结构方便地实现了文件的共享，但使得系统的管理变得更加复杂。\n文件共享\n文件共享使多个用户(进程）共享同一个文件，系统中只需保留该文件的一个副本。若系统不能提供共享功能，则每个需要该文件的用户都要有各自的副本，会造成对存储空间的极大浪费。随着计算机技术的发展，文件共享的范围已由单机系统发展到多机系统，进而通过网络扩展到全球。这些文件的分享是通过分布式文件系统、远程文件系统、分布式信息系统实现的。这些系统允许多个客户通过 C/S 模型共享网络中的服务器文件。\n现代常用的两种文件共享方法如下。\n基于索引结点的共享方式（硬链接)\n​\t在树形结构的目录中，当有两个或多个用户要共享一个子目录或文件时，必须将共享文件或子目录链接到两个或多个用户的目录中，才能方便地找到该文件，如图 4.7 所示。\n\n​\t在这种共享方式中，诸如文件的物理地址及其他的文件属性等信息，不再放在目录项中，而放在索引结点中。在文件目录中只设置文件名及指向相应索引结点的指针。在索引结点中还应有一个链接计数 count，用于表示链接到本索引结点（即文件)上的用户目录项的数目。当 count = 2 时，表示有两个用户目录项链接到本文件上，或者说有两个用户共享此文件。\n​\t用户 A 创建一个新文件时，它便是该文件的所有者，此时将 count 置为 1。用户 B 要共享此文件时，在用户 B 的目录中增加一个目录项，并设置一个指针指向该文件的索引结点。此时，文件主仍然是用户 A，count=2。用户 A 不再需要此文件，不能将文件直接删除。因为若删除了该文件，则必然也删除了该文件的索引结点，这样便会使用户 B 的指针悬空，而用户 B 可能正在此文件上执行写操作，此时用户 B 会无法访问到文件。因此用户 A 不能删除此文件，只是将该文件的 count 减 1，然后删除自己目录中的相应目录项。用户 B 仍可以使用该文件。当 count =0 时，表示没有用户使用该文件，系统将负责删除该文件。如图 4.8 给出了用户 B 链接到文件上的前、后情况。\n\n利用符号链实现文件共享（软链接)\n​\t为使用户 B 能共享用户 A 的一个文件 F，可以由系统创建一个 LINK 类型的新文件也取名为 F，并将文件 F 写入用户 B 的目录中，以实现用户 B 的目录与文件 F 的链接。在新文件中只包含被链接文件 F 的路径名。这样的链接方法被称为符号链接。\n新文件中的路径名只被视为符号链，当用户 B 要访问被链接的文件 F 且正要读 LINK 类新文件时，操作系统根据新文件中的路径名去读该文件，从而实现用户 B 对文件 F 的共享。\n​\t在利用符号链方式实现文件共享时，只有文件的拥有者才拥有指向其索引结点的指针而共享该文件的其他用户只有该文件的路径名，并不拥有指向其索引结点的指针。这样，也就不会发生在文件主删除一个共享文件后留下一个悬空指针的情况。当文件的拥有者把一个共享文件删除后，其他用户通过符号链去访问它时，会出现访问失败，于是将符号链删除，此时不会产生任何影响。当然，利用符号链实现文件共享仍然存在问题。例如，一个文件采用符号链方式共享，当文件拥有者将其删除，而在共享的其他用户使用其符号链接访问该文件之前，又有人在同一路径下创建了另一个具有同样名称的文件，则该符号链将仍然有效，但访问的文件已经改变，从而导致错误。\n​\t在符号链的共享方式中，当其他用户读共享文件时，需要根据文件路径名逐个地查找目录，直至找到该文件的索引结点。因此，每次访问时，都可能要多次地读盘，使得访问文件的开销变大并增加了启动磁盘的频率。此外，符号链的索引结点也要耗费一定的磁盘空间。\n符号链方式有一个很大的优点，即网络共享只需提供该文件所在机器的网络地址及该机器中的文件路径。\n​\t上述两种链接方式都存在一个共同的问题，即每个共享文件都有几个文件名。换言之，每增加一条链接，就增加一个文件名。这实质上是每个用户都使用自己的路径名去访问共享文件。当我们试图去遍历整个文件系统时，将会多次遍历到该共享文件。\n硬链接和软链接都是文件系统中的静态共享方法，在文件系统中还存在着另外的共享需求，即两个进程同时对同一个文件进行操作，这样的共享称为动态共享 。\n​\t可以这样说:文件共享，“软”“硬”兼施。硬链接就是多个指针指向一个索引结点，保证只要还有一个指针指向索引结点，索引结点就不能删除;软链接就是把到达共享文件的路径记录下来，当要访问文件时，根据路径寻找文件。可以想象，硬链接的查找速度要比软链接的快。\n文件保护\n​\t为了防止文件共享可能会导致文件被破坏或未经核准的用户修改文件，文件系统必须控制用户对文件的存取，即解决对文件的读、写、执行的许可问题。为此，必须在文件系统中建立相应的文件保护机制。\n​\t文件保护通过口令保护 、 加密保护和访问控制 等方式实现。其中，口令保护和加密保护是为了防止用户文件被他人存取或窃取，而访问控制则用于控制用户对文件的访问方式。\n访问类型\n对文件的保护可从限制对文件的访问类型中出发。可加以控制的访问类型主要有以下几种。\n\n\n读。从文件中读。\n\n\n写。向文件中写。\n\n\n执行。将文件装入内存并执行。\n\n\n添加。将新信息添加到文件结尾部分。\n\n\n删除。删除文件，释放空间。\n\n\n列表清单。列出文件名和文件属性。\n\n\n此外还可以对文件的重命名、复制、编辑等加以控制。这些高层的功能可以通过系统程序调用低层系统调用来实现。保护可以只在低层提供。例如，复制文件可利用一系列的读请求来完成,这样，具有读访问权限的用户同时也就具有了复制和打印权限。\n访问控制\n​\t解决访问控制最常用的方法是根据用户身份进行控制。而实现基于身份访问的最为普通的方法是，为每个文件和目录增加一个访问控制列表 (Access-Control List，ACL)，以规定每个用户名及其所允许的访问类型。\n​\t这种方法的优点是可以使用复杂的访问方法，缺点是长度无法预计并且可能导致复杂的空间管理，使用精简的访问列表可以解决这个问题。\n精简的访问列表采用拥有者、组和其他三种用户类型。\n\n\n拥有者。创建文件的用户。\n\n\n组。一组需要共享文件且具有类似访问的用户。\n\n\n其他。系统内的所有其他用户。这样，只需用三个域即可列出访问表中这三类用户的访问权限。文件拥有者在创建文件时，说明创建者用户名及所在的组名，系统在创建文件时也将文件主的名字、所属组名列在该文件的 FCB 中。用户访问该文件时，按照拥有者所拥有的权限访问文件，若用户和拥有者在同一个用户组，则按照同组权限访问，否则只能按其他用户权限访问。UNIX 操作系统即采用此种方法。\n\n\n​\t口令和密码是另外两种访问控制方法。\n​\t口令指用户在建立一个文件时提供一个口令，系统为其建立 FCB 时附上相应口令，同时告诉允许共享该文件的其他用户。用户请求访问时必须提供相应的口令。这种方法时间和空间的开销不多，缺点是口令直接存在系统内部，不够安全。\n​\t密码指用户对文件进行加密，文件被访问时需要使用密钥。这种方法保密性强，节省了存储空间，不过编码和译码要花费一定的时间。\n口令和密码都是防止用户文件被他人存取或窃取，并没有控制用户对文件的访问类型。注意两个问题:\n\n\n现代操作系统常用的文件保护方法是，将访问控制列表与用户、组和其他成员访问控制方案一起组合使用。\n\n\n对于多级目录结构而言，不仅需要保护单个文件，而且需要保护子目录内的文件，即需要提供目录保护机制。目录操作与文件操作并不相同，因此需要不同的保护机制。\n\n\n本节小结\n本节开头提出的问题的参考答案如下。\n什么是文件?什么是文件系统?\n​\t文件是以计算机硬盘为载体的存储在计算机上的信息集合，它的形式多样，可以是文本文档、图片、程序等。操作系统中负责管理和存储文件信息的软件机构称为文件管理系统，简称文件系统。文件系统由三部分组成:与文件管理有关的软件、被管理文件及实施文件管理所需的数据结构。\n文件系统要完成哪些功能?\n​\t对于用户而言，文件系统最主要的功能是实现对文件的基本操作，让用户可以按名存储和查找文件，组织成合适的结构，并应当具有基本的文件共享和文件保护功能。对于操作系统本身而言，文件系统还需要管理与磁盘的信息交换，完成文件逻辑结构和物理结构上的变换，组织文件在磁盘上的存放，采取好的文件排放顺序和磁盘调度方法以提升整个系统的性能。\n学习到这里时，读者应会有这样的一种体会:现代操作系统的管理思想中，到处能够见到面向对象程序设计的影子。本节我们学习的一个新概念————文件，实质上就是一个抽象数据类型，也就是一种数据结构 ，若读者在复习操作系统之前已复习完数据结构，则遇到一种新的数据结构时，一定会有这样的意识:要认识它的逻辑结构、物理结构，以及对这种数据结构的操作。本节我们已经学完文件的 逻辑结构逻辑结构 ，下一节将介绍文件的实现，也就是文件的 物理结构物理结构 。操作系统对文件的操作不是本课程关心的问题，我们不去研究。\n文件系统实现\n在学习本节时，请读者思考以下问题:\n1）在目录中查找某个文件可以使用什么方法?\n2）文件的逻辑结构和物理结构有何区别?单个文件的逻辑结构和物理结构之间是否存在某些制约关系?上节介绍了目录和文件的逻辑结构,本节将介绍文件物理结构和目录的实现。建议读者阅读之前先回顾上节的内容，并自己思考相应功能的实现方法，在学习过程中和本节的方法进行对比，这样能更好地理解本节的内容。\n\n文件系统层次结构\n​\t现代操作系统有多种文件系统类型（如 FAT32，NTFS,ext2，ext3，ext4 等)，因此文件系统的层次结构也不尽相同。图 4.9 是一种合理的层次结构。\n\n用户调用接口\n​\t文件系统为用户提供与文件及目录有关的调用，如新建、打开、读写、关闭、删除文件，建立、删除目录等。此层由若干程序模块组成，每个模块对应一条系统调用，用户发出系统调用时，控制即转入相应的模块。\n文件目录系统\n​\t文件目录系统的主要功能是管理文件目录，其任务有管理活跃文件目录表、管理读写状态信息表、管理用户进程的打开文件表、管理与组织存储设备上的文件目录结构、调用下一级存取控制模块。\n存取控制验证模块\n​\t实现文件保护主要由该级软件完成，它把用户的访问要求与 FCB 中指示的访问控制权限进行比较，以确认访问的合法性。\n逻辑文件系统与文件信息缓冲区\n​\t逻辑文件系统与文件信息缓冲区的主要功能是，根据文件的逻辑结构将用户要读写的逻辑记录转换成文件逻辑结构内的相应块号。\n物理文件系统\n​\t物理文件系统的主要功能是把逻辑记录所在的相对块号转换成实际的物理地址。\n辅助分配模块\n​\t分配模块的主要功能是管理辅存空间，即负责分配辅存空闲空间和回收辅存空间。\n设备管理程序模块\n​\t设备管理程序模块的主要功能是分配设备、分配设备读写用缓冲区、磁盘调度、启动设备、处理设备中断、释放设备读写缓冲区、释放设备等。\n​\t对于文件管理系统的层次结构我们不能忽略，因为它是重要考点之一，当然也不需要死记硬背，我们可以通过用户请求访问某个文件时发生的一系列事情来辅助记忆文件系统的层次结构。\n​\t例如，用户要查看文件 F 中的内容，对操作系统发出命令（操作系统有面向用户的接口),于是就经过了第 О 级的用户调用接口。\n​\t操作系统得到命令后，需要查找目录以查找文件 F 的索引信息，可能是 FCB，也可能是索引结点，经过了第 1 级文件目录系统。\n​\t通过目录找到文件 FCB 后，需要查看文件 FCB 上的信息，看看那个用户有没有访问该文件的权限，于是经过了存取控制验证模块。\n​\t用户通过验证后，就真正开始寻址。经历第 3 章的学习后，我们有这样的意识:操作系统的寻址往往要先得到逻辑地址，再得到物理地址，于是在开始寻址时，操作系统经过逻辑文件系统与文件信息缓冲区，得到了相应文件的内容的逻辑地址。\n​\t把逻辑地址 转换为物理地址 ，是在物理文件系统 中完成的。\n至此为止，寻址就已完成。寻址完成后，我们关心的是找到的这块空间应该如何管理，若要释放这块空间，则任务就交给辅助分配模块，若要把这块空间分配给设备用于输入/输出，则把任务交给设备管理程序模块。\n目录实现\n​\t在读文件前，必须先打开文件。打开文件时，操作系统利用路径名找到相应目录项，目录项中提供了查找文件磁盘块所需要的信息。目录实现的基本方法有线性列表和哈希表两种，要注意目录的实现就是为了查找，因此线性列表实现对应线性查找，哈希表的实现对应散列查找。\n线性列表\n​\t最简单的目录实现方法是使用存储文件名和数据块指针的线性表。创建新文件时，必须首先搜索目录表以确定没有同名的文件存在，然后在目录表后增加一个目录项。删除文件则根据给定的文件名搜索目录表，接着释放分配给它的空间。重用目录项有许多方法:可以将目录项标记为不再使用，或将它加到空闲目录项表上，还可以将目录表中的最后一个目录项复制到空闲位置，并降低目录表长度。采用链表结构可以减少删除文件的时间，其优点在于实现简单，不过由于线性表的特殊性，比较费时。\n哈希表\n​\t哈希表根据文件名得到一个值，并返回一个指向线性列表中元素的指针。这种方法的优点是查找非常迅速，插入和删除也较简单，不过需要一些预备措施来避免冲突。最大的困难是哈希表长度固定以及哈希函数对表长的依赖性。\n​\t目录查询是通过在磁盘上反复搜索完成的，需要不断地进行 I/O 操作，开销较大。所以如前所述，为了减少 I/O 操作，把当前使用的文件目录复制到内存，以后要使用该文件时只需在内存中操作，因此降低了磁盘操作次数，提高了系统速度。\n文件实现—文件分配方式\n​\t前面说过，文件实际上是一种抽象数据类型，我们要研究它的逻辑结构、物理结构以及关于它的一系列操作（不是统考关注的内容)。文件的实现就是研究文件的物理结构，即文件数据在物理存储设备上是如何分布和组织的。同一个问题有两个方面的回答:一是文件的分配方式，讲的是对磁盘非空闲块的管理;二是文件存储空间管理，讲的是对磁盘空闲块的管理。\n​\t文件分配对应于文件的物理结构，是指如何为文件分配磁盘块。常用的磁盘空间分配方法有三种:连续分配、链接分配和索引分配。有的系统（如 RDOS 操作系统）对三种方法都支持，但更普遍的是一个系统只支持一种方法。对于本节的内容，读者要注意与文件的逻辑结构区分，从历年的经验来看，这是很多读者容易搞混的地方（读者复习完数据结构后，应该了解线性表 、 顺序表 和 链表之间的关系，类比到这里就不易混淆)。\n连续分配\n​\t连续分配方法要求每个文件在磁盘上占有一组连续的块，如图 4.10 所示。磁盘地址定义了磁盘上的一个线性排序。这种排序使作业访问磁盘时需要的寻道数和寻道时间最小。\n\n​\t文件的连续分配可以用第一块的磁盘地址和连续块的数量来定义。若文件长 n 块并从位置 b 开始，则该文件将占有块 b,b+ 1,b+2,…,b+n-1。一个文件的目录条目包括开始块的地址和该文件所分配区域的长度。\n​\t连续分配支持顺序访问和直接访问。其优点是实现简单、存取速度快。缺点是文件长度不宜动态增加，因为一个文件末尾后的盘块可能已分配给其他文件，一旦需要增加，就需要大量移动盘块。此外，反复增删文件后会产生外部碎片（与内存管理分配方式中的碎片相似)，且很难确定一个文件需要的空间大小，因而只适用于长度固定 的文件。\n链接分配\n​\t链接分配采取离散分配的方式，消除了外部碎片，因此显著提高了磁盘空间的利用率;又因为根据文件的当前需求为其分配必需的盘块，当文件动态增长时，可以动态地再为它分配盘块，因此无须事先知道文件的大小。此外，对文件的增、删、改也非常方便。链接分配又可以分为隐式链接和显式链接两种形式。\n​\t隐式链接如图 4.11 所示。每个文件对应一个磁盘块的链表;磁盘块分布在磁盘的任何地方，除最后一个盘块外，每个盘块都有指向下一个盘块的指针，这些指针对用户是透明的。目录包括文件第一块的指针和最后一块的指针。\n\n​\t创建新文件时，目录中增加一个新条目。每个目录项都有一个指向文件首块的指针。该指针初始化为 NULL 以表示空文件，大小字段为 0。写文件会通过空闲空间管理系统找到空闲块，将该块链接到文件的尾部，以便写入。读文件则通过块到块的指针顺序读块。\n​\t隐式链接 分配的缺点是无法直接访问盘块，只能通过指针顺序访问文件，且盘块指针会消耗一定的存储空间。隐式链接分配的稳定性也是一个问题，系统在运行过程中由于软件或硬件错误导致链表中的指针丢失或损坏，会导致文件数据的丢失。\n​\t显式链接 是指把用于链接文件各物理块的指针，从每个物理块的块末尾中提取出来，显式地存放在内存的一张链接表中。该表在整个磁盘中仅设置一张，称为文件分配表(File AllocationTable，FAT)。每个表项中存放对应块的下一块链接指针，即下一个盘块号。文件的第一个盘块号记录在目录中，后续的盘块可通过查 FAT 找到。例如，某磁盘共有 100 个磁盘块，存放了两个文件:文件“aa”占三个盘块，依次是 2→8→5;文件“bbb”占两个盘块，依次是 7→1。其余盘块都是空闲盘块，则该磁盘的 FAT 表如图 4.12 所示。\n\n不难看出，FAT 的表项与全部磁盘块一一对应，并且可以用一个特殊的数字-1 表示文件的最后一块，用-2 表示这个磁盘块是空闲的（当然也可指定为-3,-4)。因此，文件分配表（FAT）不仅记录了文件各块之间的先后链接关系，同时还标记了空闲的磁盘块，操作系统也可以通过 FAT 对文件存储空间进行管理。当某进程请求操作系统分配一个磁盘块时，操作系统只需从 FAT 中找到-2 的表项,并将对应的磁盘块分配给进程即可。\n​\tFAT 表在系统启动时就会被读入内存，因此查找 FAT 的过程是在内存中进行的，因此不仅显著地提高了检索速度，而且明显减少了访问磁盘的次数。\n索引分配\n​\t链接分配解决了连续分配的外部碎片和文件大小管理的问题。但是，链接分配不能有效支持直接访问(FAT 除外)。索引分配解决了这个问题，它把每个文件的所有的盘块号都集中放在一起构成索引块（表)，如图 4.13 所示。\n\n每个文件都有其索引块 ，这是一个磁盘块地址的数组。索引块的第 i 个条目指向文件的第 i 个块。目录条目包括索引块的地址。要读第 i 块，通过索引块的第 i 个条目的指针来查找和读入所需的块。\n​\t创建文件时，索引块的所有指针都设为空。首次写入第 i 块时，先从空闲空间中取得一个块，再将其地址写到索引块的第 i 个条目。索引分配支持直接访问，且没有外部碎片问题。其缺点是由于索引块的分配，增加了系统存储空间的开销。索引块的大小是一个重要的问题，每个文件必须有一个索引块，因此索引块应尽可能小，但索引块太小就无法支持大文件。可以采用以下机制来处理这个问题。\n\n\n链接方案。一个索引块通常为一个磁盘块，因此它本身能直接读写。为了处理大文件，可以将多个索引块链接起来。\n\n\n多层索引。多层索引使第一层索引块指向第二层的索引块，第二层索引块再指向这种方法根据最大文件大小的要求，可以继续到第三层或第四层。例如，4096B 的块，能在索引块中存入 1024 个 4B 的指针。两层索引允许 1048576 个数据块，即允许最大文件为 4GB。\n\n\n混合索引。将多种索引分配方式相结合的分配方式。例如，系统既采用直接地址单级索引分配方式或两级索引分配方式（混合索引是本章最综合的高频考点，可先学习本章疑难点 4，然后回来接着学习)。\n\n\n表 4.2 是三种分配方式的比较。\n\n此外，访问文件需要两次访问外存——首先要读取索引块的内容，然后访问具体的磁盘块，因而降低了文件的存取速度。为了解决这一-问题，通常将文件的索引块读入内存的缓冲区中，以加快文件的访问速度。\n文件实现————文件存储空间管理\n(1）文件存储器空间的划分与初始化\n​\t一般来说，一个文件存储在一个文件卷中。文件卷可以是物理盘的一部分，也可以是整个物理盘，支持超大型文件的文件卷也可由多个物理盘组成，如图 4.14 所示。\n​\t在一个文件卷中，文件数据信息的空间(文件区）和存放文件控制信息 FCB 的空间(目录区)是分离的。由于存在很多种类的文件表示和存放格式，所以现代操作系统中一般都有很多不同的文件管理模块，通过它们可以访问不同格式的逻辑卷中的文件。逻辑卷在提供文件服务前，必须由对应的文件程序进行初始化，划分好目录区和文件区,建立空闲空间管理表格及存放逻辑卷信息的超级块 。\n\n(2）文件存储器空间管理\n文件存储设备分成许多大小相同的物理块，并以 块块 为单位交换信息，因此，文件存储设备的管理实质上是对空闲块的组织和管理，它包括空闲块的组织、分配与回收等问题。\n空闲表法\n​\t空闲表法属于连续分配方式，它与内存的动态分配方式类似，为每个文件分配一块连续的存储空间。系统为外存上的所有空闲区建立一张空闲盘块表，每个空闲区对应于一个空闲表项，其中包括表项序号、该空闲区第一个盘块号、该区的空闲盘块数等信息。再将所有空闲区按其起始盘块号递增的次序排列，如表 4.3 所示。\n​\t空闲盘区的分配与内存的动态分配类似，同样采用首次适应算法、循环首次适应算法等。例如，在系统为某新创建的文件分配空闲盘块时，先顺序地检索空闲盘块表的各表项，直至找到第一个其大小能满足要求的空闲区，再将该盘区分配给用户，同时修改空闲盘块表。\n​\t系统在对用户所释放的存储空间进行回收时，也采取类似于内存回收的方法，即要考虑回收区是否与空闲表中插入点的前区和后区相邻接，对相邻接者应予以合并。\n\n空闲链表法\n​\t将所有空闲盘区拉成一条空闲链,根据构成链所用的基本元素不同,可把链表分成两种形式:空闲盘块链和空闲盘区链。\n​\t空闲盘块链将磁盘上的所有空闲空间以盘块为单位拉成–条链。当用户因创建文件而请求分配存储空间时，系统从链首开始，依次摘下适当数目的空闲盘块分配给用户。当用户因删除文件而释放存储空间时，系统将回收的盘块依次插入空闲盘块链的末尾。这种方法的优点是分配和回收一个盘块的过程非常简单，但在为一个文件分配盘块时可能要重复多次操作。\n​\t空闲盘区链将磁盘上的所有空闲盘区（每个盘区可包含若干盘块）拉成一条链。在每个盘区上除含有用于指示下一个空闲盘区的指针外，还应有能指明本盘区大小(盘块数）的信息。分配盘区的方法与内存的动态分区分配类似，通常采用首次适应算法。在回收盘区时，同样也要将回收区与相邻接的空闲盘区合并。\n位示图法\n位示图利用二进制的一位来表示磁盘中一个盘块的使用情况，磁盘上所有的盘块都有一个二进制位与之对应。当其值为“0”时，表示对应的盘块空闲;当其值为“1”时，表示对应的盘块已分配。位示图法示意如图 4.15 所示。\n\n盘块的分配:\n① 顺序扫描位示图，从中找出一个或一组其值为“0”的二进制位。\n② 将找到的一个或一组二进制位，转换成与之对应的盘块号。若找到的其值为“0”的二进制位位于位示图的第 i 行、第 j 列,则其相应的盘块号应按下式计算( n 代表每行的位数):\nb= n(i−1)+j\n\n③ 修改位示图，令 map[ i,j ]= 1。\n盘块的回收:\n① 将回收盘块的盘块号转换成位示图中的行号和列号。转换公式为\ni = (b−1)DIV_n + 1\n\nj = (b−1)MOD_n + 1\n\n② 修改位示图，令 map[ i,j ]=0。\n成组链接法\n​\t空闲表法和空闲链表法都不适用于大型文件系统，因为这会使空闲表或空闲链表太大。在 UNIX 系统中采用的是成组链接法，这种方法结合了空闲表和空闲链表两种方法，克服了表太大的缺点。其大致思想是:把顺序的 n 个空闲扇区地址保存在第一个空闲扇区内，其后一个空闲扇区内则保存另一顺序空闲扇区的地址，如此继续，直至所有空闲扇区均予以链接。系统只需要保存一个指向第一个空闲扇区的指针。假设磁盘最初全为空闲扇区，其成组链接如图 4.16 所示。通过这种方式可以迅速找到大批空闲块地址。\n\n表示文件存储器空闲空间的“位向量”表或第一个成组链块，以及卷中的目录区、文件区划分信息都需要存放在辅存储器中，一般放在卷头位置，在 UNIX 系统中称为超级块。在对卷中的文件进行操作前，超级块需要预先读入系统空闲的主存，并且经常保持主存超级块与辅存卷中超级块的一致性。\n\n\n\n\n\n\n\n\n\n注意:本书如无特别提示，所使用的位示图法中行和列都从 1 开始编号。特别注意，若题目中指明从 0 开始编号，则上述计算方法要进行相应调整。\n本节小结\n本节开头提出的问题的参考答案如下。\n在目录中查找某个文件可以使用什么方法?\n可以采用线性列表法或哈希表法。线性列表把文件名组织成一个线性表，查找时依次与线性表中的每个表项进行比较。若把文件名按序排列，则使用折半查找法可以降低平均的查找时间，但建立新文件时会增加维护线性表的开销。哈希表用文件名通过哈希函数得到一个指向文件的指针，这种方法非常迅速，但要注意避免冲突。\n文件的逻辑结构和物理结构有何区别?单个文件的逻辑结构和物理结构之间是否存在着某些制约关系?\n文件的逻辑结构是用户可见的结构，即用户使用文件的结构。文件的物理结构是文件在存储器上的组织结构，它表示一个文件在辅存上安置、链接、编目的方法。它和文件的存取方法以及辅存设备的特性等都有着密切的联系。单个文件的逻辑结构和物理结构之间虽无明显的制约或关联关系，但是如果物理结构选择不慎，也很难体现出逻辑结构的特点，比如一个逻辑结构是顺序结构，而物理结构是隐式链接结构的文件，即使理论上可以很快找出某条记录的地址，而实际找时仍然需要在磁盘上一块一块地找。\n磁盘组织与管理\n在学习本节时，请读者思考以下问题:\n1）在磁盘上进行一次读写操作需要哪几部分时间?其中哪部分时间最长?\n2）存储一个文件时，当一个磁道存储不下时，剩下部分是存在同一个盘面的不同磁道好，还是存在同一个柱面上的不同盘面好?\n本节主要介绍文件系统管理磁盘的方式，由于内容较少且属于实现部分，不需要问题来引导学习，因此本节不给出问题。学习本节时，要重点掌握计算一次磁盘操作的时间，以及对于给定访盘的磁道序列，按照特定算法求出磁头通过的总磁道数及平均寻道数。\n磁盘的结构\n​\t磁盘（Disk）是由表面涂有磁性物质的金属或塑料构成的圆形盘片，通过一个称为磁头的导体线圈从磁盘存取数据。在读/写操作期间，磁头固定，磁盘在下面高速旋转。如图 4.17 所示，磁盘盘面上的数据存储在一组同心圆中，称为 磁道磁道 。每个磁道与磁头一样宽，一个盘面有上千个磁道。磁道又划分为几百个扇区，每个扇区固定存储大小(通常为 512B)，一个 扇区 称为一个盘块 。相邻磁道及相邻扇区间通过一定的间隙分隔开，以避免精度错误。注意，由于扇区按固定圆心角度划分，所以密度从最外道向里道增加，磁盘的存储能力受限于最内道的最大记录密度。\n​\t磁盘安装在一个磁盘驱动器中，它由磁头臂、用于旋转磁盘的主轴和用于数据输入/输出的电子设备组成。如图 4.18 所示，多个盘片垂直堆叠，组成磁盘组 ，每个盘面对应一个磁头，所有磁头固定在一起，与磁盘中心的距离相同且一起移动。所有盘片上相对位置相同的磁道组成柱面。按照这种物理结构组织，扇区就是磁盘可寻址的最小存储单位，磁盘地址用“柱面号·盘面号·扇区号(或块号)”表示。\n\n​\t磁盘按不同的方式可分为若干类型:磁头相对于盘片的径向方向固定的，称为固定头磁盘，每个磁道一个磁头;磁头可移动的，称为活动头磁盘，磁头臂可来回伸缩定位磁道;磁盘永久固定在磁盘驱动器内的，称为固定盘磁盘;可移动和替换的，称为可换盘磁盘。\n​\t前面说过,操作系统中几乎每介绍一类资源及对这类资源的管理时,都要涉及一类调度算法。用户访问文件，需要操作系统的服务，文件实际上存储在磁盘中，操作系统接收用户的命令后，经过一系列的检验访问权限和寻址过程后，最终都会到达磁盘，控制磁盘把相应的数据信恳读出或修改。当有多个请求同时到达时，操作系统就要决定先为哪个请求服务，这就是磁盘调度算法要解决的问题。\n磁盘调度算法\n一次磁盘读写操作的时间由寻找（寻道)时间、旋转延迟时间和传输时间决定。\n\n\n寻找时间 Ts ,。活动头磁盘在读写信息前，将磁头移动到指定磁道所需要的时间。这个时间除跨越 n 条磁道的时间外，还包括启动磁臂的时间 s ，即\n\n\nT_s = m × n + s\n\n式中，m 是与磁盘驱动器速度有关的常数，约为 0.2ms，磁臂的启动时间约为 2ms。\n\n\n旋转延迟时间 Tr 。磁头定位到某一磁道的扇区所需要的时间，设磁盘的旋转速度为 r ,则\n\n\nTt=12rT_t=\\frac 1{2r}\nT​t​​=​2r​​1​​\n对于硬盘，典型的旋转速度为 5400 转/分，相当于一周 11.1ms，则 Tr 为 5.55ms;对于软盘，其旋转速度为 300 ～ 600 转/分，则 Tr 为 50 ～ 100ms。\n\n\n传输时间 Tt 。从磁盘读出或向磁盘写入数据所经历的时间，这个时间取决于每次所读/写的字节数 b 和磁盘的旋转速度:\n\n\nTt=brNT_t=\\frac b{rN}\nT​t​​=​rN​​b​​\n式中， r 为磁盘每秒的转数， N 为一个磁道上的字节数。\n在磁盘存取时间的计算中，寻道时间与磁盘调度算法相关，下面将会介绍分析几种算法;而延迟时间和传输时间都与磁盘旋转速度相关，且为 线性相关线性相关 ，所以在硬件上，转速是磁盘性能的一个非常重要的参数。\n总平均存取时间Ta可以表示为\nTa=Ts+12r+brNT_a=T_s+\\frac1{2r}+\\frac b{rN}\nT​a​​=T​s​​+​2r​​1​​+​rN​​b​​\n虽然这里给出了总平均存取时间的公式，但是这个平均值是没有太大实际意义的，因为在实际的磁盘 IO 操作中，存取时间与磁盘调度算法密切相关。调度算法直接决定寻找时间从而决定总的存取时间。\n目前常用的磁盘调度算法有以下几种。\n先来先服务（First Come First Served，FCFS)算法\nFCFS 算法根据进程请求访问磁盘的先后顺序进行调度，这是一种最简单的调度算法，如图 4.19 所示。该算法的优点是具有公平性。若只有少量进程需要访问，且大部分请求都是访问簇聚的文件扇区，则有望达到较好的性能;若有大量进程竞争使用磁盘，则这种算法在性能上往往接近于随机调度。所以，实际磁盘调度中会考虑一些更为复杂的调度算法。\n\n例如，磁盘请求队列中的请求顺序分别为 55,58,39,18,90,160,150,38,184，磁头的初始位置是磁道 100,采用 FCFS 算法时磁头的运动过程如图 4.19 所示。磁头共移动了(45 ＋ 3+19+21+72 ＋ 70 ＋ 10+112+146)= 498 个磁道，平均寻找长度=498/9=55.3。\n最短寻找时间优先( Shortest Seek Time First, SSTF)算法\n​\tSSTF 算法选择调度处理的磁道是与当前磁头所在磁道距离最近的磁道，以便使每次的寻找时间最短。当然，总是选择最小寻找时间并不能保证平均寻找时间最小，但能提供比 FCFS 算法更好的性能。这种算法会产生“饥饿”现象。如图 4.20 所示，若某时刻磁头正在 18 号磁道，而在 18 号磁道附近频繁地增加新的请求，则 SSTF 算法使得磁头长时间在 18 号磁道附近工作，将使 184 号磁道的访问被无限期地延迟，即被“饿死”。\n\n例如，磁盘请求队列中的请求顺序分别为 55,58,39,18,90,160,150,38,184，磁头初始位置是磁道 100，采用 SSTF 算法时磁头的运动过程如图 4.20 所示。磁头共移动了 10+32+3+16+1 ＋ 20+132+10 ＋ 24= 248 个磁道，平均寻找长度=248/9 = 27.5。\n扫描（SCAN)算法（又称电梯调度算法)\n\n\nscan 求移动的磁道数的快速方法：找到「 枢纽 」，两边减去枢纽\n\n\nSCAN 算法在磁头当前移动方向上选择与当前磁头所在磁道距离最近的请求作为下一次服务的对象，实际上就是在最短寻找时间优先算法的基础上规定了磁头运动的方向，如图 4.21 所示。由于磁头移动规律与电梯运行相似，因此又称电梯调度算法。SCAN 算法对最近扫描过的区域不公平，因此它在访问局部性方面不如 FCFS 算法和 SSTF 算法好。\n\n例如，磁盘请求队列中的请求顺序分别为 55,58, 39,18,90,160,150,38,184，磁头初始位置是磁道 100。采用 SCAN 算法时，不但要知道磁头的当前位置，而且要知道磁头的移动方向，假设磁头沿磁道号增大的顺序移动，则磁头的运动过程如图 4.21 所示。移动磁道的顺序为 100,150,160,184,200,90,58,55,39,38,18。磁头共移动了(50+10+24+16+110 ＋ 32+3+16+1+20)=282 个磁道，平均寻道长度=282/9= 31.33。\n循环扫描( Circular SCAN, C-SCAN）算法\n在扫描算法的基础上规定磁头单向移动来提供服务，回返时直接快速移动至起始端而不服务任何请求。由于 SCAN 算法偏向于处理那些接近最里或最外的磁道的访问请求，所以使用改进型的 C-SCAN 算法来避免这个问题，如图 4.22 所示。\n采用 SCAN 算法和 C-SCAN 算法时，磁头总是严格地遵循从盘面的一端到另一端，显然，在实际使用时还可以改进，即磁头移动只需要到达最远端的一个请求即可返回,不需要到达磁盘端点。这种形式的 SCAN 算法和 C-SCAN 算法称为 LOOK 调度（见图 4.23-1)和 C-LOOK(见图 4.23-2)调度，因为它们在朝一个给定方向移动前会查看是否有请求。\n\n\n注意,若无特别说明,也可以默认 SCAN 算法和 C-SCAN 算法为 LOOK 和 C-LOOK 调度(请读者认真领悟，并通过结合后面的习题进一步加深对以上相关算法的理解)。\n\n例如，磁盘请求队列中的请求顺序为 55,58,39,18,90,160,150,38,184，磁头初始位置是磁道 100。采用 C-SCAN 算法时，假设磁头沿磁道号增大的顺序移动，则磁头的运动过程如图 4.23 所示。移动磁道的顺序为 100,150,160,184,200,0,18,38,39,55,58,90。磁头共移动 50 ＋ 10 ＋ 24 ＋ 16+200+ 18 ＋ 20+1+16 ＋ 3+32=390 个磁道，平均寻道长度=390/9= 43.33。\n​\t不太熟悉操作系统整体框架的读者经常混淆磁盘调度算法中的循环扫描算法和页面调度算法中的 CLOCK 算法，请读者注意区分。\n对比以上几种磁盘调度算法，FCFS 算法太过简单， 性能较差性能较差 ，仅在请求队列长度接近于 1 时才较为理想;SSTF 算法较为通用和自然;SCAN 算法和 C-SCAN 算法在磁盘 负载较大负载较大 时比较占优势。它们之间的比较见表 4.4。\n\n除减少寻找时间外，减少延迟时间也是提高磁盘传输效率的重要因素。可以对盘面扇区进行交替编号，对磁盘片组中的不同盘面错位命名。假设每个盘面有 8 个扇区，磁盘片组共 8 个盘面,则可以采用如图 4.24 所示的编号。\n​\t磁盘是连续自转设备，磁头读/写一个物理块后，需要经过短暂的处理时间才能开始读/马下一块。假设逻辑记录数据连续存放在磁盘空间中，若在盘面上按扇区交替编号连续存放,则连续读/写多条记录时能减少磁头的延迟时间;同柱面不同盘面的扇区若能错位编号，连续读/写相邻两个盘面的逻辑记录时也能减少磁头延迟时间。\n\n以图 4.24 为例，在随机扇区访问情况下，定位磁道中的一个扇区平均需要转过 4 个扇区，这时，延迟时间是传输时间的 4 倍，这是一种非常低效的存取方式。理想化的情况是不需要定位而直接连续读取扇区，没有延迟时间，这样磁盘数据存取效率可以成倍提高。但由于读取扇区的顺序是不可预测的，所以延迟时间不可避免。图 4.24 中的编号方式是读取连续编号扇区时的一种方法。\n​\t磁盘寻块时间分为三个部分，即寻道时间、延迟时间和传输时间，寻道时间和延迟时间属于“找”的时间，凡是“找”的时间都可以通过一定的方法削减，但传输时间是磁盘本身性质所决定的，不能通过一定的措施减少。\n磁盘的管理\n磁盘初始化\n​\t一个新的磁盘只是一个含有磁性记录材料的空白盘。在磁盘能存储数据之前，它必须分成扇区以便磁盘控制器能进行读和写操作，这个过程称为 低级格式化 （物理分区)。低级格式化为磁盘的每个扇区采用特别的数据结构。每个扇区的数据结构通常由 头 、数据区域 (通常为 512B 大小）和 尾部 组成。头部和尾部包含了一些磁盘控制器所使用的信息。\n​\t为了使用磁盘存储文件，操作系统还需要将自己的数据结构记录在磁盘上:第一步将磁盘分为由一个或多个柱面组成的 分区 （即我们熟悉的 C 盘、D 盘等形式的分区);第二步对物理分区进行 逻辑格式化 （创建文件系统)，操作系统将初始的文件系统数据结构存储到磁盘上,这些数据结构包括空闲和已分配的空间及一个初始为空的目录。\n引导块\n​\t计算机启动时需要运行一个初始化程序（自举程序 )，它初始化 CPU、寄存器、设备控制器和内存等，接着启动操作系统。为此，该自举程序应找到磁盘上的操作系统内核，装入内存，并转到起始地址，从而开始操作系统的运行。\n坏块\n​\t由于磁盘有移动部件且容错能力弱，因此容易导致一个或多个扇区损坏。部分磁盘甚至从出厂时就有坏扇区。根据所使用的磁盘和控制器，对这些块有多种处理方式。\n​\t对于简单磁盘，如电子集成驱动器(IDE)，坏扇区可手工处理，如 MS-DOS 的 Format 命令执行逻辑格式化时便会扫描磁盘以检查坏扇区。坏扇区在 FAT 表上会标明，因此程序不会使用。\n​\t对于复杂的磁盘，如小型计算机系统接口(SCSI)，其控制器维护一个磁盘坏块链表该链表在出厂前进行低级格式化时就已初始化，并在磁盘的整个使用过程中不断更新。低级格式化将一些块保留作为备用，对操作系统透明。控制器可用备用块来逻辑地替代坏块，这种方案称为扇区备用 。\n​\t对坏块的处理实质上就是用某种机制，使系统不去使用坏块。坏块属于硬件故障，操作系统是不能修复坏块的。\n本节小结\n本节开头提出的问题的参考答案如下。\n在磁盘上进行一次读写操作需要哪几部分时间?其中哪部分时间最长?\n​\t在磁盘上进行一次读写操作花费的时间由寻道时间、延迟时间和传输时间决定。其中寻道时间是将磁头移动到指定磁道所需要的时间，延迟时间是磁头定位到某一磁道的扇区（块号）所需要的时间，传输时间是从磁盘读出或向磁盘写入数据所经历的时间。一般来说，寻道时间因为要移动磁臂，所以占用时间最长。\n存储一个文件时，当一个磁道存储不下时，剩下部分是存在同一个盘面的不同磁道好，还是存在同一个柱面上的不同盘面好?\n​\t上一问已经说到，寻道时间对于一次磁盘访问的影响是最大的，若存在同一个盘面的不同磁道，则磁臂势必要移动，这样会大大增加文件的访问时间，而存在同一个柱面上的不同盘面就不需要移动磁道，所以一般情况下存在同一个柱面上的不同盘面更好。\n本章疑难点\n磁盘结构\n​\t引导控制块（Boot Control Block)包括系统从该分区引导操作系统所需要的信息。若磁盘没有操作系统，则这块的内容为空。它通常为分区的第一块。UFS 称为引导块(Boot Block);NTFS 称为分区引导扇区(Partition Boot Sector)。\n​\t分区控制块(Partition Control Block)包括分区详细信息，如分区的块数、块的大小、空闲块的数量和指针、空闲 FCB 的数量和指针等。UFS 称为超级块(Super Block)，而 NTFS 称为主控文件表(Master File Table)。\n内存结构\n​\t内存分区表包含所有安装分区的信息。\n​\t内存目录结构用来保存近来访问过的目录信息。对安装分区的目录，可以包括一个指向分区表的指针。\n系统范围的打开文件表，包括每个打开文件的 FCB 复制和其他信息。\n单个进程的打开文件表，包括一个指向系统范围内已打开文件表中合适条目和其他信息的指针。\n文件系统实现概述\n​\t为了创建一个文件，应用程序调用逻辑文件系统。逻辑文件系统知道目录结构形式，它将为文件分配一个新的 FCB，把相应目录读入内存，用新的文件名更新该目录和 FCB，并将结果写回磁盘。图 4.25 显示了一个典型的 FCB。\n\n​\t一旦文件被创建,它就能用于 IO,不过首先要打开文件。调用 open 将文件名传给文件系统，文件系统根据给定文件名搜索目录结构。部分目录结构通常缓存在内存中以加快目录操作。找到文件后，其 FCB 复制到系统范围的打开文件表。该表不但存储 FCB，而且存储打开该文件的进程数量的条目。\n​\t然后，单个进程的打开文件表中会增加一个条目，并通过指针将系统范围的打开文件表的条目与其他域(文件当前位置的指针和文件打开模式等)相连。调用 open 返回的是一个指向单个进程的打开文件表中合适条目的指针，所以文件操作都是通过该指针进行的。\n文件名不必是打开文件表的一部分，因为一旦完成对 FCB 在磁盘上的定位，系统就不再使用文件名。对于访问打开文件表的索引，UNIX 称之为文件描述符(File Descriptor)，而 Windows2000 称之为文件句柄(Fiie Handle)。因此，只要文件未被关闭，所有文件操作就通过打开文件表来进行。\n​\t当一个进程关闭文件时，就会删除单个进程打开文件表中的一个相应条目，即目录项，系统范围内打开文件表的打开数也会递减。当打开文件的所有用户都关闭了一个文件时，更新的文件信息会复制到磁盘的目录结构中，系统范围的打开文件表的条目也将删除。\n在实际中，系统调用 open 时会首先搜索系统范围的打开文件表，以确定某文件是否已被其他进程所使用。如果是，就在单个进程的打开文件表中创建一项，并指向现有系统范围的打开文件表的相应条目。该算法在文件已打开时，能节省大量开销。\n混合索引分配的实现\n​\t混合索引分配已在 UNIX 系统中采用。在 UNIX System V 的索引结点中，共设置了 13 个地址项，即 iaddr(0)~iaddr(12)，如图 4.26 所示。在 BSD UNIX 的索引结点中，共设置了 13 个地址项，它们都把所有的地址项分成两类，即直接地址和间接地址。\n\n\n直接地址\n\n\n​\t为了提高对文件的检索速度，在索引结点中可设置 10 个直接地址项，即用 iaddr(O)一 iaddr(9)来存放直接地址。换言之，这里每项中所存放的是该文件数据所在盘块的盘块号。假如每个盘块的大小为 4KB，当文件不大于 40KB 时，便可直接从索引结点中读出该文件的全部盘块号。\n\n\n一次间接地址\n\n\n​\t对于大、中型文件，只采用直接地址并不现实。可再利用索引结点中的地址项 iaddr(10)来提供一次间接地址。这种方式的实质就是一级索引分配方式。图中的一次间址块也就是索引块，系统将分配给文件的多个盘块号记入其中。在一次间址块中可存放 1024 个盘块号，因而允许文件长达 4MB。\n\n\n多次间接地址\n\n\n​\t当文件长度大于 4MB ＋ 40KB(一次间接地址与 10 个直接地址项)时，系统还须采用二次间接地址分配方式。这时，用地址项 iaddr(11)提供二次间接地址。该方式的实质是两级索引分配方式。系统此时在二次间接地址块中记入所有一次间接地址块的盘号。在采用二次间接地址方式时，文件的最大长度可达 4GB。同理，地址项 iaddr(12)作为三次间接地址，其允许的文件最大长度可达 4TB。\n\n最后，我们对本章内容再进行一次宏观上的把握。贯穿本章内容的有两条主线:第一条主线是介绍一种新的抽象数据类型、文件，从逻辑结构和物理结构两个方面进行;第二条主线是操作系统是如何管理“文件”这种数据结构的，介绍了多文件的逻辑结构的组织，即目录，还介绍了如何处理用户对文件的服务请求，即磁盘管理。但宏观认识是远远不够的，从宏观上把握知识的目的是从微观上更加准确地掌控细微知识点，在考试中得到好成绩。读者要通过反复做题、对答案，不断加深自己对知识点的认知程度。\n输入/输出(I/O)管理\n【考纲内容】\n(一）I/O 管理基础\n\n\n设备（设备的基本概念，设备的分类，I/O 接口，I/O 端口）\n\n\nI/O 控制方式（轮询方式、中断驱动方式、DMA 方式）\n\n\nI/O 软件层次结构（用户层 I/O、设备独立性软件、设备驱动层、中断处理层、硬件层）\n\n\n输入输出输入/输出 应用程序接口（字符设备接口，块设备接口，网络设备接口，阻塞/非阻塞 I/O）\n\n\n(二）设备独立软件\n\n\n缓冲区管理\n\n\n设备分配与回收\n\n\n假脱机技术(SPOOLing)\n\n\n设备驱动程序接口设备驱动程序接口\n\n\n(三)外存管理\n\n\n磁盘（磁盘结构，格式化，分区，磁盘调度方法）\n\n\n固态硬盘固态硬盘 （读写性能特性，磨损均衡）\n\n\n\n\n概述\n\nI/O 设备分类\nI/O 控制方式–程序直接控制、中断驱动方式、DMA 方式、通道方式\nI/O 层次结构——用户层 I/O、设备独立性软件、设备驱动层、中断处理层、硬件层\n\n\n\n缓冲区\n\n单缓冲\n双缓冲\n循环缓冲\n缓冲池\n缓冲区与高速缓存的对比\n\n\n\n设备分配\n\n概述\n\n独占设备————独占式使用\n共享设备————分时式共享\n虚拟设备————SPOOLing 方式\n\n\n数据结构————DCT、COCT、CHCT、SDT\n策略————静态分配、动态分配\n逻辑设备名到物理设备名的映射\n\n\n\nSPOOLing 系统（虚拟设备技术)————组成、实例\n\n\n【复习提示】\n本章的内容较为分散，重点掌握的内容是 I/O 设备的基本特性、I/O 子系统的特性、三种 IO 控制方式、高速缓存与缓冲区、SPOOLing 技术。本章的知识点很多，如 I/O 方式、设备控制等内容与硬件直接相关，建议结合计算机组成原理中的对应章节一起复习。本章内容与组成原理中的交叉较多，很多考点既可作为本章的考点，又可作为组成原理中的考点，因此还未复习组成原理的读者需要清楚地把握本章的每个知识点，为组成原理的学习打下基础，已复习过组成原理的读者遇到比较熟悉的内容时可以跳过，学习本章中组成原理未涉及的部分即可。另外，未复习过组成原理的读者可能会觉得本章的习题较难，但不需要担心。\n本章的内容历年来在统考题目中所占的比例不大，若统考中出现本章的题目，则基本上可以断定一定非常简单，看过相关内容的读者就一定会做，而未看过的读者基本上只能靠“蒙”。考研成功的秘诀是复习要反复多次并全面，偷工减料是要吃亏的，希望读者重视本章的内容。\n\n\n这么说来通道不考了？\n\n\n通道和 DMA 的区别\n\n\nI/O 管理概述\n学习本章时，可与计算机组成原理的相关知识相结合，并思考 I/O 管理要完成哪些功能。\nI/O 设备\nI/O 设备管理是操作系统设计中最凌乱也最具挑战性的部分。由于它包含了很多领域的不同设备及与设备相关的应用程序，因此很难有一个通用且一致的设计方案。所以在理解设备管理之前，应该先了解具体的 IO 设备类型。\n计算机系统中的 IO 设备按使用特性可分为以下类型:\n\n\n人机交互类外部设备 。用于与计算机用户之间交互的设备，如打印机、显示器、鼠标、键盘等。这类设备的数据交换速度相对较慢，通常是以字节为单位进行数据交换的。\n\n\n存储设备 。用于存储程序和数据的设备，如磁盘、磁带、光盘等。这类设备用于数据交换，速度较快，通常以多字节组成的块为单位进行数据交换。\n\n\n网络通信设备 。用于与远程设备通信的设备，如各种网络接口、调制解调器等。其速度介于前两类设备之间。网络通信设备在使用和管理上与前两类设备也有很大不同。\n\n\n除了上面最常见的分类方法，IO 设备还可以按以下方法分类。\n按传输速率分类\n\n\n低速设备 。传输速率仅为每秒几字节到数百字节的一类设备，如键盘 、鼠标 等。\n\n\n中速设备 。传输速率为每秒数千字节至数万字节的一类设备，如行式打印机 、 激光打印机 等。\n\n\n高速设备 。传输速率在数百千字节至千兆字节的一类设备，如磁带机 、 磁盘机 、 光盘机 等。\n\n\n按信息交换的单位分类\n\n\n块设备 。由于信息的存取总是以数据块为单位的，所以存储信息的设备称为块设备。它属于有结构设备，如磁盘 等。磁盘设备的基本特征是传输速率较高、可寻址，即对它可随机地读/写任一块。\n\n\n字符设备 。用于数据输入/输出的设备为字符设备，因为其传输的基本单位是字符。它属于无结构类型，如交互式终端机 、打印机 等。它们的基本特征是传输速率低、不可寻址,并且在输入/输出时常采用中断驱动方式。\n\n\nI/O 控制方式\n​\t设备管理的主要任务之一是控制设备和内存或处理机之间的数据传送。外围设备和内存之间的输入/输出控制方式有 4 种，下面分别加以介绍。\n程序直接控制方式\n​\t如图 5.1(a)所示，计算机从外部设备读取数据到存储器，每次读一个字的数据。对读入的每个字，CPU 需要对外设状态进行循环检查，直到确定该字已经在 IO 控制器的数据寄存器中。在程序直接控制方式中，由于 CPU 的高速性和 IO 设备的低速性，致使 CPU 的绝大部分时间都处于等待 IO 设备完成数据 IO 的循环测试中，造成了 CPU 资源的极大浪费。在该方式中，CPU 之所以要不断地测试 IO 设备的状态，就是因为在 CPU 中未采用中断机构，使 IO 设备无法向 CPU 报告它已完成了一个字符的输入操作。\n​\t程序直接控制方式虽然简单且易于实现，但其缺点也显而易见，由于 CPU 和 I/O 设备只能串行工作，导致 CPU 的利用率相当低。\n中断驱动方式\n​\t中断驱动方式的思想是，允许 IO 设备主动打断 CPU 的运行并请求服务，从而“解放”CPU,使得其向 I/O 控制器发送读命令后可以继续做其他有用的工作。如图 5.1(b)所示，我们从 IO 控制器和 CPU 两个角度分别来看中断驱动方式的工作过程。\n\n从 I/O 控制器的角度来看，I/O 控制器从 CPU 接收一个读命令，然后从外围设备读数据。一旦数据读入该 I/O 控制器的数据寄存器，便通过控制线给 CPU 发出一个中断信号，表示数据已准备好，然后等待 CPU 请求该数据。I/O 控制器收到 CPU 发出的取数据请求后，将数据放到数据总线上，传到 CPU 的寄存器中。至此，本次 I/O 操作完成，IO 控制器又可开始下一次 I/O 操作。\n​\t从 CPU 的角度来看，CPU 发出读命令，然后保存当前运行程序的上下文(现场，包括程序计数器及处理机寄存器)，转去执行其他程序。在每个指令周期的末尾，CPU 检查中断。当有来自 I/O 控制器的中断时，CPU 保存当前正在运行程序的上下文，转去执行中断处理程序以处理该中断。这时，CPU 从 IO 控制器读一个字的数据传送到寄存器，并存入主存。接着，CPU 恢复发出 1O 命令的程序（或其他程序）的上下文，然后继续运行。\n​\t中断驱动方式比程序直接控制方式有效，但由于数据中的每个字在存储器与 I/O 控制器之间的传输都必须经过 CPU，这就导致了中断驱动方式仍然会消耗较多的 CPU 时间。\nDMA 方式\n​\t在中断驱动方式中，I/O 设备与内存之间的数据交换必须要经过 CPU 中的寄存器，所以速度还是受限，而 DMA(直接存储器存取)方式的基本思想是在 IO 设备和内存之间开辟直接的数据交换通路，彻底“解放”CPU。DMA 方式的特点如下:\n\n\n基本单位是数据块。\n\n\n所传送的数据，是从设备直接送入内存的，或者相反。\n\n\n仅在传送一个或多个数据块的开始和结束时，才需 CPU 干预，整块数据的传送是在 DMA 控制器的控制下完成的。\n\n\n图 5.2 列出了 DMA 控制器的组成。\n\n要在主机与控制器之间实现成块数据的直接交换,须在 DMA 控制器中设置如下 4 类寄存器:\n\n\n命令/状态寄存器(CR)。用于接收从 CPU 发来的 I/O 命令或有关控制信息，或设备的状态。\n\n\n内存地址寄存器(MAR)。在输入时，它存放把数据从设备传送到内存的起始目标地址;在输出时，它存放由内存到设备的内存源地址。\n\n\n数据寄存器(DR)。用于暂存从设备到内存或从内存到设备的数据。\n\n\n数据计数器(DC)。存放本次要传送的字（节）数。\n\n\n​\t如图 5.1©所示，DMA 方式的工作过程是:CPU 接收到 IO 设备的 DMA 请求时，它给 TO 控制器发出一条命令，启动 DMA 控制器，然后继续其他工作。之后 CPU 就把控制操作委托给 DMA 控制器，由该控制器负责处理。DMA 控制器直接与存储器交互，传送整个数据块，每次传送一个字，这个过程不需要 CPU 参与。传送完成后，DMA 控制器发送一个中断信号给处理器。因此只有在传送开始和结束时才需要 CPU 的参与。\n​\tDMA 控制方式与中断驱动方式的主要区别是，中断驱动方式在每个数据需要传输时中断 CPU，而 DMA 控制方式则是在所要求传送的一批数据全部传送结束时才中断 CPU;此外，中断驱动方式数据传送是在中断处理时由 CPU 控制完成的，而 DMA 控制方式则是在 DMA 控制器的控制下完成的。\n通道控制方式\n​\tI/O 通道是指专门负责输入/输出的处理机。I/O 通道方式是 DMA 方式的发展，它可以进一步减少 CPU 的干预，即把对一个数据块的读(或写)为单位的干预，减少为对一组数据块的读（或写)及有关控制和管理为单位的干预。同时，又可以实现 CPU、通道和 IO 设备三者的并行操作，从而更有效地提高整个系统的资源利用率。\n​\t例如，当 CPU 要完成一组相关的读（或写）操作及有关控制时，只需向 IO 通道发送一条 I/O 指令，以给出其所要执行的通道程序的首地址和要访问的 IO 设备，通道接到该指令后，执行通道程序便可完成 CPU 指定的 IO 任务，数据传送结束时向 CPU 发中断请求。\nIO 通道与一般处理机的区别是:通道指令的类型单一，没有自己的内存，通道所执行的通道程序是放在主机的内存中的，也就是说通道与 CPU 共享内存 。\n​\tIO 通道与 DMA 方式的区别是:DMA 方式需要 CPU 来控制传输的数据块大小、传输的内存位置，而通道方式中这些信息是由通道控制的。另外，每个 DMA 控制器对应一台设备与内存传递数据，而一个通道可以控制多台设备与内存的数据交换。\n下面用一个例子来总结以上 4 种 IO 控制方式。想象一位客户要去裁缝店做一批衣服的情形。采用程序直接控制时，裁缝没有客户的联系方式，客户必须每隔一段时间去裁缝店看看裁缝把衣服做好了没有，这就浪费了客户不少的时间。\n​\t采用中断驱动方式时，裁缝有客户的联系方式，每当他完成一件衣服后，给客户打一个电话,让客户去拿，与程序直接控制能省去客户不少麻烦，但每完成一件衣服就让客户去拿一次，仍然比较浪费客户的时间。\n​\t采用 DMA 方式时，客户花钱雇一位单线秘书，并向秘书交代好把衣服放在哪里(存放仓库),裁缝要联系就直接联系秘书，秘书负责把衣服取回来并放在合适的位置，每处理完 100 件衣服，秘书就要给客户报告一次（大大节省了客户的时间)。\n​\t采用通道方式时，秘书拥有更高的自主权，与 DMA 方式相比，他可以决定把衣服存放在哪里，而不需要客户操心。而且，何时向客户报告，是处理完 100 件衣服就报告，还是处理完 10000 件衣服才报告，秘书是可以决定的。客户有可能在多个裁缝那里订了货，一位 DMA 类的秘书只能负责与一位裁缝沟通，但通道类秘书却可以与多名裁缝进行沟通。\nI/O 子系统的层次结构\n​\tIO 软件涉及的面非常广，往下与硬件有着密切的联系，往上又与用户直接交互，它与进程管理、存储器管理、文件管理等都存在着一定的联系，即它们都可能需要 IO 软件来实现 IO 操作。\n​\t为了使复杂的 IO 软件具有清晰的结构、良好的可移植性和适应性，在 IO 软件中普遍采用了层次式结构，将系统输入/输出功能组织成一系列的层次，每层都利用其下层提供的服务，完成输入/输出功能中的某些子功能，并屏蔽这些功能实现的细节，向高层提供服务。在层次式结构的 I/O 软件中，只要层次间的接口不变，对某一层次中的软件的修改都不会引起其下层或高层代码的变更，仅最低层才涉及硬件的具体特性。\n​\t一个比较合理的层次划分如图 5.3 所示。整个 IO 系统可以视为具有 4 个层次的系统结构，各层次及其功能如下:\n\n\n\n用户层 IO 软件 。实现与用户交互的接口，用户可直接调用在用户层提供的、与 I/O 操作有关的 库函数库函数 ，对设备进行操作。\n\n\n一般而言，大部分的 I/O 软件都在操作系统内部，但仍有一小部分在用户层，包括与用户程序链接在一起的库函数，以及完全运行于内核之外的一些程序。用户层软件必须通过一组系统调用来获取操作系统服务。\n\n\n设备独立性软件 。用于实现用户程序与设备驱动器的统一接口、设备命令、设备保护及设备分配与释放等，同时为设备管理和数据传送提供必要的存储空间。\n\n\n​\t设备独立性也称设备无关性，使得应用程序独立于具体使用的物理设备。为实现设备独立性而引入了逻辑设备和物理设备这两个概念。在应用程序中，使用逻辑设备名来请求使用某类设备;而在系统实际执行时，必须将逻辑设备名映射成物理设备名使用。使用逻辑设备名的好处是:\n​\t① 增加设备分配的灵活性;\n​\t② 易于实现 IO 重定向，所谓 IO 重定向，是指用于 IO 操作的设备可以更换（即重定向)，而不必改变应用程序。\n​\t为了实现设备独立性，必须再在驱动程序之上设置一层设备独立性软件。总体而言，设备独立性软件的主要功能可分为以下两个方面:\n​\t① 执行所有设备的公有操作。包括:对设备的分配与回收;将逻辑设备名映射为物理设备名;对设备进行保护，禁止用户直接访问设备;缓冲管理;差错控制;提供独立于设备的大小统一的逻辑块，屏蔽设备之间信息交换单位大小和传输速率的差异。\n​\t② 向用户层（或文件层）提供统一接口。无论何种设备，它们向用户所提供的接口应是相同的。例如，对各种设备的读/写操作，在应用程序中都统一使用 read/write 命令等。\n\n\n设备驱动程序 。与硬件直接相关，负责具体实现系统对设备发出的操作指令，驱动 IO 设备工作的驱动程序。\n\n\n通常，每类设备配置一个设备驱动程序，它是 I/O 进程与设备控制器之间的通信程序，常以进程形式存在。设备驱动程序向上层用户程序提供一组标准接口，设备具体的差别被设备驱动程序所封装，用于接收上层软件发来的抽象 IO 要求，如 read 和 write 命令，转换为具体要求后，发送给设备控制器，控制 IO 设备工作;它也将由设备控制器发来的信号传送给上层软件，从而为 IO 内核子系统隐藏设备控制器之间的差异。\n\n\n中断处理程序 。用于保存被中断进程的 CPU 环境，转入相应的中断处理程序进行处理，处理完并恢复被中断进程的现场后，返回到被中断进程。\n\n\n中断处理层的主要任务有:进行进程上下文的切换，对处理中断信号源进行测试，读取设备状态和修改进程状态等。由于中断处理与硬件紧密相关，对用户而言，应尽量加以屏蔽，因此应放在操作系统的底层，系统的其余部分尽可能少地与之发生联系。\n\n\n硬件设备。I/O 设备通常包括一个机械部件和一个电子部件。为了达到设计的模块性和通用性，一般将其分开:电子部件称为设备控制器（或适配器)，在个人计算机中，通常是一块插入主板扩充槽的印制电路板;机械部件则是设备本身。\n\n\n设备控制器通过寄存器与 CPU 通信，在某些计算机上，这些寄存器占用内存地址的一部分，称为内存映像 IO;另一些计算机则采用 IO 专用地址，寄存器独立编址。操作系统通过向控制器寄存器写命令字来执行 IO 功能。控制器收到一条命令后，CPU 可以转向进行其他工作，而让设备控制器自行完成具体的 I/O 操作。当命令执行完毕后，控制器发出一个中断信号，操作系统重新获得 CPU 的控制权并检查执行结果，此时，CPU 仍旧从控制器寄存器中读取信息来获得执行结果和设备的状态信息。\n设备控制器的主要功能如下:\n\n\n接收和识别 CPU 或通道发来的命令，如磁盘控制器能接收读、写、查找等命令。\n\n\n实现数据交换，包括设备和控制器之间的数据传输;通过数据总线或通道，控制器和主存之间的数据传输。\n\n\n发现和记录设备及自身的状态信息，供 CPU 处理使用。\n\n\n设备地址识别。\n\n\n为实现上述功能，设备控制器（见图 5.4)必须包含以下组成部分:\n​\t①设备控制器与 CPU 的接口 。该接口有三类信号线:数据线、地址线和控制线。数据线通常与两类寄存器相连:数据寄存器（存放从设备送来的输入数据或从 CPU 送来的输出数据）和控制/状态寄存器（存放从 CPU 送来的控制信息或设备的状态信息)。\n​\t② 设备控制器与设备的接口 。设备控制器连接设备需要相应数量的接口，一个接口连接一台设备。每个接口中都存在数据、控制和状态三种类型的信号。\n​\t③IO 控制逻辑 。用于实现对设备的控制。它通过一组控制线与 CPU 交互，对从 CPU 收到的 I/O 命令进行译码。CPU 启动设备时，将启动命令发送给控制器，同时通过地址线把地址发送给控制器,由控制器的 IO 逻辑对地址进行译码,并相应地对所选设备进行控制。\n\n\n\n\n\n\n\n\n\n\n类似于文件系统的层次结构，IO 子系统的层次结构也是我们需要记忆的内容，但记忆不是死记硬背，我们以用户对设备的一次命令来总结各层次的功能，帮助各位读者记忆。\n例如，当用户要读取某设备的内容时，通过操作系统提供的 read 命令接口，这就经过了用户层。\n操作系统提供给用户使用的接口，一般是统一的通用接口，也就是几乎每个设备都可以响应的统一命令，如 read 命令，用户发出的 read 命令，首先经过设备独立层进行解析，然后交往下层。\n接下来，不同类型的设备对 read 命令的行为会有所不同，如磁盘接收 read 命令后的行为与打印机接收 read 命令后的行为是不同的。因此，需要针对不同的设备，把 read 命令解析成不同的指令，这就经过了设备驱动层。\n命令解析完毕后，需要中断正在运行的进程，转而执行 read 命令，这就需要中断处理程序。\n最后，命令真正抵达硬件设备，硬件设备的控制器按照上层传达的命令操控硬件设备，完成相应的功能。\n本节小结\n本节开头提出的问题的参考答案如下。\nIO 管理要完成哪些功能?\nI/O 管理需要完成以下 4 部分内容:\n1）状态跟踪。要能实时掌握外部设备的状态。\n2）设备存取。要实现对设备的存取操作。\n3）设备分配。在多用户环境下，负责设备的分配与回收。\n4）设备控制。包括设备的驱动、完成和故障的中断处理。\nI/O 核心子系统\n在学习本节时，请读者思考以下问题:\n1）当处理机和外部设备速度差距较大时，并且此时不想让其中一方等待，有什么办法可以解决问题?\n2）什么是设备的独立性?引入设备的独立性有什么好处?\nI/O 子系统概述\n由于 IO 设备种类繁多，功能和传输速率差异巨大，因此需要多种方法来进行设备控制。这些方法共同组成了操作系统内核的 I/O 子系统，它将内核的其他方面从繁重的 IO 设备管理中解放出来。I/O 核心子系统提供的服务主要有 I/O 调度、缓冲与高速缓存、设备分配与回收、假脱机、设备保护和差错处理等。\nI/O 调度概念\nIO 调度就是确定一个好的顺序来执行这些 IO 请求。应用程序所发布的系统调用的顺序不一定总是最佳选择，所以需要 IO 调度来改善系统整体性能，使进程之间公平地共享设备访问，减少 I/O 完成所需要的平均等待时间。\n操作系统开发人员通过为每个设备维护一个请求队列来实现调度。当一个应用程序执行阻塞 IO 系统调用时，该请求就加到相应设备的队列上。IO 调度会重新安排队列顺序，以改善系统总体效率和应用程序的平均响应时间。\nIO 子系统还可使用主存或磁盘上的存储空间的技术，如缓冲、高速缓存、假脱机等来改善计算机效率。\n4.3 节的磁盘调度算法其实就是 IO 调度的一种。\n高速缓存与缓冲区\n磁盘高速缓存( Disk Cache)\n操作系统中使用磁盘高速缓存技术来提高磁盘的 IO 速度，对高速缓存复制的访问要比原始数据访问更为高效。例如，正在运行的进程的指令既存储在磁盘上，又存储在物理内存上，也被复制到 CPU 的二级和一级高速缓存中。\n不过，磁盘高速缓存技术不同于通常意义下的介于 CPU 与内存之间的小容量高速存储器，而是指利用内存中的存储空间来暂存从磁盘中读出的一系列盘块中的信息。因此，磁盘高速缓存 逻辑逻辑 上属于 磁盘磁盘 ， 物理物理 上则是驻留在 内存内存 中的盘块。\n高速缓存在内存中分为 两种形式两种形式 :一种是在内存中开辟一个单独的存储空间作为磁盘高速缓存，大小固定;另一种是把未利用的内存空间作为一个缓冲池，供请求分页系统和磁盘 IO 时共享。\n缓冲区(Buffer)\n在设备管理子系统中，引入缓冲区的目的主要如下:\n1）缓和 CPU 与 VO 设备间速度不匹配的矛盾。\n2）减少对 CPU 的中断频率，放宽对 CPU 中断响应时间的限制。\n3）解决基本数据单元大小（即数据粒度）不匹配的问题。\n4）提高 CPU 和 IO 设备之间的并行性。\n其实现方法如下:\n1）采用硬件缓冲器，但由于成本太高，除一些关键部位外，一般不采用硬件缓冲器。\n2）采用缓冲区（位于内存区域)。\n缓冲区有一个特点，即当缓冲区的数据非空时，不能往缓冲区冲入数据，只能从缓冲区把数据传出;当缓冲区为空时，可以往缓冲区冲入数据，但必须把缓冲区充满后，才能从缓冲区把数据传出。\n根据系统设置缓冲器的个数，缓冲技术可以分为如下几种:\n\n\n单缓冲 。在设备和处理机之间设置一个缓冲区。设备和处理机交换数据时，先把被交换数据写入缓冲区，然后需要数据的设备或处理机从缓冲区取走数据。\n\n\n如图 5.5 所示，在块设备输入时，假定从磁盘把一块数据输入缓冲区的时间为 T，操作系统将该缓冲区中的数据传送到用户区的时间为 M,而 CPU 对这一块数据处理的时间为 C。在研究各种缓冲技术的每块数据的处理时间时，有一个技巧:假设一种初始状态，然后计算下一次到达相同状态时所需要的时间，就是处理一块数据所需要的时间。在单缓冲中，这种初始状态为:工作区是满的，缓冲区是空的。如题目没有明确说明，一般认为缓冲区的大小和工作区的大小相等。\n我们假设 T&gt;C，从初始状态开始，当工作区数据处理完后，时间为 C，缓冲区还没充满，当缓冲区充满时，经历了 T 时间，停止再冲入数据，然后缓冲区向工作区传送数据，当工作区满了以后，缓冲区的数据同时也为空，用时为 M，到达下一个开始状态，整个过程用时 M+T;若 T&lt; C，同理，整个过程用时 M+C。所以单缓冲区处理每块数据的用时为 max(C, T)+M。.\n\n\n\n双缓冲 。根据单缓冲的特点，CPU 在传送时间 M 内处于空闲状态，由此引入双缓冲。IO 设备输入数据时先装填到缓冲区 1，在缓冲区 1 填满后才开始装填缓冲区 2，与此同时处理机可以从缓冲区 1 中取出数据放入用户进程处理，当缓冲区 1 中的数据处理完后，若缓冲区 2 已填满，则处理机又从缓冲区 2 中取出数据放入用户进程处理，而 I/O 设备又可以装填缓冲区 1。注意，必须等缓冲区 2 充满才能让处理机从缓冲区 2 取出数据。双缓冲机制提高了处理机和输入设备的并行操作的程度。\n\n\n为了研究双缓冲处理一块数据的用时，我们先规定一种初始状态:工作区是空的，其中一个缓冲区是满的，另外一个缓冲区是空的;我们不妨假设缓冲区 1 是空的，缓冲区 2 是满的。\n如图 5.6 所示，我们假设 T&lt; C+M，缓冲区 2 开始向工作区传送数据，缓冲区 1 开始冲入数据，当工作区充满数据后，缓冲区为空，时间为 M，然后工作区开始处理数据，缓冲区 1 继续冲入数据，因为此时只有一个 IO 设备，所以缓冲区 2 虽然为空，但不能冲入数据。当缓冲区 1 充满数据后，工作区的数据还未处理完毕，时间为 T，当工作区数据处理完毕后，此时工作区为空，缓冲区 1 满，缓冲区 2 为空，达到下一个初始状态，用时 C+M。\n\n我们再来分析 T&gt;C+M 的情况。缓冲区 2 开始向工作区传送数据，缓冲区 1 开始冲入数据，当工作区充满数据并处理完后，用时 C+M，但缓冲区 1 的数据还未充满;当时间为 T 时，缓冲区 1 的数据充满，到达下一个初始状态。\n总结:双缓冲区处理一块数据的用时为 max(C+ M, T)。\n若 M+C&lt; T，则可使块设备连续输入;若 C+ M &gt; T，则可使 CPU 不必等待设备输入。对于字符设备，若采用行输入方式，则采用双缓冲可使用户在输入第一行后，在 CPU 执行第一行中的命令的同时，用户可继续向第二缓冲区输入下一行数据。而单缓冲情况下则必须等待一行数据被提取完毕才可输入下一行的数据。\n若两台机器之间通信仅配置了单缓冲，如图 5.7(a)所示，则它们在任意时刻都只能实现单方向的数据传输。例如，只允许把数据从 A 机传送到 B 机，或从 B 机传送到 A 机，而绝不允许双方同时向对方发送数据。为了实现双向数据传输，必须在两台机器中都设置两个缓冲区，一个用作发送缓冲区，另一个用作接收缓冲区，如图 5.7(b)所示。\n\n\n\n循环缓冲 。包含多个大小相等的缓冲区，每个缓冲区中有一个链接指针指向下一个缓冲区，最后一个缓冲区指针指向第一个缓冲区，多个缓冲区构成一个环形。\n\n\n循环缓冲用于输入/输出时，还需要有两个指针 in 和 out。对输入而言，首先要从设备接收数据到缓冲区中，in 指针指向可以输入数据的第一个空缓冲区;当运行进程需要数据时，从循环缓冲区中取一个装满数据的缓冲区，并从此缓冲区中提取数据，out 指针指向可以提取数据的第一个满缓冲区。输出则正好相反。\n\n\n缓冲池 。由多个系统公用的缓冲区组成，缓冲区按其使用状况可以形成三个队列:空缓冲队列、装满输入数据的缓冲队列(输入队列)和装满输出数据的缓冲队列(输出队列)。\n\n\n还应具有 4 种缓冲区:用于收容输入数据的工作缓冲区、用于提取输入数据的工作缓冲区、用于收容输出数据的工作缓冲区及用于提取输出数据的工作缓冲区，如图 5.8 所示。\n\n​\t当输入进程需要输入数据时，便从空缓冲队列的队首摘下一个空缓冲区，把它作为收容输入工作缓冲区，然后把输入数据输入其中，装满后再将它挂到输入队列队尾。当计算进程需要输入数据时，便从输入队列取得一个缓冲区作为提取输入工作缓冲区，计算进程从中提取数据，数据用完后再将它挂到空缓冲队列尾。当计算进程需要输出数据时，便从空缓冲队列的队首取得一个空缓冲区，作为收容输出工作缓冲区，当其中装满输出数据后，再将它挂到输出队列队尾。当要输出时，由输出进程从输出队列中取得一个装满输出数据的缓冲区，作为提取输出工作缓冲区，当数据提取完后，再将它挂到空缓冲队列的队尾。\n​\t对于循环缓冲和缓冲池，我们只是定性地介绍它们的机理，而不去定量研究它们平均处理一块数据所需要的时间。而对于单缓冲和双缓冲，我们只要按照上面的模板分析，就可以解决任何计算单缓冲和双缓冲情况下数据块处理时间的问题，以不变应万变。\n高速缓存与缓冲区的对比\n高速缓存是可以保存数据拷贝的高速存储器，访问高速缓存比访问原始数据更高效，速度更快。高速缓存和缓冲区的对比见表 5.1。\n\n设备分配与回收\n设备分配概述\n设备分配是指根据用户的 IO 请求分配所需的设备。分配的总原则是充分发挥设备的使用效率，尽可能地让设备忙碌，又要避免由于不合理的分配方法造成进程死锁。从设备的特性来看，采用下述三种使用方式的设备分别称为独占设备、共享设备和虚拟设备。\n\n\n独占式使用设备 。指在申请设备时，若设备空闲，则将其独占，不再允许其他进程申请使用，一直等到该设备被释放才允许其他进程申请使用。例如，打印机，在使用它打印时，只能独占式使用，否则在同一张纸上交替打印不同任务的内容，无法正常阅读。\n\n\n分时式共享使用设备 。独占式使用设备时，设备利用率很低，当设备没有独占使用的要求时，可以通过分时共享使用提高利用率。例如，对磁盘设备的 IO 操作，各进程的每次 I/O 操作请求可以通过分时来交替进行。\n\n\n以方式使用外部设备以 SPOOLing 方式使用外部设备 。SPOOLing (Simultaneous Peripheral Operation On-Line)技术是在批处理操作系统时代引入的，即假脱机 I/O 技术。这种技术用于对设备的操作，实质上就是对 IO 操作进行批处理。SPOOLing 技术实质上是一种以空间换时间的技术，而我们熟悉的请求分页系统中的页面调度算法就刚好相反，是以时间换空间的技术。\n\n\n设备分配的数据结构\n设备分配依据的主要数据结构有设备控制表（DCT)、控制器控制表（COCT)、通道控制表(CHCT)和系统设备表(SDT)，各数据结构功能如下。设备控制表（DCT):我们可以认为，一个设备控制表就表征一个设备，而这个控制表中的表项就是设备的各个属性，如图 5.9 所示。\n\n​\t前面我们学过 4 种 IO 控制方式，通道方式显然要比其他几种方式更加优越，因此现代操作系统的 I/O 控制采用的都是通道控制。设备控制器控制设备与内存交换数据，而设备控制器又需要请求通道为它服务，因此每个 COCT[见图 5.10(a) ]必定有一个表项存放指向相应通道控制表(CHCT)[见图 5.10(b) ]的指针，而一个通道可为多个设备控制器服务，因此 CHCT 中必定有一个指针，指向一个表，这个表上的信息表达的是 CHCT 提供服务的那几个设备控制器。CHCT 与 COCT 的关系是一对多 的关系。\n​\t系统设备表(SDT):整个系统只有一张 SDT，如图 5.10©所示。它记录已连接到系统中的所有 物理设备的情况物理设备的情况 ，每个物理设备占一个表目。\n\n由于在多道程序系统中，进程数多于资源数，会引起资源的竞争，因此要有一套合理的分配原则，主要考虑的因素有:I/O 设备的固有属性、I/O 设备的分配算法、I/O 设备分配的安全性以及 IO 设备的独立性。\n设备分配的策略\n\n\n设备分配原则。设备分配应根据设备特性、用户要求和系统配置情况。分配的总原则是:既要充分发挥设备的使用效率，又要避免造成进程死锁，还要将用户程序和具体设备隔离开。\n\n\n设备分配方式。设备分配方式有静态分配和动态分配两种。\n\n\n​\t静态分配 主要用于对独占设备的分配，它在用户作业开始执行前，由系统一次性分配该作业所要求的全部设备、控制器（如通道等)。一旦分配，这些设备、控制器（和通道)就一直为该作业所占用，直到该作业被撤销。静态分配方式不会出现死锁，但设备的使用效率低。因此，静态分配方式并不符合分配的总原则。\n​\t动态分配 在进程执行过程中根据执行需要进行。当进程需要设备时，通过系统调用命令向系统提出设备请求，由系统按照事先规定的策略给进程分配所需要的设备、IO 控制器,一旦用完，便立即释放。动态分配方式有利于提高设备的利用率，但若分配算法使用不当，则有可能造成进程死锁。\n\n\n设备分配算法。常用的动态设备分配算法有先请求先分配、优先级高者优先等。\n\n\n​\t对于独占设备，既可以采用动态分配方式，又可以采用静态分配方式，但往往采用静态分配方式，即在作业执行前，将作业所要用的这一类设备分配给它。共享设备可被多个进程所共享，一般采用动态分配方式，但在每个 IO 传输的单位时间内只被一个进程所占有，通常采用先请求先分配和优先级高者优先的分配算法。\n设备分配的安全性\n设备分配的安全性是指设备分配中应防止发生进程死锁。\n\n\n安全分配方式 。每当进程发出 IO 请求后便进入阻塞态，直到其 IO 操作完成时才被唤醒。这样，一旦进程已经获得某种设备后便阻塞，不能再请求任何资源，而且在它阻塞时也不保持任何资源。优点是设备分配安全;缺点是 CPU 和 IO 设备是串行工作的（对同一进程而言)。\n\n\n不安全分配方式 。进程在发出 I/O 请求后继续运行，需要时又发出第二个、第三个 I/O 请求等。仅当进程所请求的设备已被另一进程占用时，才进入阻塞态。优点是一个进程可同时操作多个设备，从而迅速推进进程;缺点是这种设备分配有可能产生死锁 。\n\n\n逻辑设备名到物理设备名的映射\n​\t为了提高设备分配的灵活性和设备的利用率，方便实现 IO 重定向，引入了设备独立性。设备独立性是指应用程序独立于具体使用的物理设备。\n​\t为了实现设备独立性，在应用程序中使用逻辑设备名来请求使用某类设备，在系统中设置一张逻辑设备表 (Logical Unit Table，LUT)，用于将逻辑设备名映射为物理设备名。LUT 表项包括逻辑设备名、物理设备名和设备驱动程序入口地址;当进程用逻辑设备名来请求分配设备时，系统为它分配相应的物理设备，并在 LUT 中建立一个表项，以后进程再利用逻辑设备名请求 I/O 操作时，系统通过查找 LUT 来寻找相应的物理设备和驱动程序。\n在系统中可采取两种方式建立逻辑设备表:\n\n\n在整个系统中只设置一张 LUT。这样，所有进程的设备分配情况都记录在这张表中，因此不允许有相同的逻辑设备名，主要适用于单用户系统。\n\n\n为每个用户设置一张 LUT。当用户登录时，系统便为该用户建立一个进程，同时也为之建立一张 LUT，并把该表放入进程的 PCB。\n\n\nSPOOLing 技术（假脱机技术）\n​\t为了缓和 CPU 的高速性与 I/O 设备低速性之间的矛盾，引入了脱机输入/输出技术。该技术利用专门的外围控制机，将低速 IO 设备上的数据传送到高速磁盘上，或者相反。SPOOLing 的意思是外部设备同时联机操作，又称假脱机输入/输出操作，是操作系统中采用的一项将独占设备改造成共享设备的技术。\nSPOOLing 系统的组成如图 5.11 所示。\n\n输入井和输出井\n输入井和输出井是指在磁盘上开辟出的两个存储区域。输入井模拟脱机输入时的磁盘,用于收容 IO 设备输入的数据。输出井模拟脱机输出时的磁盘，用于收容用户程序的输出数据。\n输入缓冲区和输出缓冲区\n输入缓冲区和输出缓冲区是在内存中开辟的两个缓冲区。输入缓冲区用于暂存由输入设备送来的数据，以后再传送到输入井。输出缓冲区用于暂存从输出井送来的数据，以后再传送到输出设备。\n输入进程和输出进程\n输入进程模拟脱机输入时的外围控制机，将用户要求的数据从输入机通过输入缓冲区再送到输入井。当 CPU 需要输入数据时，直接将数据从输入井读入内存。输出进程模拟脱机输出时的外围控制机，把用户要求输出的数据先从内存送到输出井，待输出设备空闲时，再将输出井中的数据经过输出缓冲区送到输出设备。\n共享打印机是使用 SPOOLing 技术的一个实例，这项技术已被广泛地用于多用户系统和局域网络。当用户进程请求打印输出时，SPOOLing 系统同意为它打印输出，但并不真正立即把打印机分配给该用户进程，而只为它做两件事:\n\n\n由输出进程在输出井中为之申请一个空闲磁盘块区，并将要打印的数据送入其中。\n\n\n输出进程再为用户进程申请一张空白的用户请求打印表，并将用户的打印要求填入其中，再将该表挂到请求打印队列上。\n\n\n​\tSPOOLing 系统的主要特点有:提高了 IO 的速度;将独占设备改造为共享设备﹔实现了虚拟设备功能。\n​\t前面我们提到过 SPOOLing 技术是一种以空间换时间的技术,我们很容易理解它牺牲了空间,因为它开辟了磁盘上的空间作为输入井和输出井，但它又如何节省时间呢?\n​\t从前述内容我们了解到，磁盘是一种高速设备，在与内存交换数据的速度上优于打印机、键盘、鼠标等中低速设备。试想一下，若没有 SPOOLing 技术，CPU 要向打印机输出要打印的数据，打印机的打印速度比较慢，CPU 就必须迁就打印机，在打印机把数据打印完后才能继续做其他的工作，浪费了 CPU 的不少时间。在 SPOOLing 技术下，CPU 要打印机打印的数据可以先输出到磁盘的输出井中（这个过程由输出进程控制)，然后做其他的事情。若打印机此时被占用，则 SPOOLing 系统就会把这个打印请求挂到等待队列上，待打印机有空时再把数据打印出来。向磁盘输出数据的速度比向打印机输出数据的速度快，因此就节省了时间。\n本节小结\n本节开头提出的问题的参考答案如下。\n当处理机和外部设备速度差距较大时，并且此时不想让其中一方等待，有什么办法可以解决问题?\n可以采用缓冲技术来缓解处理机与外部设备速度上的矛盾，即在某块地方（一般为主存)设立一片缓冲区，外部设备与处理机的输入/输出都经过缓冲区，这样外部设备和处理机就都不用互相等待。\n什么是设备的独立性?引入设备的独立性有什么好处?\n​\t设备独立性是指用户在编程序时使用的设备与实际设备无关。一个程序应独立于分配给它的某类设备的具体设备，即在用户程序中只指明 IO 使用的设备类型即可。\n设备独立性有以下优点:\n​\t① 方便用户编程。\n​\t② 使程序运行不受具体机器环境的限制。\n​\t③ 便于程序移植。\n","slug":"操作系统基础","date":"2023-07-20T12:14:48.000Z","categories_index":"计算机基础,操作系统","tags_index":"操作系统","author_index":"ND_LJQ"},{"id":"497c273b21b6384f2b97078d8e2b85c3","title":"File&Blob","content":"什么是文件\n这是一张纯色图片\n\n文件的内容\n这是他的二进制代码格式:\n\n以下是一些常见的文件的二进制代码前缀\n.exe的：\n\nMZ? + This program cannot be run in DOS mode.\n\n.jpg的：\n\nJFIF Or Exif\n\n  \n\n.png：\n\nNG\n\n.zip：\n\nPK+文件列表名+This program cannot be run in DOS mode.\n\n.gif：\n\nGIF……\n\n。txt：\n\n你认识的字\n\n.html\n\n带有&lt;>的\n\n.pdf：\n\n%PDF……\n\n.rar：\n\nRar!\n\n.doc：\n\n邢 + 大段空白内容\n\n.docx\n\nPK+[Content_Types].xml\n\n.7z\n\n> 7z\n\n.avi\n\nAVI\n\n.chm\n\nITSF+/css+/images/+htm\n\n  \n\n.mp3\n\nID3 Or [uuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuu x](https://www.zhihu.com/search?q=uuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuu%20x&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A104662028%7D) n\nFile和Blob的介绍与区别\nFile 和 Blob 都是在前端开发中经常使用的对象，它们可以用来处理二进制数据。\nFile 对象是 HTML5 中新增的一个API，它代表着一个文件对象，可以用来读取和处理本地文件。File 对象通常用于通过 &lt;input type=&quot;file&quot;&gt; 元素选择文件后，将选择的文件对象传递到服务器端。\nBlob 对象也是 HTML5 中新增的一个API，它代表着一个不可变的、原始数据的类文件对象。可以看做一个包含了二进制数据的容器，一般用于对于文件的处理，例如文件上传、视频播放、音频播放等等。\n它们的区别在于：\n\n\nFile 对象通常是由用户通过界面选择上传的文件，而 Blob 对象可以通过多种方式来创建，例如从 File 对象中提取出二进制数据，或者手动创建一个包含二进制数据的 Blob 对象。\n\n\nFile 对象有文件名、大小等属性，而 Blob 对象没有这些属性。\n\n\nFile 对象可以在上传文件时传递到服务器端，而 Blob 对象通常用于在客户端中进行处理，例如通过 URL.createObjectURL() 方法将 Blob 对象转换为可用于视频或音频播放的 URL。\n\n\n总的来说，File 和 Blob 都是用于处理二进制数据的对象，但是它们在使用场景和属性上还是有所区别的。\nJS中的File和Blob\n这个file和blob不再是文件层次的了,而是代码层次里js的对象\n创建flie和blob\nconst blob = new Blob([123]);\nconst file = new File(['123'],\"123.txt\");\nconsole.log(blob);\nconsole.log(file);\n\nconsloe.log(await blob.arrayBuffer());\nconsole.log(await file.arrayBuffer());\n//打印结果完全一样 至此我们可以姑且认为file和Blob在数据层面基本上就是一回事\n\n可以看出file的原型(Prototype)仍然是Blob\n修改file&amp;blob(二进制层面)\nconst dv = new DataView(await blob.arrayBuffer());\nconsole.log(dv);\nconsole.log(dv.getUint8(1)); //给一个字节的索引来获取该字节的值 \ndv.setUnit8(1,65); //修改索引为1的字节的值为65\n打开本地文件/获取远端文件\n选择文件\n&lt;!DOCTYPE html>\n&lt;html lang=\"en\">\n  &lt;head>\n    &lt;meta charset=\"UTF-8\" />\n    &lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\" />\n    &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n    &lt;title>Document&lt;/title>\n  &lt;/head>\n  &lt;body>\n\t&lt;input type=\"file\" onChange=onFileChange(event)>&lt;/input>\n    &lt;script>\n\t\t//同一文件打开两次 fileChange不会被触发\n\t   const onFileChange = async (e) => &#123;\n\t\t   console.log(e.target); //FileList\n\t\t   console.log(e.target.files[0]); //File\n\t\t   console.log(await e.target.files[0].arrayBuffer());   \n\t   &#125;\n    &lt;/script>\n  &lt;/body>\n&lt;/html>\n拖拽选择文件\n&lt;!DOCTYPE html>\n&lt;html lang=\"en\">\n  &lt;head>\n    &lt;meta charset=\"UTF-8\" />\n    &lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\" />\n    &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n    &lt;title>Document&lt;/title>\n  &lt;/head>\n\n  &lt;style>\n    .dragInput &#123;\n      position: absolute;\n      top: 50%;\n      left: 50%;\n      height: 100px;\n      width: 100px;\n      text-align: center;\n      border: 1px solid black;\n    &#125;\n  &lt;/style>\n  &lt;body>\n\n    &lt;div\n      class=\"dragInput\"\n      ondragover=\"onDragOver(event)\"\n      ondrop=\"onDragFile(event)\"\n    >&lt;/div>\n\n    &lt;script>\n      const onDragOver = (e) => &#123;\n        e.preventDefault();  //阻止浏览器默认的拖放行为（例如在拖放文件时防止浏览器打开文件）\n      &#125;;\n\n      const onDragFile = async (e) => &#123;\n        e.preventDefault();\n        console.log('files', e.dataTransfer.files);\n        console.log(e.dataTransfer.files[0]);\n        console.log(await e.dataTransfer.files[0].arrayBuffer());\n      &#125;;\n    &lt;/script>\n  &lt;/body>\n&lt;/html>\n限制选择文件(浏览器自带-较新)\nfile picker\n&lt;!DOCTYPE html>\n&lt;html lang=\"en\">\n  &lt;head>\n    &lt;meta charset=\"UTF-8\" />\n    &lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\" />\n    &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n    &lt;title>Document&lt;/title>\n  &lt;/head>\n  &lt;style>\n    .dragInput &#123;\n      position: absolute;\n      top: 50%;\n      left: 50%;\n      height: 100px;\n      width: 100px;\n      text-align: center;\n      border: 1px solid black;\n    &#125;\n  &lt;/style>\n\n  &lt;body>\n    &lt;div class=\"dragInput\" onclick=\"onClick()\">&lt;/div>\n    &lt;script>\n\n      // options是可选参数，支持下面这些属性\n      // multiple\n      // 布尔值，默认值是 false ，表示只能选择一个文件。\n      // excludeAcceptAllOption\n      // 布尔值，默认值是 false ，表示是否排除下面 types 中的所有的accept文件类型。\n      // types\n      // 可选择的文件类型数组，每个数组项也是个对象，支持下面两个参数：\n      // description：表示文件或者文件夹的描述，字符串，可选。\n      // accept：接受的文件类型，对象，然后对象的键是文件的MIME匹配，值是数组，表示支持的文件后缀。具体可以下面的示意。\n\n      const pickerOpts = &#123;\n        types: [\n          &#123;\n            description: 'Images',\n            accept: &#123;\n              'image/*': ['.png', '.gif', '.jpg', '.jpeg'],\n            &#125;,\n          &#125;,\n        ],\n        excludeAcceptAllOptions: true,\n        multiple: false, //是否可以多选\n      &#125;;\n\n      const onClick = async (e) => &#123;\n\t  //在window.showOpenFilePicker返回的Promise中，如果用户选择了一个或多个文件，那么Promise将被解释为一个FileHandle对象的数组。因此，如果只需要处理一个文件，可以使用解构赋值将数组中的第一个FileHandle对象提取出来，如下所示：\n        const [fileHandle] = await window.showOpenFilePicker(pickerOpts);\n        console.log(fileHandle);\n        const f = await fileHandle.getFile();\n        console.log(f);\n        console.log(await f.arrayBuffer());\n      &#125;;\n    &lt;/script>\n  &lt;/body>\n&lt;/html>\n需要注意的是，如果用户取消选择文件，window.showOpenFilePicker返回的Promise将被拒绝，需要使用try-catch块来捕获此类错误并进行处理。\n操作文件\n文本文件的创建、编辑、保存、打开、另存为\n&lt;!DOCTYPE html>\n&lt;html lang=\"en\">\n  &lt;head>\n    &lt;meta charset=\"UTF-8\" />\n    &lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\" />\n    &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n    &lt;title>Document&lt;/title>\n  &lt;/head>\n  &lt;style>\n    .fileInput &#123;\n      position: absolute;\n      top: 50%;\n      left: 50%;\n      text-align: center;\n      transform: translate(-50%, -50%);\n      border: 1px solid black;\n    &#125;\n\n    .btn-box &#123;\n      width: 100%;\n      display: flex;\n    &#125;\n\n    .container > textarea &#123;\n      border: 0;\n    &#125;\n\n    .btn-box > button &#123;\n      flex-grow: 1;\n    &#125;\n  &lt;/style>\n\n  &lt;body>\n    &lt;div class=\"fileInput\">\n      &lt;div class=\"container\">\n        &lt;textarea name=\"\" id=\"userInput\" cols=\"30\" rows=\"10\">&lt;/textarea>\n        &lt;div class=\"btn-box\">\n          &lt;button onclick=\"onCreate()\">create&lt;/button>\n          &lt;button onclick=\"onOpen()\">open&lt;/button>\n          &lt;button onclick=\"onSaveAs(true)\">save&lt;/button>\n          &lt;button onclick=\"onSaveAs(false)\">save as&lt;/button>\n        &lt;/div>\n      &lt;/div>\n    &lt;/div>\n    &lt;script>\n      const textArea = document.querySelector('#userInput');\n      let textValue = '';\n      let nowFile = null;\n      let nowFileHandler = null;\n\n      const options = &#123;\n        types: [\n          &#123;\n            description: 'Text Files',\n            accept: &#123;\n              'text/plain': ['.txt'],\n              'text/html': ['.html', '.htm'],\n              'application/json': ['.json'],\n            &#125;,\n          &#125;,\n        ],\n      &#125;;\n\n      const onCreate = async () => &#123;\n        const fileHandler = await window.showSaveFilePicker(options);\n        const writable = await fileHandle.createWritable();\n        await writable.write(textArea.value);\n        await writable.close();\n      &#125;;\n\n      const onOpen = async () => &#123;\n        //如果选择的是多个文件 则用forEach或者map遍历\n        // try &#123;\n        //   const fileHandles = await window.showOpenFilePicker(options);\n        //   fileHandles.forEach(async (fileHandle) => &#123;\n        //     const file = await fileHandle.getFile();\n        //     console.log(file);\n        //   &#125;);\n        // &#125; catch (error) &#123;\n        //   console.error(error);\n        // &#125;\n        const [fileHandler] = await window.showOpenFilePicker(options);\n        nowFileHandler = fileHandler;\n        nowFile = await fileHandler.getFile();\n        textArea.value = await nowFile.text();\n        textValue = textArea.value\n      &#125;;\n\n      const save = async (fileHandle) => &#123;\n        if (!fileHandle) &#123;\n          return;\n        &#125;\n        const stream = await fileHandle.createWritable();\n        console.log(textValue);\n        await stream.write(textValue);\n        await stream.close();\n        console.log('文件已被保存');\n      &#125;;\n\n      const onSaveAs = async (flag) => &#123;\n        // e.preventDefault();\n        const fileHandler =\n          flag &amp;&amp; !!nowFileHandler ? nowFileHandler : await onCreate();\n        save(fileHandler);\n      &#125;;\n\n      textArea.addEventListener('input', (e) => &#123;\n        // console.log(textArea.value);\n        textValue = textArea.value;\n      &#125;);\n    &lt;/script>\n  &lt;/body>\n&lt;/html>\n\n文件夹的选择\nwindow.showDirectoryPicker()\ndirHandle.values  //得到的是一个迭代器数组,你通过遍历数组才能拿到文件的handle\ndirHandle.getFileHandle()\nBlob URL&amp;File URL\nURL.createObjectURL(blob) &#x2F;&#x2F;blob url\n&#x2F;&#x2F; http:&#x2F;&#x2F;localhost:3000&#x2F;UUID\n\n&#x2F;&#x2F;需要new\nFileReader.readAsDataURL(file); &#x2F;&#x2F;data url\n&#x2F;&#x2F; data:text&#x2F;plain;base64,YW.....\n&#x2F;&#x2F;处于安全性考虑,浏览器不允许用a标签的方式打开data url\n\n&#x2F;&#x2F;其实参数中的blob和file都可以相互替换 在数据层面(二进制)二者一样\n\n&lt;a&gt;\ntarget&#x3D;&quot;_blank&quot;\ndownload&#x3D;&quot;fileName&quot;\n","slug":"File&Blob","date":"2023-07-19T14:19:55.000Z","categories_index":"前端,基本概念","tags_index":"基本概念(前端)","author_index":"ND_LJQ"},{"id":"81ec849fc0ebda5e058742eb82eb6d73","title":"页面渲染以及重排","content":"用户使用浏览器一般会打开多个页面，现代浏览器使用单独的进程 Render Process 渲染每个页面，以提升页面性能和稳定性\n\n页面的渲染\n\n\n渲染图示\n\n\n\n渲染图解\n根据 HTML 标记 解析出 DOM 树\n根据 CSS 样式 解析出 CSS 规则树\n根据 DOM 树 和 CSS 规则树 生成 渲染树\n根据渲染树计算 DOM 节点的信息（节点的大小、位置等）\n根据计算好的信息绘制页面（颜色、背景、字体等）\n\n\n重绘和回流\n\n\n重绘（repaint）\n当 DOM 元素的外观属性发生变化时，如：字体颜色或背景颜色\n浏览器会重新绘制受影响的元素到屏幕，这个过程称之为重绘\n\n\n回流（reflow）\n当 DOM 元素的几何属性发生变化时，如：盒子模型相关的属性。其周围元素的位置也会受到影响\n浏览器会重新生成渲染树且重新布局，这个过程称之为回流\n\n\n影响关系\n重绘不一定导致回流，但回流一定会导致重绘\n\n\n常见重绘、回流以及优化方案\n\n\n常见场景\n\n\n​\t\t浏览器的窗口大小改变（resize 事件）\n​\t\t添加或删除可见的 DOM 元素（必要的 DOM 操作）\n​\t\t页面中的内容发生变化\n\n\n优化方案\n\n\n​\t\t使用 document.createDocumentFragement() 优化必要的 DOM 操作\n​\t\t使用 opacity、transform、3D转换属性 开启动画的 GPU 加速\n​\t\t使用 el.style.cssText 替代 el.style 来集中改变样式\n​\t\t使用 textContent 替代 innerText 来动态修改页面中的内容\n​\t\t使用 will-change 属性提前通知浏览器元素将要做什么，让浏览器提前准备合适的优化机制，增强页面的动画渲染性能\n  `will-change` 应该被视为最后的应对手段，用于解决现有的性能问题。不应该被用来预测性能问题。\n\n实战\n滑动选项卡\n\n\n基本结构\n&lt;div class=\"tab\" id=\"tabId\">\n  &lt;ul class=\"tab-nav\">\n    &lt;li class=\"slider\" role=\"slider\">&lt;/li>\n    &lt;li data-index=\"0\">导航项&lt;/li>\n  &lt;/ul>\n  &lt;div class=\"tab-content\">\n    &lt;div>滑动内容&lt;/div>\n  &lt;/div>\n&lt;/div>\n\n\n布局技巧\n.tab &#123;\n  overflow: hidden;\n&#125;\n.tab-nav > .slider&#123;\n  transition: left .3s ease;\n&#125;\n.tab-nav:hover &#123;\n  will-change: margin-left;\n&#125;\n.tab-content &#123;\n  display: flex;\n  width: 100%;\n  transition: margin-left .3s ease;\n&#125;\n.tab-content > div &#123;\n  flex-shrink: 0;\n  width: 100%;\n&#125;\nflex-shrink 定义元素占多余空间的缩小比例（子元素的宽度和大于父元素的宽度时起作用），默认值为 1 ，即空间不足时，元素都将等比例缩小\n如果 flex-shrink 的属性设为 0 时，则空间不足时不进行缩小\n\n\n绑定事件实现滑动\nconst tabId = document.querySelector('#tabId')\nconst tabNav = tabId.querySelector('.tab-nav')\nconst tabSlideBar = tabId.querySelector('.slider')\nconst tabSlideContent = tabId.querySelector('.tab-content')\ntabNav.addEventListener('click', event => &#123;\n  const index = event.target.dataset.index\n  tabSlideBar.style = `left: $&#123;event.target.offsetLeft&#125;px;`\n  tabSlideContent.style = `margin-left: -$&#123;index * 100&#125;%;`\n&#125;)\n\n\n场景:\n列表页会有很多商品图片，自适应没有用css定义图片高度，当图片加载完成后会发生重排。为了避免这样的情况，是需要用css定好图片宽高吗？\n为了避免重排，所以要限定好图片宽高,自适应的图片，建议使用第三方CDN 结合picture标签来处理\n","slug":"页面渲染以及重排","date":"2023-07-19T13:19:55.000Z","categories_index":"前端,业务与性能优化","tags_index":"业务与性能优化(前端)","author_index":"ND_LJQ"},{"id":"ba4943db0729dc2efbbff5980075647c","title":"网络传输优化","content":"浏览器从输入地址到页面显示的过程中发生了什么？\n1、浏览器对输入的地址进行 URL 解析\n2、缓存解析，如 浏览器缓存、系统缓存、路由器缓存 等\n3、通过 DNS 服务器将主机域名转换为 IP 地址\n4、根据 IP 地址找到对应的服务器，发起 TCP 连接\n5、建立 TCP 连接后，发起 HTTP 请求\n6、服务器响应 HTTP 请求，浏览器获得 HTML 代码\n7、浏览器解析 HTML 代码，再请求代码中的资源，如 CSS、JS、图片 等\n8、浏览器解析渲染视图页面\n9、服务器断开 TCP 连接\n从整个页面渲染的链路中，可以提取关键词：URL解析、DNS解析、HTTP协议、HTTP缓存、TCP连接、服务器、响应体、渲染，根据这些关键词产出性能优化策略\nDNS域名解析优化\n\n递归查询 主机向本地域名服务器的查询\n迭代查询 本地域名服务器向根域名服务器的查询\nHTTP页面自动解析\n在页面加载的过程当中，浏览器会自动将超链接 href 属性中的域名解析为 IP 地址，但为了确保安全性，HTTPS 页面中已不再允许自动解析\nHTTPS页面自动解析\n通过HTML标签方式\n&lt;meta http-equiv&#x3D;&quot;x-dns-prefetch-control&quot; content&#x3D;&quot;on&quot;&gt;\n复制代码\n通过设置响应头的方式\nctx.set(&#39;X-DNS-Prefetch-Control&#39;, &#39;on&#39;)\n复制代码\non 表示开启解析，off 表示关闭解析\n手动解析\n&lt;link rel=\"dns-prefetch\" href=\"//file.cdn.com\">\n复制代码\n开启指定域名的预解析功能，多用于 优化 CDN 资源，推荐在项目中使用。最佳使用位置如下\n&lt;meta charset=\"utf-8\">\n&lt;link rel=\"dns-prefetch\" href=\"//file.cdn.com\">\n复制代码\n优化总结\nDNS 请求消耗的带宽非常小，但延迟有点高，尤其是在手机网络上尤为明显，通过 DNS 预解析可以明显的减少一些延迟\n可以减少用户点击链接时的等待时间，从而提升页面的响应速度\n渲染链路：HTTP1.1协议\n对异步任务并发量进行限流\n浏览器同域名下对并发请求的数量是有限制的，通常是 4 ~ 8 以内。超出的会被置入队列等待发送，即 待处理 pending 状态\n如果并发请求量达到一定量级的时候，堆积了无数的调用栈就有可能会导致 内存溢出\n浏览器的并发限制\n\n\nChrome 浏览器\n同一域名同时最多只能建立 6 个 TCP 连接，也就是说单个域名最大的并发量不超过 6 个\n\n\nSafari 浏览器\n同一域名同时最多只能建立 4 个 TCP 连接，也就是说单个域名最大的并发量不超过 4 个\n\n\n业务场景\n假设现在有 1000 个异步任务需要执行，但出于性能的考虑，我们必须将执行的数量控制在 3 个以内，同时还要尽可能快的拿到响应结果\n如：大文件的批量上传、大量的图片加载等 量化异步任务的执行且影响性能 的场景\n\n\n优化方案\n\n\n参数注解\n/**\n* @description 异步任务并发量的控制\n* @param &#123;Array&#125; list 迭代数组\n* @param &#123;Number&#125; limit 控制的并发数量\n* @param &#123;Function&#125; handler 对list每一项的处理函数\n*/\n复制代码\n\n\n首先，通过 while 循环实现初始并发\nwhile(limit--) &#123;\n  handler(list.shift())\n&#125;\n\n\n然后，通过递归依次执行下一个，直到全部执行完\nconst runInSequence = async (list, handler, callback) => &#123;\n  const item = list.shift()\n  if (item) &#123;\n    const result = await handler(item)\n    callback(result)\n    list.length &amp;&amp; runInSequence(list, handler, callback)\n  &#125;\n&#125;\n\n\n最后，组合以上逻辑\nconst asyncThrottling = (&#123; list, limit = 3, handler = () => &#123;&#125; &#125;) => &#123;\n  const response = [], len = list.length\n  return new Promise(resolve => &#123;\n    limit = len > limit ? limit : len\n    while(limit--) &#123;\n      runInSequence(list, handler, result => &#123;\n        response.push(result)\n        response.length === len &amp;&amp; resolve(response)\n      &#125;)\n    &#125;\n  &#125;)\n&#125;\n\n\n渲染链路：HTTP2协议\n","slug":"网络传输优化","date":"2023-07-19T13:19:39.000Z","categories_index":"前端,业务与性能优化","tags_index":"业务与性能优化(前端)","author_index":"ND_LJQ"},{"id":"ea1216806aa93b5906ea3a04ab718635","title":"搜索引擎排名技巧(SEO)","content":"应用的性能好坏直接影响到用户的体验，SEO 做的再好，脱离了性能优化一切也都是空谈，所以 SEO 和性能优化是相辅相成的。响应速度也是搜索引擎排序的一个重要指标\n页面头部标签\n\n\n标题（30字以内）\n&lt;title>淘宝网 - 淘！我喜欢&lt;/title>\n强调重点即可，重要的关键词出现不要超过 2 次，而且要靠前，不同页面的 title 要有所不同\n\n\n描述（150字以内）\n&lt;meta name=\"description\" content=\"淘宝网 - 亚洲较大的网上交易平台，提供各类服饰、美容、家居、数码、话费/点卡充值… 数亿优质商品，同时提供担保交易(先收货后付款)等安全交易保障服务，并由商家提供退货承诺、破损补寄等消费者保障服务，让你安心享受网上购物乐趣！\">\n对页面内容的高度概括，不可过分堆砌关键词，不同页面的 description 要有所不同\n\n\n关键字\n&lt;meta name=\"keywords\" content=\"淘宝,掏宝,网上购物,C2C,在线交易,交易市场,网上交易,交易市场,网上买,网上卖,购物网站,团购,网上贸易,安全购物,电子商务,放心买,供应,买卖信息,网店,一口价,拍卖,网上开店,网络购物,打折,免费开店,网购,频道,店铺\">\n告诉搜索引擎本页的重点、关键词，用英文逗号分隔\n\n\n总结\n代码顺序按照 标题 -&gt; 描述 -&gt; 关键字 依次\n\n\n语义化的好处\n\n\n符合W3C规范\n\n\n代码结构清晰，方便阅读，有利于团队合作开发\n\n\n语义化代码让搜索引擎容易理解网页，有利于搜索引擎优化（SEO）\n\n\n语义化内容标签\n\n\n超链接\n内部链接，要加 title 属性加以说明\n外部链接，要加 rel=&quot;nofollow&quot; 属性，告诉蜘蛛无需追踪\n\n\n图片\nimg 要加上 alt 属性加以说明\n\n\n表格\n标题使用 caption 标签\n\n\n标题\nh1 一个页面只可有一个，多用于包含 logo\nh2 模块标题\nh3 段落的小节标题\nh4, h5, h6 基本上不使用\n\n\n强调内容的重要性\n&lt;em>强调文本&lt;/em>\n&lt;strong>强调文本&lt;/strong>\nstrong 和 em 都表示强调，strong 显示为粗体，em 显示为斜体，且 strong 的强调程度要比 em 更高\n\n\n视觉上突出显示文本\n&lt;mark>&lt;/mark>\n如：搜索结果中高亮的关键词\n\n\n时间\n&lt;p>文章发表于&lt;time datetime=\"2019-08-28 20:00\">2019-08-28&lt;/time>&lt;/p>\n\n\n定义联系信息\n&lt;address>&lt;/address>\n也可定义 article 元素的作者信息，但不适用于嵌套的 article 元素\n\n\n代表一段独立的内容，经常与说明配合使用\n&lt;figure>\n  &lt;!-- 图片、图表、表格等 -->\n  &lt;figcaption>标题/说明&lt;/figcaption>\n&lt;/figure>\nfigcaption 元素必须是 figure 元素的第一个或者最后一个子元素\n\n\n换行\nbr 只用于文本内容的换行\n\n\n版权符号\n输入法输入 'banquan'，按序号选择版权符号\n\n\n语义化结构标签\n\n\nsection使用场景\n&lt;header>&lt;/header>\n&lt;section>\n  &lt;h2>标题&lt;/h2>\n  &lt;p>段落内容&lt;/p>\n&lt;/section>\n&lt;section>\n  &lt;h2>标题&lt;/h2>\n  &lt;img src=\"./img/product.jpg\" alt=\"图片说明\">\n&lt;/section>\n&lt;section>\n  &lt;h2>标题&lt;/h2>\n  &lt;p>段落内容&lt;/p>\n&lt;/section>\n&lt;footer>&lt;/footer>\n对页面中的内容进行分块，一个 section 元素通常由标题以及内容组成\n不推荐为那些没有标题的内容使用 section 标签\n\n\narticle使用场景\n&lt;article>\n  &lt;header>\n    &lt;h2>标题&lt;/h2>\n    &lt;p>发表日期：&lt;time datetime=\"2019-08-28 20:00\">2019-08-28&lt;/time>&lt;/p>\n  &lt;/header>\n  &lt;p>文章内容段&lt;/p>\n  &lt;p>文章内容段&lt;/p>\n&lt;/article>\n它比 section 具有更明确的语义，代表一个独立的、完整的相关内容块，可以包含一个或多个 section\n\n\naside使用场景\n&lt;aside>\n  &lt;h2>&lt;/h2>\n  &lt;ul>\n    &lt;li>&lt;/li>\n    &lt;li>&lt;/li>\n  &lt;/ul>\n&lt;/aside>\n独立于内容的一部分，且可以被单独的拆分出来而不会使整体受影响，常用于定义页面侧边栏\n\n\nmain使用场景\n&lt;main>&lt;/main>\n用来呈现文档或应用的主体部分，一个页面只能有一个 main 标签\n\n\nheader使用场景\n1、页面中的header\n&lt;header>\n  &lt;h1 role=\"logo\">\n    &lt;a href=\"/\">文字Logo&lt;/a>\n  &lt;/h1>\n  &lt;nav>\n    &lt;a href=\"/\">首页&lt;/a>\n    &lt;a href=\"/product\">产品介绍&lt;/a>\n    &lt;a href=\"/about\">关于我们&lt;/a>\n  &lt;/nav>\n&lt;/header>\n2、分块中的header\n&lt;section>\n  &lt;header>\n    &lt;h2>标题&lt;/h2>\n    &lt;p>信息介绍&lt;/p>\n  &lt;/header>\n  &lt;p>分块内容段&lt;/p>\n&lt;/section>\n3、文章中的header\n&lt;article>\n  &lt;header>\n    &lt;h2>标题&lt;/h2>\n    &lt;p>发表日期：&lt;time datetime=\"2019-08-28 18:00\">2019-08-28&lt;/time>&lt;/p>\n  &lt;/header>\n  &lt;p>文章内容段&lt;/p>\n&lt;/article>\narticle、section、aside、nav 都可以拥有自己的 header 和 footer\n\n\nrole属性的使用场景\n用来增强语义性，当现有的 HTML 标签不能充分表达语义的时候，可以借助 role 属性来说明\n\n\n注意事项\n\n\n重要内容尽量靠前放\n搜索引擎抓取 HTML 的顺序是从上到下的，而有的搜索引擎对抓取的内容长度有一定的限制\n\n\n重要内容不要用JS输出\n搜索引擎不会抓取 JS 的生成内容\n\n\n其他\n页面结构尽量扁平化，目录结构不宜过深，最好不超过 三级，每级都有 面包屑导航，成树状结构分布。否则不利于搜索引擎抓取\n做 404 页面，不仅提高蜘蛛体验，也提高用户体验\n\n\n","slug":"搜索引擎排名技巧-SEO","date":"2023-07-19T13:19:20.000Z","categories_index":"前端,业务与性能优化","tags_index":"业务与性能优化(前端)","author_index":"ND_LJQ"},{"id":"4ce09d3d170357da8e430d5390eb09ca","title":"视频与推流","content":"Video标签\n&lt;video>\n&lt;/video>\n\n&lt;!-- \nvideo 标签属性中的属性:\nsrc=\"\" :资源路径\ncontrols : 在视频块中添加视频控件(暂停,倍速...)\nalt=\"\":用于SEO(Search Engine Optimization 搜索引擎优化)\nautoplay 视频自动播放,因为浏览器的安全机制问题,有的浏览器支持,有的浏览器需要用户手动点击进行播放操作\nloop=\"true/false\":视频播放完是否循环播放\nposter=\"url\": 视频播放前显示预览图（海报图片）\n---->\n如果浏览器不支持video标签则在其子元素中添加提示语句\n&lt;video>\n    浏览器不支持video\n&lt;/video>\n也可以通过js创建一个空video元素,进行判断\nif(document.createElement('video').canPlayType)&#123;\n    console.log('支持video');\n&#125;else&#123;\n    console.log('不支持video');\n&#125;\n浏览器video中src出现错误无法进行加载情况:使用video子元素source来进行视频的轮询\n&lt;video controls>\n    &lt;source src=\"\">&lt;/source>\n\t&lt;source src=\"\">&lt;/source>\n\t&lt;source src=\"\">&lt;/source>\n&lt;/video>\nsource中的地址从上至下依次请求,直到请求成功\n自己实现控件(使用js中创建的video元素对象中的方法)\n&lt;video class=\"video-test\">\n    &lt;source src=\"\">&lt;/source>\n\t&lt;source src=\"\">&lt;/source>\n\t&lt;source src=\"\">&lt;/source>\n&lt;/video>\n\n&lt;button onClick=\"videoPlay(e)\">\n\t播放\n&lt;/button>\n\n&lt;script>\n\tconst video = document.querySelector(\".video-test\");\n    \n    const videoPlay = (e) =>&#123;\n        video.play();\n    &#125;\n    \n&lt;/script>\ncurrentTime\n由js创建的vidoe的dom对象中的属性,记录了当前视频的相对时间,即当前视频播放进度(刚开始默认为0)\n&lt;video class=\"video-test\">\n    &lt;source src=\"\">&lt;/source>\n\t&lt;source src=\"\">&lt;/source>\n\t&lt;source src=\"\">&lt;/source>\n&lt;/video>\n\n&lt;button onClick=\"videoPlay(e)\">\n\t播放\n&lt;/button>\n\n&lt;script>\n\tconst video = document.querySelector(\".video-test\");\n    video.load();//虽然没有进行播放操作,但是可以从远端拉取流到本地缓冲区\n    \n    \n    const videoPlay = (e) =>&#123;\n        video.play();\n        console.log(video.currentTime)\n    &#125;\n    \n&lt;/script>\n通过对currentTime进行赋值,可以使视频跳转到指定时间帧\n音量(Volume)\n视频中的音量是相对与系统的音量的逻辑值(0%-100%)\n即假如系统的音量是80,那么视频的最高100%就是系统音量的80\n&lt;script>\n\tconst video = document.querySelector(\".video-test\");\n    video.load();//虽然没有进行播放操作,但是可以从远端拉取流到本地缓冲区\n    \n    \n    const videoPlay = (e) =>&#123;\n        video.play();\n       \tvideo.volume = 0.2\n    &#125;\n    \n&lt;/script>\nmuted\n通过设置创建的video的dom属性的muted可以控制视频是否静音true静音,false有声音\n&lt;script>\n\tconst video = document.querySelector(\".video-test\");\n    video.load();//虽然没有进行播放操作,但是可以从远端拉取流到本地缓冲区\n    \n    \n    video.onclick = () =>&#123;\n        video.play();\n        video.muted = !video.muted\n    &#125;\n    \n&lt;/script>\nduration\n返回视频总共的时长,获取失败返回NaN,获取成功返回秒数\ncurrentSrc\n返回当前正在播放资源的地址\n即返回video标签的当前在播放的子标签source的src\npaused:是否为暂停状态,是为true,否为false\nended:是否为完播状态,是为true,否为false\n视频\n相关概念\nFPS(帧率)\n视频内一秒内播放的画面,越高越流畅,越占用系统资源\nPs:24fps为人眼观看流畅标准,30为正常标准,60为显示器标准\n分辨率\n水平方向上的包含的像素点×垂直方向上包含的像素点 = 分辨率\n码率\n视频文件在单位时间内使用的数据流量,通俗来讲就是单位时间画面采集频率\n文件体积=时间X码率/8 (这里时间单位是秒,码率单位为bps即比特每秒)\n三者之间的关系:\n\n\n帧率越高,每秒经过的画面越多,需要的码率也越高,体积也越大\n\n\n在码率一定的情况下,分辨率与清晰度成反比:分辨率越高,图像越不清晰,分辨率越低图像越清晰\n\n\n在分辨率一定的情况下,码率与清晰度成反比:码率越高,图像越不清晰,码率越低图像越清晰\n\n\n每帧的图片大小\n1帧 = 分辨率 × 24  -&gt;一个像素点是由rgb组成 rgb为三个字节一个字节8比特,则为3×8 = 24\n直播推流\n\n整体架构\n\n工作流程\n\n","slug":"视频与推流","date":"2023-07-19T13:18:56.000Z","categories_index":"前端,业务与性能优化","tags_index":"业务与性能优化(前端)","author_index":"ND_LJQ"},{"id":"5f8a523ee16501c6a364a90cb823f180","title":"事件处理程序的相关优化","content":"事件流机制\n向水里扔一个西瓜，\n首先它会有一个下降的过程，这个过程可以理解为从最顶层元素向事件发生的具体元素（目标点）的捕获过程\n之后会产生泡泡，会在最低点（具体元素）之后漂浮到水面上，这个过程相当于事件冒泡\n\n事件处理程序\n\n\n事件委托原理\n利用事件冒泡，只使用一个事件处理程序来管理一系列的类型事件\n也就是说给所有目标元素的共同祖先节点添加一个事件处理程序即可\n这样可以减少大量的内存消耗，提升性能\n\n\n性能解析\n页面中事件处理程序的数量与页面的整体性能直接相关\n每个函数都是对象，都占用内存空间，对象越多，性能越差\n事件处理程序所需访问的 DOM 次数会影响整个页面的就绪时间，导致页面响应缓慢\n\n\n事件对象\nevent.target  &#x2F;&#x2F; 触发事件的目标元素\nevent.currentTarget  &#x2F;&#x2F; 绑定事件的元素\nevent.stopPropagation()  &#x2F;&#x2F; 阻止事件冒泡\nevent.preventDefault()  &#x2F;&#x2F; 阻止元素的默认事件\n\n\n划入划出事件\n\n\nmouseover 和 mouseout\n在鼠标指针从父元素移动到子元素时，会先触发父元素的 mouseout 事件，再触发子元素的 mouseover 事件；在鼠标指针从子元素移回父元素时，会先触发子元素的 mouseout 事件，再触发父元素的 mouseover 事件。这种行为被称为事件冒泡或捕获机制。\n&lt;div id=\"box\">\n  &lt;button type=\"button\">按钮&lt;/button>\n&lt;/div>\n.box &#123;\n  width: 200px;\n  height: 80px;\n  background-color: #0f0;\n&#125;\nconst box = document.querySelector('#box')\nbox.addEventListener('mouseover', () => &#123;\n  console.log('移动到自身和其子元素身上都会触发事件')\n&#125;)\n\n\nmouseenter 和 mouseleave\nbox.addEventListener('mouseenter', () => &#123;\n  console.log('只移动到自身触发事件')\n&#125;)\n\n\n","slug":"事件处理程序的相关优化","date":"2023-07-19T13:18:43.000Z","categories_index":"前端,业务与性能优化","tags_index":"业务与性能优化(前端)","author_index":"ND_LJQ"},{"id":"86764947a727ee084db201a1bc419262","title":"上传文件校验","content":"如果把任意的垃圾文件后缀名修改成允许上传的类型，不仅会造成程序崩溃，还有可能会浪费不必要的资源\n这种恶意上传的操作，不仅带来安全隐患，还会造成不必要的性能开销\n前置知识点\n[[File&amp;Blob]]\n\n\nBlob 对象\nBlob（Binary Large Object）二进制类型的大对象，表示一个不可变、原始数据的类文件对象。可以通过 slice() 方法将它们分割成为非常小的数据块\nFile 接口基于 Blob 实现，继承了其功能并将其扩展，使其支持用户系统上的文件\n\n\nFileReader 对象\n主要用于将文件内容读入 内存，通过一系列 异步接口 读取本地文件内容并输出结果\nreadAsArrayBuffer() 按字节读取文件内容，结果用 ArrayBuffer 对象表示\nreadAsText() 按字节读取文件内容，结果用字符串表示\nreadAsDataURL() 读取文件内容，结果用 data:URL 格式的 Base64 字符串表示\n\n\nArrayBuffer 对象\n表示通用的、固定长度的原始二进制数据缓冲区，它是一个 二进制字节数组\n\n\nUint8Array 数组类型\n表示一个 8 位无符号整型数组，创建时内容被初始化为 0。创建完后，可以以 对象的方式或使用数组下标索引的方式 引用数组中的元素\n\n\n前置插件配置\n\n\n安装 VSCode 插件\n\n\n在插件商店中搜索并安装 Hex Editor\n\n\n使用插件查看文件的十六进制内容（以 jpg 文件为例）\n\n\n\n常规类型校验\n\n\n使用 HTML 属性\n&lt;input type=\"file\" accept=\".mp4, .mov\">\n&lt;input type=\"file\" accept=\".png, .jpg, .jpeg, .gif\">\n缺点：可通过浏览器控制台删除 accept 属性，绕过限制\n\n\n使用文件 MIME 类型\nconst validFileType = Object.assign(Object.create(null), &#123;\n        video: ['video/mp4', 'video/quicktime'],\n        image: ['image/png', 'image/jpeg', 'image/gif'],\n      &#125;);\n\n\nconst validator = (type, files) =&gt;\n        files\n          .map((file) =&gt; ({\n            filename: file.name,\n            valid: validFileType[type].includes(file.type),\n          }))\n          .filter((f) =&gt; !f.valid);\n    \n\n    缺点：可通过本地修改文件扩展名，绕过限制\n\n\n# 安全性类型校验\n\n- 核心思想\n\n  使用 &#96;slice()&#96; 方法截取文件头部数据，将其转换为 &#96;十六进制&#96; 字符串，然后进行逻辑判断\n\n- 配置文件类型映射策略\n\n  &#96;&#96;&#96;js\n  const typeMapping &#x3D; new Map([\n    [&#39;mp4&#39;, &#123; num: 4, hexs: [&#39;00 00 00 18&#39;, &#39;00 00 00 20&#39;, &#39;00 00 00 1C&#39;] &#125;],\n    [&#39;mov&#39;, &#123; num: 8, hexs: [&#39;00 00 00 14 66 74 79 70&#39;] &#125;],\n    [&#39;jpg&#39;, &#123; num: 3, hexs: [&#39;FF D8 FF&#39;] &#125;],\n    [&#39;png&#39;, &#123; num: 8, hexs: [&#39;89 50 4E 47 0D 0A 1A 0A&#39;] &#125;],\n    [&#39;gif&#39;, &#123; num: 4, hexs: [&#39;47 49 46 38&#39;] &#125;],\n    [&#39;pdf&#39;, &#123; num: 7, hexs: [&#39;25 50 44 46 2D 31 2E&#39;] &#125;],\n    [&#39;zip&#39;, &#123; num: 6, hexs: [&#39;50 4B 03 04 14 00&#39;] &#125;],\n    [&#39;excel&#39;, &#123; num: 4, hexs: [&#39;50 4B 03 04&#39;] &#125;],\n    [&#39;image&#39;, &#123; num: 8, hexs: [&#39;FF D8 FF&#39;, &#39;89 50 4E 47 0D 0A 1A 0A&#39;, &#39;47 49 46 38&#39;] &#125;],\n    [&#39;video&#39;, &#123; num: 8, hexs: [&#39;00 00 00 18&#39;, &#39;00 00 00 20&#39;, &#39;00 00 00 1C&#39;, &#39;00 00 00 14 66 74 79 70&#39;] &#125;]\n  ])\n使用 num 来配置提取文件头部数据的范围，提取起始处的索引从 0 开始\n使用 hexs 来配置提取范围对应的十六进制字符串，用于策略逻辑判断\n\n\n根据文件类型读取映射策略\nconst validFileType = async (type, file) => &#123;\n  const &#123; num, hexs &#125; = typeMapping.get(type)\n  const str = await blobToString(file.slice(0, num))\n  if (type === 'image' || type === 'video') &#123;\n    return hexs.some(hex => str.startsWith(hex))\n  &#125; else &#123;\n    return str === hexs.join()\n  &#125;\n&#125;\n\n\n文件的二进制数据转为十六进制字符串\n/**\n* @param &#123;Blob&#125; blob 二进制文件数据\n* @return &#123;String&#125; 16进制字符串\n*/\nconst blobToString = async (blob) => &#123;\n        const buffer = await blob.arrayBuffer();\n        return [...new Uint8Array(buffer)]\n          .map((n) => n.toString(16).toUpperCase().padStart(2, '0'))\n          .join(' ');\n      &#125;;\n\n\n文件类型校验\n/**\n* @param &#123;String&#125; type 文件类型\n* @param &#123;Array&#125; files 文件对象\n* @return &#123;Array&#125; 文件类型校验不通过的文件列表\n*/\nconst validator = async (type, files) =>\n        (\n          await Promise.all(\n            files.map(async (file) => (&#123;\n              filename: file.name,\n              valid: await validFileType(type, file),\n            &#125;))\n          )\n        ).filter((f) => !f.valid);\n经测试，即便通过本地修改文件扩展名，文件也会被校验限制\n\n\n总结\n很多攻击方式都是把可执行文件的后缀名进行修改，然后上传到服务器进行攻击，可见文件类型校验的重要性\n\n\n","slug":"上传文件校验","date":"2023-07-19T13:18:22.000Z","categories_index":"前端,业务与性能优化","tags_index":"业务与性能优化(前端)","author_index":"ND_LJQ"},{"id":"b8bc55f65f263c1da29bfad5ecf3ec77","title":"防盗链以减少第三方使用","content":"详解Referer\n\n\nReferer是什么\nReferer 是请求头信息里的一个常见字段，它提供了访问来源的信息\n当客户端向服务端发送请求时，都会携带 Referer 头字段，告知服务器该请求的来源，即 触发请求的页面链接\n\n\nReferer存在的条件\n1、点击页面中的超链接\n2、通过 src 或 href 属性加载静态资源，如图片、视频、脚本、样式等等\n3、通过 get 或 post 发送请求\n\n\n获取不到Referer的情况\n1、直接在浏览器中输入 URL 地址\n2、在 HTTPS 应用中使用第三方应用的 HTTP 资源\n\n\nReferer的作用\n1、对应用流量的来源做统计\n2、防止资源被盗链\n\n\n当页面链接至使用 target=&quot;_blank&quot; 的另一个页面时，新页面将与您的页面在同一个进程上运行。 如果新页面正在执行开销极大的 JavaScript，页面性能可能会受影响。target=&quot;_blank&quot;也是一个安全漏洞。新的页面可以通过window.opener 访问您的窗口对象，并且它可以使用 window.opener.location = newURL将页面导航至不同的网址。\n原来，当你使用target=&quot;_blank&quot;打开一个新的标签页时，新页面的window对象上有一个属性 opener ,它指向的是前一个页面的window对象，因此，后一个新打开的页面就可以控制前一个页面了，事情就是这么的可怕…\na标签&lt;a href='https://www.xxx.com'&gt;https://www.xxx.com&lt;/a&gt;,如果打开的页面的域名和当前页面的域名是在同一个域名下，在打开后的控制台输入window.opener.alert(1),你会惊讶的发现，上一个页面竟然弹出个大大的1，自己动手试一下吧！\n而在跳转到另一个域名的页面的情况下，使用window.opener.location.replace方法，可以把上一个页面的url给改掉\n详解盗链\n\n\n什么是盗链\n未经第三方授权或同意，就把其资源引用到了自己的应用上，比如图片、视频、文件下载等等，可以通过消耗第三方应用的流量来在自己的应用中使用这些资源\n浏览器在页面呈现的过程中，拉取非当前应用的资源，就称为是盗链\n\n\n实现盗链\n1、在 HTTPS 应用中使用第三方应用的 HTTP 资源\n\n\n2、通过设置 a 标签的 rel 属性\n\n\n&lt;a href=\"视频资源地址\" target=\"_blank\" rel=\"noopener noreferrer\">\n通过设置 noreferrer 属性禁用请求头部的 Referer 属性，可在新页面中访问防盗链资源\n通过设置 noopener 属性在新打开的页面中不授予对打开它的文档的访问权限，即 window.opener 属性值返回 null，以此来确保无法通过 window.opener 属性来篡改原始文档\nrel=noreferrer 是为了兼容旧浏览器。\n\n\n注意事项\n平常在应用中通过 a 标签链接第三方外部资源时（打开新页面），都应该添加以上属性，以增强应用的安全性\n从 Chromium 88 版开始，默认情况下，带有 target=“_blank” 的锚点会自动获得 noopener 行为。\n","slug":"防盗链以减少第三方使用","date":"2023-07-19T13:18:04.000Z","categories_index":"前端,业务与性能优化","tags_index":"业务与性能优化(前端)","author_index":"ND_LJQ"},{"id":"f5f9f413e1e1b984d70a81caebf4b657","title":"代码中大量ifelse的优化策略","content":"单个 if 语句单条件优化\n\n\n优化前\nif (flag) &#123;\n  this.handleFunc()\n&#125;\n\n\n优化后\nflag &amp;&amp; this.handleFunc()\n如果有很多的 if 语句，但执行的功能函数是同一个的情况下，可以使用 &amp; 和 || 逻辑运算符合成一个表达式，增强其 可读性\n\n\n单个 if 语句多条件优化\n\n\n优化前\nif (filetype === 'image/png' || filetype === 'image/jpeg' || filetype === 'image/gif') &#123;\n  console.log('文件类型为图片')\n&#125;\n\n\n优化后\nconst mimetypes = ['image/png', 'image/jpeg', 'image/gif']\nif (mimetypes.includes(filetype)) &#123;\n  console.log('文件类型为图片')\n&#125;\n\n\n单个 if/else 语句优化\n\n\n优化前\nlet accountStatus = ''\nif (enabled) &#123;\n  accountStatus = '正常'\n&#125; else &#123;\n  accountStatus = '禁用'\n&#125;\n\n\n优化后\nconst accountStatus = enabled ? '正常' : '禁用'\n只需要一行语句，代码既简练又易读\n\n\n多个 else if 分支优化\n\n\n优化前\nif (operation === 'open') &#123;\n  this.handleOpen()\n&#125; else if (operation === 'pause') &#123;\n  this.handlePause()\n&#125; else if (operation === 'edit') &#123;\n  this.handleEdit()\n&#125; else &#123;\n  this.handleDelete()\n&#125;\n设计复杂，代码可读性差，随着逻辑复杂性的增加，代码会变得越来越臃肿\n\n不同条件分支的代码具有很高的耦合度。前边的条件判断影响后续的代码流，这样的代码对于后期的维护非常的不友好\n\n\n优化后\nswitch(operation) &#123;\n  case 'open': \n    this.handleOpen()\n    break\n  case 'pause':\n    this.handlePause()\n    break\n  case 'edit':\n    this.handleEdit()\n    break\n  default:\n    this.handleDelete()\n&#125;\n\n\n多个 if 语句多层复杂条件优化\n\n\n优化前\nif (mode === 'kwai') &#123;\n  if (operation === 'open') &#123;\n    this.handleKwaiOpen()\n  &#125; else if (operation === 'pause') &#123;\n    this.handleKwaiPause()\n  &#125; else if (operation === 'edit') &#123;\n    this.handleKwaiEdit()\n  &#125; else &#123;\n    this.handleKwaiDelete()\n  &#125;\n&#125; else if (mode === 'tencent') &#123;\n  if (operation === 'open') &#123;\n    this.handleTencentOpen()\n  &#125; else if (operation === 'pause') &#123;\n    this.handleTencentPause()\n  &#125; else if (operation === 'edit') &#123;\n    this.handleTencentEdit()\n  &#125; else &#123;\n    this.handleTencentDelete()\n  &#125;\n&#125;\n\n\n优化后\nconst operations = Object.assign(Object.create(null), &#123;\n  'kwai': new Map([\n    ['open', handleKwaiOpen],\n    ['pause', handleKwaiPause],\n    ['edit', handleKwaiEdit],\n    ['delete', handleKwaiDelete],\n  ]),\n  'tencent': new Map([\n    ['open', handleTencentOpen],\n    ['pause', handleTencentPause],\n    ['edit', handleTencentEdit],\n    ['delete', handleTencentDelete],\n  ])\n&#125;)\n\nfunction(mode, type) &#123;\n  console.log('handleType', operations[mode].get(type))\n&#125;\n\n\n可选链运算符\n\n\n优化前\nif (res &amp;&amp; res.userInfo &amp;&amp; res.userInfo.roles) &#123;\n  const roles = res.userInfo.roles\n&#125;\n对象属性层层判断是否存在不仅麻烦还会产生冗余的代码\n\n\n优化后\nconst roles = res?.userInfo?.roles\n\n\n优化总结\nif-else 不超过 2 层，块中代码 1~5 行，直接写到块中，否则封装为方法\nif-else 超过 2 层，但块中的代码不超过 3 行，尽量使用 Switch 语句\nif-else 超过 2 层，且块中代码超过 3 行，尽量使用策略模式\n","slug":"代码中大量ifelse的优化策略","date":"2023-07-19T13:17:38.000Z","categories_index":"前端,业务与性能优化","tags_index":"业务与性能优化(前端)","author_index":"ND_LJQ"},{"id":"cf49f6c451570ecd3976ecdcea1f962a","title":"遍历一次把扁平数组转Tree","content":"树结构（Tree） 是一种典型的非线性数据结构，它是由 n (n &gt; 0) 个有限节点组成的一个具有层次关系的集合\n\n在实际的工作中，为了满足业务需求，需要把后端返回的扁平化的数组结构，转换成树形结构\n数据结构\n\n\n扁平数据\n[\n  &#123; id: 1, pid: null, name: 'M1部门' &#125;,\n  &#123; id: 11, pid: 1, name: '张三' &#125;,\n  &#123; id: 12, pid: 1, name: '李四' &#125;,\n  &#123; id: 13, pid: 1, name: '王五' &#125;,\n  &#123; id: 2, pid: null, name: 'M2部门' &#125;,\n  &#123; id: 21, pid: 2, name: '赵六' &#125;,\n  &#123; id: 22, pid: 2, name: '周七' &#125;,\n  &#123; id: 23, pid: 2, name: '吴八' &#125;\n]\n\n\n树形数据\n[\n  &#123;\n    id: 1, pid: null, name: 'M1部门',\n    children: [\n      &#123; id: 11, pid: 1, name: '张三' &#125;,\n      &#123; id: 12, pid: 1, name: '李四' &#125;,\n      &#123; id: 13, pid: 1, name: '王五' &#125;\n    ]\n  &#125;,\n  &#123;\n    id: 2, pid: null, name: 'M2部门',\n    children: [\n      &#123; id: 21, pid: 2, name: '赵六' &#125;,\n      &#123; id: 22, pid: 2, name: '周七' &#125;,\n      &#123; id: 23, pid: 2, name: '吴八' &#125;\n    ]\n  &#125;\n]\n\n\n递归算法\n\n\n定义\n程序调用自身的编程技巧称为递归\n\n\n作用\n它通常把一个大型复杂的问题层层转化为一个与原问题相似的规模较小的问题来求解，递归策略只需少量的程序就可描述出解题过程所需要的多次重复计算，大大地减少了程序的代码量\n\n\n递归转换\n\n\n根据 pid 和 id 的对应关系筛选出根结点\nlist.filter(item => item.pid === null)\n\n\n遍历根节点调用自身匹配子节点\nconst listToTree = (list, &#123;rootid = null, id = 'id', pid = 'pid'&#125; = &#123;&#125;) => &#123;\n  return list.filter(item => item[pid] === rootid)\n              .map(item => (&#123; ...item, children: listToTree(list, &#123; rootid: item[id] &#125;) &#125;))\n&#125;\n\n\n性能解析\n递归容易造成堆栈的溢出，且消耗大量的内存\n\n\n遍历转换\n\n\n核心思想\n利用引用数据类型浅拷贝的特性，直接从 Map 中找对应的数据进行存储\n\n\n通过 id 给列表的每一项做一个映射\nconst hash &#x3D; new Map()\nlist.forEach(item &#x3D;&gt; hash.set(item.id, item))\n\n\n通过 pid 从映射中取父节点\nconst listToTree &#x3D; (list &#x3D; [], &#123;id &#x3D; &#39;id&#39;, pid &#x3D; &#39;pid&#39;, branch &#x3D; &#39;children&#39;&#125; &#x3D; &#123;&#125;) &#x3D;&gt; &#123;\n  const hash &#x3D; new Map(), roots &#x3D; []\n  list.forEach(item &#x3D;&gt; &#123;\n    hash.set(item[id], item)\n    const parent &#x3D; hash.get(item[pid])\n    if (!parent) &#123;\n      roots.push(item)\n    &#125; else &#123;\n      !parent[branch] &amp;&amp; (parent[branch] &#x3D; [])\n      parent[branch].push(item)\n    &#125;\n  &#125;)\n  return roots\n&#125;\n如果节点不存在则当前节点 item 为根节点\n如果存在则把当前 item 节点添加到 parent 节点的 children 属性中\n\n\n参数注解\n/**\n* 扁平数据结构转Tree\n* \n* @param &#123;Array&#125; list 源数据\n* @param &#123;String&#125; id 唯一的自增ID名称\n* @param &#123;String&#125; pid 父ID名称\n* @param &#123;String&#125; branch 树杈字段名称\n* @return &#123;Array&#125; roots 目标数据\n* @example\n*\n*   listToTree(data)\n*   listToTree(data, &#123; branch: 'children' &#125;)\n*/\n\n\n","slug":"遍历一次把扁平数组转Tree","date":"2023-07-19T13:17:11.000Z","categories_index":"","tags_index":"","author_index":"ND_LJQ"},{"id":"9912943b0301d4d9cf01afa248355baf","title":"chatGpt返回数据实时更新(SSE)","content":"服务器发送事件（Server-Sent Events，简称 SSE） 其实就是浏览器向服务器发送一个 HTTP 请求，然后服务器不断单向地向浏览器推送消息\n所谓的消息，其实就是一定格式的文本事件流（数据流）\n\nSSE的特点\n\n\n基于 http 协议的单向通信\n\n\n默认支持断线重连，并支持发送自定义事件类型消息\n\n\n只支持发送文本\n\n\n是 WebSocket 的一种轻型替代方案，受同源策略的限制\n\n\n前端: 不使用xhr/fetch,而使用特定的API : EventSource\n\n\n后端: Content-Type: text/event-stream\n\n\n消息的构成\n\n\n消息唯一标识（id）\n相当于每一条数据的编号，可通过 lastEventId 属性读取。一旦连接中断，浏览器会发送包含 Last-Event-ID: id 头信息来帮助服务器重建连接\n\n\n消息内容（data）\n只能为文本字符串，发送 JSON 数据 data:$&#123;JSON.stringify(&#123; name: 'adiu', alias: '老夫子' &#125;)&#125;\\n\\n\n\n\n自定义事件类型（event）\n服务器端可自定义，浏览器端通过 addEventListener 监听，如果未指定，则触发浏览器端的 message 事件\n\n\n最大间隔时间/毫秒（retry）\n如果未指定通信的最大间隔时间，服务器端 3 秒内没有发送任何信息，浏览器端默认开始重连\n由于网络错误导致连接出错，浏览器也会自动重新发起连接\n\n\nSSE和Socket的区别\n\n\n通信方式\nSSE为单向通信,Socket为全双工、半双工通信\n\n\n协议\nSSE为http GET,Socket为ws\n\n\n跨域\nSSE不能跨域,Socket可以跨域\n\n\n客户端代码\n\n\n检测浏览器是否支持\nif (!!window.EventSource) &#123;\n  console.log('当前浏览器支持事件推送')\n&#125;\n\n\n建立连接\nif (!!window.EventSource) &#123;\n  const ets = new EventSource('http://127.0.0.1/sse/notice')\n&#125;\n\n\n连接状态（ets.readyState）\n0 表示连接还未建立，或者连接断线\n1 表示连接已经建立，可以接受数据\n2 表示连接已断，且不会重连\n\n\n建立连接，触发事件\nets.addEventListener('open', event => &#123;\n  console.log('handle open event')\n&#125;)\n连接一旦建立，就会触发 open 事件\n\n\n错误处理\nets.addEventListener('error', event => &#123;\n  console.log('handle error event')\n&#125;)\n如果发生通信错误（比如连接中断），就会触发 error 事件\n\n\n自定义事件\nets.addEventListener('notice', event => &#123;\n  const &#123; data, origin, lastEventId &#125; = event\n  console.log('消息内容', data)\n  console.log('服务器端URL的域名部分，即协议、域名和端口', origin)\n  console.log('数据的编号，由服务器端发送。如果没有编号，这个属性为空', lastEventId)\n&#125;)\n\n\n关闭推送\nets.close()\n默认情况下，如果客户端和服务端之间的连接关闭，则会自动重连。可以通过 close() 方法终止连接\n\n\n实战\n&lt;!DOCTYPE html>\n&lt;html lang=\"en\">\n  &lt;head>\n    &lt;meta charset=\"UTF-8\" />\n    &lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\" />\n    &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n    &lt;title>chatgpt stream 响应数据SSE测试 demo&lt;/title>\n  &lt;/head>\n  &lt;body>\n    &lt;button class=\"btn\">请求接口&lt;/button>\n    &lt;div id=\"result\" style=\"word-wrap: break-word;\">&lt;/div>\n    &lt;script type=\"module\">\n    let resultEl = document.querySelector('#result')\n    // SSE https://developer.mozilla.org/zh-CN/docs/Web/API/Server-sent_events/Using_server-sent_events#%E4%BB%8E%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%8E%A5%E5%8F%97%E4%BA%8B%E4%BB%B6\n    // 前端 EventStream API 发起请求，后端 Koa，ctx.body 设置 stream 可写流，ctx.set 响应类型 text/event-stream。\n    document.querySelector(\".btn\").addEventListener(\"click\", () => &#123;\n        const evtSource = new EventSource(\"/open-ai/sendMsg\");\n        evtSource.onmessage = function (event) &#123;\n          console.log(\"message: \" + event.data);\n          resultEl.innerHTML += event.data;\n        &#125;;\n      &#125;);\n    &lt;/script>\n  &lt;/body>\n&lt;/html>\n注意事项\n\n\n由于传输的数据格式必须是文本，所以每个字段之间要用换行符 \\n 隔开，最后一个字段要用 \\n\\n 表示一条消息的结束\n\n\n服务端发送数据时必须设置响应头标识推送的数据是流信息 Content-Type: text/event-stream\n\n\n不建议缓存事件推送数据\n\n\n如果用户量很多，就需要保持很多长连接，因此会占用服务器大量内存和连接数\n\n\n若前端部署使用的是Nginx配置\nNginx配置(若不进行配置,前端无法接收)\n这并不是最优解\nserver&#123;\n\tlisten 80;\n\tserver_name test.com;\n\tlocation / &#123;\n\t\tproxy_pass http://127.0.0.1:9000\n\t\t#修复sse eventSource 无法接收到消息的问题\n\t\tproxy_set_header Connection '';\n\t\tproxy_http_version 1.1;\n\t\tchunked_transfer_encoding off;\n\t\t// 默认配置中proxy_buffering是on,SSE的实时性被打破了,有缓存,前端不会定时输出\n\t\tproxy_buffering off;  \n\t\tproxy_cache off;\n\t&#125;\n&#125;\n最优解是后端返回的接口响应头中设置 Cache-Control:no-cache\n","slug":"chatGpt返回数据实时更新-SSE","date":"2023-07-19T13:16:48.000Z","categories_index":"前端,业务与性能优化","tags_index":"业务与性能优化(前端)","author_index":"ND_LJQ"},{"id":"4bb3e720239fee0f6b9b7f2b0b357704","title":"长任务优化","content":"由于浏览器 GUI 渲染线程与 JS 引擎线程是互斥的关系，当页面中有很多长任务时，会造成页面 UI 阻塞，出现界面卡顿、掉帧等情况\n查看页面的长任务：\n打开控制台，选择 Performance 工具，点击 Start 按钮，展开 Main 选项，会发现有很多红色的三角，这些就属于长任务（长任务：执行时间超过50ms的任务）\n\n优化方案\nWeb Worker\n业务背景:前端需要进行大量的数学计算\n介绍\nWeb Worker 的作用，就是为 JavaScript 创造多线程环境，允许主线程创建 Worker 线程，将一些任务分配给后者运行。在主线程运行的同时，Worker 线程在后台运行，两者互不干扰。等到 Worker 线程完成计算任务，再把结果返回给主线程。这样的好处是，一些计算密集型或高延迟的任务可以交由 Worker 线程执行，主线程（通常负责 UI 交互）能够保持流畅，不会被阻塞或拖慢。\nWorker 线程一旦新建成功，就会始终运行，不会被主线程上的活动（比如用户点击按钮、提交表单）打断。这样有利于随时响应主线程的通信。但是，这也造成了 Worker 比较耗费资源，不应该过度使用，而且一旦使用完毕，就应该关闭。\n使用限制\n\n\n同源限制\n分配给 Worker 线程运行的脚本文件，必须与主线程的脚本文件同源。\n\n\nDOM 限制\n\n\n​\t\tWorker 线程所在的全局对象，与主线程不一样，无法读取主线程所在网页的 DOM 对象，也无法使用document、window\tparent这些对象。但是，Worker 线程可以使用navigator对象和location对象。\n\n\n全局对象限制\n\n\n​\t\tWorker 的全局对象WorkerGlobalScope，不同于网页的全局对象Window，很多接口拿不到。比如，理论上 Worker 线程不能使用\t\tconsole.log，因为标准里面没有提到 Worker 的全局对象存在console接口，只定义了Navigator接口和Location接口。不\t\t过，浏览器实际上支持 Worker 线程使用console.log，保险的做法还是不使用这个方法。\n\n\n通信联系\n\n\n​\t\tWorker 线程和主线程不在同一个上下文环境，它们不能直接通信，必须通过消息完成。\n\n\n脚本限制\n\n\n​\t\tWorker 线程不能执行alert()方法和confirm()方法，但可以使用 XMLHttpRequest 对象发出 AJAX 请求。\n\n\n文件限制\n\n\n​\t\tWorker 线程无法读取本地文件，即不能打开本机的文件系统（file://），它所加载的脚本，必须来自网络。\n基本用法\n主线程\n浏览器原生提供Worker()构造函数，用来供主线程生成 Worker 线程。\nvar worker = new Worker(jsUrl, options)\nWorker()构造函数，可以接受两个参数。第一个参数是脚本的网址（必须遵守同源政策），该参数是必需的，且只能加载 JS 脚本，否则会报错。第二个参数是配置对象，该对象可选。它的一个作用就是指定 Worker 的名称，用来区分多个 Worker 线程。\n// 主线程\nvar worker = new Worker('worker.js', &#123; name : 'myWorker' &#125;);\n\n// Worker 线程\nself.name //在worker线程中可以通过self.name来获取其线程名myWorker\n然后，主线程调用worker.postMessage()方法，向 Worker 发消息。worker.postMessage()方法的参数，就是主线程传给 Worker 的数据。它可以是各种数据类型，包括二进制数据。\nworker.postMessage(&#123;method: 'echo', args: ['Work']&#125;)\n主线程通过worker.onmessage指定监听函数，接收子线程发回来的消息。通过 event.data 可以获取 Worker 子线程发过来的数据。\nworker.onmessage = function (event) &#123;\n  doSomething(event.data);\n&#125;\nfunction doSomething() &#123;\n  ...\n&#125;\nWorker 完成任务以后，主线程就可以把它关掉。\nworker.terminate()\nWorker 线程\nWorker 线程内部需要有一个监听函数，监听message事件。通过 e.data 可以获取主线程发过来的数据。\nself.addEventListener('message', function (e) &#123;\n  doSomething(e.data)\n&#125;, false)\nfunction doSomething() &#123;\n  ...\n&#125;\n上面代码中，self代表子线程自身，即子线程的全局对象。因此，等同于下面两种写法。\n// 写法一\nthis.addEventListener('message', function (e) &#123;\n...\n&#125;, false);\n\n// 写法二\naddEventListener('message', function (e) &#123;\n  ...\n&#125;, false);\nself.postMessage()方法用来向主线程发送消息。\nself.postMessage(...)\nWorker 也可以关闭自身\nself.close()\nWorker 加载脚本\nWorker 内部如果要加载其他脚本，有一个专门的方法importScripts()。\nimportScripts('script1.js'[,...'scripts']);\n错误处理\n主线程可以监听 Worker 是否发生错误。如果发生错误，Worker 会触发主线程的error事件。Worker 内部也可以监听error事件。\nworker.addEventListener('error', function (event) &#123;\n   console.log(\n    'ERROR: Line ', event.lineno, ' in ', event.filename, ': ', event.message\n  )\n&#125;);\n\n\n// 主线程\nworker.onerror = function () &#123;\n    // ...\n&#125;\n\n// 主线程使用专用线程\nworker.onmessageerror = function () &#123;\n    // ...\n&#125;\n\n// 主线程使用共享线程\nworker.port.onmessageerror = function () &#123;\n    // ...\n&#125;\n\n// worker 线程\nonerror = function () &#123;\n\n&#125;\n使用实战\n页面中有十万条数据，对其进行复杂运算，需要多久呢？\n表格4000行，25列，共十万条数据\n运算包括：总和、算术平均、加权平均、最大、最小、计数、样本标准差、样本方差、中位数、总体标准差、总体方差\n直接把下面这段代码直接丢到主线程中，计算过程中页面一直处于假死状态(大概35s)\nlet sum = 0;\nlet start = performance.now();\nfor (let i = 0; i &lt; 200000; i++) &#123;\n   for (let i = 0; i &lt; 10000; i++) &#123;\n     sum += Math.random()\n   &#125;\n&#125;\nlet end = performance.now();\nlet time = end - start;\nconsole.log(`本次计算用时$&#123;time&#125;ms,结果为$&#123;sum&#125;`)\n多线程代码\n//主线程\n&lt;template>\n    &lt;div>\n        &lt;button @click=\"makeWorker\">开始线程&lt;/button>\n        &lt;!--在计算时 往input输入值时 没有发生卡顿-->\n        &lt;p>&lt;input type=\"text\">&lt;/p>\n    &lt;/div>\n&lt;/template>\n\n&lt;script>\n    import Worker from \"worker-loader!./worker\";\n\n    export default &#123;\n        data() &#123;\n          // 模拟数据\n          let arr = new Array(100000).fill(1).map(() => Math.random()* 10000);\n          let weightedList = new Array(100000).fill(1).map(() => Math.random()* 10000);\n          let calcList = [\n              &#123;type: 'sum', name: '总和'&#125;,\n              &#123;type: 'average', name: '算术平均'&#125;,\n              &#123;type: 'weightedAverage', name: '加权平均'&#125;,\n              &#123;type: 'max', name: '最大'&#125;,\n              &#123;type: 'middleNum', name: '中位数'&#125;,\n              &#123;type: 'min', name: '最小'&#125;,\n              &#123;type: 'variance', name: '样本方差'&#125;,\n              &#123;type: 'popVariance', name: '总体方差'&#125;,\n              &#123;type: 'stdDeviation', name: '样本标准差'&#125;,\n              &#123;type: 'popStandardDeviation', name: '总体标准差'&#125;\n          ]\n          return &#123;\n              workerList: [], // 用来存储所有的线程\n              calcList, // 计算类型\n              arr, // 数据\n              weightedList // 加权因子\n          &#125;\n        &#125;,\n        methods: &#123;\n            makeWorker() &#123;\n                this.calcList.forEach(item => &#123;\n                    let workerName = `worker$&#123;this.workerList.length&#125;`;\n                    let worker = new Worker();\n                    let start = performance.now();\n                    worker.postMessage(&#123;arr: this.arr, type: item.type, weightedList: this.weightedList&#125;);\n                    worker.addEventListener(\"message\", (e) => &#123;\n                        worker.terminate();\n\n                        let tastName = '';\n                        this.calcList.forEach(item => &#123;\n                            if(item.type === e.data.type) &#123;\n                                item.value = e.data.value;\n                                tastName = item.name;\n                            &#125;\n                        &#125;)\n\n                        let end = performance.now();\n                        let duration = end - start;\n                        console.log(`当前任务: $&#123;tastName&#125;, 计算用时: $&#123;duration&#125; 毫秒`);\n                    &#125;);\n                    this.workerList.push(&#123; [workerName]: worker &#125;);\n                &#125;)\n            &#125;,\n            clearWorker() &#123;\n                if (this.workerList.length > 0) &#123;\n                    this.workerList.forEach((item, key) => &#123;\n                        item[`worker$&#123;key&#125;`].terminate &amp;&amp; item[`worker$&#123;key&#125;`].terminate(); // 终止所有线程\n                    &#125;);\n                &#125;\n            &#125;\n        &#125;,\n        // 页面关闭，如果还没有计算完成，要销毁对应线程\n        beforeDestroy() &#123;\n            this.clearWorker();\n        &#125;,\n    &#125;\n&lt;/script>\n\n//worker.js\n\nimport &#123; create, all &#125; from 'mathjs'\nconst config = &#123;\n  number: 'BigNumber',\n  precision: 20 // 精度\n&#125;\nconst math = create(all, config);\n\n//加\nconst numberAdd = (arg1,arg2) => &#123;\n  return math.number(math.add(math.bignumber(arg1), math.bignumber(arg2)));\n&#125;\n//减\nconst numberSub = (arg1,arg2) => &#123;\n  return math.number(math.subtract(math.bignumber(arg1), math.bignumber(arg2)));\n&#125;\n//乘\nconst numberMultiply = (arg1, arg2) => &#123;\n  return math.number(math.multiply(math.bignumber(arg1), math.bignumber(arg2)));\n&#125;\n//除\nconst numberDivide = (arg1, arg2) => &#123;\n  return math.number(math.divide(math.bignumber(arg1), math.bignumber(arg2)));\n&#125;\n\n// 数组总体标准差公式\nconst popVariance = (arr) => &#123;\n  return Math.sqrt(popStandardDeviation(arr))\n&#125;\n\n// 数组总体方差公式\nconst popStandardDeviation = (arr) => &#123;\n  let s,\n    ave,\n    sum = 0,\n    sums= 0,\n    len = arr.length;\n  for (let i = 0; i &lt; len; i++) &#123;\n    sum = numberAdd(Number(arr[i]), sum);\n  &#125;\n  ave = numberDivide(sum, len);\n  for(let i = 0; i &lt; len; i++) &#123;\n    sums = numberAdd(sums, numberMultiply(numberSub(Number(arr[i]), ave), numberSub(Number(arr[i]), ave)))\n  &#125;\n  s = numberDivide(sums,len)\n  return s;\n&#125;\n\n// 数组加权公式\nconst weightedAverage = (arr1, arr2) => &#123; // arr1: 计算列，arr2: 选择的权重列\n  let s,\n    sum = 0, // 分子的值\n    sums= 0, // 分母的值\n    len = arr1.length;\n  for (let i = 0; i &lt; len; i++) &#123;\n    sum = numberAdd(numberMultiply(Number(arr1[i]), Number(arr2[i])), sum);\n    sums = numberAdd(Number(arr2[i]), sums);\n  &#125;\n  s = numberDivide(sum,sums)\n  return s;\n&#125;\n\n// 数组样本方差公式\nconst variance = (arr) => &#123;\n  let s,\n    ave,\n    sum = 0,\n    sums= 0,\n    len = arr.length;\n  for (let i = 0; i &lt; len; i++) &#123;\n    sum = numberAdd(Number(arr[i]), sum);\n  &#125;\n  ave = numberDivide(sum, len);\n  for(let i = 0; i &lt; len; i++) &#123;\n    sums = numberAdd(sums, numberMultiply(numberSub(Number(arr[i]), ave), numberSub(Number(arr[i]), ave)))\n  &#125;\n  s = numberDivide(sums,(len-1))\n  return s;\n&#125;\n\n// 数组中位数\nconst middleNum = (arr) => &#123;\n  arr.sort((a,b) => a - b)\n  if(arr.length%2 === 0)&#123; //判断数字个数是奇数还是偶数\n    return numberDivide(numberAdd(arr[arr.length/2-1], arr[arr.length/2]),2);//偶数个取中间两个数的平均数\n  &#125;else&#123;\n    return arr[(arr.length+1)/2-1];//奇数个取最中间那个数\n  &#125;\n&#125;\n\n// 数组求和\nconst sum = (arr) => &#123;\n  let sum = 0, len = arr.length;\n  for (let i = 0; i &lt; len; i++) &#123;\n    sum = numberAdd(Number(arr[i]), sum);\n  &#125;\n  return sum;\n&#125;\n\n// 数组平均值\nconst average = (arr) => &#123;\n  return numberDivide(sum(arr), arr.length)\n&#125;\n\n// 数组最大值\nconst max = (arr) => &#123;\n  let max = arr[0]\n  for (let i = 0; i &lt; arr.length; i++) &#123;\n    if(max &lt; arr[i]) &#123;\n      max = arr[i]\n    &#125;\n  &#125;\n  return max\n&#125;\n\n// 数组最小值\nconst min = (arr) => &#123;\n  let min = arr[0]\n  for (let i = 0; i &lt; arr.length; i++) &#123;\n    if(min > arr[i]) &#123;\n      min = arr[i]\n    &#125;\n  &#125;\n  return min\n&#125;\n\n// 数组有效数据长度\nconst count = (arr) => &#123;\n  let remove = ['', ' ', null , undefined, '-']; // 排除无效的数据\n  return arr.filter(item => !remove.includes(item)).length\n&#125;\n\n// 数组样本标准差公式\nconst stdDeviation = (arr) => &#123;\n  return Math.sqrt(variance(arr))\n&#125;\n\n// 数字三位加逗号，保留两位小数\nconst formatNumber = (num, pointNum = 2) => &#123;\n  if ((!num &amp;&amp; num !== 0) || num == '-') return '--'\n  let arr = (typeof num == 'string' ? parseFloat(num) : num).toFixed(pointNum).split('.')\n  let intNum = arr[0].replace(/\\d&#123;1,3&#125;(?=(\\d&#123;3&#125;)+(.\\d*)?$)/g,'$&amp;,')\n  return arr[1] === undefined ? intNum : `$&#123;intNum&#125;.$&#123;arr[1]&#125;`\n&#125;\n\nonmessage = function (e) &#123;\n\n  let &#123;arr, type, weightedList&#125; = e.data\n  let value = '';\n  switch (type) &#123;\n    case 'sum':\n      value = formatNumber(sum(arr));\n      break\n    case 'average':\n      value = formatNumber(average(arr));\n      break\n    case 'weightedAverage':\n      value = formatNumber(weightedAverage(arr, weightedList));\n      break\n    case 'max':\n      value = formatNumber(max(arr));\n      break\n    case 'middleNum':\n      value = formatNumber(middleNum(arr));\n      break\n    case 'min':\n      value = formatNumber(min(arr));\n      break\n    case 'variance':\n      value = formatNumber(variance(arr));\n      break\n    case 'popVariance':\n      value = formatNumber(popVariance(arr));\n      break\n    case 'stdDeviation':\n      value = formatNumber(stdDeviation(arr));\n      break\n    case 'popStandardDeviation':\n      value = formatNumber(popStandardDeviation(arr));\n      break\n    &#125;\n\n  // 发送数据事件\n  postMessage(&#123;type, value&#125;);\n&#125;\n\nVue中使用web worker\n在 Vue 项目中\nwebpack使用 Web Worker 需要安装 worker-loader\nvite使用:\n在 Vite 中静态资源处理 ，其中可以导入脚本作为 Worker\n","slug":"长任务优化","date":"2023-07-19T13:16:03.000Z","categories_index":"前端,业务与性能优化","tags_index":"业务与性能优化(前端)","author_index":"ND_LJQ"},{"id":"aa70f67d4ef6e029542c043a9994018c","title":"js学习笔记","content":"小知识\n浏览器内核\nWebkit 苹果开发 用于 Safari\nBlink Webkit 的一个分支,Google 开发,目前应用于 Google Chrome,Edge,Opera 等浏览器\n浏览器的渲染过程\n\nJs 引擎\njs 引擎将 js 代码翻译成CPU 指令来执行\nV8 引擎\n\n1.js 引擎在解析成 AST 语法树中会在堆内存中默认创建一个全局对象 globalObject ,并将我们创建的属性名(值为 undefined)(普通变量)添加到 该全局对象中\n预解析时函数会在内存中创建一个储存空间(函数对象) (函数 的父级作用域在定义时就已经确定,不会因调用的位置而改变)\n解析时全局对象时(GO)\n会首先解析变量 后声明函数并赋值\n在预解析函数时(AO)\n首先形参和变量的声明\n然后实参赋值给形参\n最后声明函数并赋值\n\n然后在全局对象(GO)中则储存函数的地址\nGlobalObject:&#123;\n    name:undefined,\n    foo:0x...\n&#125;\n2.运行代码时\nV8 引擎为了执行代码,其内部会有一个执行上下文栈(Execution Context Stack)(函数调用栈) 内放将要执行的函数\n全局代码执行顺序\nconst name = 'ljq';\nconst num1 = 2;\nconst num2 = 5;\nconst num3 = num1 + num2;\n此时 V8 引擎创建了一个执行上下文栈 后创建一个全局执行上下文\n此时创建 GEC(全局执行上下文) ,其中的 VO 指向 解析时创建的 GO\n在最新的规范中VO(variable Object)已经被更新为VE(VariableEnvironment)(变量环境)\n\n在执行代码中的变量和函数声明会作为环境记录(Environment Record) 添加到变量环境中,\n\n对于函数,其参数也会被作为环境记录被添加到变量环境中\n\n而函数则较为特殊\n全局函数的执行过程\nfunction foo(num) &#123;\n  var m = 10;\n  var n = 20;\n&#125;\n\nfoo();\n接着在执行上下文栈中创建一个函数执行上下文(FEC) (函数实例)\n\n此时 AO(Actiction Object)为\nAO:&#123;\n    num:undefined,\n    m:undefined,\n    n:undefined\n&#125;\n接着函数内的代码将会执行\nAO 中的属性被依次赋值\n当函数执行完后,函数执行上下文将会被弹出执行上下文栈(被销毁)\n面试题\nfunction foo() &#123;\n  m = 10;\n  // 没有使用变量关键字会被声明到全局对象中\n&#125;\n\nconsole.log(m); // 10\nfunction foo() &#123;\n  var a = (b = 10);\n  // 此时这句语句在js引擎中会被转化为\n  // b = 10 ; var a = 10 (从右向左执行)\n&#125;\n\nconsole.log(a); // erro a is not defined\nconsole.log(b); // 10\njs 的内存管理和闭包\n对于基本数据类型内存的分配时会直接在栈空间内分配\n对于复杂数据类型内存的分配时会直接在堆空间内分配\njs 的垃圾回收(GC)\n常见的 GC 算法\n引用计数\n标记清除:\n设置一个根对象,垃圾回收器会定期从这个根开始找所有从根开始有引用到的对象,对于那些没有引用到的对象,就认为是不可用对象\nV8 GC 优化策略\n因为 js 在 gc 时会停止响应其他操作,所以要通过优化来避免长时间的停止响应\n1.分代回收\n通过区分\"临时\"和\"持久\"对象,多回收\"临时对象区\",少回收\"持久对象区\",减少每次需要的变量,减少每次GC耗时\n2.增量 GC\n就是每次处理一部分\njs运行 -&gt; gc运行js暂停 -&gt; js运行 -&gt; gc运行js暂停\n闭包\n在计算机科学中\n闭包在实现上是一个结构体,它储存了一个函数和其关联的环境\n闭包跟函数最大的区别就是,当捕捉闭包的时候,它的自由变量会在捕捉的时候就被确定,这样即使脱离了捕捉时的上下文,它也能照常运行\n在 JavaScript 中\n一个函数和对其周围状态的引用绑定在一起 这就叫闭包\nfunction foo() &#123;\n  var name = 'ljq';\n  function bar() &#123;\n    console.log('bar', name);\n  &#125;\n\n  return bar;\n&#125;\n\nvar fn = foo();\nfn();\n在 fn = foo() 被执行后 GO 中的 fn 值已经被赋值为了 bar() 的地址值\nfoo 的 FEC 会被销毁 但是 bar 依旧能访问到 foo 中的 “name” 值\n此时 函数 bar()和 “name” 变量 构成一个闭包(函数和其能访问的外层作用域的自由变量共同组成闭包)\n闭包的内存泄露\nfunction foo() &#123;\n  var name = 'ljq';\n  function bar() &#123;\n    console.log('foo', name);\n  &#125;\n  return bar;\n&#125;\n\nvar fn = foo();\nfn();\n函数中的 this 指向\n函数在执行时才会绑定 this\n在浏览器中 全局对象中 this 指向 window\n在 nodejs 中的 this 是一个空对象\n// this指向什么与函数所处位置无关\n// this的指向与函数被调用的方式有关\n\nfunction foo() &#123;\n  console.log(this);\n&#125;\n\nfoo(); // window\n\nconst obj = &#123;\n  name: 'ljq',\n  foo: foo,\n&#125;;\n\nconsole.log(obj.foo()); // obj对象\n\nconsole.log(foo.apply('abc')); // String:&#123;\"abc\"&#125;\n优先级从上至下以此升高\n默认绑定\n// 函数调用的时无任何调用前缀 默认绑定时this指向全局对象window(非严格模式)\nfunction fn() &#123;\n  console.log(this); // window\n  let fn1 = function () &#123;\n    console.log(this); // window\n    fn2(); // window\n  &#125;;\n\n  function fn2() &#123;\n    console.log(this);\n  &#125;\n&#125;\n\n// 要注意的是在严格模式环境下 默认绑定的this指向undefined\nfunction fn() &#123;\n  console.log(this); // window\n&#125;\n\n('use strict');\nfunction fn1() &#123;\n  console.log(this); // undefined\n  console.log(this.name);\n&#125;\n\nvar name = 'dnmd';\nfn1(); // TypeError: Cannot read property 'name' of undefined\n间接函数引用\nconst obj1 = &#123;\n    name:\"obj1\"\n    foo:function()&#123;\n        console.log(this)\n    &#125;\n&#125;\n\nconst obj2 = &#123;\n    name:\"obj2\"\n&#125;;\n\n(obj2.bar = obj1.foo)() // 作为独立的函数调用 output:window\n隐式绑定\n// 他的调用位置中,是通过某个对象发起的函数调用\nfunction foo() &#123;\n  console.log(this);\n&#125;\n\nconst obj = &#123;\n  name: 'ljq',\n  foo: foo,\n&#125;;\n\nconst obj1 = &#123;\n  obj: obj,\n&#125;;\n\nobj.foo(); // obj\n\nobj1.obj.foo(); // obj\n\nconst div = document.querySelector('.box');\ndiv.onclick = function () &#123;\n  console.log(this);\n&#125;;\n\n// 当点击box时 output:\n// &lt;div class=\"box\" style=\"width: 100px;height: 100px;background-color: red;\">&lt;/div>\n// 所以其应该是进行了隐式绑定\n显式绑定\n// 通过apply,call,bind进行绑定\n\nfunction foo() &#123;\n  console.log(this);\n&#125;\n\nvar newFoo = foo.bind('aaa');\n\nnewFoo(); // String\n\nconst div = document.querySelector('.box');\ndiv.addEventListener('click', function () &#123;\n  console.log(this);\n&#125;);\n\ndiv.addEventListener('click', function () &#123;\n  console.log(this);\n&#125;);\n\ndiv.addEventListener('click', function () &#123;\n  console.log(this);\n&#125;);\n\n// 所有的click函数被存入一个数组\n// 当点击发生是遍历调用数组中的函数\n// fn.call(div)\n\n// 当点击box时 output:\n// &lt;div class=\"box\" style=\"width: 100px;height: 100px;background-color: red;\">&lt;/div>\n忽略显式绑定\n// apply,bind,call 当传入的值为 null/undefined 时,自动将this绑定为全局对象\nfunction foo() &#123;\n  console.log(this);\n&#125;\n\nfoo.call(null); // window\nfoo.apply(undefined); // window\nconst data = foo.bind(null);\ndata(); // window\nnew 绑定\n// 我们通过一个new关键字调用一个函数时(构造器),这个时候this是在调用这个构造器时创建出来的对象\n// this = 创建出来的对象\n// 这个过程就是new绑定\n\nfunction foo(name, age) &#123;\n  console.log(this);\n&#125;\n\nvar p = new foo(); // foo&#123;&#125;\n箭头函数\n// 如果函数的执行体只有一行,那么&#123;&#125;可以省略,并且默认将这行代码的执行结果作为返回值\n// 箭头函数不适用this的四种规则,而是调用上层作用域中的this\n\n箭头函数与普通函数的区别\n1.语法更加清晰\n2.箭头函数不能作为构造函数调用(new)\n3.箭头函数没有\"arguments\"\n4.call(),bind()函数不能改变箭头函数的this指向\n5.箭头函数没有prototype\n6.箭头函数不会创建自己的this,其会继承上层作用域的this,且创建的上层作用域的\nthis 面试题\nvar name = 'ljq';\nvar person = &#123;\n  name: 'person',\n  sayName: function () &#123;\n    console.log(this.name);\n  &#125;,\n&#125;;\nfunction sayName() &#123;\n  var sss = person.sayName;\n  sss(); // ljq\n  person.sayName(); // person\n  person.sayName(); // person\n  (b = person.sayName)(); // ljq\n&#125;\nsayName();\nvar name = 'ljq';\nvar person1 = &#123;\n  name: 'person1',\n  foo1: function () &#123;\n    console.log(this.name);\n  &#125;,\n  foo2: () => console.log(this.name),\n  foo3: function () &#123;\n    return function () &#123;\n      console.log(this.name);\n    &#125;;\n  &#125;,\n  foo4: function () &#123;\n    return () => &#123;\n      console.log(this.name);\n    &#125;;\n  &#125;,\n&#125;;\n\nvar person2 = &#123; name: 'person2' &#125;;\n\nperson1.foo1(); // person1\nperson1.foo1.call(person2); // person2\n\nperson1.foo2(); // ljq\nperson1.foo2.call(person2); // ljq\n\nperson1.foo3()(); // ljq\nperson1.foo3.call(person2)(); //  ljq\n\nperson1.foo4()(); // ljq\nperson1.foo4.call(person2)(); // persno2\n实现 apply,call,bind(手写 )\n\narguments 的使用\n// 在浏览器中全局状态下没有arguments , nodejs下有\n函数式编程\n纯函数\n// 确定的输入,一定会产生确定的输出\n// 函数的执行过程中,不会产生副作用(副作用的概念就是,在执行一个函数的时候,除了返回函数值外,还对调用函数产生了附加的影响,例如修改的全局变量,修改参数或者改变外部储存)\n柯里化\n// 将多个传入参数,拆分成多个函数调用的过程\nconst sum = function (x) &#123;\n  return function (y) &#123;\n    return function (z) &#123;\n      return x + y + z;\n    &#125;;\n  &#125;;\n&#125;;\n\nconst res = sum(10)(20)(30);\nconsole.log(res); // 60\n\n// 使用箭头函数简写\n\nconst sum1 = (x) => (y) => (z) => x + y + z;\nconst res1 = sum(10)(20)(30);\nconsole.log(res1); // 60\n\n// 为什么需要柯里化\n// 函数式编程中我们往往希望一个函数处理的问题单一,而不是将一大堆处理过程中交给一个函数来处理\n\n// 模板字符串应用的柯里化\nconst log = function (date, type, message) &#123;\n  console.log(`[$&#123;date.getHours()&#125;:$&#123;date.getMinutes()&#125;][$&#123;type&#125;]:[$message]`);\n&#125;;\n\nlog(new Date(), 'DEBUG', '查找到轮播图BUG');\nlog(new Date(), 'DEBUG', '查找到菜单BUG');\nlog(new Date(), 'DEBUG', '查找到数据BUG');\n\n//柯里化的优化\nconst log1 = (date) => (type) => (message) =>\n  console.log(`[$&#123;date.getHours()&#125;:$&#123;date.getMinutes()&#125;][$&#123;type&#125;]:[$message]`);\n\n// 定制化\n// 如果要打印的都是当前时间\nconst nowlog = log1(new Date());\nnowlog('DEBUG')('查找到菜单BUG');\nnowlog('DEBUG')('查找到轮播图BUG');\n\n// 自动转柯里化函数的实现(手写)\n组合函数(手写)\n\n严格模式\n// 严格模式下,不允许静默错误\n// 不允许原先的八进制\n// with 语句不允许使用\n// eval函数不允许向上引用变量\n// 自执行函数(默认绑定)会指向undefined\n// setTimeout的this不变(指向window)\nJS 的面向对象\nObject.defineProperty(objName,objKeyName,descriptor//属性描述符) // 对对象中的属性做操作\n// 数据属性描述符\n  Configurable:表示属性是否能够通过delete删除属性 false表示不可配置(删除,修改)\n  也不可以重新定义属性描述符\n\n  enumerable:表示属性是否能被枚举(是否能被for-in或Object.key()返回该属性)\n\n  writeable: 表示属性是否能被修改(写入)\n\n//存取属性描述符\n  1.隐藏某一个私有属性不被外界直接使用和赋值\n    js并没有私有属性的定义 社区中默认 _keyName为私有属性\n  2.截获某一个属性它访问和设置值的过程\n\tget:function()&#123;&#125;\n    set:function()&#123;&#125;\n\n\n\nObject.defineProperty(obj,\"height\",&#123;\n    //配置\n    value:1.88\n&#125;)\n\n\n// 也可以一次性对多个属性配置属性描述符\nObject.defineProperty(obj,&#123;\n    name:&#123;\n        Configurable:false\n        writable:false\n        value:\"ljq\"\n    &#125;,\n    age:&#123;\n        Configurable:false\n        writable:false\n        value:20\n    &#125;\n&#125;)\n\n//获取属性描述符\nObject.getOwnPropertyDescriptor(obj_nmae,obj_key_name)\nObject.getOwnPropertyDescriptors()\n\n\n// 对对象进行限制\nObject.seal(obj_name) // 禁止对象配置/修改删除里面的属性\nObject.freeze(obj_name) // 属性不可修改\n工厂模式\n&#x2F;&#x2F; 工厂模式:工厂函数\nfunction createPerson(name,age,height,address)&#123;\n    const newObejct &#x3D; &#123;&#125;\n    newObject.name &#x3D; name\n    newObject.age &#x3D; age\n    newObject.height &#x3D; height\n    newObject.address &#x3D; address\n\n    return newObject\n&#125;\n\nconst p1 &#x3D; createPerson(&quot;ljq&quot;,20,176,&quot;株洲市&quot;)\n构造函数\n// new 操作符\n当一个new操作符被调用,那么他会执行如下操作\n1.在内存中创建一个新的空对象\n2.这个对象内部的prototype属性会被赋值为该构造函数的prototype属性\n3.构造函数内部的this会指向创建出来的新对象\n4.执行函数内部的代码(函数体代码)\n5.如果构造函数没有返回非空对象,则返回创建出来的新对象\n\n手写\n继承与原型链\n// 我们每个对象中提供了一个prototype,这个属性可以称为对象的原型(隐式原型)\n// 浏览器和node中支持查询隐式原型(__proto__)\n// ES5后提供了一个方法查看原型\nObject.getPrototypeOf(obj_name);\n\n// 函数也是一个对象\n// console.log(foo.__proto__) 函数作为对象来说 他也是有[[prototype]]隐式原型的\n\n// 函数因为他是一个函数,所以他还会多出一个显示原型属性:prototype\nconsole.log(foo.prototype);\n当函数被 new 关键字创建后,他的执行过程为\nfunction Foo() &#123;&#125;\n\nvar p1 = new Foo();\nvar p2 = new Foo();\n\n创建对象方案\n// 将函数通用属性加入函数原型\nfunction Person(name, age, height, address) &#123;\n  this.name = name;\n  this.age = age;\n  this.height = height;\n  this.address = address;\n&#125;\n\nPerson.prototype.eating = function () &#123;\n  console.log(this.name + '在吃东西');\n&#125;;\n\nPerson.prototype.running = function () &#123;\n  console.log(this.name + '在跑步');\n&#125;;\n原型链\n\n参数中的&quot;[]&quot;代表可选\n操作字符串的方法\nindexOf()\nString.indexOf(searchValue, [fromIndex]);\n// 返回子字符或字符串在父字符串中首次出现的索引位置\n// 若子字符串不存在则会返回 -1\n// 若 fromIndex 大于字符串长度,则会返回父字符串长度\n// 该方法区分大小写\nString.lastIndexOf(searchValue, [fromIndex]);\n// 返回子字符或字符串在父字符串中最后一次出现的索引位置\ncharAt()\nString.charAt(index); // 获得字符串指定位置的字符\ntouppercase()\nString.toUpperCase();\n// 将字符串中的字符全变为大写后返回一个新字符串,原字符串不变\nString.tolowerCase();\n// 将字符串中的字符全变为小写后返回一个新字符串,原字符串不变\nconcat()\nString.concat(str, [...strN]);\n// 将一个或多个字符串与原字符串串联合并,返回一个新字符串\nslice()\nString.slice(beginIndex, [endIndex]);\n// 提取父字符串自 beginIndex 位置开始 [到 endIndex 结束]的字符/字符串\n// 并返回一个新字符串,原字符串不变\n// slice()不传参数会返回一个跟原数组一样的新数组\n// 若 beginIndex/endIndex 的值为负数\n// 则其值看成 str.length-beginIndex/endIndex\n// 若 beginIndex 大于 endIndex 则 slice 的执行的效果为 从 beginIndex 开始向前截取到 endIndex\nsubString()\nString.subString(indexStart, [indexEnd]);\n// 返回一个提取自字符串 indexStart 开始[至indexEnd 结束]的一个新的子字符串\n// 如果参数中的值小于 '0' 或者 'NaN' 则自动默认为0\n// 如果参数中的任意一值大于父字符串的长度 那么该值默认为父字符串的长度\n// 如果 indexStart 大于 indexEnd，则 substring 的执行效果就像两个参数调换了一样。\n// 即 String.subString(indexEnd,indexStart)\nsubStr()\nString.subStr(strat, [length]); //该方法半遗弃,尽量避免使用\nsplit()\nString.split([separator, [limit]]);\n// 以 separator 字符/字符串或正则表达式来切割原字符 ,用 limit(number) 来限制返回的数组中\n// 切割后的片段的数量\n// 若不传参,则返回原字符串的数组\n// 若以 \"\"/'' 来作为分隔符可能会破坏 unicode 安全\n// 例:\n// const a = '𝟘𝟙𝟚𝟛'.split('');\n// console.log(a);\n// Output: [\"�\",\"�\",\"�\",\"�\",\"�\",\"�\",\"�\",\"�\"]\n// 这时候推荐使用es6的拓展运算符 \"...\" 来解决\n// 例:\n// const a = '𝟘𝟙𝟚𝟛'\n// console.log([...a])\n// Output: ['𝟘', '𝟙', '𝟚', '𝟛']\ntrim()\nString.trim();\n//去除字符串两端空白\n//该方法返回一个新的去除字符串两端空白的新字符串,并不影响原字符串本身\nreplace()\nString.replace(regexp|subStr , newSubStr|function)\n// 将字符串中某个字符串/字符(subStr),替换成新字符(newSubStr)\n// 若是是一个function,则newSubStr为function的返回值\n// 第一个参数是subStr则只有第一个匹配项会被替换\n// 若第一个参数是正则表达式则正则所匹配到的对象会被替换\n操作数组的方法\n数组的扁平化\nArray.flat();\nArray.toString().split();\n不会改变原始数组的方法\nindexOf()\nArray.indexOf(searchElement, [fromIndex]);\n// 查找某一个值在数组中首次出现的位置\n// fromIndex 参数若大于 Array.length 则默认不会从数组中查找,返回 -1\n// 若小于 0 则其默认为数组长度的抵消值,若抵消值仍为负数则默认为 0\n// 即若数组长度为6 fromIndex值为 -1 则意味着从索引为 6+(-1) 开始查找\nslice()\nArray.slice(begin, [end]);\n// 返回数组的某一部分(浅拷贝)\n// 提取从原数组中从索引 begin 到 end 中的元素\n// 若参数为负,则其值默认为 array.length + 参数值\n// 若 |begin| > |end| 则会返回一个空数组,不会将end和begin交换\nconcat()\nArray.concat(value1, [...valueN]);\n// 将原数组进行浅拷贝的副本与参数中的数组/单个元素进行合并,返回合并后的副本\njoin()\nArray.join([separator]);\n// 将数组中的元素拼接起来后返回一个总的字符串\n// 可选参数separator 是指定每个元素之间的分隔符\n// 如果缺省参数 separator 则每个元素之间默认分隔符为\",\"\n// 如果参数是空字符串(\"\")则每个元素之间没有任何字符\n// 若数组中的某一个元素为 undefined 或 null ,则返回的字符串为空字符串\nfilter()\nArray.fliter(callbackFunction(element, [index]));\n// 创建一个新数组，其包含通过所提供函数实现的测试的所有元素\n// callbackFunction为测试数组每个元素的函数 返回true则表示该元素通过测试,保留该元素,反之则返回false,不保留该元素\n// callbackFunction中的 element参数则是当前测试的元素 index是正在测试中的元素在原数组中的索引\nreduce()\nArray.reduce(reducer, [initiaValue]);\n// 方法对数组中的每个元素按序执行一个由您提供的 reducer 函数，每一次运行 reducer 会将先前元素的计算结果作为参数传入，最后将其结果汇总为单个返回值。\n//reducer = function(previousValue,currentValue,[currentIndex])&#123;&#125;\n// previousValue 为 上次调用reducer返回的的值\n// currentValue 为 数组中正在处理的元素\n// currentIndex 为 数组中正在处理的元素在数组中的索引值\n// 作为第一次调用 reducer 函数时参数 previousValue 的值。若指定了初始值 initialValue，则 currentValue 则将使用数组第一个元素；否则 previousValue 将使用数组第一个元素，而 currentValue 将使用数组第二个元素\nmap()\nArray.map(callbackFunction, [thisArg]);\n// callbackFunction(currentValue,[index]) 为数组每一个元素执行该函数 并返回一个由原数组每个元素执行回调函数的结果组成的新数组\n// currentValue为当前所处理的元素\n// index 为当前所处理元素在数组中的索引值\n// thisArg 为当执行回调函数 callbackFunction时，用作 this 的值。\n会改变原始数组的方法\npush()\nArray.push(element1, ..., elementN)\n// 将元素添加到数组末尾\n// 调用该方法时的返回值为新数组的length\npop()\nArray.pop();\n// 从数组中删除最后一个元素 并返回被删除的元素\n// 在空数组中调用pop(),将返回undefined\nshift()\nArray.shift();\n// 从数组中删除索引为0的元素 并返回被删除的元素\n// 在空数组中调用shift(),将返回undefined\nunshift()\nArray.unshift(element1, [...elementN]);\n// 将一个或多个元素添加到数组开头,并返回该数组的新length\n// 当传入参数为多个值时,它们将被以 块 的形式被插入到对象开始位置,他们的顺序和被传入时的顺序一致,所以，传入多个参数调用一次 unshift()，和传入一个参数调用多次 unshift()（例如，循环调用），它们将得到不同的结果。例如：\nlet arr = [4, 5, 6];\n\narr.unshift(1, 2, 3);\nconsole.log(arr);\n// [1, 2, 3, 4, 5, 6]\n\narr = [4, 5, 6]; // 重置数组\n\narr.unshift(1);\narr.unshift(2);\narr.unshift(3);\n\nconsole.log(arr);\n// [3, 2, 1, 4, 5, 6]\nsort()\nArray.sort([compareFunction(a, b)]);\n// 将数组按照某一规则来进行排序,返回排序后的数组\n// 若不指定规则则默认将数组中的元素转换为字符串的逐个字符的unicode位点进行排序\n// 若指定compareFunction(a,b) 那么数组会按照调用该函数返回值进行排序\n// 如果compareFunction(a,b) 大于 0 那么b会排列到a之前\n// 如果compareFunction(a,b) 小于 0 那么a会排列到b之前\n// 如果compareFunction(a,b) 等于 0 那么a与b的相对位置不变\nsplice()\nArray.splice(start, [deleteCount, [item1, ...itemN]]);\n// 删除或替换或添加元素来修改数组,并以数组的方式返回被删除元素所组成的数组\n// 从指定修改从 start 索引开始修改\n// 若 start 的值大于Array.length则意味着从数组末尾开始修改\n// 若 start 的值为负数 则值默认为Array.length + start的值\n// 若 start 的值为负数 且绝对值大于Array.length 则默认为0\n// deleteCount为删除元素的个数\n// item1-itemN为需要添加进数组的元素\nforEach()\nArray.forEach(callbackFucntion);\n// callbackFunction(currentValue,[index],[thisArg]) 为数组每一个元素执行该函数\n// currentValue为当前所处理的元素\n// index 为当前所处理元素在数组中的索引值\n// thisArg 为当执行回调函数 callbackFunction时，用作 this 的值。\nES6 新特性\nSet()对象\n// Set 对象允许储存任何类型的唯一值,无论是原始值或是对象引用\nconst newSet = new Set();\n// Set的一些实例方法\nSet.size(); // 返回Set对象中值的个数\nSet.add(value); // 在Set对象的尾部添加一个元素并返回,该Set对象\nSet.has(value); // 查询Set对象中是否有value值 返回一个布尔值\nSet.value(); // 返回一个Set迭代器对象内包含Set对象中按插入属性顺序摆列的所有元素\nSet.delete(value); // 删除Set对象中的value值\nSet.forEach(callback); // dddd\n\n// 使用Set进行数组去重\nconst arr = [1, 1, 2, 2, 3, 3, 4, 4];\nconst arrSet = new Set(arr);\nreturn [...arrSet];\n\n// 利用Set将字符串转为数组\nconst str = 'hello';\nconst newSet = new Set(str);\nreturn [...newSet];\n\n// 用Set获得并集\nconst arr1 = [1, 2, 3, 4];\nconst arr2 = [3, 4, 5, 6];\nconst newSet = new Set([...arr1, ...arr2]); // &#123;1, 2, 3, 4, 5, 6&#125;\n\n// 用Set获得交集\nconst arr1 = [1, 2, 3, 4];\nconst arr2 = [3, 4, 5, 6];\nconst newSet = new Set([...arr1].fliter((e) => arr2.has(e)));\nSymbol()\n//symbol 是一种基本数据类型（primitive data type）。Symbol() 函数会返回 symbol 类型的值\n// 每个从Symbol()方法返回的值都是唯一的\n// 但是Symbol 不支持 new Symbol() 构造\nMap()对象\n// Map 对象保存键值对，并且能够记住键的原始插入顺序。任何值（对象或者基本类型）都可以作为一个键或一个值。\nconst newMap = new Map();\nes6 的剩余参数\n// rest parameters\nfunction foo(...nums) &#123;\n  //nums是形参名  => var nums = [  ]\n&#125;\n\nfoo(10);\nfoo(10, 20, 30);\nfoo(10, 20, 30, 40);\nEs6 展开运算符\nvar nums = ['abc', 'cba', 'bac'];\nfoo(...nums);\n","slug":"js学习笔记","date":"2023-07-19T12:53:54.000Z","categories_index":"前端","tags_index":"js","author_index":"ND_LJQ"},{"id":"2f890567b7501c264678f89b083cd223","title":"Hbase基础","content":"HBase 简介\nGoogle 三篇论文\n\n\n\n论文名\n说明\nhadoop\n\n\n\n\n《GFS》\n分布式文件系统\nHDFS(Hadoop Distributed File System)\n\n\n《MapReduce》\n分布式计算模型\nMapReduce\n\n\n《Bigtable》\n超级大表\nHBase\n\n\n\n结论：HBase 起源于 Google 的《Bigtable: A Distributed Storage System for Structured Data》这篇论文。\nHadoop HBase 是一个高可靠、高性能、可伸缩、面向列、随机实时读写的，分布式的数据库由于 HBase 属于我们的 Hadoop 生态圈，所以 HBase 的底层使用 HDFS 来进行存储，使用 MapReduce 来进行计算。并且主要存储的是“半结构化”与“非结构化”的数据。\nHBase 与传统关系数据库的对比分析\n\n\n数据类型：关系数据库采用关系模型，具有丰富的数据类型和存储方式，HBase 则采用了更加简单的数据模型，它把数据存储为未经解释的字符串；\n\n\n数据操作：关系数据库中包含了丰富的操作，其中会涉及复杂的多表连接。HBase 操作则不存在复杂的表与表之间的关系，只有简单的插入、查询、删除、清空等，因为 HBase 在设计上就避免了复杂的表和表之间的关系；\n\n\n存储模式：关系数据库是基于行模式存储的。HBase 是基于列存储的，每个列族都由几个文件保存，不同列族的文件是分离的；\n\n\n数据索引：关系数据库通常可以针对不同列构建复杂的多个索引，以提高数据访问性能。HBase 只有一个索引——行键，通过巧妙的设计，HBase 中的所有访问方法，或者通过行键访问，或者通过行键扫描，从而使得整个系统不会慢下来；\n\n\n数据维护：在关系数据库中，更新操作会用最新的当前值去替换记录中原来的旧值，旧值被覆盖后就不会存在。而在 HBase 中执行更新操作时，并不会删除数据旧的版本，而是生成一个新的版本，旧有的版本仍然保留；\n\n\n可伸缩性：关系数据库很难实现横向扩展，纵向扩展的空间也比较有限。相反，HBase 和 BigTable 这些分布式数据库就是为了实现灵活的水平扩展而开发的，能够轻易地通过在集群中增加或者减少硬件数量来实现性能的伸缩\n\n\n数据模型相关概念\n\n\n表：HBase 采用表来组织数据，表由行和列组成，列划分为若干个列族；\n\n\n行：每个 HBase 表都由若干行组成，每个行由行键（row key）来标识；\n\n\n列族：一个 HBase 表被分组成许多“列族”（Column Family）的集合，它是基本的访问控制单元，创建表的时候创建；\n\n\n列限定符：列族里的数据通过列限定符（或列）来定位；\n\n\n单元格：在 HBase 表中，通过行、列族和列限定符确定一个“单元格”（cell）；\n\n\n时间戳：每个单元格都保存着同一份数据的多个版本，这些版本采用时间戳进行索引；\n\n\n数据坐标\nHBase 中需要根据行键、列族、列限定符和时间戳来确定一个单元格，因此，可以视为一个“四维坐标”，即[行键, 列族, 列限定符, 时间戳]\nHBase 的数据存储模型\nHBase 的数据的存储结构不同于传统的关系型数据库，HBase 是一种结构松散，分布式，多维 度有序映射的持久化存储系统，它索引的依据是行键、列键和时间戳。\nHBase 数据存储结构中主要包括：表、行、列族、列限定符、单元格和时间戳，下面将对 HBase 的数据存储模型的概念进行解释：\n\n\n表(Table)：对应于关系型数据库中的一张张表，HBase 以“表”为单位组织数据，表由多行组成。\n\n\n行(Row)：行包含在表中，数据以行的形式存储在 HBase 的表中。HBase 的表中的每一行数 据都会被一个唯一标识的行键（RowKey）标识，这个 RowKey 类似于关系型数据库表中的 主键，RowKey 根据字典序进行排序，并且只能存储 64KB 的数据。\n\n\n列族(Colunm Family)：行中的数据又分为多个列族，并且每个列族下可包含多个列。列族 会在使用前定义，也就是在定义表的时候就定义列族。\n\n\n列限定符(Column Qualifier)：通常以列族，和列限定符来确定列族中的某列。\n\n\n时间戳(Timestamp)：每个单元格里面可以存储每一份数据的多个版本，时间戳是区分每 一份数据的一个版本号标识，每一个值都会对应一个时间戳，在默认情况下，时间戳表示数 据写入的时间。并且是按照时间倒序进行排序（最新的数据放在最上面）。也可以自己设 置，但是一般情况下不需要。\n\n\n单元格(Cell)：单元格由 RowKey、列族、列限定符唯一定位，单元格之中存放一个值**{row key， column(= family + qualifier)， version}** ，并且值以字节形式存储。\n\n\n下面是一个具体的 HBase 表数据，来研究它的逻辑存储方式 👇\n\n上表展示的是 HBase 中的学生信息表 Student，有三行记录和两个列族，行键分别为 0001、 0002 和 0003，两个列族分别为 Stulnfo 和 Grades，每个列族中含有若干列，如列族 Stulnfo 包括 Name、Age、Sex 和 Class 四列，列族 Grades 包括 BigData、Computer 和 Math 三列。\n在 HBase 中，列不是固定的表结构，在创建表时，不需要预先定义列名，可以在插入数据时临时创建。\n从上表的逻辑模型来看，HBase 表与关系型数据库中的表结构之间似乎没有太大差异，只不过 多了列族的概念。但实际上是有很大差别的，关系型数据库中表的结构需要预先定义，如列名及 其数据类型和值域等内容。\n如果需要添加新列，则需要修改表结构，这会对已有的数据产生很大影响。同时，关系型数据 库中的表为每个列预留了存储空间，即上表中的空白 Cell 数据在关系型数据库中以“NULL”值占 用存储空间。因此，对稀疏数据来说，关系型数据库表中就会产生很多“NULL”值，消耗大量的存储空间。\n在 HBase 中，如上表中的空白 Cell 在物理上是不占用存储空间的，即不会存储空白的键值对。因此，若一个请求为获取 RowKey 为 0001 在 T2 时间的 Stulnfo:class 值时，其结果为空。 类似地，若一个请求为获取 RowKey 为 0002 在 T1 时间的 Grades Computer 值时，其结果也为空。\n下表展示了 Stulnfo 这个列族的实际物理存储方式，列族 Grades 的存储与之类似。在下表中可以看到空白 Cell 是没有被存储下来的。\n\n\n\n行键\n列标识\n值\n时间戳\n\n\n\n\n0001\nName\nTom\nT2\n\n\n0001\nAge\n18\nT2\n\n\n0001\nSex\nMale\nT2\n\n\n0002\nName\nAmy\nT1\n\n\n0002\nAge\n19\nT1\n\n\n0002\nClass\n01\nT1\n\n\n0003\nName\nAllen\nT1\n\n\n0003\nAge\n19\nT1\n\n\n0003\nSex\nMale\nT1\n\n\n0003\nClass\n02\nT1\n\n\n\n\nHBase 架构\n从下面的架构图可以发现 HBase 里面有这么几个角色：Client、Zookeeper、HMaster、 HRegionServer、HRegion、Store、MemStore、StoreFile、HFile、HLog 等。👇\n\nClient\n包含访问 HBase 的接口，Client 访问用户数据前需要首先访问 ZooKeeper，Region 所在的位 置，然后才能找到用户所需要的数据，客户端会通过维护 cache 来加快对 HBase 的访问。\nZooKeeper\n我们的 HBase 会使用到zookeeper，这里要注意，我们的 HBase 采用的是“主从结构”，有别于 HDFS 高可用中的“主备模式”，很凑巧它使用的是跟 zookeeper 一样的“主从模式”。在 HBase 中 zookeeper 主要有以下几个作用：\n\n\n✅ 为 HBase 提供故障转义机制，选举HMaster，避免单点 HMaster 单点故障问题。\n\n\n✅ 存储所有 Region 的寻址入口，我们的表在哪台服务器上，也就是这张表的位置信息。\n\n\n✅ 实时监控RegionServer的状态，将 RegionServer 的上线和下线信息实时通知给 HMaster。\n\n\n✅ 存储 HBase 的schema和table元数据，包括有哪些 Table，每个 Table 有哪些 Column Family。\n\n\nHMaster\nHMaster 一般运行在 NameNode 节点上面，它的主要作用有以下几点：\n\n\n✅ 为 RegionServer 分配 Region\n\n\n✅ 负责 RegionServer 的负载均衡\n\n\n✅ 发现失效的 RegionServer 并重新分配其上的 Region\n\n\n✅HDFS 上属于 HBase 的垃圾文件回收。\n\n\n✅ 处理客户端的更新请求（表的创建，删除，修改，列簇的增加等等）。\n\n\nHRegion\nHBase 的table在行的方向上分隔为多个Region（对应列族）。Region是 HBase 中分布式存储 和负载均衡的最小单元，即不同的region可以分别在不同的Region Server上，但同一个Region是不会拆分到多个 server 上，每个 region 会保存一个表里面某段连续的数据。\nRegion按大小分隔，表中每一行只能属于一个region。随着数据不断插入表，region不断增大，当region的 某个列族达到一个阈值时(默认256M)就会分成两个新的region。当一个表的数据越来越多的时候，有可能张在表的数据被保存在多个 Regionserver 上。\nStore\n每一个region有一个或多个store组成，至少是一个store，hbase 会把一起访问的数据放在一个store里面，即为每个ColumnFamily建一个store（即有几个ColumnFamily，也就有几个 Store）。一个Store由一个memStore和0或多个StoreFile组成。HBase 以 store 的大小来判断是否需要切分 region。\nMemStore的值达到某个阈值（默认128MB），RegionServer会启动flashcache进程写入 StoreFile，每次写入形成单独的一个StoreFile，当StoreFile文件的数量增长到一定阈值后，系统会进行合并，在合并过程中会进行版本合并和删除工作，形成更大的StoreFile。\n当一个Region所有StoreFile的大小和数量超过一定阈值后，会把当前的Region分割为两个， 并由 HMaster 分配到相应的 RegionServer 服务器，实现系统的负载均衡。\nHFile\nHBase 中的数据的存储格式，HFile 是 Hadoop 的 二进制格式文件，实际上 StoreFile 就是对 HFile 做了轻量级包装，即 StoreFile 底层就是 HFile。\nHLog\nHLog(WAL log)：WAL 意为 write ahead log，用来做灾难恢复使用，HLog 记录数据的所有变 更，一旦 region server 宕机，就可以从 log 中进行恢复\nHLog 文件就是一个普通的 Hadoop Sequence File， Sequence File 的 value 是 key 时 HLogKey 对象，其中记录了写入数据的归属信息，除了 table 和 region 名字外，还同时包括 sequence number 和 timestamp，timestamp 是写入时间，sequence number 的起始值为 0，或者是最近 一次存入文件系统中的 sequence number。 Sequence File 的 value 是 HBase 的 KeyValue 对象， 即对应 HFile 中的 KeyValue。\n整体物理结构如下👇\n\n总结：\n1️⃣HRegion 是 HBase 中分布式存储和负载均衡的最小单元。最小单元就表示不同的 HRegion 可 以分布在不同的 HRegionServer 上。\n2️⃣HRegion 由一个或者多个 Store 组成，每个 store 保存一个 columns family。\n3️⃣ 每个 Strore 又由一个 MemStore 和 0 至多个 StoreFile 组成，最终 StoreFile 以 HFile 格式保存在 HDFS 上。\nHBase 的 shell 操作\n操作命名空间\n命名空间(namespace)是与关系数据库系统中的数据库类似，我们以前使用 MySQL 的时候会先 创建数据库，然后在这个数据库里面创建表，我们的 HBase 也类似。\n查看所有命名空间\n使用“list_namespace”查看命名空间，有点类似于 MySQL 里面的“show databases”来查看系统 里面的所有数据库一样。\n# 查看系统里面的所有的命名空间。\nlist_namespace\n创建命名空间\n# 创建命名空间的语法\ncreate_namespace '命名空间的名称'\n显示命名空间下的表\nlist_namespace_tables '命名空间名称'\n删除命名空间\n如果命名空间不需要了可以使用“drop_namespace”命令来删除，要注意删除命名空间的时 候，这个命名空间得是空的。\ndrop_namespace '要删除的命名空间的名称'\nhbase 表格的基本结构\n\n\n\n\n表(Table)：对应于关系型数据库中的一张张表，HBase 以“表”为单位组织数据，表由多行组 成。\n\n\n行(Row)：行包含在表中，数据以行的形式存储在 HBase 的表中。HBase 的表中的每一行数 据都会被一个唯一标识的行键（RowKey）标识，这个 RowKey 类似于关系型数据库表中的 主键，RowKey 根据字典序进行排序，并且只能存储 64KB 的数据。\n\n\n列族(Colunm Family)：行中的数据又分为多个列族，并且每个列族下可包含多个列。列族 会在使用前定义，也就是在定义表的时候就定义列族。\n\n\n列限定符(Column Qualifier)：通常以列族，和列限定符来确定列族中的某列。\n\n\n时间戳(Timestamp)：每个单元格里面可以存储每一份数据的多个版本，时间戳是区分每 一份数据的一个版本号标识，每一个值都会对应一个时间戳，在默认情况下，时间戳表示数 据写入的时间。并且是按照时间倒序进行排序（最新的数据放在最上面）。也可以自己设 置，但是一般情况下不需要。\n\n\n单元格(Cell)：单元格由 RowKey、列族、列限定符唯一定位，单元格之中存放一个值{row key， column(= family + qualifier)， version} ，并且值以字节形式存储。\n\n\n创建表\n常规表的创建\n  create '表名', '列族名1'[,…]\n  create '命名空间:表名', '列族名1'[,…]\n# 或者\n  create '表名', &#123;NAME => '列族1',VERSIONS => versionNum(最多存储的版本数量)&#125; [, &#123;NAME => '列族2'&#125; ... ]\n  create '命名空间:表名', &#123;NAME => '列族1'&#125; [, &#123;NAME => '列族2'&#125; ... ]\n\n # =>不是>=的意思\n\n# 创建一个test的表，并且指定一个列族cf。\ncreate 'test', 'cf'\n\n# 创建一个学生表“student”，然后指定两个列族，一个是“detail”一个是“grade”。\n create 'student', 'detail', 'grade'\n\n# 在my_nn命名空间下面创建学生表\ncreate 'my_nn:student1', 'detail', 'grade'\n\n\n\n\n\n\n\n\n\n⚠注意：建表的时候需要指定表名，并且还需要同时指定至少一个列族。\n查看表的信息\n我们可以通过“list”命令查看表是否存在，以及使用“describe”命令来查看表的结构信息。\n# 查看'test'表是否存在\nlist 'test'\n我们也可以通过“exists ”来检查表是否存在，他比上面的“list”更加直观。\nexists 'my_tab'\n\n=> true/false\n我们可以通过“describe”查看表的描述信息，这个和以前的 MySQL 里面的“desc”的效果是类似 的。\ndescribe 'test'\n操作表\n插入数据\nput '表名' 'RowKey', '列族名:列名', '列对应的值'\n\n#使用put语句插入数据\nput 'test', 'row1', 'cf:a', 'value1'\nput 'test', 'row2', 'cf:b', 'value2'\nput 'test', 'row3', 'cf:c', 'value3'\n\n#插入数据并且带时间戳。\nput 'test', 'row4', 'cf:a', 'value1', 1647938469167\nput 'test', 'row5', 'cf:b', 'value2', 1647938469167\nput 'test', 'row5', 'cf:c', 'value3', 1647938469167\n扫描表的数据\nscan(全表查询)\nscan '表名'\n\n#通过版本来获取值：查看最近两个版本的数据。\nscan 'tab_ver', &#123; COLUMNS => ['cf:col1'], VERSIONS => 2 &#125;\n通过 get 查询\n上面的查询是全表查询，有的时候我们是通过 RowId 或者单元(cell)的值来进行查询，这个时候 就可以通过 get。\n# 获取列族下面的全部数据。\nget '表名', 'RowKey'\n# 获取列族下面的某一列。\nget '表名', 'RowKey', '列族名称:列'\n\n#使用get命令通过\"RowKey\"查询数据\nget 'test', 'row1'\n\n#通过列来查询数据\nget 'test', 'row1', 'cf:a'\n\n#通过版本来获取值：查看最近两个版本的数据\nget 'tab_ver', '0001', &#123; COLUMNS => ['cf:col1'],VERSIONS => 2 &#125;\n删除表的数据\ndelete\ndelete '表名', 'RowKey', '列族名称:列' [, 时间戳]\n\n#注意:如果不指定时间戳会删除最新的version!\n\n\n# 删除'test'表，RowKey为‘row1’的，并且列族“cf”的值为“a”的值。\ndelete 'test', 'row1', 'cf:a'\ndelete 只会删除指定列中的指定位置的数据,并不会删除这个数据的所在行\ndeleteall\n如需删除表中某一行上所有列族的数据，即删除上表中一个逻辑行， 则需要使用 deleteall，如下所示，不需要指定列族和列的名称。\ndeleteall '表名', 'RowKey'\ntruncate\n“truncate”命令也是删除表的数据，但是它和上面的 delete、deleteall 有不同，它的作用和关 系型数据库里面的作用类似，使用它的效果是：“使得表无效，然后删除表，再重新创建表”。使 用场景：就是当表的数据很大时候，可以使用“truncate”来清空表。\ntruncate '表名'\n删除表\n先要使用表不可用，然后再使用删除\n# 使得表不可用\ndisable 'test'\n\n# 删除表\ndrop 'test'\n登录 shell\nhbase shell\n","slug":"Hbase基础","date":"2023-07-19T12:30:44.000Z","categories_index":"NoSQL","tags_index":"Hbase","author_index":"ND_LJQ"},{"id":"dfbecd5a2d7d99309d0ce29d3d8528f9","title":"Redis6.0学习笔记","content":"Redis  是典型的  NoSQL  数据库，支持多种数据结构类型。设计思想是：单线程+多路 IO 复用技术\n\nredis 官方介绍\n\n\n\n\n\n\n\n\n\nRedis  是一个开源的  key-value  存储系统。和  Memcached  类似，它支持存储的  value  类型相对更多，包括  string、list、set、zset、sorted set、hash。\n这些数据类型都支持  push/pop、add/remove  及取交集并集和差集及更丰富的操作，而且这些操作都是原子性的\n这些数据类型都支持  push/pop、add/remove  及取交集并集和差集及更丰富的操作，而且这些操作都是原子性的。\n在此基础上，Redis  支持各种不同方式的排序。\n与  **memcached**一样，为了保证效率，数据都是缓存在内存中。区别的是  Redis  会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件。\n并且在此基础上实现了**master-slave** （主从）同步。单线程 + IO  多路复用。\nRedis 中的 key 操作\n查看当前库中所有的 key 值\nkeys  *\n设置 key-value 值\nset key_name value //返回ok代表成功\n查看 key 是否存在\nexists key_name //返回值为1表示存在,0则不存在\n查看 key 的 type\ntype key_name\nredis 的操作是原子操作，即不会被线程调度机制打断的操作\n同时设置一个或多个 key-value 对\nmset key1_name value1 key2_name value2.....\nkey 值不存在的时候设置 key 的值\nsetnx key_name value\nkey 值不存在的时候设置一个或多个 key 的值\nmsetnx key1_name value1 key2_name value2 key3_name value3.... // 原子性，有一个失败则都失败\n设置键值的同时，设置过期时间\nsetex key_name time value\n设置旧值的同时设置新值\ngetset key_name value\n获取 key 的 value 值\nget key_name\n获取一个或多个 key-value 对\nmget key1_name key2_name key3_name...\n将给定的值追加到目标 key 的末尾\nappend key_name value\n获得 key 值长度\nstrlen key_name\n将 key 中存储的数字增长 1\nincr key_name  //只能对数字值操作，如果为空，新增值为1\n将 key 中存储的数字增长任意值\nincrby key_name value\n将 key 中存储的数字减一\ndecr key_name\n将 key 中存储的数字减去任意值\ndecrby key_name value\n删除指定 key\ndel key_name //返回值为1表示成功\n非阻塞删除\nunlink key_name  //仅将keys从keyspace元数据中删除，真正的删除会在后续一步操作\n设置 key 过期时间\nexpire key_name time //以s为单位\n查看 key 的过期时间\nttl key_name  // -1代表永不过期 -2代表已经过期\n查看当前库的 key 的数量\ndbsize\n清空当前库\nflushdb\n清空所有库\nflushall\nRedis 的基本数据类型\nRedis 是使用了一个「哈希表」保存所有键值对，哈希表的最大好处就是让我们可以用 O(1) 的时间复杂度来快速查找到键值对。哈希表其实就是一个数组，数组中的元素叫做哈希桶。\nRedis 的哈希桶是怎么保存键值对数据的呢？\n哈希桶存放的是指向键值对数据的指针（dictEntry*），这样通过指针就能找到键值对数据，然后因为键值对的值可以保存字符串对象和集合数据类型的对象，所以键值对的数据结构中并不是直接保存值本身，而是保存了 void * key 和 void _ value 指针，分别指向了实际的键对象和值对象，这样一来，即使值是集合数据，也可以通过 void _ value 指针找到。\n这里有一张 Redis 保存键值对所涉及到的数据结构。\n\n\n\nredisDb 结构，表示 Redis 数据库的结构，结构体里存放了指向了 dict 结构的指针；\n\n\ndict 结构，结构体里存放了 2 个哈希表，正常情况下都是用「哈希表 1」，「哈希表 2」只有在 rehash 的时候才用，具体什么是 rehash，在哈希表数据结构会讲；\n\n\nditctht 结构，表示哈希表的结构，结构里存放了哈希表数组，数组中的每个元素都是指向一个哈希表节点结构（dictEntry）的指针；\n\n\ndictEntry 结构，表示哈希表节点的结构，结构里存放了  **void _ key 和 void _ value 指针， key 指向的是 String 对象，而 value 则可以指向 String 对象，也可以指向集合类型的对象，比如 List 对象、Hash 对象、Set 对象和 Zset 对象。\n\n\n特别说明下，void _ key 和 void _ value 指针指向的是  Redis 对象，Redis 中的每个对象都由 redisObject 结构表示，如下图：\n\n对象结构里包含的成员变量：\n\n\ntype，标识该对象是什么类型的对象（String 对象、 List 对象、Hash 对象、Set 对象和 Zset 对象）；\n\n\nencoding，标识该对象使用了哪种底层的数据结构；\n\n\nptr，指向底层数据结构的指针。\n\n\nString\nSDS\n字符串在 Redis 中是很常用的，键值对中的键是字符串类型，值有时也是字符串类型。\nRedis 是用 C 语言实现的，但是它没有直接使用 C 语言的 char* 字符数组来实现字符串，而是自己封装了一个名为简单动态字符串（simple dynamic string，SDS） 的数据结构来表示字符串，也就是 Redis 的 String 数据类型的底层数据结构是 SDS。\n既然 Redis 设计了 SDS 结构来表示字符串，肯定是 C 语言的 char* 字符数组存在一些缺陷。\n要了解这一点，得先来看看 char* 字符数组的结构。\nC 语言字符串的缺陷\nC 语言的字符串其实就是一个字符数组，即数组中每个元素是字符串中的一个字符。\n比如，下图就是字符串“xiaolin”的 char* 字符数组的结构：\n\n没学过 C 语言的同学，可能会好奇为什么最后一个字符是“\\0”？\n在 C 语言里，对字符串操作时，char * 指针只是指向字符数组的起始位置，而字符数组的结尾位置就用“\\0”表示，意思是指字符串的结束。\n因此，C 语言标准库中的字符串操作函数就通过判断字符是不是 “\\0” 来决定要不要停止操作，如果当前字符不是 “\\0” ，说明字符串还没结束，可以继续操作，如果当前字符是 “\\0” 是则说明字符串结束了，就要停止操作。\n举个例子，C 语言获取字符串长度的函数  strlen，就是通过字符数组中的每一个字符，并进行计数，等遇到字符为 “\\0” 后，就会停止遍历，然后返回已经统计到的字符个数，即为字符串长度。下图显示了 strlen 函数的执行流程：\n\n很明显，C 语言获取字符串长度的时间复杂度是 O（N）（这是一个可以改进的地方）\nC 语言字符串用 “\\0” 字符作为结尾标记有个缺陷。假设有个字符串中有个 “\\0” 字符，这时在操作这个字符串时就会提早结束，比如 “xiao\\0lin” 字符串，计算字符串长度的时候则会是 4，如下图：\n\n因此，除了字符串的末尾之外，字符串里面不能含有 “\\0” 字符，否则最先被程序读入的 “\\0” 字符将被误认为是字符串结尾，这个限制使得 C 语言的字符串只能保存文本数据，不能保存像图片、音频、视频文化这样的二进制数据（这也是一个可以改进的地方）\n另外， C 语言标准库中字符串的操作函数是很不安全的，对程序员很不友好，稍微一不注意，就会导致缓冲区溢出。\n举个例子，strcat 函数是可以将两个字符串拼接在一起。\nc //将 src 字符串拼接到 dest 字符串后面 char *strcat(char *dest, const char* src);\nC 语言的字符串是不会记录自身的缓冲区大小的，所以 strcat 函数假定程序员在执行这个函数时，已经为 dest 分配了足够多的内存，可以容纳 src 字符串中的所有内容，而一旦这个假定不成立，就会发生缓冲区溢出将可能会造成程序运行终止，（这是一个可以改进的地方）。\n而且，strcat 函数和 strlen 函数类似，时间复杂度也很高，也都需要先通过遍历字符串才能得到目标字符串的末尾。然后对于 strcat 函数来说，还要再遍历源字符串才能完成追加，对字符串的操作效率不高。\n好了， 通过以上的分析，我们可以得知 C 语言的字符串不足之处以及可以改进的地方：\n\n\n获取字符串长度的时间复杂度为 O（N）；\n\n\n字符串的结尾是以 “\\0” 字符标识，字符串里面不能包含有 “\\0” 字符，因此不能保存二进制数据；\n\n\n字符串操作函数不高效且不安全，比如有缓冲区溢出的风险，有可能会造成程序运行终止；\n\n\nRedis 实现的 SDS 的结构就把上面这些问题解决了，接下来我们一起看看 Redis 是如何解决的。\nSDS 结构设计\n下图就是 Redis 5.0 的 SDS 的数据结构：\n\n结构中的每个成员变量分别介绍下：\n\n\nlen，记录了字符串长度。这样获取字符串长度的时候，只需要返回这个成员变量值就行，时间复杂度只需要 O（1）。\n\n\nalloc，分配给字符数组的空间长度。这样在修改字符串的时候，可以通过  alloc - len  计算出剩余的空间大小，可以用来判断空间是否满足修改需求，如果不满足的话，就会自动将 SDS 的空间扩展至执行修改所需的大小，然后才执行实际的修改操作，所以使用 SDS 既不需要手动修改 SDS 的空间大小，也不会出现前面所说的缓冲区溢出的问题。\n\n\nflags，用来表示不同类型的 SDS。一共设计了 5 种类型，分别是 sdshdr5、sdshdr8、sdshdr16、sdshdr32 和 sdshdr64，后面再说明区别之处。\n\n\nbuf[]，字符数组，用来保存实际数据。不仅可以保存字符串，也可以保存二进制数据。\n\n\n总的来说，Redis 的 SDS 结构在原本字符数组之上，增加了三个元数据：len、alloc、flags，用来解决 C 语言字符串的缺陷。\nO（1）复杂度获取字符串长度\nC 语言的字符串长度获取 strlen 函数，需要通过遍历的方式来统计字符串长度，时间复杂度是 O（N）。\n而 Redis 的 SDS 结构因为加入了 len 成员变量，那么获取字符串长度的时候，直接返回这个成员变量的值就行，所以复杂度只有 O（1）。\n二进制安全\n因为 SDS 不需要用 “\\0” 字符来标识字符串结尾了，而是有个专门的 len 成员变量来记录长度，所以可存储包含 “\\0” 的数据。但是 SDS 为了兼容部分 C 语言标准库的函数， SDS 字符串结尾还是会加上 “\\0” 字符。\n因此， SDS 的 API 都是以处理二进制的方式来处理 SDS 存放在 buf[] 里的数据，程序不会对其中的数据做任何限制，数据写入的时候时什么样的，它被读取时就是什么样的。\n通过使用二进制安全的 SDS，而不是 C 字符串，使得 Redis 不仅可以保存文本数据，也可以保存任意格式的二进制数据。\n不会发生缓冲区溢出\nC 语言的字符串标准库提供的字符串操作函数，大多数（比如 strcat 追加字符串函数）都是不安全的，因为这些函数把缓冲区大小是否满足操作需求的工作交由开发者来保证，程序内部并不会判断缓冲区大小是否足够用，当发生了缓冲区溢出就有可能造成程序异常结束。\n所以，Redis 的 SDS 结构里引入了 alloc 和 len 成员变量，这样 SDS API 通过  alloc - len  计算，可以算出剩余可用的空间大小，这样在对字符串做修改操作的时候，就可以由程序内部判断缓冲区大小是否足够用。\n而且，当判断出缓冲区大小不够用时，Redis 会自动将扩大 SDS 的空间大小（小于 1MB 翻倍扩容，大于 1MB 按 1MB 扩容），以满足修改所需的大小。\n在扩展 SDS 空间之前，SDS API 会优先检查未使用空间是否足够，如果不够的话，API 不仅会为 SDS 分配修改所必须要的空间，还会给 SDS 分配额外的「未使用空间」。\n这样的好处是，下次在操作 SDS 时，如果 SDS 空间够的话，API 就会直接使用「未使用空间」，而无须执行内存分配，有效的减少内存分配次数。\n所以，使用 SDS 即不需要手动修改 SDS 的空间大小，也不会出现缓冲区溢出的问题。\n节省内存空间\nSDS 结构中有个 flags 成员变量，表示的是 SDS 类型。\nRedos 一共设计了 5 种类型，分别是 sdshdr5、sdshdr8、sdshdr16、sdshdr32 和 sdshdr64。\n这 5 种类型的主要区别就在于，它们数据结构中的 len 和 alloc 成员变量的数据类型不同。\n比如 sdshdr16 和 sdshdr32 这两个类型，它们的定义分别如下：\nstruct __attribute__ ((__packed__)) sdshdr16 &#123;\n    uint16_t len;\n    uint16_t alloc; \n    unsigned char flags; \n    char buf[];\n&#125;;\n\n\nstruct __attribute__ ((__packed__)) sdshdr32 &#123;\n    uint32_t len;\n    uint32_t alloc; \n    unsigned char flags;\n    char buf[];\n&#125;;\n可以看到：\n\n\nsdshdr16 类型的 len 和 alloc 的数据类型都是 uint16_t，表示字符数组长度和分配空间大小不能超过 2 的 16 次方。\n\n\nsdshdr32 则都是 uint32_t，表示表示字符数组长度和分配空间大小不能超过 2 的 32 次方。\n\n\n之所以 SDS 设计不同类型的结构体，是为了能灵活保存不同大小的字符串，从而有效节省内存空间。比如，在保存小字符串时，结构头占用空间也比较少。\n除了设计不同类型的结构体，Redis 在编程上还使用了专门的编译优化来节省内存空间，即在 struct 声明了  __attribute__ ((packed)) ，它的作用是：告诉编译器取消结构体在编译过程中的优化对齐，按照实际占用字节数进行对齐。\n比如，sdshdr16 类型的 SDS，默认情况下，编译器会按照 16 字节对齐的方式给变量分配内存，这意味着，即使一个变量的大小不到 16 个字节，编译器也会给它分配 16 个字节。\n举个例子，假设下面这个结构体，它有两个成员变量，类型分别是 char 和 int，如下所示：\n#include &lt;stdio.h>\n\n struct test1 &#123;\n    char a;\n    int b;\n &#125; test1;\n\nint main() &#123;\n     printf(\"%lu\\n\", sizeof(test1));\n     return 0;\n&#125;\n猜猜这个结构体大小是多少？我先直接说答案，这个结构体大小计算出来是 8。\n\n这是因为默认情况下，编译器是使用「字节对齐」的方式分配内存，虽然 char 类型只占一个字节，但是由于成员变量里有 int 类型，它占用了 4 个字节，所以在成员变量为 char 类型分配内存时，会分配 4 个字节，其中这多余的 3 个字节是为了字节对齐而分配的，相当于有 3 个字节被浪费掉了。\n如果不想编译器使用字节对齐的方式进行分配内存，可以采用了  __attribute__ ((packed))  属性定义结构体，这样一来，结构体实际占用多少内存空间，编译器就分配多少空间。\n比如，我用  __attribute__ ((packed))  属性定义下面的结构体 ，同样包含 char 和 int 两个类型的成员变量，代码如下所示：\n#include &lt;stdio.h>\n\nstruct __attribute__((packed)) test2  &#123;\n    char a;\n    int b;\n &#125; test2;\n\nint main() &#123;\n     printf(\"%lu\\n\", sizeof(test2));\n     return 0;\n&#125;\n这时打印的结果是 5（1 个字节 char + 4 字节 int）。\n\n可以看得出，这是按照实际占用字节数进行分配内存的，这样可以节省内存空间。\n部分操作指令\n获取 key 的指定范围的值\ngetrange key_name start_number end_number\n在 key 的指定位置插入值\nsetrange key_name start_number value\nList\n允许重复值\n单键多值底层：双向链表 对两端的操作性能高，中间的操作性能低\n数据结构\nqickList:链表+ziplist\n\n\n首先在列表元素较少的情况下会使用一块连续的内存存储，这个结构是  ziplist，也即是压缩列表\n\n它将所有的元素紧挨着一起存储，分配的是一块连续的内存。\n\n\n\n当数据量比较多的时候才会改成  quicklist。\n\n因为普通的链表需要的附加指针空间太大，会比较浪费空间。比如这个列表里存的只是  int  类型的数据，结构上还需要两个额外的指针  prev  和  next\n\n\n\n\n\n\nRedis  将链表和  ziplist  结合起来组成了  quicklist。也就是将多个  ziplist  使用双向指针串起来使用。这样既满足了快速的插入删除性能，又不会出现太大的空间冗余。**quicklist**结构图如下：\n\n\n\n链表节点结构设计\n先来看看「链表节点」结构的样子：\ntypedef struct listNode &#123;\n    //前置节点\n    struct listNode *prev;\n    //后置节点\n    struct listNode *next;\n    //节点的值\n    void *value;\n&#125; listNode;\n有前置节点和后置节点，可以看的出，这个是一个双向链表。\n\n链表结构设计\n不过，Redis 在 listNode 结构体基础上又封装了 list 这个数据结构，这样操作起来会更方便，链表结构如下：\ntypedef struct list &#123;\n    //链表头节点\n    listNode *head;\n    //链表尾节点\n    listNode *tail;\n    //节点值复制函数\n    void *(*dup)(void *ptr);\n    //节点值释放函数\n    void (*free)(void *ptr);\n    //节点值比较函数\n    int (*match)(void *ptr, void *key);\n    //链表节点数量\n    unsigned long len;\n&#125; list;\nlist 结构为链表提供了链表头指针 head、链表尾节点 tail、链表节点数量 len、以及可以自定义实现的 dup、free、match 函数。\n举个例子，下面是由 list 结构和 3 个 listNode 结构组成的链表。\n\n链表的优势与缺陷\nRedis 的链表实现优点如下：\n\n\nlistNode 链表节点的结构里带有 prev 和 next 指针，获取某个节点的前置节点或后置节点的时间复杂度只需 O(1)，而且这两个指针都可以指向 NULL，所以链表是无环链表；\n\n\nlist 结构因为提供了表头指针 head 和表尾节点 tail，所以获取链表的表头节点和表尾节点的时间复杂度只需 O(1)；\n\n\nlist 结构因为提供了链表节点数量 len，所以获取链表中的节点数量的时间复杂度只需 O(1)；\n\n\nlistNode 链表节使用 void* 指针保存节点值，并且可以通过 list 结构的 dup、free、match 函数指针为节点设置该节点类型特定的函数，因此链表节点可以保存各种不同类型的值；\n\n\n链表的缺陷也是有的：\n\n\n链表每个节点之间的内存都是不连续的，意味着无法很好利用 CPU 缓存。能很好利用 CPU 缓存的数据结构就是数组，因为数组的内存是连续的，这样就可以充分利用 CPU 缓存来加速访问。\n\n\n还有一点，保存一个链表节点的值都需要一个链表节点结构头的分配，内存开销较大。\n\n\n因此，Redis 3.0 的 List 对象在数据量比较少的情况下，会采用「压缩列表」作为底层数据结构的实现，它的优势是节省内存空间，并且是内存紧凑型的数据结构。\n不过，压缩列表存在性能问题（具体什么问题，下面会说），所以 Redis 在 3.2 版本设计了新的数据结构 quicklist，并将 List 对象的底层数据结构改由 quicklist 实现。\n然后在 Redis 5.0 设计了新的数据结构 listpack，沿用了压缩列表紧凑型的内存布局，最终在最新的 Redis 版本，将 Hash 对象和 Zset 对象的底层数据结构实现之一的压缩列表，替换成由 listpack 实现。\n\n压缩列表\n压缩列表的最大特点，就是它被设计成一种内存紧凑型的数据结构，占用一块连续的内存空间，不仅可以利用 CPU 缓存，而且会针对不同长度的数据，进行相应编码，这种方法可以有效地节省内存开销。\n但是，压缩列表的缺陷也是有的：\n\n\n不能保存过多的元素，否则查询效率就会降低；\n\n\n新增或修改某个元素时，压缩列表占用的内存空间需要重新分配，甚至可能引发连锁更新的问题。\n\n\n因此，Redis 对象（List 对象、Hash 对象、Zset 对象）包含的元素数量较少，或者元素值不大的情况才会使用压缩列表作为底层数据结构。\n接下来，就跟大家详细聊下压缩列表。\n压缩列表结构设计\n压缩列表是 Redis 为了节约内存而开发的，它是由连续内存块组成的顺序型数据结构，有点类似于数组。\n\n压缩列表在表头有三个字段：\n\n\nzlbytes，记录整个压缩列表占用对内存字节数；\n\n\nzltail，记录压缩列表「尾部」节点距离起始地址由多少字节，也就是列表尾的偏移量；\n\n\nzllen，记录压缩列表包含的节点数量；\n\n\nzlend，标记压缩列表的结束点，固定值 0xFF（十进制 255）。\n\n\n在压缩列表中，如果我们要查找定位第一个元素和最后一个元素，可以通过表头三个字段的长度直接定位，复杂度是 O(1)。而查找其他元素时，就没有这么高效了，只能逐个查找，此时的复杂度就是 O(N) 了，因此压缩列表不适合保存过多的元素。\n另外，压缩列表节点（entry）的构成如下：\n\n压缩列表节点包含三部分内容：\n\n\nprevlen，记录了「前一个节点」的长度；\n\n\nencoding，记录了当前节点实际数据的类型以及长度；\n\n\ndata，记录了当前节点的实际数据；\n\n\n当我们往压缩列表中插入数据时，压缩列表就会根据数据是字符串还是整数，以及数据的大小，会使用不同空间大小的 prevlen 和 encoding 这两个元素里保存的信息，这种根据数据大小和类型进行不同的空间大小分配的设计思想，正是 Redis 为了节省内存而采用的。\n分别说下，prevlen 和 encoding 是如何根据数据的大小和类型来进行不同的空间大小分配。\n压缩列表里的每个节点中的 prevlen 属性都记录了「前一个节点的长度」，而且 prevlen 属性的空间大小跟前一个节点长度值有关，比如：\n\n\n如果前一个节点的长度小于 254 字节，那么 prevlen 属性需要用  1 字节的空间来保存这个长度值；\n\n\n如果前一个节点的长度大于等于 254 字节，那么 prevlen 属性需要用  5 字节的空间来保存这个长度值；\n\n\nencoding 属性的空间大小跟数据是字符串还是整数，以及字符串的长度有关：\n\n\n如果当前节点的数据是整数，则 encoding 会使用  1 字节的空间进行编码。\n\n\n如果当前节点的数据是字符串，根据字符串的长度大小，encoding 会使用  1 字节/2 字节/5 字节的空间进行编码。\n\n\n连锁更新\n压缩列表除了查找复杂度高的问题，还有一个问题。\n压缩列表新增某个元素或修改某个元素时，如果空间不不够，压缩列表占用的内存空间就需要重新分配。而当新插入的元素较大时，可能会导致后续元素的 prevlen 占用空间都发生变化，从而引起「连锁更新」问题，导致每个元素的空间都要重新分配，造成访问压缩列表性能的下降。\n前面提到，压缩列表节点的 prevlen 属性会根据前一个节点的长度进行不同的空间大小分配：\n\n\n如果前一个节点的长度小于 254 字节，那么 prevlen 属性需要用  1 字节的空间来保存这个长度值；\n\n\n如果前一个节点的长度大于等于 254 字节，那么 prevlen 属性需要用  5 字节的空间来保存这个长度值；\n\n\n现在假设一个压缩列表中有多个连续的、长度在 250 ～ 253 之间的节点，如下图：\n\n因为这些节点长度值小于 254 字节，所以 prevlen 属性需要用 1 字节的空间来保存这个长度值。\n这时，如果将一个长度大于等于 254 字节的新节点加入到压缩列表的表头节点，即新节点将成为 e1 的前置节点，如下图：\n\n因为 e1 节点的 prevlen 属性只有 1 个字节大小，无法保存新节点的长度，此时就需要对压缩列表的空间重分配操作，并将 e1 节点的 prevlen 属性从原来的 1 字节大小扩展为 5 字节大小。\n多米诺牌的效应就此开始。\n\ne1 原本的长度在 250 ～ 253 之间，因为刚才的扩展空间，此时 e1 的长度就大于等于 254 了，因此原本 e2 保存 e1 的 prevlen 属性也必须从 1 字节扩展至 5 字节大小。\n正如扩展 e1 引发了对 e2 扩展一样，扩展 e2 也会引发对 e3 的扩展，而扩展 e3 又会引发对 e4 的扩展…. 一直持续到结尾。\n这种在特殊情况下产生的连续多次空间扩展操作就叫做「连锁更新」，就像多米诺牌的效应一样，第一张牌倒下了，推动了第二张牌倒下；第二张牌倒下，又推动了第三张牌倒下….，\n压缩列表的缺陷\n空间扩展操作也就是重新分配内存，因此连锁更新一旦发生，就会导致压缩列表占用的内存空间要多次重新分配，这就会直接影响到压缩列表的访问性能。\n所以说，虽然压缩列表紧凑型的内存布局能节省内存开销，但是如果保存的元素数量增加了，或是元素变大了，会导致内存重新分配，最糟糕的是会有「连锁更新」的问题。\n因此，压缩列表只会用于保存的节点数量不多的场景，只要节点数量足够小，即使发生连锁更新，也是能接受的。\n虽说如此，Redis 针对压缩列表在设计上的不足，在后来的版本中，新增设计了两种数据结构：quicklist（Redis 3.2 引入） 和 listpack（Redis 5.0 引入）。这两种数据结构的设计目标，就是尽可能地保持压缩列表节省内存的优势，同时解决压缩列表的「连锁更新」的问题。\nquicklist\n在 Redis 3.0 之前，List 对象的底层数据结构是双向链表或者压缩列表。然后在 Redis 3.2 的时候，List 对象的底层改由 quicklist 数据结构实现。\n其实 quicklist 就是「双向链表 + 压缩列表」组合，因为一个 quicklist 就是一个链表，而链表中的每个元素又是一个压缩列表。\n在前面讲压缩列表的时候，我也提到了压缩列表的不足，虽然压缩列表是通过紧凑型的内存布局节省了内存开销，但是因为它的结构设计，如果保存的元素数量增加，或者元素变大了，压缩列表会有「连锁更新」的风险，一旦发生，会造成性能下降。\nquicklist 解决办法，通过控制每个链表节点中的压缩列表的大小或者元素个数，来规避连锁更新的问题。因为压缩列表元素越少或越小，连锁更新带来的影响就越小，从而提供了更好的访问性能。\nquicklist 结构设计\nquicklist 的结构体跟链表的结构体类似，都包含了表头和表尾，区别在于 quicklist 的节点是 quicklistNode。\ntypedef struct quicklist &#123;\n    //quicklist的链表头\n    quicklistNode *head;      //quicklist的链表头\n    //quicklist的链表头\n    quicklistNode *tail; \n    //所有压缩列表中的总元素个数\n    unsigned long count;\n    //quicklistNodes的个数\n    unsigned long len;       \n    ...\n&#125; quicklist;\n接下来看看，quicklistNode 的结构定义：\ntypedef struct quicklistNode &#123;\n    //前一个quicklistNode\n    struct quicklistNode *prev;     //前一个quicklistNode\n    //下一个quicklistNode\n    struct quicklistNode *next;     //后一个quicklistNode\n    //quicklistNode指向的压缩列表\n    unsigned char *zl;              \n    //压缩列表的的字节大小\n    unsigned int sz;                \n    //压缩列表的元素个数\n    unsigned int count : 16;        //ziplist中的元素个数 \n    ....\n&#125; quicklistNode;\n可以看到，quicklistNode 结构体里包含了前一个节点和下一个节点指针，这样每个 quicklistNode 形成了一个双向链表。但是链表节点的元素不再是单纯保存元素值，而是保存了一个压缩列表，所以 quicklistNode 结构体里有个指向压缩列表的指针 *zl。\n我画了一张图，方便你理解 quicklist 数据结构。\n\n在向 quicklist 添加一个元素的时候，不会像普通的链表那样，直接新建一个链表节点。而是会检查插入位置的压缩列表是否能容纳该元素，如果能容纳就直接保存到 quicklistNode 结构里的压缩列表，如果不能容纳，才会新建一个新的 quicklistNode 结构。\nquicklist 会控制 quicklistNode 结构里的压缩列表的大小或者元素个数，来规避潜在的连锁更新的风险，但是这并没有完全解决连锁更新的问题。\nlistpack\nquicklist 虽然通过控制 quicklistNode 结构里的压缩列表的大小或者元素个数，来减少连锁更新带来的性能影响，但是并没有完全解决连锁更新的问题。\n因为 quicklistNode 还是用了压缩列表来保存元素，压缩列表连锁更新的问题，来源于它的结构设计，所以要想彻底解决这个问题，需要设计一个新的数据结构。\n于是，Redis 在 5.0 新设计一个数据结构叫 listpack，目的是替代压缩列表，它最大特点是 listpack 中每个节点不再包含前一个节点的长度了，压缩列表每个节点正因为需要保存前一个节点的长度字段，就会有连锁更新的隐患。\nlistpack 结构设计\nlistpack 采用了压缩列表的很多优秀的设计，比如还是用一块连续的内存空间来紧凑地保存数据，并且为了节省内存的开销，listpack 节点会采用不同的编码方式保存不同大小的数据。\n我们先看看 listpack 结构：\n\nlistpack 头包含两个属性，分别记录了 listpack 总字节数和元素数量，然后 listpack 末尾也有个结尾标识。图中的 listpack entry 就是 listpack 的节点了。\n每个 listpack 节点结构如下：\n\n主要包含三个方面内容：\n\n\nencoding，定义该元素的编码类型，会对不同长度的整数和字符串进行编码；\n\n\ndata，实际存放的数据；\n\n\nlen，encoding+data 的总长度；\n\n\n可以看到，listpack 没有压缩列表中记录前一个节点长度的字段了，listpack 只记录当前节点的长度，当我们向 listpack 加入一个新元素的时候，不会影响其他节点的长度字段的变化，从而避免了压缩列表的连锁更新问题。\n插入数据\n从左边插入一个或多个数据\nlpush key_name value1 value2 value3...\n\n例子: lpush k1 v1 v2 v3\n\t lrange k1 0 -1  //代表取所有\n\t (1)v3\n\t (2)v2\n\t (3)v1\n\n从右边插入一个或多个数据\nrpush key_name value1 value2 value3...\n\n在list的某一值前或后插入数据\nlinsert key_name target_value new_value\nlpush 原理(推箱子):\n\n\n\nv1\n\n\n\n\n\n\n\n\nv2\nv1\n\n\n\n\n\n\n\nv3\nv2\nv1\n\n\n\nrpush 原理(同理):\n\n\n\n\n\nv1\n\n\n\n\n\n\n\nv1\nv2\n\n\n\n\n\n\nv1\nv2\nv3\n\n\n\n获取范围内的数据\n从左边取\nlrange key_name start_number end_number  // lrange k1 0 -1 代表list中的全部value\n\nlindex key_name index //取list中的某一索引的值\n\nllen key_name  //获取list长度\n弹出数据\nrpop/lpop key_name //字面意思从左边或者右边弹出值\n\nrpoppush key1_name key2_name //从key1列表右边吐出一个值,插到key2左边\n删除数据\nlrem key_name n value // 从左边删除n个value\n数据的替换\nlset key_name index value //将列表下标为index的值替换为value\nSet(集合 )\nSet 是 string 类型的无序集合.底层是一个 value 为 null 的 hash 表,所以添加,删除,查找的复杂度都是 o(0),单位是 menmber(成员)\n集合中的值具有唯一性\n数据结构\nSet 的数据结构是 dict 字典,字典是用哈希表实现的\n在Redis7.2之前，当一个集合满足以下两个条件时，Redis 会选择使用intset编码：\n\n\n集合对象保存的所有元素都是整数值\n\n\n集合对象保存的元素数量小于等于 512 个（默认）\n\n\nintset 最大元素数量可在 redis.conf 配置\n\n\nset-max-intset-entries 512\n为什么加入了listpack\n在redis7.2之前，sds类型的数据会直接放入到编码结构式为hashtable 的 set 中。其中，sds其实就是 redis 中的 string 类型。\n而在redis7.2之后，sds类型的数据，首先会使用listpack结构当 set 达到一定的阈值时，才会自动转换为hashtable。\n添加listpack结构是为了提高内存利用率和操作效率，因为 hashtable 的空间开销和碰撞概率都比较高。\n整数集合(intset)\n整数集合是 Set 对象的底层实现之一。当一个 Set 对象只包含整数值元素，并且元素数量不时，就会使用整数集这个数据结构作为底层实现。\n整数集合结构设计\n整数集合本质上是一块连续内存空间，它的结构定义如下：\ntypedef struct intset &#123;\n    //编码方式\n    uint32_t encoding;\n    //集合包含的元素数量\n    uint32_t length;\n    //保存元素的数组\n    int8_t contents[];\n&#125; intset;\n可以看到，保存元素的容器是一个 contents 数组，虽然 contents 被声明为 int8_t 类型的数组，但是实际上 contents 数组并不保存任何 int8_t 类型的元素，contents 数组的真正类型取决于 intset 结构体里的 encoding 属性的值。比如：\n\n\n如果 encoding 属性值为 INTSET_ENC_INT16，那么 contents 就是一个 int16_t 类型的数组，数组中每一个元素的类型都是 int16_t；\n\n\n如果 encoding 属性值为 INTSET_ENC_INT32，那么 contents 就是一个 int32_t 类型的数组，数组中每一个元素的类型都是 int32_t；\n\n\n如果 encoding 属性值为 INTSET_ENC_INT64，那么 contents 就是一个 int64_t 类型的数组，数组中每一个元素的类型都是 int64_t；\n\n\n不同类型的 contents 数组，意味着数组的大小也会不同。\n整数集合的升级操作\n整数集合会有一个升级规则，就是当我们将一个新元素加入到整数集合里面，如果新元素的类型（int32_t）比整数集合现有所有元素的类型（int16_t）都要长时，整数集合需要先进行升级，也就是按新元素的类型（int32_t）扩展 contents 数组的空间大小，然后才能将新元素加入到整数集合里，当然升级的过程中，也要维持整数集合的有序性。\n整数集合升级的过程不会重新分配一个新类型的数组，而是在原本的数组上扩展空间，然后在将每个元素按间隔类型大小分割，如果 encoding 属性值为 INTSET_ENC_INT16，则每个元素的间隔就是 16 位。\n举个例子，假设有一个整数集合里有 3 个类型为 int16_t 的元素。\n\n现在，往这个整数集合中加入一个新元素 65535，这个新元素需要用 int32_t 类型来保存，所以整数集合要进行升级操作，首先需要为 contents 数组扩容，在原本空间的大小之上再扩容多 80 位（4x32-3x16=80），这样就能保存下 4 个类型为 int32_t 的元素。\n\n扩容完 contents 数组空间大小后，需要将之前的三个元素转换为 int32_t 类型，并将转换后的元素放置到正确的位上面，并且需要维持底层数组的有序性不变，整个转换过程如下：\n\n\n\n\n\n\n\n\n\n\n整数集合升级有什么好处呢？\n如果要让一个数组同时保存 int16_t、int32_t、int64_t 类型的元素，最简单做法就是直接使用 int64_t 类型的数组。不过这样的话，当如果元素都是 int16_t 类型的，就会造成内存浪费的情况。\n整数集合升级就能避免这种情况，如果一直向整数集合添加 int16_t 类型的元素，那么整数集合的底层实现就一直是用 int16_t 类型的数组，只有在我们要将 int32_t 类型或 int64_t 类型的元素添加到集合时，才会对数组进行升级操作。\n因此，整数集合升级的好处是节省内存资源。\n\n\n\n\n\n\n\n\n\n整数集合支持降级操作吗？\n不支持降级操作，一旦对数组进行了升级，就会一直保持升级后的状态。比如前面的升级操作的例子，如果删除了 65535 元素，整数集合的数组还是 int32_t 类型的，并不会因此降级为 int16_t 类型。\n添加一个或多个数据\nsadd key_name value1 value2 value3....\n查看集合中所有的数据\nsmembers key_name\n判断集合中是否有某一个值\nsismember key_name value\n查询集合元素个数\nscard key_name\n删除集合中的某一元素\nsrem key_name value1 value2 value3...\n在集合中随机弹值\nspop key_name\n集合中随机取 n 个值\nsrandmember key_name n\n集合间传值\nsmove key1_name key2_name key1_value //相同的值会忽略,但是还是会删除\n集合间取交集\nsinter key1_name key2_name\n集合间取并集\nsunion key1_name key2_name\n集合间取差集\nsdiif key1_name key2_name //key1中有的,不包含key2中的\nHash(哈希)\n哈希表是一种保存键值对（key-value）的数据结构。\n哈希表中的每一个 key 都是独一无二的，程序可以根据 key 查找到与之关联的 value，或者通过 key 来更新 value，又或者根据 key 来删除整个 key-value 等等。\n在讲压缩列表的时候，提到过 Redis 的 Hash 对象的底层实现之一是压缩列表（最新 Redis 代码已将压缩列表替换成 listpack）。Hash 对象的另外一个底层实现就是哈希表。\n哈希表优点在于，它能以 O(1) 的复杂度快速查询数据。怎么做到的呢？将 key 通过 Hash 函数的计算，就能定位数据在表中的位置，因为哈希表实际上是数组，所以可以通过索引值快速查询到数据。\n但是存在的风险也是有，在哈希表大小固定的情况下，随着数据不断增多，那么哈希冲突的可能性也会越高。\n解决哈希冲突的方式，有很多种。\nRedis 采用了「链式哈希」来解决哈希冲突，在不扩容哈希表的前提下，将具有相同哈希值的数据串起来，形成链接起，以便这些数据在表中仍然可以被查询到。\n接下来，详细说说哈希表。\nHash  类型对应的数据结构是两种：ziplist（压缩列表），hashtable（哈希表）。\n当  field-value  长度较短且个数较少时，使用  ziplist，否则使用  hashtable。\nhash 是一个 string 类型的 field 和 value 的映射表,hash 特别适合用来储存对象如:\n\n\n\nkey\nvalue\n\n\n\n\n\nuser\nfield\nvalue\n\n\n\nid\n1\n\n\n\nname\n张三\n\n\n\nage\n20\n\n\n\n存储格式\n第一种\nkey value\nuser: {id:1,name:jack,age:20} 修改太麻烦(不推荐)\n第二种\nkey value\nuser :id 1\nuser :name jack\nuser :age 20\n第三种 hash\nkey value\nfield value\nuser id 1\nname jack\nage 20\n哈希表结构设计\nRedis 的哈希表结构如下：\ntypedef struct dictht &#123;\n    //哈希表数组\n    dictEntry **table;\n    //哈希表大小\n    unsigned long size;  \n    //哈希表大小掩码，用于计算索引值\n    unsigned long sizemask;\n    //该哈希表已有的节点数量\n    unsigned long used;\n&#125; dictht;\n可以看到，哈希表是一个数组（dictEntry **table），数组的每个元素是一个指向「哈希表节点（dictEntry）」的指针。\n\n哈希表节点的结构如下：\ntypedef struct dictEntry &#123;\n    //键值对中的键\n    void *key;\n\n    //键值对中的值\n    union &#123;\n        void *val;\n        uint64_t u64;\n        int64_t s64;\n        double d;\n    &#125; v;\n    //指向下一个哈希表节点，形成链表\n    struct dictEntry *next;\n&#125; dictEntry;\ndictEntry 结构里不仅包含指向键和值的指针，还包含了指向下一个哈希表节点的指针，这个指针可以将多个哈希值相同的键值对链接起来，以此来解决哈希冲突的问题，这就是链式哈希。\n另外，这里还跟你提一下，dictEntry 结构里键值对中的值是一个「联合体 v」定义的，因此，键值对中的值可以是一个指向实际值的指针，或者是一个无符号的 64 位整数或有符号的 64 位整数或 double 类的值。这么做的好处是可以节省内存空间，因为当「值」是整数或浮点数时，就可以将值的数据内嵌在 dictEntry 结构里，无需再用一个指针指向实际的值，从而节省了内存空间。\n哈希冲突\n哈希表实际上是一个数组，数组里多每一个元素就是一个哈希桶。\n当一个键值对的键经过 Hash 函数计算后得到哈希值，再将(哈希值 % 哈希表大小)取模计算，得到的结果值就是该 key-value 对应的数组元素位置，也就是第几个哈希桶。\n\n\n\n\n\n\n\n\n\n什么是哈希冲突呢？\n举个例子，有一个可以存放 8 个哈希桶的哈希表。key1 经过哈希函数计算后，再将「哈希值 % 8 」进行取模计算，结果值为 1，那么就对应哈希桶 1，类似的，key9 和 key10 分别对应哈希桶 1 和桶 6。\n\n此时，key1 和 key9 对应到了相同的哈希桶中，这就发生了哈希冲突。\n因此，当有两个以上数量的 kay 被分配到了哈希表中同一个哈希桶上时，此时称这些 key 发生了冲突。\n链式哈希\nRedis 采用了「链式哈希」的方法来解决哈希冲突。\n\n\n\n\n\n\n\n\n\n链式哈希是怎么实现的？\n实现的方式就是每个哈希表节点都有一个 next 指针，用于指向下一个哈希表节点，因此多个哈希表节点可以用 next 指针构成一个单项链表，被分配到同一个哈希桶上的多个节点可以用这个单项链表连接起来，这样就解决了哈希冲突。\n还是用前面的哈希冲突例子，key1 和 key9 经过哈希计算后，都落在同一个哈希桶，链式哈希的话，key1 就会通过 next 指针指向 key9，形成一个单向链表。\n\n不过，链式哈希局限性也很明显，随着链表长度的增加，在查询这一位置上的数据的耗时就会增加，毕竟链表的查询的时间复杂度是 O(n)。\n要想解决这一问题，就需要进行 rehash，也就是对哈希表的大小进行扩展。\n接下来，看看 Redis 是如何实现的 rehash 的。\nrehash\n哈希表结构设计的这一小节，介绍了 Redis 使用 dictht 结构体表示哈希表。不过，在实际使用哈希表时，Redis 定义一个 dict 结构体，这个结构体里定义了两个哈希表（ht[2]）。\ntypedef struct dict &#123;\n    …\n    //两个Hash表，交替使用，用于rehash操作\n    dictht ht[2]; \n    …\n&#125; dict;\n之所以定义了 2 个哈希表，是因为进行 rehash 的时候，需要用上 2 个哈希表了。\n\n在正常服务请求阶段，插入的数据，都会写入到「哈希表 1」，此时的「哈希表 2 」 并没有被分配空间。\n随着数据逐步增多，触发了 rehash 操作，这个过程分为三步：\n\n\n给「哈希表 2」 分配空间，一般会比「哈希表 1」 大 2 倍；\n\n\n将「哈希表 1 」的数据迁移到「哈希表 2」 中；\n\n\n迁移完成后，「哈希表 1 」的空间会被释放，并把「哈希表 2」 设置为「哈希表 1」，然后在「哈希表 2」 新创建一个空白的哈希表，为下次 rehash 做准备。\n\n\n为了方便你理解，我把 rehash 这三个过程画在了下面这张图：\n\n这个过程看起来简单，但是其实第二步很有问题，如果「哈希表 1 」的数据量非常大，那么在迁移至「哈希表 2 」的时候，因为会涉及大量的数据拷贝，此时可能会对 Redis 造成阻塞，无法服务其他请求。\n渐进式 rehash\n为了避免 rehash 在数据迁移过程中，因拷贝数据的耗时，影响 Redis 性能的情况，所以 Redis 采用了渐进式 rehash，也就是将数据的迁移的工作不再是一次性迁移完成，而是分多次迁移。\n渐进式 rehash 步骤如下：\n\n\n给「哈希表 2」 分配空间；\n\n\n在 rehash 进行期间，每次哈希表元素进行新增、删除、查找或者更新操作时，Redis 除了会执行对应的操作之外，还会顺序将「哈希表 1 」中索引位置上的所有 key-value 迁移到「哈希表 2」 上；\n\n\n随着处理客户端发起的哈希表操作请求数量越多，最终在某个时间嗲呢，会把「哈希表 1 」的所有 key-value 迁移到「哈希表 2」，从而完成 rehash 操作。\n\n\n这样就巧妙地把一次性大量数据迁移工作的开销，分摊到了多次处理请求的过程中，避免了一次性 rehash 的耗时操作。\n在进行渐进式 rehash 的过程中，会有两个哈希表，所以在渐进式 rehash 进行期间，哈希表元素的删除、查找、更新等操作都会在这两个哈希表进行。\n比如，查找一个 key 的值的话，先会在「哈希表 1」 里面进行查找，如果没找到，就会继续到哈希表 2 里面进行找到。\n另外，在渐进式 rehash 进行期间，新增一个 key-value 时，会被保存到「哈希表 2 」里面，而「哈希表 1」 则不再进行任何添加操作，这样保证了「哈希表 1 」的 key-value 数量只会减少，随着 rehash 操作的完成，最终「哈希表 1 」就会变成空表。\nrehash 触发条件\n介绍了 rehash 那么多，还没说什么时情况下会触发 rehash 操作呢？\nrehash 的触发条件跟**负载因子（load factor）**有关系。\n负载因子可以通过下面这个公式计算：\n\n触发 rehash 操作的条件，主要有两个：\n\n\n当负载因子大于等于 1 ，并且 Redis 没有在执行 bgsave 命令或者 bgrewiteaof 命令，也就是没有执行 RDB 快照或没有进行 AOF 重写的时候，就会进行 rehash 操作。\n\n\n当负载因子大于等于 5 时，此时说明哈希冲突非常严重了，不管有没有有在执行 RDB 快照或 AOF 重写，都会强制进行 rehash 操作。\n\n\n存储数据(单个)\nhset key_name field_name field_value //给key_name集合中的 field键赋值\n存储数据(多个)\nhmset key_name field1_name value1 field2_name value2\n取出数据\nhget key_name field_name\n取出 key hash 集合内所有的 field 值\nhkeys key_name\n取出 key hash 集合内所有的 value 值\nhvals key_name\n查看 key 中的 field 是否存在\nhexists key_name field_name\nkey 中的 hash 集合中 field 加值\nhincrby key_name field_name n\nkey 中 hash 集合中的 field 值不存在的时候设置一个 field 值\nhsetnx key_name field_name value\nZset(有序集合)\nRedis 有序集合 zset 与普通合集 set 非常相似,是一个没有重复元素的字符串集合\n不同之处在于有序集合中的每一个成员都关联了一个评分,这个评分(score)被用来按照从低到高的方式\n排序集合中的成员,集合的成员是唯一的,但是评分可以是重复的\n数据结构\n数据结构\nSortedSet（**zset**是  Redis  提供的一个非常特别的数据结构，一方面它等价于  Java  的数据结构  Map&lt;String, Double&gt;，可以给每一个元素  value  赋予一个权重  score，另一方面它又类似于  TreeSet，内部的元素会按照权重  score  进行排序，可以得到每个元素的名次，还可以通过  score  的范围来获取元素的列表。\nzset  底层使用了两个数据结构\n(1) hash(存储成员) field value\nmember_name score\n(2)跳跃表(可以快速找到成员),跳跃表的目的在于给元素  value  排序，根据  score  的范围获取元素列表\n\n跳表\nRedis 只有在 Zset 对象的底层实现用到了跳表，跳表的优势是能支持平均 O(logN) 复杂度的节点查找。\nZset 对象是唯一一个同时使用了两个数据结构来实现的 Redis 对象，这两个数据结构一个是跳表，一个是哈希表。这样的好处是既能进行高效的范围查询，也能进行高效单点查询。\ntypedef struct zset &#123;\n    dict *dict;\n    zskiplist *zsl;\n&#125; zset;\nZset 对象能支持范围查询（如 ZRANGEBYSCORE 操作），这是因为它的数据结构设计采用了跳表，而又能以常数复杂度获取元素权重（如 ZSCORE 操作），这是因为它同时采用了哈希表进行索引。\n接下来，详细的说下跳表。\n跳表结构设计\n链表在查找元素的时候，因为需要逐一查找，所以查询效率非常低，时间复杂度是 O(N)，于是就出现了跳表。跳表是在链表基础上改进过来的，实现了一种「多层」的有序链表，这样的好处是能快读定位数据。\n那跳表长什么样呢？我这里举个例子，下图展示了一个层级为 3 的跳表。\n\n图中头节点有 L0~L2 三个头指针，分别指向了不同层级的节点，然后每个层级的节点都通过指针连接起来：\n\n\nL0 层级共有 5 个节点，分别是节点 1、2、3、4、5；\n\n\nL1 层级共有 3 个节点，分别是节点 2、3、5；\n\n\nL2 层级只有 1 个节点，也就是节点 3 。\n\n\n如果我们要在链表中查找节点 4 这个元素，只能从头开始遍历链表，需要查找 4 次，而使用了跳表后，只需要查找 2 次就能定位到节点 4，因为可以在头节点直接从 L2 层级跳到节点 3，然后再往前遍历找到节点 4。\n可以看到，这个查找过程就是在多个层级上跳来跳去，最后定位到元素。当数据量很大时，跳表的查找复杂度就是 O(logN)。\n那跳表节点是怎么实现多层级的呢？这就需要看「跳表节点」的数据结构了，如下：\ntypedef struct zskiplistNode &#123;\n    //Zset 对象的元素值\n    sds ele;\n    //元素权重值\n    double score;\n    //后向指针\n    struct zskiplistNode *backward;\n\n    //节点的level数组，保存每层上的前向指针和跨度\n    struct zskiplistLevel &#123;\n        struct zskiplistNode *forward;\n        unsigned long span;\n    &#125; level[];\n&#125; zskiplistNode;\nZset 对象要同时保存元素和元素的权重，对应到跳表节点结构里就是 sds 类型的 ele 变量和 double 类型的 score 变量。每个跳表节点都有一个后向指针，指向前一个节点，目的是为了方便从跳表的尾节点开始访问节点，这样倒序查找时很方便。\n跳表是一个带有层级关系的链表，而且每一层级可以包含多个节点，每一个节点通过指针连接起来，实现这一特性就是靠跳表节点结构体中的zskiplistLevel 结构体类型的 level 数组。\nlevel 数组中的每一个元素代表跳表的一层，也就是由 zskiplistLevel 结构体表示，比如 leve[0] 就表示第一层，leve[1] 就表示第二层。zskiplistLevel 结构体里定义了「指向下一个跳表节点的指针」和「跨度」，跨度时用来记录两个节点之间的距离。\n比如，下面这张图，展示了各个节点的跨度。\n\n第一眼看到跨度的时候，以为是遍历操作有关，实际上并没有任何关系，遍历操作只需要用前向指针就可以完成了。\n跨度实际上是为了计算这个节点在跳表中的排位。具体怎么做的呢？因为跳表中的节点都是按序排列的，那么计算某个节点排位的时候，从头节点点到该结点的查询路径上，将沿途访问过的所有层的跨度累加起来，得到的结果就是目标节点在跳表中的排位。\n举个例子，查找图中节点 3 在跳表中的排位，从头节点开始查找节点 3，查找的过程只经过了一个层（L3），并且层的跨度是 3，所以节点 3 在跳表中的排位是 3。\n另外，图中的头节点其实也是 zskiplistNode 跳表节点，只不过头节点的后向指针、权重、元素值都会被用到，所以图中省略了这部分。\n问题来了，由谁定义哪个跳表节点是头节点呢？这就介绍「跳表」结构体了，如下所示：\ntypedef struct zskiplist &#123;\n    struct zskiplistNode *header, *tail;\n    unsigned long length;\n    int level;\n&#125; zskiplist;\n跳表结构里包含了：\n\n\n跳表的头尾节点，便于在 O(1)时间复杂度内访问跳表的头节点和尾节点；\n\n\n跳表的长度，便于在 O(1)时间复杂度获取跳表节点的数量；\n\n\n跳表的最大层数，便于在 O(1)时间复杂度获取跳表中层高最大的那个节点的层数量；\n\n\n跳表节点查询过程\n查找一个跳表节点的过程时，跳表会从头节点的最高层开始，逐一遍历每一层。在遍历某一层的跳表节点时，会用跳表节点中的 SDS 类型的元素和元素的权重来进行判断，共有两个判断条件：\n\n\n如果当前节点的权重「小于」要查找的权重时，跳表就会访问该层上的下一个节点。\n\n\n如果当前节点的权重「等于」要查找的权重时，并且当前节点的 SDS 类型数据「小于」要查找的数据时，跳表就会访问该层上的下一个节点。\n\n\n如果上面两个条件都不满足，或者下一个节点为空时，跳表就会使用目前遍历到的节点的 level 数组里的下一层指针，然后沿着下一层指针继续查找，这就相当于跳到了下一层接着查找。\n举个例子，下图有个 3 层级的跳表。\n\n如果要查找「元素：abcd，权重：4」的节点，查找的过程是这样的：\n\n\n先从头节点的最高层开始，L2 指向了「元素：abc，权重：3」节点，这个节点的权重比要查找节点的小，所以要访问该层上的下一个节点；\n\n\n但是该层上的下一个节点是空节点，于是就会跳到「元素：abc，权重：3」节点的下一层去找，也就是 leve[1];\n\n\n「元素：abc，权重：3」节点的 leve[1] 的下一个指针指向了「元素：abcde，权重：4」的节点，然后将其和要查找的节点比较。虽然「元素：abcde，权重：4」的节点的权重和要查找的权重相同，但是当前节点的 SDS 类型数据「大于」要查找的数据，所以会继续跳到「元素：abc，权重：3」节点的下一层去找，也就是 leve[0]；\n\n\n「元素：abc，权重：3」节点的 leve[0] 的下一个指针指向了「元素：abcd，权重：4」的节点，该节点正是要查找的节点，查询结束。\n\n\n跳表节点层数设置\n跳表的相邻两层的节点数量的比例会影响跳表的查询性能。\n举个例子，下图的跳表，第二层的节点数量只有 1 个，而第一层的节点数量有 6 个。\n\n这时，如果想要查询节点 6，那基本就跟链表的查询复杂度一样，就需要在第一层的节点中依次顺序查找，复杂度就是 O(N) 了。所以，为了降低查询复杂度，我们就需要维持相邻层结点数间的关系。\n跳表的相邻两层的节点数量最理想的比例是 2:1，查找复杂度可以降低到 O(logN)。\n下图的跳表就是，相邻两层的节点数量的比例是 2 : 1。\n\n\n\n\n\n\n\n\n\n\n那怎样才能维持相邻两层的节点数量的比例为 2 : 1 呢？\n如果采用新增节点或者删除节点时，来调整跳表节点以维持比例的方法的话，会带来额外的开销。\nRedis 则采用一种巧妙的方法是，跳表在创建节点的时候，随机生成每个节点的层数，并没有严格维持相邻两层的节点数量比例为 2 : 1 的情况。\n具体的做法是，跳表在创建节点时候，会生成范围为[0-1]的一个随机数，如果这个随机数小于 0.25（相当于概率 25%），那么层数就增加 1 层，然后继续生成下一个随机数，直到随机数的结果大于 0.25 结束，最终确定该节点的层数。\n这样的做法，相当于每增加一层的概率不超过 25%，层数越高，概率越低，层高最大限制是 64。\n添加一个或多个成员\nzadd key_name score1 value1 score2 value2 score3 value3... //score(评分)\n输出范围中的值\nzrange key_name start_index end_index [withscores] // 0 -1代表输出所有的值\n//输出下标在start_index和end_index之间的元素,添加withscores则会将评分(score)一起输出\n\nzrangebyscore key_name min_score max_score [withscore] [limit offset count]\n//返回有序集合key中,所有score值介于min和max之间的(包括min或max)成员\n//有序集合按score值从小到大的次序排列\n\nzrevrangescore key_name min_score max_score [withscore] [limit offset count]\n//返回有序集合key中,所有score值介于min和max之间的(包括min或max)成员\n//有序集合按score值大到小 的次序排列\n增加成员的值\nzincrby key_name incre_number member_name\n删除成员\nzrem key_name member_name\n统计评分区间的成员个数\nzcount key_name min_score max_score\n查看成员在集合中的排名\nzrank key_name member_name //返回索引(索引从0开始)\nRedis6 新数据类型\nBitmaps\n\n\n\n将 Bitmaps 数据类型理解为一个数组，每个单位只存储 0 和 1\n实例：\n\n\n\ngetbit ：获取 Bitmaps 中某个偏移量的值\n\n\nbitcount [start end]：统计字符串被设置为 1 的 bit 数，start end 可以指定范围，且可以使用负数值，例如：-1 表示最后一个位，-2 表示倒数第二个位置（从 0 开始…）\n\n\nbitop and(or/not/xor) [key…]：复合操作，可以做多个 Bitmaps 的交集、并集等操作，并将结果保存在 destkey 中\n\n例如：bitop and users:1 users:2 users:3，将 users:2 与 users:3 的交集结果存放到 key 为 users:1 的值中\n\n\n\nBitmaps 与 set 对比\n\n\n\nHyperLogLog\n[\n\n\n\n\npfadd [element…]：添加指定元素到 HyperLogLog 中，执行命令后，若基数发生变化则返回 1，否则返回 0\n\ncount [key…]：计算基数值\n\nmerge [其中，sourcekey 可以为多个]：将多个 HyperLogLog 数据类型进行合并，例子比如将月活跃用户数与日活跃用户数进行合并，就可以使用 pfcount 进行统计基数\n\n\nGeospatial\n[\nRedis 的配置文件\n只支持 bytes 不支持 bit\nNETWORK\n修改配置以网络连接(默认只能本地连接)\nbind 127.0.0.1 -::1 (默认本地连接)\n// 用#号注释掉即可允许远程连接\n\nprotected-mode yes //保护模式(只允许本机连接) 将yes改为no即可支持远程访问\n\nPort\n默认 6379\ntcp-backlog\n默认值 511\nbacklog 其实是一个连接队列,backlog 队列的总和=未完成三次握手队列+已完成三次握手的队列\n高并发环境下需要一个高 backlog 来避免慢客户端的连接问题\ntcp-backlog 511\ntimeout\ntimeout 0 //客户端未操作指定时间后断开连接 默认值为0(永不过期) 单位为秒\ntcp-keepalive\n检测客户端的 tcp 是否活着(操作) 默认每 300 秒检查一次\ntcp-keepalive 300\nGENERAL\n允许后台启动(默认为 no)\ndaemonize yes\nLimits\n设置最大的客户端连接数\nmaxclients 10000 //默认最大连接数10000\n设置最大的内存占用量\nmaxmemory &lt;bytes>   //达到最大的内存占用数后根据maxmemory-policy规则进行操作\n设置最大内存占用规则\nmaxmemory-policy\nRedis 发布和订阅\nRedis  发布订阅（ pub/sub ）是一种消息通信模式：发送者（ pub ）发送消息，订阅者（ sub ）接收消息。\nRedis  客户端可以订阅任意数量的频道。\n\n可以建立许多个频道进行消息的发送（如上图频道 1、频道 2、频道 3），供订阅者进行接收和监听消息。\n\n\n客户端可以订阅频道\n\n\n\n\n\n当给这个频道发布消息后，消息就会发送给订阅的客户端\n\n\n\n发布订阅命令行实现\n\n\n打开一个客户端订阅 channel1\n\n\n\n\nsubscribe channel1\n\n\n\n\n打开另一个客户端，给 channel1 发布消息 hello\n\n\n\n\npublish channel1 hello\n\n\n返回的数字表示：订阅者的数量、\n\n\n\n\n打开第一个客户端可以看到发送的信息\n\n\n\n发布的消息如果没有持久化，那么在订阅的客户端是接收不到消息的，只能收到订阅后发布的消息\n订阅频道\nSUBSCRIBE channel_name //   返回值为订阅人数\n向频道发送信息\npublish channel_name message\nRedis6 新数据类型\nBitmap\nBitmap 本身不是一种数据类型,它实际上就是字符串(key-value)\n但是它可以对字符串进行位操作\n通过 jedis 操作 Redis\n基本操作\n\n\n依赖\n\n\n&lt;dependency>\n  &lt;groupId>redis.clients&lt;/groupId>\n  &lt;artifactId>jedis&lt;/artifactId>\n  &lt;version>3.2.0&lt;/version>\n&lt;/dependency>\n\n\n连接 Redis\n\n\npublic class JedisDemo &#123;\n  public static void main(String[] args) &#123;\n    // 创建Jedis对象\n    Jedis jedis = new Jedis(\"192.168.xx.xxx\", 6379);\n    // 测试，能够连接上的话，ping通，会返回一个值\n    String ping = jedis.ping();\n    System.out.println(\"连接成功：\" + ping);\n    jedis.close();\n  &#125;\n&#125;\n注意：使用 Jedis 进行操作，需要对 Redis 的网络相关配置文件进行修改：\n\n\n**bind：**默认是 bind 绑定本机，不进行修改的情况下，只能接受本机的访问请求，不写的情况下，能够无限制接受任何 ip 地址的访问。\n\n\nprotected-mode：将本机访问保护模式设置为 no\n\n\n如果出现 connet timed out 错误，检查两块，第一是否配置文件进行了修改，第二防火墙是否关闭。\nkey\njedis.set(\"k1\", \"v1\");\n jedis.set(\"k2\", \"v2\");\njedis.set(\"k3\", \"v3\");\n Set&lt;String> keys = jedis.keys(\"*\"); // 返回所有key\nSystem.out.println(keys.size());\nSystem.out.println(key);\n&#125;\nSystem.out.println(jedis.exists(\"k1\")); // 是否存在\nSystem.out.println(jedis.ttl(\"k1\")); // 过期时间\nSystem.out.println(jedis.get(\"k1\")); // 获取key对应value值\nString\njedis.mset(\"str1\",\"v1\",\"str2\",\"v2\",\"str3\",\"v3\");\nSystem.out.println(jedis.mget(\"str1\",\"str2\",\"str3\"));\nList\n// 可以使用lpush或者rpush添加k-v\nList&lt;String> list = jedis.lrange(\"mylist\",0,-1);\nfor (String element : list) &#123;\n\tSystem.out.println(element);\n&#125;\nSet\njedis.sadd(\"orders\", \"order01\");\njedis.sadd(\"orders\", \"order02\");\njedis.sadd(\"orders\", \"order03\");\njedis.sadd(\"orders\", \"order04\");\nSet&lt;String> smembers = jedis.smembers(\"orders\");\nfor (String order : smembers) &#123;\n\tSystem.out.println(order);\n&#125;\njedis.srem(\"orders\", \"order02\");\nHash\njedis.hset(\"hash1\",\"userName\",\"lisi\");\nSystem.out.println(jedis.hget(\"hash1\",\"userName\"));\nMap&lt;String,String> map = new HashMap&lt;String,String>();\nmap.put(\"telphone\",\"13810169999\");\nmap.put(\"address\",\"atguigu\");\nmap.put(\"email\",\"abc@163.com\");\njedis.hmset(\"hash2\",map);\nList&lt;String> result = jedis.hmget(\"hash2\", \"telphone\",\"email\");\nfor (String element : result) &#123;\n\tSystem.out.println(element);\n&#125;\nzset\njedis.zadd(\"zset01\", 100d, \"z3\");\njedis.zadd(\"zset01\", 90d, \"l4\");\njedis.zadd(\"zset01\", 80d, \"w5\");\njedis.zadd(\"zset01\", 70d, \"z6\");\n\nSet&lt;String> zrange = jedis.zrange(\"zset01\", 0, -1);\nfor (String e : zrange) &#123;\n\tSystem.out.println(e);\n&#125;\n模拟验证码发送\n[\npublic class PhoneCode &#123;\n    public static void main(String[] args) &#123;\n        // 模拟验证码发送\n//        verifyCode(\"123456789\");\n        getRedisCode(\"123456789\", \"123456\");\n    &#125;\n\n    // 1. 生成6位数字验证码\n    public static String getCode()&#123;\n        Random random = new Random();\n        String code = \"\";\n        for (int i = 0; i &lt; 6; i++) &#123;\n            int nextInt = random.nextInt(10);\n            code += nextInt;\n        &#125;\n\n        return code;\n    &#125;\n\n    // 2. 每个手机每天只能发送三次验证码请求，验证码放到redis中，并设置过期时间\n    public static void verifyCode(String phone) &#123;\n        // 连接redis\n        Jedis jedis = new Jedis(\"127.0.0.1\", 6379);\n\n        // 拼接key\n        // 手机发送次数的key\n        String countKey = \"VerifyCode-\" + phone + \":count\";\n        // 验证码的key\n        String phoneKey = \"VerifyCode-\" + phone + \":code\";\n\n        // 每个手机每天只能发送三次验证码\n        String count = jedis.get(countKey);\n        if(count == null) &#123;\n            // 之前还没发送过，这次是第一次发送，设置发送次数为1\n            jedis.setex(countKey, 24*60*60, \"1\"); // 设置过期时间为一天\n        &#125; else if (Integer.parseInt(count) &lt; 3) &#123;\n            // 发送次数加1\n            jedis.incr(countKey);\n        &#125; else if (Integer.parseInt(count) >= 3) &#123;\n            // 发送已经有三次了，不能再发送了\n            System.out.println(\"今天发送验证码的次数已经达到三次，无法再发送！\");\n            jedis.close(); // 关闭连接\n\n            return; // 不执行下面的代码\n        &#125;\n\n        // 验证码放到redis中\n        String code1 = getCode();\n        jedis.setex(phoneKey, 120, code1); // 设置验证码的过期时间为两分钟，会进行覆盖\n        jedis.close();\n    &#125;\n\n    // 3. 验证码校验\n    public static void getRedisCode(String phone, String code)&#123;\n        // 连接redis\n        Jedis jedis = new Jedis(\"127.0.0.1\", 6379);\n\n        // 拼接key\n        // 验证码的key\n        String phoneKey = \"VerifyCode-\" + phone + \":code\";\n        // 判断\n        String codePhone = jedis.get(phoneKey);\n        if(codePhone.equals(code)) &#123;\n            System.out.println(\"成功！\");\n        &#125; else &#123;\n            System.out.println(\"失败！\");\n        &#125;\n        jedis.close();\n    &#125;\n&#125;\nJedis 主从复制\nprivate static JedisSentinelPool jedisSentinelPool=null;\n\npublic static  Jedis getJedisFromSentinel()&#123;\n\n  if(jedisSentinelPool==null)&#123;\n    Set&lt;String> sentinelSet=new HashSet&lt;>();\n    sentinelSet.add(\"172.16.88.168:26379\"); // 端口为sentinal\n    JedisPoolConfig jedisPoolConfig =new JedisPoolConfig();\n    jedisPoolConfig.setMaxTotal(10); // 最大可用连接数\n    jedisPoolConfig.setMaxIdle(5); // 最大闲置连接数\n    jedisPoolConfig.setMinIdle(5); // 最小闲置连接数\n    jedisPoolConfig.setBlockWhenExhausted(true); // 连接耗尽是否等待\n    jedisPoolConfig.setMaxWaitMillis(2000); // 等待时间\n    jedisPoolConfig.setTestOnBorrow(true); // 取连接的时候进行测试\n\n    jedisSentinelPool=new JedisSentinelPool(\"mymaster\",sentinelSet,jedisPoolConfig); // 服务主机名\n    return jedisSentinelPool.getResource();\n  &#125;\n  else &#123;\n    return jedisSentinelPool.getResource();\n  &#125;\n&#125;\n集群的 Jedis 开发\n即使连接的不是主机，集群会自动切换主机存储。主机写，从机读。\n无中心化主从集群。无论从哪台主机写的数据，其他主机上都能读到数据。\npublic class JedisClusterTest &#123;\n  public static void main(String[] args) &#123;\n     // 创建对象\n     Set&lt;HostAndPort> set = new HashSet&lt;HostAndPort>();\n     set.add(new HostAndPort(\"172.16.xx.xxx\",6379)); // 任何一个端口\n     JedisCluster jedisCluster = new JedisCluster(set);\n     // 操作\n     jedisCluster.set(\"k1\", \"v1\");\n     System.out.println(jedisCluster.get(\"k1\"));\n     jedisCluster.close();\n  &#125;\n&#125;\nSpringBoot 整合 Redis\n\n\n依赖\n\n\n&lt;!-- redis -->\n&lt;dependency>\n  &lt;groupId>org.springframework.boot&lt;/groupId>\n  &lt;artifactId>spring-boot-starter-data-redis&lt;/artifactId>\n&lt;/dependency>\n\n&lt;!-- 连接池：spring2.X集成redis所需common-pool2-->\n&lt;dependency>\n  &lt;groupId>org.apache.commons&lt;/groupId>\n  &lt;artifactId>commons-pool2&lt;/artifactId>\n  &lt;version>2.6.0&lt;/version>\n&lt;/dependency>\n\n\n配置文件配置 Redis\n\n\n#Redis服务器地址\nspring.redis.host= ip地址\n#Redis服务器连接端口\nspring.redis.port=6379\n#Redis数据库索引（默认为0，一共有16个）\nspring.redis.database= 0\n#连接超时时间（毫秒）\nspring.redis.timeout=1800000\n#连接池最大连接数（使用负值表示没有限制）\nspring.redis.lettuce.pool.max-active=20\n#最大阻塞等待时间(负数表示没限制)\nspring.redis.lettuce.pool.max-wait=-1\n#连接池中的最大空闲连接\nspring.redis.lettuce.pool.max-idle=5\n#连接池中的最小空闲连接\nspring.redis.lettuce.pool.min-idle=0\n\n\nRedis 配置类（需要继承 CachingConfigurerSupport）\n\n\n@EnableCaching\n@Configuration\npublic class RedisConfig extends CachingConfigurerSupport &#123;\n    @Bean\n    public RedisTemplate&lt;String, Object> redisTemplate(RedisConnectionFactory factory) &#123;\n        RedisTemplate&lt;String, Object> template = new RedisTemplate&lt;>();\n        RedisSerializer&lt;String> redisSerializer = new StringRedisSerializer();\n        Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class);\n        ObjectMapper om = new ObjectMapper();\n        om.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY);\n        om.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL);\n        jackson2JsonRedisSerializer.setObjectMapper(om);\n        template.setConnectionFactory(factory);\n\t\t\t\t// key序列化方式\n        template.setKeySerializer(redisSerializer);\n\t\t\t\t// value序列化\n        template.setValueSerializer(jackson2JsonRedisSerializer);\n\t\t\t\t// value hashmap序列化\n        template.setHashValueSerializer(jackson2JsonRedisSerializer);\n        return template;\n    &#125;\n\n    @Bean\n    public CacheManager cacheManager(RedisConnectionFactory factory) &#123;\n        RedisSerializer&lt;String> redisSerializer = new StringRedisSerializer();\n        Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class);\n\t\t\t\t// 解决查询缓存转换异常的问题\n        ObjectMapper om = new ObjectMapper();\n        om.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY);\n        om.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL);\n        jackson2JsonRedisSerializer.setObjectMapper(om);\n\t\t\t\t// 配置序列化（解决乱码的问题）,过期时间600秒\n        RedisCacheConfiguration config =\n          RedisCacheConfiguration.defaultCacheConfig()\n                .entryTtl(Duration.ofSeconds(600))\n      .serializeValuesWith(RedisSerializationContext.SerializationPair.fromSerializer(jackson2JsonRedisSerializer))\n                .disableCachingNullValues();\n        RedisCacheManager cacheManager = RedisCacheManager.builder(factory)\n                .cacheDefaults(config)\n                .build();\n        return cacheManager;\n    &#125;\n&#125;\n\n\n测试\n\n\n\nRedis 中的事务操作\nMulti、Exec、discard\n从输入 Multi 命令开始,输入的命令一次进入命令队列,但不会执行,知道输入 Exec 后,Redis 会将之前的命令队列中的命令依次执行\n组队的时候可以通过 discard 来放弃组队\n--redis客户端\n127.0.0.1:6379> multi\nOK\n127.0.0.1:6379(TX)>set key1 value1\nQUEUED\n127.0.0.1:6379(TX)>set key2 value2\nQUEUED\n127.0.0.1:6379(TX)>exec\n1) OK\n2) OK\n127.0.0.1:6379>\n\n\n127.0.0.1:6379> multi\nOK\n127.0.0.1:6379(TX)>set key1 value1\nQUEUED\n127.0.0.1:6379(TX)>set key2 value2\nQUEUED\n127.0.0.1:6379(TX)>discard\nOK\n127.0.0.1:6379>\n事务的错误处理\n提交错误\n使用 exec 语句提交时,命令队列无法执行\n--redis客户端\n127.0.0.1:6379> multi\nOK\n127.0.0.1:6379(TX)>set key1 value1\nQUEUED\n127.0.0.1:6379(TX)>set key2 //语句有语法错误\n(error) ERR wrong number of arguments for 'set' command\n127.0.0.1:6379(TX)>exec\n(error) EXECABORT Transaction discarded because of previous errors.\n127.0.0.1:6379>\n执行错误\n能正确执行 exec 提交,但是命令队列中错误的语句报错\n--redis客户端\n127.0.0.1:6379> multi\nOK\n127.0.0.1:6379(TX)>set key1 value1\nQUEUED\n127.0.0.1:6379(TX)>incr key1 //此时语句语法正确 但是逻辑不正确\nQUEUED\n127.0.0.1:6379(TX)>set key2 value2\nQUEUED\n127.0.0.1:6379(TX)>exec\n1) OK\n2) (erro)ERR value is not an integer or out of range\n3) OK\n127.0.0.1:6379>\n事务冲突问题\n悲观 🔒\n每次拿数据的时候都认为其他事务会修改数据,所以每次拿数据的时候都会上 🔒\n这样别的事务想拿这个数据就会被 block(阻塞)直到它拿到 🔒\n乐观 🔒\n在数据上添加版本号,当有事务对数据成功进行更新后同步更新版本号,同时间在进行的事务会将开始事务时\n获得的版本号与现在的版本号进行对比,若版本号更新则更新数据后再进行事务的操作\n在执行 multi 之前,先执行 watch 指令 ,可以监视一个(或多个)key,如果在事务执行之前这个(或这些)key 被其他命令所改动\n那么事务将会被打断(返回 nil)\nwatch key1 [key2]\n事务的三特性\n单独隔离操作\n事务中的所有命令都会序列化、按顺序的执行.事务在执行的过程中,不会\n被其他客户端发送来的命令请求所打断\n没有隔离级别\n队列中的命令么有提交之前都不会实际被执行,因为事务提交前任何指令都\n不会被实际执行\n不保证原子性\n事务中有一条命令执行失败,其后命令仍然会被执行,没有回滚\n并发\n测试工具\nab 模拟测试\n安装:\nyum install httpd-tools\n通过浏览器测试\nab -n 1000 -c 100 -p ~/postfile -T application/x-www-form-urlencoded http://192.168.137.1:8080/seckill/doseckil\n//ab -n 1000 -c 100 代表1000个请求中有100个是并发操作\n//-p ~/postfile 代表此目录下的postfile文件\n// -p的意思是提交类型为POST ,-T的意思是 content-type的类型\n//http://192.168.137.1:8080/seckill 本地的cotroller方法的路径\n并发出现的问题\n出现秒杀后商品存量为负值(超买超卖)\n--乐观锁解决\n//监视库存\njedis.watch(kcKey)\n\n//使用事务\nTransaction multi = jedis.multi();\n//组队操作\nmulti.decr(kcKey) //kcKey 库存key\nmulti.sadd(userKey,uid) //秒杀成功的用户uid\n\n并发量太大出现连接超时问题\n--使用jedis连接池解决\n\n\n库存遗留问题(秒杀结束,但是商品未被抢完)\nLUA脚本\n将复杂的或者多步的redis操作,写为一个脚本,一次提交给redis执行,减少反复连接redis的次数,性能\n利用LUA脚本淘汰用户,解决超卖问题\n(实际上是redis利用其单线程的特性,用任务队列的方式解决多任务并发问题)\n\n\nRedis 中的持久化操作\nRedis 会单独创建(fork)一个子进程来进行持久化,会先将数据写入到一个临时文件中\n待持久化过程结束了,再用这个临时文件取替换上次持久化好的文件.整个过程中,主进程\n是不进行任何 IO 操作的,这就确保了极高的性能,如果需要进行大规模数据的恢复,且对数据恢复\n完整性并不是很敏感,那 RDB 方式要比 AOF 方式更加高效.RDB 的缺点是最后一次持久化后\n数据可能会丢失\ndump.rdb\n在 redis.conf 中的配置文件,默认为 dump.rdb\ndbfilename dump.rdb\n在指定目录生成 rdb 文件(默认在启动目录生成文件)\ndir ./\nsave\n表示写操作的次数。\nsave time num //在time时间(秒)内至少有num个key被改变时执行数据持久化操作\n\nredis 无法写入硬盘时停止写入(默认 no)\nstop-writes-on-bgsave-error yes\n对存入到磁盘中的快照是否进行压缩\nrdbcompression yes //使用LZF算法进行压缩 但是会消耗CPU性能\n检查快照完整性\nrdbchecksum yes //开启会有大概10%的数据损耗\nRDB(Redis DataBase)\n在指定时间间隔内将内存中的数据集快照写入磁盘\nAOF(Append only File)\n以日志的形式来记录每个写操作（增量保存），将  Redis  执行过的所有写指令记录下来（读操作不记录）， 只许追加文件但不可以改写文件（可能是使用的 redo 和 undo 日志恢复？）。Redis  启动之初会读取该文件重新构建数据，换言之，如果  Redis  重启就会根据日志文件的内容将写指令从前到后执行一次，以完成数据的恢复工作。\n一种使用追加方式记录数据的方法\n执行流程\n\n\n客户端的请求写命令会被  append  追加到  AOF  缓冲区内；\n\n\nAOF  缓冲区根据  AOF  持久化策略  [always,everysec,no]  将操作  sync  同步到磁盘的  AOF  文件中；\n\n\nAOF  文件大小超过重写策略或手动重写时，会对  AOF  文件  Rewrite  重写，压缩  AOF  文件容量；\n\n\nRedis  服务重启时，会重新  load  加载  AOF  文件中的写操作达到数据恢复的目的。\n\n\nAOF  和  RDB  同时开启时，系统默认读取  AOF  的数据（数据不会存在丢失）\nAOF 开启\nAOF 和 RDB 同时开启后,系统默认取 AOF 数据(数据不会存在丢失)\n在 redis.conf 中修改\nappendonly no // 默认为no 启动为yes\n生成路径\n跟RDB生成路径相同\n异常恢复\n如果遇到 AOF 文件损坏,通过/usr/loacl!/bin/redis-check-aof–fix appendonly.aof 来进行修复\nredis-check-aof --fix appendonly.aof\nAOF 配置\nAOF 同步频率设置\nappendfsync always\n//始终同步,每次Redis的写入都会立刻记入日志;性能较差但是数据完整性较好\n\nappendfsync everysec\n//每秒同步,每秒记入日志一次,如果宕机,本秒的数据可能丢失\nappendfsync no\nredis不主动进行同步,把同步时机交给操作系统\nRewrite 压缩\nAOF 采用文件追加方式,文件会越来越大,为避免出现此种情况,新增了重写机制\n当 AOF 文件超过所设定的阈值时,Redis 就会采用 AOF 文件压缩,只保留可以恢复\n数据的最小指令集.可以使用命令 bgrewriteaof\nauto-aof-rewrite-min-size:设置重写基准值,最小文件为64位.达到这个值后开始重写\n重写后达到前一次重写大小的200%后再次重写\n系统载入或者上次重写完毕时,Redis 会记录此时 AOF 大小,设为 base_size\n如果 Redis 的 AOF 当前大小&gt;= base_size + base_size*100% 且当前大小&gt;=64mb(默认)的情况下,Redis 会对 AOF 进行重写\n持久化操作总结\n官方推荐两个都启用\n如果对数据不敏感,可以单独用 RDB\n不建议单独用 AOF ,因为会出现 bug\n如果只是做纯内存缓存,可以都不用\nRedis 的主从复制\n主服务器进行写操作,从服务器只能进行读操作\n\n\n读写分离,性能拓展\n\n\n容灾的快速恢复\n\n\n\n\n\n当从服务器连接到主服务器后,从服务器向主服务器发送进行数据同步的消息\n\n\n主服务器收到消息后对数据进行持久化操作,生成 rdb 文件,再将 rdb 文件发送给\n从服务器,从服务器拿到 rdb 文件后进行读取\n\n\n每次主服务器进行写操作之后,就会和服务器进行数据同步\n\n\n配置\n查看主机信息\ninfo replication\n在从机上设置主机\nslaveof &lt;主机ip> &lt;主机端口号>\n//从服务器挂掉后重启并不能自动连接之前的主服务器,而是恢复成默认(将自己认为是主服务器),必须重新设置\n//主服务器挂了后重启还是主服务器,他的从服务器仍不会\"篡位\"\n搭建一主两从\n\n\n创建文件目录\n\n\n/opt/etc\n\n\n将  redis.conf  复制到当前目录\n\n\ncp /etc/redis.conf /opt/etc/\n\n\n创建 3 个  redis.conf  配置文件\n\n\nredis6379.conf\nredis6380.conf\nredis6381.conf\n# redis6379.conf\ninclude /opt/etc/redis.conf\npidfile /var/run/redis_6379.pid\nport 6379\ndbfilename dump6379.rdb\n\n# redis6380.conf\ninclude /opt/etc/redis.conf\npidfile /var/run/redis_6380.pid\nport 6380\ndbfilename dump6380.rdb\n\n# redis6381.conf\ninclude /opt/etc/redis.conf\npidfile /var/run/redis_6381.pid\nport 6381\ndbfilename dump6381.rdb\n\n\n启动 3 台  redis  服务器\n\n\n\n\n\n查看主机运行情况\n\n\ninfo replication\n[\n\n\n配从不配主\n在从机中进行设置，成为谁的从机\n\n\nslaveof  &lt;ip> &lt;port>\n# 成为某个实例的从服务器\n\n\n\n\n再次查看主机运行情况\n\n\n\n成功搭建。\n一主二从\n特点：\n\n\n\n\n\n\n\n\n\n主机  6379，从机  6380  和  6381。\n\n\n假设从机  6380  挂掉。（从机挂掉）\n\n当 6380 重启后，6380 不再是 6379 的从机，而是作为新的 master；（从机重启后，不再是某个主机的从机，其自身就是一个主机）\n当再次把 6380 作为 6379 的从机加入后，从机才会把数据从头到尾复制。（从机重启后，需要再输入成为从机的指令）\n\n\n\n假设主机  6379  挂掉。（主机挂掉）\n\n6380 和 6381 仍然是 6379 的从机，不会做任何事；（从机不会改变）\n当 6379 重启后，既然是主服务器。（主机重启后，还是主机）\n\n\n\n主从复制原理\n完整版：\n\n\nslave  启动成功连接到  master  后会发送一个  sync  命令（同步命令）。\n\n\nmaster  接到命令启动后台的存盘进程，对数据进行持久化操作，同时收集所有接收到的用于修改数据集命令，在后台进程执行完毕之后，master  将传送整个数据文件（rdb）到  slave，以完成一次完全同步。\n\n\n当主服务进行写操作后，和从服务器进行数据同步。\n\n\n全量复制：而  slave  服务在接收到数据库文件数据后，将其存盘并加载到内存中。\n\n\n增量复制：master  继续将新的所有收集到的修改命令依次传给  slave，完成同步。\n\n\n只要是重新连接  master，一次完全同步（全量复制）将被自动执行。\n\n\n\n\n\n\n\n\n\n\n\n全量复制：是从机主动去请求主机进行同步操作，是一开始连接的时候\n增量复制：主机进行一次写操作之后，就主动同步从机\n简洁版：\n[\n薪火相传\n\n上一个  slave  可以是下一个  slave  的  master（从机是另一个从机的主机，并由这个担任主机的从机，进行数据同步），slave  同样可以接收其他  **slave**的连接和同步请求，那么该  slave  作为了链条中下一个的  master，可以有效减轻  master  的写压力，去中心化降低风险。\nslaveof &lt;ip> &lt;port>\n\n\n特点与一主二从类似\n\n\n中途变更转向：会清除之前的数据，重新建立拷贝最新的。\n\n\n当某个担任主机的  slave  宕机，其挂在后面的  slave  都没法备份。\n\n即当主机挂掉，从机还是从机，但是无法继续写数据。\n\n\n\n反客为主\n大哥挂了小弟立马上位(主服务器挂了,从服务器变成主服务器)\nslaveof no one  //将从机设置为主机 必须我们在从机手动设置\n哨兵模式(反客为主自动版)\n反客为主自动版,能够后台监控主机是否故障,如果故障了根据投票数自动将从库转换为主库\n规则:\n\n\n优先级:值越小优先级越高\n\n\n偏移量:获得原主机数据最全的\n\n\nrunid:每个 redis 实例启动后都会生成一个随机的 runid\n\n\n--在自定义的/myredis目录下新建sentinel.conf文件,名字绝对不能错\n\n--在文件中配置哨兵,填写内容\nsentinel monitor mymaster 127.0.0.1 6379 1 //  mymaster是为监控对象起的服务器名称,1为至少有多少个哨兵同意迁移的数量\n\n\n\n启动\nredis-sentinel /myredis/sentinel.conf\n\n从服务器的优先级在redis.conf中默认\nslave-priority 100 --值越小优先度越高\n主机挂掉，哨兵监控到之后，会按照选举规则，从 从机 中选举中产生新的主机，原来挂掉的主机会变成新主机的从机。\n\n选举规则\n选择条件依次为：\n\n\n根据优先级别，slave-priority/replica-priority，优先选择优先级靠前的。（越小优先级越高）\n\n\n\n根据偏移量，优先选择偏移量大的。（偏移量是指获得原主机数据最全的）\n\n\n若前两个条件相同，那么选择  runid  最小的，优先选择最小的服务\n\n每个 redis 实例启动后，都会随机生成一个 40 位的 runid\n\n\n\n复制延时\n由于所有的写操作都是先在  master  上操作，然后同步更新到  slave  上，所以从  master  同步到  slave  从机有一定的延迟，当系统很繁忙的时候，延迟问题会更加严重，slave  机器数量的增加也会使这个问题更加严重。\nRedis 集群\n容量不够,redis 如何进行扩容?\n并发操作,redis 如何分摊?\n解决方法:无中心化集群\n代理服务器模式\n\n无中心化集群模式\n\n无中心化集群配置\n//redis.conf中进行配置\n\ncluster-enbled yes --打开集群模式\n\ncluster-config-file nodes-6379.conf --设定节点配置文件名,自定义\n\ncluster-node-timeout 15000 设定节点失联时间,超过该时间(毫秒),集群自动进行主从切换\n合体\n进入 redis 的主目录下的 src 目录\nredis-cli --cluster create --cluster-replicas 1 192.168.11.101:6379 192.168.11.101:6380 192.168.11.101:6381 192.168.11.101:6389 192.168.11.101:6390 192.168.11.101:6391\n\n--replicacs 1 采用最简单的方式配集群,一台主机,一台从机正好三组\n\n\n以集群的方式连接 Redis\nredis-cli -c -p 6379 // -c是以集群的策略连接Redis  -p是连接到6379端口(从服务器)\n这时候在从服务器中执行写操作,Redis集群会自动切换到集群中的写服务器(主服务器 )\n查看集群中的服务器信息\ncluster nodes\n集群如何分配系节点\n一个集群至少要有三个主节点\n选项–cluster-reolicas 1 表示我们希望为集群中的每一个主节点创建一个从节点\n插槽(slot)\n一个 Redis 集群中包含 16384 个插槽,数据库中的每个键都属于这 16384 个插槽的其中一个\n集群使用 CRC16(key)%16384 来计算键 key 属于哪个槽,其中 CRC16(key)语句用于计算键\nkey 的 CRC16 的校验和\n集群中的每个节点负责处理一部分插槽.举个例子,如果一个集群可以有主节点,其中:\n节点 A 负责处理 0 号至 5460 号插槽\n节点 B 负责处理 5461 号至 10922 号插槽\n节点 C 负责处理 10923 号至 16384 号插槽\n在集群中设置多个值\n> mset name lucy age 20 address china\n>(error) CROSSSLOT Keys in request don't hash to the same slot\n> mset name&#123;user&#125; lucy age&#123;user&#125; 20 address(user) china //为这些值设置一个共同的组\n查询集群中的值\ncluster keyslot key_name\n返回值为插槽值\n故障恢复\n//redis.conf\n\ncluster-require-full-coverage yes/no --yes(如果某段插槽的主从服务器全部挂掉,那么整个集群都挂掉)\n\t\t\t\t\t\t\t\t\t --no(如果某一段插槽的主从都挂掉,那么该插槽数据全部不能使用,也无法存储)\n集群的 Jedis 开发\nHostAndPort hostAndPort =  new HostAndPort(\"集群中任意服务器的IP地址\",集群中任意服务器的端口号)\nJedisCluster jediscluster = new Jediscluster(hostAndPort)\njedisCluster.set(\"b1\",\"value1\") //设置值\nString value = jedisCluster.get(\"b1\") //取值\njedisCluster.close()\nRedis 应用问题的解决\n缓存穿透\n\n现象\nkey 对应的数据在数据源并不存在，每次针对此 key 的请求从缓存获取不到，请求都会压到数据源，从而可能压垮数据源。\nredis 查询不到数据库，出现了很多非正常 url 访问。黑客攻击就是通过查询一个不存在的值，缓存里面没有，那么就会查数据库，大量类似的请求发生后，导致数据库崩溃。若黑客利用此漏洞进行攻击可能压垮数据库。\n造成的条件：\n\n\n应用服务器压力变大，访问请求增光\n\n\n*redis* 命中率下降（重点）\n\n\n导致一直访问查询数据库\n\n\n\n\n\n\n\n\n\n\n\n服务器压力变大，请求太多，导致 redis 缓存命中率开始下降，对数据库的访问越来越多，数据库最终承受不住压力，崩溃了。\n如何解决\n\n\n对空值缓存\n如果一个查询返回的数据为空（不管是数据是否不存在），仍然把这个空结果（null）进行缓存，设置空结果的过期时间会很短，最长不超过五分钟。\n\n\n设置可访问的名单（白名单）：\n使用 bitmaps 类型定义一个可以访问的名单，名单 id 作为 bitmaps 的偏移量，每次访问和 bitmap 里面的 id 进行比较，如果访问 id 不在 bitmaps 里面，进行拦截，则不允许访问。\n\n\n采用布隆过滤器\n布隆过滤器（Bloom Filter）是 1970 年由布隆提出的。它实际上是一个很长的二进制向量（位图）和一系列随机映射函数（哈希函数）。（跟 bitmaps 类似，不过效率更高）\n布隆过滤器可以用于检索一个元素是否在一个集合中。它的优点是空间效率和查询时间都远远超过一般的算法，缺点是有一定的误识别率和删除困难，命中率不一定高。\n将所有可能存在的数据哈希到一个足够大的 bitmaps 中，一个一定不存在的数据会被这个 bitmaps 拦截掉，从而避免了对底层存储系统的查询压力。\n\n\n进行实时监控\n当发现 Redis 的命中率开始急速降低，需要排查访问对象和访问的数据，和运维人员配合，可以设置黑名单限制服务。\n\n\n缓存击穿\n\n\n\n\n\n\n\n\n\n\n注意与缓存穿透的区别：\n\n缓存穿透\n\nredis 命中率下降，导致数据库访问量激增\n\n\n缓存击穿\n\nredis 正常访问，但某个热点 key 突然失效，导致瞬间数据库的访问量激增\n\n\n\n现象\nkey 对应的数据存在，但在 redis 中过期，此时若有大量并发请求过来，这些请求发现缓存过期一般都会从后端**DB** 加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端 DB 压垮。\n\n\n数据库访问压力瞬间增大\n\n\nredis 中没有出现大量 key 过期，redis 正常运行（与缓存穿透的区别）\n\n\n某个经常访问的 *key*，即十分热点的 key，不停地被大量访问，当这个 key 过期的瞬间，持续的高并发就击穿了缓存，大量请求数据库，导致数据库奔溃\n\n\n如何解决\n\n\n预先设置热门数据\n在 redis 高峰访问之前，把一些热门数据提前存入到 redis 里面，加大这些热门数据 *key* 的时长。\n\n\n实时调整\n现场监控哪些数据热门，实时调整 key 的过期时长。\n\n\n使用锁\n\n\n缓存雪崩\n\n现象\nkey 对应的数据存在，但在 redis 中过期，此时若有大量并发请求过来，这些请求发现缓存过期后，一般都会从后端 DB 加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端 DB 压垮。\n缓存雪崩与缓存击穿的区别在于这里针对很多 key 缓存，前者则是某一个 key。\n\n\n数据库压力变大\n\n\n极少的时间段，查询大量 *key* 的集中过期情况（大量 key 集中过期，而缓存击穿是热点 key 过期）\n\n\n如何解决\n\n\n构建多级缓存架构\nnginx 缓存 + redis 缓存 + 其他缓存（**ehcache**等）\n\n\n使用锁或队列：\n用加锁或者队列的方式保证来保证不会有大量的线程对数据库一次性进行读写，从而避免失效时大量的并发请求落到底层存储系统上。不适用高并发情况。\n\n\n设置过期标志更新缓存：\n记录缓存数据是否过期（设置提前量），快过期的时候，提前进行一个缓存。如果过期会触发通知另外的线程在后台去更新实际 key 的缓存。\n\n\n将缓存失效时间分散开：\n比如我们可以在原有的失效时间基础上增加一个随机值，比如 1 ～ 5 分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。\n\n\n分布式锁(共享锁)\n基本介绍\n随着业务发展的需要，原单体单机部署的系统被演化成分布式集群系统后，由于分布式系统多线程、多进程并且分布在不同机器上，这将使原单机部署情况下的并发控制锁策略失效，单纯的 Java API 并不能提供分布式锁的能力。为了解决这个问题就需要一种跨 JVM 的互斥机制来控制共享资源的访问，这就是分布式锁要解决的问题。\n分布式锁主流的实现方案：\n\n\n基于数据库实现分布式锁\n\n\n基于缓存（Redis 等）\n\n\n基于 Zookeeper\n\n\n每一种分布式锁解决方案都有各自的优缺点：\n\n\n性能：redis 最高\n\n\n可靠性：zookeeper 最高\n\n\n设置锁以及过期时间\n\n\n设置锁的命令\n\n\nSETNX KEY VALUE  # 设置锁\ndel key   # 删除锁\n\n\n给锁设置过期时间\n\n\nexpire users 30 # 给users上锁30s\n\n\n上锁的同时设置过期时间\nset key value nx ex time # nx 上锁；ex 设置过期时间\n\n\nJava 实现\n\n\n@GetMapping(\"testLock\")\npublic void testLock()&#123;\n    //1获取锁，setne ,顺便设置过期时间\n    Boolean lock = redisTemplate.opsForValue().setIfAbsent(\"lock\", \"111\",3,TimeUnit.SECONDS); // key, value, 过期时间，时间单位\n    //2获取锁成功、查询num的值\n    if(lock)&#123;\n        Object value = redisTemplate.opsForValue().get(\"num\");\n        //2.1判断num为空return\n        if(StringUtils.isEmpty(value))&#123;\n            return;\n        &#125;\n        //2.2有值就转成成int\n        int num = Integer.parseInt(value+\"\");\n        //2.3把redis的num加1\n        redisTemplate.opsForValue().set(\"num\", ++num);\n        //2.4释放锁，del\n        redisTemplate.delete(\"lock\");\n\n    &#125;else&#123;\n        //3获取锁失败、每隔0.1秒再获取\n        try &#123;\n            Thread.sleep(100); // 休眠，等一会\n            testLock(); // 再去尝试获取锁\n        &#125; catch (InterruptedException e) &#123;\n            e.printStackTrace();\n        &#125;\n    &#125;\n&#125;\n分布式锁产生的问题\n使用 UUID 防止误删锁\n\n现象\na 先上锁后，在执行操作的过程中，服务器卡顿，而 10 秒过期后，b 抢到锁进行具体操作，然而此时 a 的服务器恢复正常，a 继续执行操作并结束，此时有一个释放锁的操作，那么此时释放的锁是 b 的锁，这就是导致误删除锁的现象发生。\n解决方案\n\n现修改版：\n@GetMapping(\"testLock\")\npublic void testLock()&#123;\n    // 设置UUID\n\tString uuid = UUID.randomUUID().toString();\n    .....\n    if(lock)&#123;\n       ...\n        // 判断UUID值是否一样\n        String lockUuid = (String)redisTemplate.opsForValue().get(\"lock\");\n        if(uuid.equals(lockUuid))&#123; // UUID一样时，才释放锁\n             //2.4释放锁，del\n        \tredisTemplate.delete(\"lock\");\n        &#125;\n    &#125;else&#123;\n       ...\n    &#125;\n&#125;\nLua 保证删除原子性\n问题：删除操作缺乏原子性，即 uuid 的比较操作和删除操作不是原子操作\n\n现修改：\n@GetMapping(\"testLockLua\")\npublic void testLockLua() &#123;\n    //1 声明一个uuid ,将做为一个value 放入我们的key所对应的值中\n    String uuid = UUID.randomUUID().toString();\n\n    //2 定义一个锁：lua 脚本可以使用同一把锁，来实现删除！\n    String skuId = \"25\"; // 访问skuId 为25号的商品 100008348542\n    String locKey = \"lock:\" + skuId; // 锁住的是每个商品的数据\n\n    // 3 获取锁\n    Boolean lock = redisTemplate.opsForValue().setIfAbsent(locKey, uuid, 3, TimeUnit.SECONDS);\n\n    // 第一种： lock 与过期时间中间不写任何的代码。\n    // redisTemplate.expire(\"lock\",10, TimeUnit.SECONDS);//设置过期时间\n    // 如果true\n    if (lock) &#123;\n        // 执行的业务逻辑开始\n        // 获取缓存中的num 数据\n        Object value = redisTemplate.opsForValue().get(\"num\");\n        // 如果是空直接返回\n        if (StringUtils.isEmpty(value)) &#123;\n            return;\n        &#125;\n        // 不是空 如果说在这出现了异常！ 那么delete 就删除失败！ 也就是说锁永远存在！\n        int num = Integer.parseInt(value + \"\");\n        // 使num 每次+1 放入缓存\n        redisTemplate.opsForValue().set(\"num\", String.valueOf(++num));\n\n        /*使用lua脚本来锁*/\n\n        // 定义lua 脚本\n        String script = \"if redis.call('get', KEYS[1]) == ARGV[1] then return redis.call('del', KEYS[1]) else return 0 end\";\n\n        // 使用redis执行lua执行\n        DefaultRedisScript&lt;Long> redisScript = new DefaultRedisScript&lt;>();\n        redisScript.setScriptText(script);\n        // 设置一下返回值类型 为Long\n        // 因为删除判断的时候，返回的0,给其封装为数据类型。如果不封装那么默认返回String 类型，\n        // 那么返回字符串与0 会有发生错误。\n        redisScript.setResultType(Long.class);\n        // 第一个要是script 脚本 ，第二个需要判断的key，第三个就是key所对应的值。\n        redisTemplate.execute(redisScript, Arrays.asList(locKey), uuid);\n\n    &#125; else &#123;\n        .....\n    &#125;\n&#125;\n总结\n为了确保分布式锁可用，我们至少要确保锁的实现同时满足以下四个条件：\n\n\n互斥性。在任意时刻，只有一个客户端能持有锁。\n\n\n不会发生死锁。即使有一个客户端在持有锁的期间崩溃而没有主动解锁，也能保证后续其他客户端能加锁。\n\n\n解铃还须系铃人。加锁和解锁必须是同一个客户端，客户端自己不能把别人加的锁给解了。\n\n\n加锁和解锁必须具有原子性。\n\n\nRedis6 的新功能\nACL(访问控制列表)\n将用户的权限进行更细粒度的权限控制\n(1),接入权限:用户名,密码\n(2)用户可执行的命令\n(3)用户可以操作的 key\n命令\nacl list &#x2F;&#x2F;展现当前所有用户的信息\nacl cat  &#x2F;&#x2F;查看具体操作的指令列表\nacl setuser user_name &#x2F;&#x2F;添加用户以及权限\nacl whoami &#x2F;&#x2F;查看当前用户名\n模拟秒杀\n基本实现\n核心的逻辑代码：\npublic class SecKill_redis &#123;\n\n    public static void main(String[] args) &#123;\n        Jedis jedis =new Jedis(\"192.168.242.110\",6379);\n        System.out.println(jedis.ping());\n        jedis.close();\n    &#125;\n\n    //秒杀过程\n    public static boolean doSecKill(String uid,String prodid) throws IOException &#123;\n        //1 uid和prodid非空判断\n        if(uid == null || prodid == null)&#123;\n            return false;\n        &#125;\n\n        //2 连接redis\n        Jedis jedis =new Jedis(\"192.168.xx.xxx\",6379);\n\n        //3 拼接key\n        // 3.1 库存key\n        String kcKey = \"sk:\"+prodid+\":qt\";\n        // 3.2 秒杀成功用户key\n        String userKey = \"sk:\"+prodid+\":user\";\n\n        //4 获取库存，如果库存null，秒杀还没有开始\n        String kc = jedis.get(kcKey);\n        if(kc == null)&#123;\n            System.out.println(\"秒杀还没开始，请稍等\");\n            jedis.close();\n            return false;\n        &#125;\n\n        // 5 判断用户是否重复秒杀操作\n        if(jedis.sismember(userKey, uid))&#123;\n            System.out.println(\"每个用户只能秒杀成功一次，请下次再来\");\n            jedis.close();\n            return false;\n        &#125;\n\n        //6 判断如果商品数量，库存数量小于1，秒杀结束\n        if(Integer.parseInt(kc) &lt; 1)&#123;\n            System.out.println(\"秒杀结束，请下次参与\");\n            jedis.close();\n            return false;\n        &#125;\n\n        //7 秒杀过程\n        //7.1库存-1\n        jedis.decr(kcKey);\n        //7.2 把秒杀成功的用户添加到清单里面\n        jedis.sadd(userKey,uid);\n        System.out.println(\"用户\" + uid + \"秒杀成功\");\n        jedis.close();\n        return true;\n    &#125;\n&#125;\n使用 ab 工具模拟并发以及暴露出的问题\n\n\n\n\n\n\n\n\n\nCentOS 6 默认安装\nCentOS 7 手动安装（yum -y install httpd-tools）\n\n\n通过 ab 命令发送并发操作\nab -n 2000 -c 200 -k -p ~/postfile -T application/x-www-form-urlencoded http://192.168.0.43:8080/Seckill/doseckill\n-n：测试会话中所执行的请求个数\n-c：一次产生的请求个数\n\n\n并发暴露出来的问题\n\n\n会出现超卖问题：卖完了商品，但还存在继续购买，即库存变为负数\n\n\n\n解决方案：使用乐观锁，进行版本控制**（redis 事务+watch）**\n\n代码修改：\n//秒杀过程\npublic static boolean doSecKill(String uid,String prodid) throws IOException &#123;\n    //1 uid和prodid非空判断\n    if(uid == null || prodid == null)&#123;\n        return false;\n    &#125;\n    \n    //2 连接redis\n    //Jedis jedis =new Jedis(\"192.168.xx.xxx\",6379);\n    \n    //通过连接池获取连接redis的对象\n    JedisPool jedisPoolInstance = JedisPoolUtil.getJedisPoolInstance();\n    Jedis jedis = jedisPoolInstance.getResource();\n    \n    //3 拼接key\n    // 3.1 库存key\n    String kcKey = \"sk:\"+prodid+\":qt\";\n    // 3.2 秒杀成功用户key\n    String userKey = \"sk:\"+prodid+\":user\";\n    \n    //监视库存\n    jedis.watch(kcKey);\n    \n    //4 获取库存，如果库存null，秒杀还没有开始\n    String kc = jedis.get(kcKey);\n    if(kc == null)&#123;\n        System.out.println(\"秒杀还没开始，请稍等\");\n        jedis.close();\n        return false;\n    &#125;\n    \n    // 5 判断用户是否重复秒杀操作\n    if(jedis.sismember(userKey, uid))&#123;\n        System.out.println(\"每个用户只能秒杀成功一次，请下次再来\");\n        jedis.close();\n        return false;\n    &#125;\n    \n    //6 判断如果商品数量，库存数量小于1，秒杀结束\n    if(Integer.parseInt(kc) &lt; 1)&#123;\n        System.out.println(\"秒杀结束，请下次参与\");\n        jedis.close();\n        return false;\n    &#125;\n    \n    //7 秒杀过程\n    //使用事务\n    Transaction multi = jedis.multi();\n    \n    //组队操作\n    multi.decr(kcKey);\n    multi.sadd(userKey,uid);\n    \n    //执行\n    List&lt;Object> results = multi.exec();\n    \n    if(results == null || results.size()==0) &#123;\n        System.out.println(\"秒杀失败了....\");\n        jedis.close();\n        return false;\n    &#125;\n    \n    //\t\t//7.1库存-1\n    //\t\tjedis.decr(kcKey);\n    //        //7.2 把秒杀成功的用户添加到清单里面\n    //        jedis.sadd(userKey,uid);\n    System.out.println(\"用户\" + uid + \"秒杀成功\");\n    jedis.close();\n    return true;\n&#125;\n\n\n\n\n连接超时问题\n\n解决方案：采用连接池\n\n// 创建工具类\npublic class JedisPoolUtil &#123;\n    private static volatile JedisPool jedisPool = null;\n\n    private JedisPoolUtil() &#123;\n    &#125;\n\n    public static JedisPool getJedisPoolInstance() &#123;\n        if (null == jedisPool) &#123;\n            synchronized (JedisPoolUtil.class) &#123;\n                if (null == jedisPool) &#123;\n                    JedisPoolConfig poolConfig = new JedisPoolConfig();\n                    poolConfig.setMaxTotal(200);\n                    poolConfig.setMaxIdle(32);\n                    poolConfig.setMaxWaitMillis(100*1000);\n                    poolConfig.setBlockWhenExhausted(true);\n                    poolConfig.setTestOnBorrow(true);  // ping  PONG\n\n                    jedisPool = new JedisPool(poolConfig, \"192.168.xx.xxx\", 6379, 60000 );\n                &#125;\n            &#125;\n        &#125;\n        return jedisPool;\n    &#125;\n\n    public static void release(JedisPool jedisPool, Jedis jedis) &#123;\n        if (null != jedis) &#123;\n            jedisPool.returnResource(jedis);\n        &#125;\n    &#125;\n&#125;\n修改代码，主要是针对前面基本实现中的核心代码，对获取 redis 对象进行修改：\n//2 连接redis\n//Jedis jedis =new Jedis(\"192.168.xx.xxx\",6379);\n\n//通过连接池获取连接redis的对象\nJedisPool jedisPoolInstance = JedisPoolUtil.getJedisPoolInstance();\nJedis jedis = jedisPoolInstance.getResource();\n\n\n商品遗留问题，即秒杀已经结束了，却还有商品库存\n\n解决方案：使用 Lua 脚本\n\n\n\n\n\n\n\n\n\n\nLua 是一个小巧的脚本语言，Lua 脚本可以很容易的被 C/C++ 代码调用，也可以反过来调用 C/C++的函数，Lua 并没有提供强大的库，一个完整的 Lua 解释器不过 200k，所以 Lua 不适合作为开发独立应用程序的语言，而是作为嵌入式脚本语言。很多应用程序、游戏使用 LUA 作为自己的嵌入式脚本语言，以此来实现可配置性、可扩展性。\n将复杂的或者多步的 redis 操作，写为一个脚本，一次提交给 redis 执行，减少反复连接 redis 的次数。提升性能。\nLua 脚本是类似 redis 事务，有一定的原子性，不会被其他命令插队，可以完成一些 redis 事务性的操作。\n但是注意 redis 的 lua 脚本功能，只有在 Redis 2.6 以上的版本才可以使用。\n利用 Lua 脚本淘汰用户，解决超卖问题。\nredis 2.6 版本以后，通过 lua 脚本解决争抢问题，实际上是 redis 利用其单线程的特性，用任务队列的方式解决多任务并发问题。\n\n\n\n\n\n","slug":"Redis6.0学习笔记","date":"2023-07-19T11:54:00.000Z","categories_index":"NoSQL","tags_index":"Redis","author_index":"ND_LJQ"},{"id":"241e4fb174a989083556866451d735d1","title":"Linux基本操作","content":"Linux 简介\nLinux 系统的起源与发展\nLinux 是一种免费使用和自由传播的类 UNIX 操作系统,是一个基于 POSIX 的多用户、多任务、支持多线程和多 CPU 的操作系统。它能运行主要的 Unix 工具软件、应用程序和网络协议。它支持 32 位和 64 位硬件。Linux 继承了 Unix 以网络为核心 的设计思想，是一个性能稳定的多用户网络操作系统。并且 Linux 是一款自由软件，可以完全免费自由地提供给用户使用。\nLinux 系统的介绍\nLinux 系统的特点\n基本思想\n① 一切都是文件 :系统中的所有都归结为一个文件，包括命令、硬件和软件设备、操作系统、进程 等等对于操作系统内核而言，都被视为拥有各自特性或类型的文件。\n② 每个文件都有确定的用途\n特点\n① 开放系统 : Linux 系统遵循[[计算机网络基础#OSI与TCP/IP模型|开放式系统互联通信参考模型（Open System Interconnection Reference Model，缩写为 OSI）]]\n② 完全开源免费\n③ 多用户、多用户 : 多用户是指系统资源可以被不同用户同各自拥有，即每个用户对自己的资源（文件、设备） 有特定的权限，并且互不影响。\n④ 出色的稳定性和速度性能 : Linux 可以连续运行很长时间而不需要重启（Linux 的主要使用场景是作为服务器，服务器是很 大重启或者关机的）\n⑥ 安全可靠的系统 : Linux 采取了许多安全技术措施，可以在网络及多用户的情况下提供：包括对读/写文件系统进 行权限的限制、核心程序、关键操作的授权等。再有由于 Linux 是开源免费的（不像 Winidows），在敏感行业（政府、军工）可以避免后门漏洞造成的系统安全问题。\n⑦ **提供丰富的网络功能 **: Linux 的设计初衷就是基于网络，所以 Linux 系统中有完善的内置网络服务，比如： DNS,DHCP,Samba 等，完善的网络服务也是 Linux 由于其它操作系统的一个原因\n⑧ 支持多种平台 : Linux 可以运行在多种硬件平台上，如具有 x86、ARM、SPARC 等处理器的平台架构。此外 Linux 还是一种嵌入式操作系统，可以运行在掌上电脑、手机、机顶盒或游戏机上。\n⑨ 良好的界面 : Linux 同时具有字符界面和图形界面。在字符界面用户可以通过键盘输入相应的指令来进行操 作。它同时也提供了类似 Windows 图形界面的 X-Window 系统\nLinux 系统的组成\nLinux 系统一般有 4 个主要部分：内核、shell、文件系统和应用程序，如下图所示（最内层是各种硬件设备）。\n\n内核\n内核(Kernel)是操作系统的核心，具有很多最基本功能，它负责管理系统的进程、内存、设备 驱动程序、文件和网络系统，决定着系统的性能和稳定性。内核从应用层接受命令，根据调度算 法调度相关进程使用系统资源，使得程序能够顺利的运行。\nLinux 内核由如下几部分组成：内存管理、进程管理、设备驱动程序、文件系统和网络管理等。\nshell\nshell 是一种命令解释器，提供了用户与内核进行交互操作的一种接口。它接收用户输入的命令 并把它送入内核去执行，并且将执行的结果返回个给用户。shell 还有自己的编程语言，运行用户 编写由 shell 命令组成的程序。\nshell 有多个版本，目前主流的 shell 版本有四个：\n\n\n\n名称\n描述\n\n\n\n\nBASH\nbash 是 BourneAgain Shell 的缩写，bash 是 Linux 标准默认的 shell。它基于 Bourne shell，吸收了 C shell 和 Korn shell 的一些特性。bash 完全兼容 Bourne shell。\n\n\nBourne Shell\n一般缩写成 sh，由贝尔实验室开发，是 Unix 标准默认的 shell。\n\n\nKorn Shell\nKorn shell 缩写 ksh，其特点是兼容性好。\n\n\nC Shell\nSun 公司 Shell 的 BSD 版本。\n\n\n\nshell 是用户与 Linux 操作系统之间的沟通的桥梁，在使用 shell 命令之前了解一下 Shell 命令的格式：\n命令名称 [选项] [参数1] [参数2]...\n命令名：需要提交给系统执行的命令，这些命令是个可执行文件或 She 脚本文件。\n选项：是对命令的特别定义，以短线(-) 开始。在 Linux 中，如果一个命令有多个选项可以使用一 个短线 (-)将所有选项连接起来，也可分开输入。同一个命令可以通过不同的选项来实现不同的功 能。\n参数：是提供给命令运行的信息或命令执行过程中所使用的文件名。 一个简单的 Shell 命令可以只有命令名，复杂一些的可以通过不同的选项和参数来实现命令、选项以及参数之间通过空格键来分隔。如果有多条命令要执行，可将这些令输入在一行中， 各命令 之间用分号(😉 进行分隔。命令的执行顺序与输入的顺序相同。\n文件系统:文件系统是文件存放在磁盘等存储设备上的存储规则，系统只有规定了文件系统，也就是文件数据的存储组织方式，数据的读/写才能正常进行。目前 Linux 支持多种文件系统，如 EXT2、 EXT3、 XFS、FAT、 VFAT 和 MFS 等。\n应用程序:标准的 Linux 系统除了系统核心外，一般都有一套都有称为应用程序的程序集，以方便用户的 使用。它包括文本编辑器（vi）、编程语言、XWindow、办公套件、Internet 工具和数据库等。\nLinux 的基本操作\n文件系统\nxfs #centOs7 默认的文件系统 高性能日志文件系统\next2 #linux自带的文件系统类型\next3 #是在ext2的基础之上发展演变而来的，二者区别在于ext3文件系统带有日志功能，它会跟踪对于磁盘的写入操作并记录于日志，这样可以在需要时回溯查找。\nswap #文件系统在 Linux中作为交换分区的文件系统使用。交换分区是在硬盘上分配出来的一块存储空间，用来弥补物理内存空间的不足。交换空间由操作系统自动管理。因为Linux系统有提前读和延后写的操作机制，所以在安装Linux系统的过程中，交换分区是必须被分配的，其文件系统类型是swap。\n\n各个系统文件夹的意义\n\n\n\n\n目录\n说明\n\n\n\n\n/\n根目录\n\n\n/boot\n引导程序，内核等存放的目录\n\n\n/sbin\n超级用户可以使用的命令的存放目录 --软链接(快捷方式) 真实路径是/usr/sbin\n\n\n/selinux\n这个目录是 Redhat/CentOS 所特有的目录，Selinux 是一个安全机制，类 似于 windows 的防火墙，但是这套机制比较复杂，这个目录就是存放 selinux 相关的文件的。\n\n\n/srv\n该目录存放一些服务启动之后需要提取的数据。\n\n\n/bin\n普通用户可以使用的命令的存放目录 --软链接(快捷方式) 真实路径是/usr/bin\n\n\n/lib\n根目录下的所程序的共享库目录\n\n\n/dev\n设备文件目录 在 linux 系统中设备是以文件的形式存在,通过访问设备文件(设备驱动)则可以访问到设备\n\n\n/home\n普通用户的家目录\n\n\n/root\n用户 root 的$HOME 目录\n\n\n/etc\n全局的配置文件存放目录。 --系统和程序一般都可以通过修改相应的配置文件，来进行配置\n\n\n/usr\n这个目录中包含了命令库文件和在通常操作中不会修改的文件。 --安装程序时默认安装到此目录下的某个子目录 (相当于 window 中软件默认安装到 Program Files 文件夹中) /usr/local 程序默认安装位置 /usr/sbin 超级用户使用的比较高级的管理程序和系统守护程序。 /usr/src 内核源代码默认的放置目录。\n\n\n/opt\n可择的文件目录这个目录表示的是可择的意思，些自定义软件包或者第三方工具，就可以安装在这里。(比如自己编的程序可以安装到这里)\n\n\n/mnt\n临时挂载目录这个目录一般是用于存放挂载储存设备的挂载目录的，比如磁盘，光驱，网络文件系统等，当我们需要挂载某个磁盘设备的时候，可以把磁盘设备挂载到这个目录上去\n\n\n/media\n挂载的媒体设备目录例如 u 盘\n\n\n/tmp\n临时文件目录该目录存放系统中的一些临时文件，文件可能会被系统自动清空。\n\n\n/proc\nprocess(进程)的缩写\n\n\n/var\nvar 是 variable(变量) 的缩写，用于存放运行时需要改变数据的文件，我们习惯将那些经常被修改的目录放在这个目录下。包括各种日志文件。\n\n\n/run\n是一个临时文件系统，存储系统启动以来的信息。当系统重启时,这个目录下的文件应该被删掉或清除。如果你的系统上有 /var/run 目录，应该让 它指向 run。\n\n\n\n特殊目录\n\n\n\n符号\n说明\n\n\n\n\n.\n当前目录\n\n\n…\n上一级目录\n\n\n~\n用户的主目录\n\n\n-\n前一个工作目录\n\n\n\n# 当前目录\ncd .\n# 上一级目录\ncd ..\n# 去用户的主目录\ncd ~\n# 去上一次目录\ncd -\n文件的命名\nLinux 支持长文件名，最长可以达到256字节。Linux 的文件名中不能含有空格和以下特殊字符：\n! @ # ￥ % ~ &amp; × () [] &#123;&#125; ' \" \\ / | ; &lt; > &lt;&lt; >>\n文件介绍之后进行,先进行系统基础命令的学习\n系统基础命令\n查看/修改当前时间\ndate [-options] [mm/dd/yy] [hh:mm:ss]\n\noptions:\n\td : 设置年月日\n\ts : 设置时分秒\n\n\t#设置月日年\n\tdate -d 02/28/21\n\n\t#设置时分秒\n\tdate -s 23:45:00\n\n查看命令类型\ntype 命令名称\n\n[nd_ljq@ROOT ~]$ type ifconfig\nifconfig is /usr/sbin/ifconfig\n[nd_ljq@ROOT ~]$ type type\ntype is a shell builtin\n\nps:若响应为路径则代表这条命令是`外部命令`\n   若响应为`xxx is a shell builtin`则代表这条命令是`内核命令`\n查看命令帮助文档\nhelp [options] 命令名称\n\nhelp type\nhelp cd\n\nps:该命令只能用来查询linux`内部命令`的帮助文档\nman [options] 命令名称\n\nman ssh\n\nps: man（manual：手册），“Linux System Administrator's Manual”，命令可以快速查询Linux\n命令（内核命令/外部命令）的详细描述和使用方法。\n查看系统基础信息\nuname [options] [--help][--version]\n\noptions:\n\t-a 或--all 　显示全部的信息，包括内核名称、主机名、操作系统版本、处理器类型和硬件架构等。\n\t-m 或--machine 　显示处理器类型。\n\t-n 或--nodename 　显示主机名。\n\t-r 或--release 　显示内核版本号。\n\t-s 或--sysname 　显示操作系统名称。\n\t-v 　显示操作系统的版本。\n\t--help 　显示帮助。\n\t--version 　显示版本信息。\n\t-p 显示处理器类型（与 -m 选项相同）。\n查看历史输入\nhistory num\n\nps: num为选取最近的n条指令打印\n注销用户\nlogout\nexit\n重启与关机\nshutdown [-t seconds] [option] time [message]\n\n-t seconds : 设定在几秒钟之后进行关机程序。\n-k : 并不会真的关机，只是将警告讯息传送给所有使用者。\n-r : (reboot)关机后重新开机。\n-h : (halt)关机后停机。\n-n : 不采用正常程序来关机，用强迫的方式杀掉所有执行中的程序后自行关机。\n-c : 取消目前已经进行中的关机动作。\ntime : 设定关机的时间。\nmessage : 传送给所有使用者的警告讯息。\n\nshutdown -k 5 \"system will be reboot! \"\n!号后要有空格\n\npoweroff 关机\n\nreboot 重启\n\n组/用户的操作\n\n\n\n\n\n\n\n\n\n对用户组的操作,实质性是对/etc/group 文件和/etc/gshadow 文件的操作\n创建组\ngroupadd [-g gid] groupName\n\nps: -g 为指定组的id\n删除组\ngroupdel goupName\n\nps:删除组的前提是这个组为空\n\n\n\n\n\n\n\n\n\n对用户的操作,实质上是对/etc/passwd 文件的操作\n用户的密码是经过加密后存储在 /etc/shadow 文件中\n查看所有用户可以查看/etc/passwd 文件中的记录数\n查看组(组数)可以查看/etc/group 文件中的记录数\n/etc/passwd 中\n每一行有七个字段组成，之间用&quot;:&quot;分隔，各个字段的顺序和含义如下：\nLOGNAME:PASSWORD:UID:GID:USERINFO:HOME:SHELL\n创建用户\nuseradd [options] userName\n\noptions:\n\t-e:有效期\n\t-f:缓冲天数\n\t-g:用户所属群\n\t-s:指定用户的shell 若未指定centos7会给其默认分配一个shell 为 /bin/bash\n\t /bin/sh\n\t /bin/ksshell\n\t /bin/bash ...\n\n\t-d:用户的工作目录(家目录)\n\t-u:指定用户id\n\n\n例子:\n\t1.创建一个不能登录的的用户\n\t\tuseradd -s /sbin/nologin(更优,后面会提及)\n\n\t\tuseradd -s /bin/false\n\n\n\n\n字段\n说明\n\n\n\n\nLOGNAME\n用户名：用于区分不同的用户。在同一系统中注册名是惟一的。注意！通常 在 Linux 系统中对字母大小写是敏感的。\n\n\nPASSWORD\n口令：用户的口令，注意用户的密码系统会加密存储在/etc/shadow 下，所以这里只显示一个 x 字符。\n\n\nUID\nUID：用户的 ID，是 Linux 系统中惟一的用户标识，用于区别不同的用户。 这个 ID 可以创建用户的时候指定，或者由系统自动分配。\n\n\nGID\nGID：用户所属的组 ID，用户的组存放在/etc/group 文件中。\n\n\nUSERINFO\n用户信息：包含有关用户的一些信息。\n\n\nHOME\n用户主目录：该字段定义了用户的主目录，当用户登录后，他的 Shell 将把 该目录作为用户的工作目录。 在 Linux 系统中，root 的工作目录为/root； 而其它个人用户在的默认主目录在/home/用户名的目录，或者也可以创建 用户的时候指定。\n\n\nSHELL\nShell：用户的 shell，比如：bash、sh、csh、ksh 等。\n\n\n\n删除用户\nuserdel [option] userName\n\n  option:\n    -r: 删除用户登录目录以及目录中的所有文件\n查看当前用户 ID\nid\n修改用户密码\npasswd [options] userName\n\noptions:\n\t-d 删除密码\n\t-w 口令要到期提前警告的天数\n\t-k 更新只能发送在过期之后\n\t-l (lock)停止账号使用\n\t-S 显示密码信息\n\t-u (unlock)启用已被停止的账户\n\t-x 指定口令最长存活期\n\t-g 修改群组密码\n\t-n 指定口令最短存活期\n\t-i 口令过期后多少天停用账户\n修改用户信息\nusermod [options] userName\n\noptions:\n\t-d &lt;登入目录> 　修改用户登入时的目录。\n\t-e &lt;有效期限> 　修改帐号的有效期限。\n\t-f &lt;缓冲天数> 　修改在密码过期后多少天即关闭该帐号。\n\t-g &lt;群组> 　修改用户所属的群组。\n\t-l &lt;帐号名称> 　修改用户帐号名称。\n\t-L 锁定用户密码，使密码无效。\n\t-s 修改用户登入后所使用的shell。\n\t-u 修改用户ID。\n\t-U 解除密码锁定。\n\n\t查看用户信息:\n\tcat /etc/passwd | grep userName\n切换用户\nsu（英文全拼：switch user）命令用于变更为其他使用者的身份。同时使用 whoami 命令查看当前用户。\nsu 命令语法：\nsu [-] userName\n\n#切换到root用户\nsu\nsu -\nsu root\n\n\n\n\n\n\n\n\n\nsu 命令用户切换登录用户的命令。注意：普通用户切 root 是需要 root 密码的，但是 root 切普通 用户不要密码，并且英文安全考虑，输入的密码是不回显的。\n系统高级应用与设置\n系统性能分析\nuptime\nuptime 命令可以用来查看服务器已经运行了多久，依次显示：现在时间，系统运行了多久，\n当前登录的用户有多少，以及服务器在过去的1分钟、5分钟、15分钟的系统平均负载值。\nfree\nfree 命令会显示内存的使用情况，包括实体内存，虚拟的交换文件内存，共享内存区段，以及 系统核心使用的缓冲区等。\nfree [-options] [-s &lt;间隔秒数>]\n\n options:\n\t-b:以Byte为单位显示内存使用情况。\n\t-k:以KB为单位显示内存使用情况。\n\t-m:以MB为单位显示内存使用情况。\n\t-h:以人可视化的单位显示内存使用情况。\n\n\t-s &lt;间隔秒数>:每隔n秒刷新一次\n结果说明：\n\n\ntotal: 内存总数。\n\n\nused: 已经使用内存数。\n\n\nfree: 完全空闲内存。\n\n\nshared: 多个进程共享的内存。\n\n\nbuffers: 用于块设备数据缓冲，记录文件系统 metadata（目录，权限，属性等)。\n\n\ncached: 用于文件内容的缓冲。\n\n\navailable：真正剩余的可被程序应用的内存数。\n\n\ntop 指令\n相当于 windows 中的任务管理器\n\n第一行，任务队列信息，同 uptime 命令的执行结果\n第一行，任务队列信息，同 uptime 命令的执行结果\n系统时间：11:08:47\n\n运行时间：up 36 min,\n\n当前登录用户：  1 user\n\n负载均衡(uptime)  load average: 0.32, 0.26, 0.20\n\naverage后面的三个数分别是1分钟、5分钟、15分钟的负载情况。\n\nload average数据是每隔5秒钟检查一次活跃的进程数，然后按特定算法计算出的数值。如果这个数除以逻辑CPU的数量，结果高于5的时候就表明系统在超负荷运转了\n第二行，Tasks — 任务（进程）\n总进程:150 total, 运行:1 running, 休眠:149 sleeping, 停止: 0 stopped, 僵尸进程: 0 zombie\n第三行，cpu 状态信息\n0.0%us【user space】— 用户空间占用CPU的百分比。\n\n0.3%sy【sysctl】— 内核空间占用CPU的百分比。\n\n0.0%ni【】— 改变过优先级的进程占用CPU的百分比\n\n99.7%id【idolt】— 空闲CPU百分比\n\n0.0%wa【wait】— IO等待占用CPU的百分比\n\n0.0%hi【Hardware IRQ】— 硬中断占用CPU的百分比\n\n0.0%si【Software Interrupts】— 软中断占用CPU的百分比\n第四行,内存状态\n1003020k total,   234464k used,   777824k free,    24084k buffers【缓存的内存量】\n第五行，swap 交换分区信息\n2031612k total,      536k used,  2031076k free,   505864k cached【缓冲的交换区总量】\n\n备注：\n\n可用内存=free + buffer + cached\n\n对于内存监控，在top里我们要时刻监控第五行swap交换分区的used，如果这个数值在不断的变化，说明内核在不断进行内存和swap的数据交换，这是真正的内存不够用了。\n\n第四行中使用中的内存总量（used）指的是现在系统内核控制的内存数，\n\n第四行中空闲内存总量（free）是内核还未纳入其管控范围的数量。\n\n纳入内核管理的内存不见得都在使用中，还包括过去使用过的现在可以被重复利用的内存，内核并不把这些可被重新使用的内存交还到free中去，因此在linux上free内存会越来越少，但不用为此担心。\n第六行，空行\n第七行以下：各进程（任务）的状态监控\nPID — 进程id\nUSER — 进程所有者\nPR — 进程优先级\nNI — nice值。负值表示高优先级，正值表示低优先级\nVIRT — 进程使用的虚拟内存总量，单位kb。VIRT=SWAP+RES\nRES —  进程使用的、未被换出的物理内存大小，单位kb。RES=CODE+DATA\nSHR — 共享内存大小，单位kb\nS —进程状态。D=不可中断的睡眠状态 R=运行 S=睡眠 T=跟踪/停止 Z=僵尸进程\n%CPU — 上次更新到现在的CPU时间占用百分比\n%MEM — 进程使用的物理内存百分比\nTIME+ — 进程使用的CPU时间总计，单位1/100秒\nCOMMAND — 进程名称（命令名/命令行）\n\n\n说明:\nVIRT：virtual memory usage 虚拟内存\n1、进程“需要的”虚拟内存大小，包括进程使用的库、代码、数据等\n2、假如进程申请100m的内存，但实际只使用了10m，那么它会增长100m，而不是实际的使用量\n\nRES：resident memory usage 常驻内存\n1、进程当前使用的内存大小，但不包括swap out\n2、包含其他进程的共享\n3、如果申请100m的内存，实际使用10m，它只增长10m，与VIRT相反\n4、关于库占用内存的情况，它只统计加载的库文件所占内存大小\n\nSHR：shared memory 共享内存\n1、除了自身进程的共享内存，也包括其他进程的共享内存\n2、虽然进程只使用了几个共享库的函数，但它包含了整个共享库的大小\n3、计算某个进程所占的物理内存大小公式：RES – SHR\n4、swap out后，它将会降下来\n\nDATA\n1、数据占用的内存。如果top没有显示，按f键可以显示出来。\n2、真正的该程序要求的数据空间，是真正在运行中要使用的。\ntop 指令的相关参数\n在top运行中可以使用以下命令在top中进行操作\ns – 改变画面更新频率\nl – 关闭或开启第一部分第一行 top 信息的表示\nt – 关闭或开启第一部分第二行 Tasks 和第三行 Cpus 信息的表示\nm – 关闭或开启第一部分第四行 Mem 和 第五行 Swap 信息的表示\nN – 以 PID 的大小的顺序排列表示进程列表\nP – 以 CPU 占用率大小的顺序排列进程列表\nM – 以内存占用率大小的顺序排列进程列表\nh – 显示帮助\nn – 设置在进程列表所显示进程的数量\nq – 退出 top\n启动 top 时的参数列表\ntop [-] [options]\n\noptions:\nd：指定每两次屏幕信息刷新之间的时间间隔。当然用户可以使用s交互命令来改变之。\n\np:通过指定监控进程ID来仅仅监控某个进程的状态。\n\nq:该选项将使top没有任何延迟的进行刷新。如果调用程序有超级用户权限，那么top将以尽可能高的优先级运行。\n\nS：指定累计模式。\n\ns：使top命令在安全模式中运行。这将去除交互命令所带来的潜在危险。\n\ni：使top不显示任何闲置或者僵死进程。\n\nc:显示整个命令行而不只是显示命令名。\ndf\ndf（英文全拼：disk free） 命令用于显示目前在 Linux 系统上的文件系统磁盘使用情况统计。\ndf [-options]\n\n options:\n \t-a, --all 包含所有的具有 0 Blocks 的文件系统\n \t-h, --human-readable 使用人类可读的格式(预设值是不加这个选项的...)\n \t-i, --inodes 列出 inode 资讯，不列出已使用 block\n\t-k, --kilobytes 就像是 --block-size=1024\n\t-l, --local 限制列出的文件结构\n\t-m, --megabytes 就像 --block-size=1048576\n防火墙\n基本操作\n基本操作包括：查看防火墙状况、开启防火墙、关闭防火墙、重启防火墙、设置防火墙随系统 启动而启动、关闭防火墙随着系统的启动而启动、查看防火墙随统启动而启动。\n# 查看防火墙的状态\nsystemctl status firewalld\n\n# 开启防火墙\nsystemctl start firewalld\n\n# 关闭防火墙\nsystemctl stop firewalld\n\n# 重启防火墙\nsystemctl restart firewalld\n\n# 设置防火墙，并且随着系统的启动而启动\nsystemctl enable firewalld\n\n# 关闭防火墙随着系统的启动而启动，重启以后生效\nsystemctl disable firewalld\n\n# 检查防火墙服务是否开机启动\nsystemctl is-enabled firewalld\n\n开启端口\nfirewall-cmd [选项...]\n\n选项:\n\t--state: 显示firewalld的状态。\n\t--reload: 不中断服务的重新加载防火墙。\n\t--list-ports: 查看所有打开的端口。\n\t--zone: 作用域：block dmz drop external home internal public trusted work\n\t--add-port=80/tcp :添加端口，格式为：端口/通讯协议。\n\t--permanent: 永久生效，没有此参数重启后失效。\n\t--query-service: 查看对应的服务，比如：ftp、ssh服务。\n\n\n#查看已经打开的端口\nfirewall-cmd --zone=public --list-ports\n\n# 查看8080端口有没有打开\nfirewall-cmd --query-port=8080/tcp\n\n# 如果不需要了，可以删除防火墙上面开辟的8080端口\nfirewall-cmd --zone=public --remove-port=8080/tcp --permanent\n系统的启动与配置\n\n\n硬件启动阶段：开机，然后初始化硬件设备，然后检查硬件设备，比如：CPU、内存、硬 盘、键盘等设备。\n\n\nGRUB 引导阶段：硬件启动后，通过执行固件里面的指令跳转到 BIOS，然后 BIOS 找到启动设 备并获取 MBR，MBR 又指向 GRUB。当 GRUB 获得引导控制权后，会现实 GRUB 的提示符，此时 如果用户不做任何操作，GRUB 将在等待指定时间后自动引导默认的操作系统，如果此时按 TAB 键，则可以看到一个可引导的操作系统的列表，用户可以选择相应的操作系统。如果用户选择了 某个 Linux 操作系统，GRUB 就会从/boot 分区里面读取并装载的压缩内核，然后压缩的内核解 压，加载内核镜像到内存，之后构建虚拟根文件系统，然后把控制权交给内核。\n\n\n内核引导阶段：通过内存中的虚拟根文件系统，加载驱动，然后切换到真正的根文件系统， 然后执行的初始化程序/sbin/init（其实指向的是/usr/lib/systemd/systemd）。\n\n\nsystemed 初始化阶段：又叫系统初始化阶段，CentOS7 中我们的初始化进程为 systemd （天字号排行第一的进程，因为其 PID 为 1，可以通过 top 命令查看），然后系统执行默认 target 配置文件（/etc/systemd/system/default.target），然后根据这个默认的 target，引导系 统启动并进入指定的运行级别，并启动相应的服务程序。然后等待用户登录使用。\n\n\n系统的运行级别\n\n\n\n级别\n描述\n详解\n\n\n\n\n0\n系统停机模式\n系统关机状态，系统默认运行级别不能设置为 0，否则不能正常启动。\n\n\n1\n单用户模式\nroot 权限，用于系统维护，禁止远程登陆，就像 Windows 下的安全 模式登录。\n\n\n2\n多用户模式\n多用户状态，但是没有 NFS 和网络支持。\n\n\n3\n完全多用户模式\n有 NFS 和网络，登陆后进入控制台命令行模式（如果默认是命令行则 它是默认的）。\n\n\n4\n系统未使用\n保留一般不用，在一些特殊情况下可以用它来做一些事情。\n\n\n5\n图形化模式\n登陆后进入图形用户模式，X Window 系统。\n\n\n6\n重启模式\n默认运行级别不能设为 6，否则不能正常启动。运行 init 6 机器就会 重启。\n\n\n\n#使用启动级别来关机、重启、进入命令行模式、进入图形用户模式\n\n# 关机\ninit 0\n#复习 还有 halt\\poweroff\\shutdown -h now\n\n# 重启\ninit 6\n#复习 还有reboot\\shutdown -r now\n\n# 进入命令行模式\ninit 3\n# 进入图形用户模式\ninit 5\n每个运行级别都有属于自己的 target 文件，这些 target 文件都是以链接文 件的形式保存在“/lib/systemd/system”目录。运行级别的设置由 “/etc/systemd/system/default.target”来控制，default.target 里面配置的是什么运行级别，系统启动的时候就运行哪个运行级别。\n“/lib/systemd/system”定义好的运行级别文件：\n\ndefault.target 指向的默认的一个运行级别。\n\n由于不同的运行级别将要启动的服务不尽相同，所以，为了合理的管理各个运行级别的服务进 程，系统为每一个运行级别在目录下准备了一个目录用于存放各自的服务程序，命名规范是 “rcn.d”（n 代表 0~6 的七个运行级别），具体如下图所示。\n\n在运行级别对应的目录中，所有文件的命名规则是“Snnxxxx” 和“Knnxxxx” 。其中，以 “S”开头的文件是系统启动时调用的服务程序，以“K”开头的文件是系统终止时调用的服务程序。 nn 是 00 ～ 99 之间的一个整数，数字 nn 的大小决定程序执行的先后顺序。xxx 是服务程序的名 称。 由于各个运行级别中的服务程序集合有可能存在交集，所以为了节省硬盘空间和便于更新服务 程序，在 rcn.d 目录中存放的只是各个服务程序的链接文件，我们装 CentOS7 的默认运行级别是 “完全多用户模式”，我们进入它对应的目录“/etc/rc.d/rc3.d”，如下图所示。\n\n查看系统默认运行级别\nrunlevel\n设置系统运行级别\nsystemctl 设置\n# 设置默认第三启动级别\nsystemctl set-default multi-user.target\n# 设置默认第五启动级别\nsystemctl set-default graphical.target\n# 查看当前默认的启动级别\nsystemctl get-default\n重置软链接文件\n#设置完全多用户模式为默认的运行级别\n\n# 先删除原有的软链接文件\nrm -rf /etc/systemd/system/default.target\n# 创建软连接文件\nln -s /usr/lib/systemd/system/multi-user.target\n/etc/systemd/system/default.target\n# 重启\nreboot\n网络\n网卡的配置\n网卡配置文件\n网卡的配置信息，通常包括 IP 地址、子网掩码、网关。这些网卡信息保存在配置文件中，这个 网卡的配置文件位于**/etc/sysconfig/network-scripts**，我们的 CentOS7 的网卡配置信息就在 ifcfg-ens33文件中。\n查看 ifcfg-ens33 的内容\ncat /etc/sysconfig/network-scripts/ifcfg-ens33\n显示内容:\nTYPE=\"Ethernet\"\nPROXY_METHOD=\"none\"\nBROWSER_ONLY=\"no\"\nBOOTPROTO=\"dhcp\"\nDEFROUTE=\"yes\"\nIPV4_FAILURE_FATAL=\"no\"\nIPV6INIT=\"yes\"\nIPV6_AUTOCONF=\"yes\"\nIPV6_DEFROUTE=\"yes\"\nIPV6_FAILURE_FATAL=\"no\"\nIPV6_ADDR_GEN_MODE=\"stable-privacy\"\nNAME=\"ens33\"\nUUID=\"1bedffd6-a745-41a6-b981-e3fff4e13b71\"\nDEVICE=\"ens33\"\nONBOOT=\"yes\"\nIPV6_PRIVACY=\"no\"\n配置信息\n\n\n\n配置项\n介绍\n\n\n\n\nDEVICE\n定义该网卡的识别名称。\n\n\nTYPE\n网卡类型。\n\n\nBOOTPROTO\n启动该网卡的方式。有 static/none 表示固定 IP 地址；bootp/dhcp 表示通 过 BOOTP 或者 DHCP 协议动态获取 IP 地址。 如果自己设置就用 static，如果想自动获取就用 dhcp。\n\n\nONBOOT\n启动 NetworkManager 的时候，是否启动该网卡。有些情况下安装 CentOS 的时候网络老是不启动这个时候，就可以看这个配置项是否是 “yes”\n\n\nIPADDR\n静态方式设置指定的 IP 地址。\n\n\nNETMASK\n指定子网掩码。\n\n\nGATEWAY\n指定默认网关。\n\n\nDNS1\n配置 DNS 服务器\n\n\n\n设置静态 IP\n安装的时候，我们设置的是网络采取的是“dhcp”网络配置方式，这种方式 IP 是动态设置的，这 个在我们以后的集群里面是不行的，所以我们设置成静态 ip，具体的步骤如下：\n# 进入网络配置目录\ncd /etc/sysconfig/network-scripts/\n\n# 查看网络配置文件\nls -al\n\n# 编辑网络配置文件\nvi + /etc/sysconfig/network-scripts/ifcfg-ens33\nTYPE=\"Ethernet\"\nPROXY_METHOD=\"none\"\nBROWSER_ONLY=\"no\"\n# 注意这个要注释或者删除\n#BOOTPROTO=\"dhcp\"\nDEFROUTE=\"yes\"\nIPV4_FAILURE_FATAL=\"no\"\nIPV6INIT=\"yes\"\nIPV6_AUTOCONF=\"yes\"\nIPV6_DEFROUTE=\"yes\"\nIPV6_FAILURE_FATAL=\"no\"\nIPV6_ADDR_GEN_MODE=\"stable-privacy\"\nNAME=\"ens33\"\nUUID=\"e9ce67e1-7d2a-41b4-9989-dfbc75278d80\"\nDEVICE=\"ens33\"\nONBOOT=\"yes\"\nIPV6_PRIVACY=\"no\"\n# 配置静态的IP\nBOOTPROTO=\"static\"\n# IP地址\nIPADDR=192.168.60.100\n# 子网掩码\nNETMASK=255.255.255.0\n# 默认网关\nGATEWAY=192.168.60.1\n# 配置DNS\nDNS1=8.8.8.8\n重启网络与重新登陆\n# 重启网络：\nsystemctl restart network\n# 重新登录\nssh root@192.168.60.100\nifconfig 命令\nifconfig 命令（来源于 net-tools 软件包，默认的精简版的 CentOS7 里面是没遇的，得先安装） 功能比较的强大，用于显示或设置网络设备。\nyum -y install net-tools\n查看网卡信息\n命令格式：\nifconfig [选项]\n选项说明:\n\n\n\n选项\n说明\n\n\n\n\n无选项\n显示当前活动的网卡信息。\n\n\n-a\n显示系统中所有的网卡配置信息。\n\n\n网卡设备名\n显示指定网卡的配置信息。\n\n\n\n设置 IP 地址\n命令格式：\nifconfig 网卡设备名 IP地址 netmask 子网掩码\n\n#使用ifconfig将ens33网卡的ip改成192.168.60.133，子网掩码改成255.255.255.0\nifconfig ens33 192.168.60.133 netmask 255.255.255.0\n\n\n\n\n\n\n\n\n\n注意：这种方式设置 IP 只是临时性的，如果重启机器，IP 又会恢复到原来的 IP。\nifdown\n用于禁用网卡\n命令格式：\nifdown 网卡设备名\n\n#禁用ens33\nifdown ens33\nifup\n重新启用网卡\nifup 网卡设备名\n\n#重新启用ens33\nifup ens33\nping\nping 命令用于检测主机。执行 ping 指令会发出要求回应的信息，若远端主机的网络功能没有问 题，就会回应该信息，因而得知该主机运作正常。\n命令格式：\nping [选项] 主机ip地址、主机名、或者域名\n\n选项说明：\n-c：指定向目标主机发送的报文次数。\n-s：指定发送报文的大小，单位字节。\n-W：设置等待接收响应报文的时间间隔，单位秒。\n\n\n\n\n\n\n\n\n\nping 命令默认情况下是一直往目标地址发生 ping 请求，然后数据包的大小是 64KB，直到按” Ctrl+c“才退出。\n软件的安装\nLinux 各个不同版本中内置了一些不同的工具用于下载和安装软件\n文件的下载\nwget\nwget 是 Linux 中的一个下载文件的工具，wget 是在 Linux 下开发的开放源代码的软件，作者是 Hrvoje Niksic，后来被移植到包括 Windows 在内的各个平台上。\nwget 工具体积小但功能完善，它支持断点下载功能，同时支持 FTP 和 HTTP 下载方式\n安装 wget\nyum install -y wget\n命令格式\nwget [参数] [URL地址]\n使用实例:\n实例 1：使用 wget 下载单个文件\n以下的例子是从网络下载一个文件并保存在当前目录，在下载的过程中会显示进度条，包含下载完成百分比，已经下载的字节，当前下载速度和剩余下载时间：\nwget http://www.minjieren.com/wordpress-3.1-zh_CN.zip\n实例 2：使用 wget -O 下载并以不同的文件名保存\nwget 默认会以最后一个符合”/”的后面的字符来命名，对于动态链接的下载通常文件名会不正确下面的例子会下载一个文件并以名称 download.aspx?id=1080 保存，即使下载的文件是 zip 格式，它仍然以 download.php?id=1080 命令：\nwget http://www.minjieren.com/download?id=1\n为了解决这个问题，我们可以使用参数-O 来指定一个文件名：\nwget -O wordpress.zip http://www.minjieren.com/download.aspx?id=1080\n实例 3：使用 wget –limit -rate 限速下载\n当你执行 wget 的时候，它默认会占用全部可能的宽带下载。但是当你准备下载一个大文件，而你还需要下载其它文件时就有必要限速了：\nwget --limit-rate=300k http://www.minjieren.com/wordpress-3.1-zh_CN.zip\n实例 4：使用 wget -c 断点续传\n使用 wget -c 重新启动下载中断的文件，对于我们下载大文件时突然由于网络等原因中断非常有帮助，我们可以继续接着下载而不是重新下载一个文件。需要继续中断的下载时可以使用-c 参数\nwget -c http://www.minjieren.com/wordpress-3.1-zh_CN.zip\n实例 5：使用 wget -b 后台下载\n对于下载非常大的文件的时候，我们可以使用参数-b 进行后台下载\nwget -b http://www.minjieren.com/wordpress-3.1-zh_CN.zip\n\nwget -b http://www.minjieren.com/wordpress-3.1-zh_CN.zip\nContinuing in background, pid 1840.\nOutput will be written to `wget-log'.\n你可以使用以下命令来察看下载进度：\ntail -f wget-log\n实例 6：伪装代理名称下载\n有些网站能通过根据判断代理名称不是浏览器而拒绝你的下载请求。不过你可以通过–user-agent 参数伪装。\nwget --user-agent=\"Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US) AppleWebKit/534.16 (KHTML, like Gecko) Chrome/10.0.648.204 Safari/534.16\" http://www.minjieren.com/wordpress-3.1-zh_CN.zip\n实例 7：使用 wget –spider 测试下载链接\n当你打算进行定时下载，你应该在预定时间测试下载链接是否有效。我们可以增加–spider 参数进行检查。\nwget --spider URL\n如果下载链接正确，将会显示：\nwget --spider URL\n\nSpider mode enabled. Check if remote file exists.\nHTTP request sent, awaiting response... 200 OK\nLength: unspecified [text/html]\nRemote file exists and could contain further links,\nbut recursion is disabled -- not retrieving.\n这保证了下载能在预定的时间进行，但当你给错了一个链接，将会显示如下错误：\nwget --spider url\n\nSpider mode enabled. Check if remote file exists.\nHTTP request sent, awaiting response... 404 Not Found\nRemote file does not exist -- broken link!!!\n你可以在以下几种情况下使用 spider 参数：\n\n\n定时下载之前进行检查\n\n\n间隔检测网站是否可用\n\n\n检查网站页面的死链接\n\n\n实例 8：使用 wget –tries 增加重试次数\n如果网络有问题或下载一个大文件也有可能失败。wget 默认重试 20 次连接下载文件。如果需要，你可以使用–tries 增加重试次数：\nwget --tries=40 URL\n实例 9：使用 wget -i 下载多个文件\n首先，保存一份下载链接文件：\ncat > filelist.txt\nurl1\nurl2\nurl3\nurl4\n12345\n接着使用这个文件和参数-i 下载：\nwget -i filelist.txt\n1\n实例 10：使用 wget –mirror 镜像网站\n下载整个网站到本地：\nwget --mirror -p --convert-links -P .&#x2F;LOCAL URL\n1\n说明：\n–miror:开户镜像下载\n-p:下载所有为了 html 页面显示正常的文件\n–convert-links:下载后，转换成本地的链接\n-P ./LOCAL：保存所有文件和目录到本地指定目录\n实例 11：使用 wget –reject 过滤指定格式下载\n下载一个网站，但你不希望下载图片，可以使用以下命令：\nwget --reject=gif url\n实例 12：使用 wget -o 把下载信息存入日志文件\n不希望下载信息直接显示在终端而是在一个日志文件，可以使用：\nwget -o download.log URL\n实例 13：使用 wget -Q 限制总下载文件大小\n命令：\nwget -Q5m -i filelist.txt\n说明：\n当你想要下载的文件超过 5M 而退出下载，你可以使用。注意：这个参数对单个文件下载不起作用，只能递归下载时才有效。\n实例 14：使用 wget -r -A 下载指定格式文件\nExample：\nwget -r -A.pdf url\n可以在以下情况使用该功能：\n\n\n下载一个网站的所有图片\n\n\n下载一个网站的所有视频\n\n\n下载一个网站的所有 PDF 文件\n\n\n实例 15：使用 wget FTP 下载\n使用 wget 匿名 ftp 下载：\nwget ftp-url\n使用 wget 用户名和密码认证的 ftp 下载\nwget --ftp-user=USERNAME --ftp-password=PASSWORD url\ncurl\ncURL是用于数据传输的命令行工具，支持多种传输协议，包括 HTTP、HTTPS、SCP、FTP、SFTP、TELNET、FILE、SMTP、POP3 等等。可以使用cURL进行HTTP/HTTPS请求、上传/下载文件等，且支持Cookie、用户身份验证、代理支持、限速等。\n基本语法:\ncurl [options] [URL...]\n常见用法:\n#1、下载(option:-o或者option:-O)\n\n#1.1、下载页面：\n\ncurl -o dodo1.jpg http:www.linux.com/dodo1.JPG\n#要注意-O这里后面的url要具体到某个文件，不然抓不下来\ncurl -O http://www.linux.com/dodo1.JPG\n\n#1.2：循环下载\n#有时候下载图片可以能是前面的部分名称是一样的，就最后的尾椎名不一样。这样就会把dodo1，dodo2，dodo3，dodo4，dodo5全部保存下来\ncurl -O http://www.linux.com/dodo[1-5].JPG\n\n\n#1.3：下载重命名\n#在hello/dodo1.JPG的文件下载下来就会变成hello_dodo1.JPG,其他文件依此类推，从而有效的避免了文件被覆盖\ncurl -o #1_#2.JPG http://www.linux.com/&#123;hello,bb&#125;/dodo[1-5].JPG\n\n#由于下载的hello与bb中的文件名都是dodo1，dodo2，dodo3，dodo4，dodo5。因此第二次下载的会把第一次下载的覆盖，这样就需要对文件进行重命名。\ncurl -O http://www.linux.com/&#123;hello,bb&#125;/dodo[1-5].JPG\n\n\n#1.4：分块下载(option：-r)\ncurl -r 0-100 -o dodo1_part1.JPG http://www.linux.com/dodo1.JPG\ncurl -r 100-200 -o dodo1_part2.JPG http://www.linux.com/dodo1.JPG\ncurl -r 200- -o dodo1_part3.JPG http://www.linux.com/dodo1.JPG\ncat dodo1_part* > dodo1.JPG  #这样就可以查看dodo1.JPG的内容了\n\n\n#1.5：通过ftp下载文件(option：-u)\ncurl可以通过ftp下载文件，curl提供两种从ftp中下载的语法\ncurl -O -u 用户名:密码 ftp://www.linux.com/dodo1.JPG\ncurl -O ftp://用户名:密码@www.linux.com/dodo1.JPG\n\n\n#1.6:下载，显示进度条(option：-#)或不显示进度条(option：-s)\ncurl -# -O http://www.linux.com/dodo1.JPG\ncurl -s -O http://www.linux.com/dodo1.JPG\n\n#1.7、下载，断点续传(-C &lt;offset>)\n断点续转，从文件头的指定位置开始继续下载/上传；offset续传开始的位置，如果offset值为“-”，curl会自动从文件中识别起始位置开始传输；\ncurl -# -o centos6.8.iso -C - http://mirrors.aliyun.com/centos/6.8/isos/x86_64/CentOS-6.8-x86_64-minimal.iso\ncurl -C -O http://www.linux.com/dodo1.JPG\n\n\n\n#2、上传文件(option:-T)\n\ncurl -T dodo1.JPG -u 用户名:密码 ftp://www.linux.com/img/\n\n\n\n#3、伪造来源页面|伪造referer|盗链 (option：-e)\n\n#很多服务器会检查http访问的referer从而来控制访问。比如：你是先访问首页，然后再访问首页中的邮箱页面，这里访问邮箱的referer地址就是访问首页成功后的页面地址，如果服务器发现对邮箱页面访问的referer地址不是首页的地址，就断定那是个盗连了\n#这样就会让服务器其以为你是从www.linux.com点击某个链接过来的\ncurl -e \"www.linux.com\" http://mail.linux.com\n#告诉爱E族，我是从百度来的\ncurl -e http://baidu.com http://aiezu.com\n\n\n\n#4、伪造代理设备(模仿浏览器)\n\n#有些网站需要使用特定的浏览器去访问他们，有些还需要使用某些特定的版本。curl内置option:-A可以让我们指定浏览器去访问网站\ncurl -A \"Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 5.0)\" http://www.linux.com\n#告诉爱E族，我是GOOGLE爬虫蜘蛛（其实我是curl命令）\ncurl -A \" Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)\" http://aiezu.com\n#告诉爱E族，我用的是微信内置浏览器\ncurl -A \"Mozilla/5.0 AppleWebKit/600 Mobile MicroMessenger/6.0\" http://aiezu.com\n\n\n#5、设置http请求\n\n#5.1、设置http请求头(或option:-H或option:--head)\ncurl -H \"Cache-Control:no-cache\"  http://aiezu.com\n\n#5.2、指定proxy服务器以及其端口(option::-x)\n#很多时候上网需要用到代理服务器(比如是使用代理服务器上网或者因为使用curl别人网站而被别人屏蔽IP地址的时候)，幸运的是curl通过使用内置option：-x来支持设置代理\ncurl -x 192.168.100.100:1080 http://www.linux.com\n\n\n\n#6、http响应头\n\n#6.1、查看http响应头(option:-I)\n# 看看本站的http头是怎么样的\ncurl -I  http://aiezu.com\n输出：\nHTTP/1.1 200 OK\nDate: Fri, 25 Nov 2016 16:45:49 GMT\nServer: Apache\nSet-Cookie: rox__Session=abdrt8vesprhnpc3f63p1df7j4; path=/\nExpires: Thu, 19 Nov 1981 08:52:00 GMT\nCache-Control: no-store, no-cache, must-revalidate, post-check=0, pre-check=0\nPragma: no-cache\nVary: Accept-Encoding\nContent-Type: text/html; charset=utf-8\n\n#6.2、保存http的response里面的header信息(option:-D)\ncurl -D cookied.txt http://www.linux.com\n执行后cookie信息就被存到了cookied.txt里面了\n注意：-c(小写)产生的cookie和-D里面的cookie是不一样的。\n\n\n\n#7、发送表单数据\n\ncurl -F \"pic=@logo.png\" -F \"site=aiezu\"  http://aiezu.com/\n\n\n\n#8、cookie\n\n#8.1、发送cookie(option:-b）\n#有些网站是使用cookie来记录session信息。对于chrome这样的浏览器，可以轻易处理cookie信息，但在curl中只要增加相关参数也是可以很容易的处理cookie\ncurl -b \"domain=aiezu.com\"  http://aiezu.com\n#很多网站都是通过监视你的cookie信息来判断你是否按规矩访问他们的网站的，因此我们需要使用保存的cookie信息。内置option: -b\ncurl -b cookiec.txt http://www.linux.com\n\n\n#8.2、保存http的response里面的cookie信息(option:-c）\n#执行后http的response里面的cookie信息就被存到了cookiec.txt里面了\ncurl -c cookiec.txt  http://www.linux.com\n\n\n\n#9、测试一个网址\n\n#9.1、测试一个网址是否可达\ncurl -v http://www.linux.com\n\n#9.2、测试网页返回值(option:-w [format])\ncurl -o /dev/null -s -w %&#123;http_code&#125; www.linux.com\n\n\n\n#10、保存访问的网页(>>)\n\n#2.1:使用linux的重定向功能保存\ncurl http://www.linux.com >> linux.html\nRedHat\nrpm\nrpm（英文全拼：redhat package manager） 原本是Red Hat Linux发行版专门用来管理 Linux 各项套件的程序，由于它遵循 GPL 规则且功能强大方便，因而广受欢迎。逐渐受到其他发行版的采用。RPM 套件管理方式的出现，让 Linux 易于安装，升级，间接提升了 Linux 的适用度。包的格式为*.rpm\n命令格式:\nrpm [选项] [文件&#x2F;软件包]\n常见选项:\n\n\n\n选项\n说明\n\n\n\n\n-a\n(all)显示所有软件包。\n\n\n-q\n(query)查询功能。\n\n\n-i\n安装指定的软件包。通常和-v，-h 选项结合使用。\n\n\n-e\n(erase)删除指定的软件包。\n\n\n-f\n查询拥有指定文件的软件包。\n\n\n-l\n(list)显示软件包的文件列表。\n\n\n-p\n查询待安装的软件包。\n\n\n-s\n显示文件状态，通常结合-l 选项使用。\n\n\n-U\n升级指定的软件包。\n\n\n-h\n在安装过程中将显示一系列的“#”来表示安装进度。\n\n\n-v\n显示指令执行过程。\n\n\n-vv\n详细显示指令执行过程，便于排错。\n\n\n–nodeps\n强制删除，不管它的依赖关系。\n\n\n\n常用命令:\n#查询系统中已经安装的全部RPM包\nrpm -qa\n\n#结合管道符进行查询\nrpm -qa | more\nrpm -qa | less\nrpm -qa | wc -l\n\n#结合全局正则表达式进行查询\nrpm -qa | grep python\n\n#查询是否安装特定(多个)的软件包\nrpm -q openssh-server [openssh-clients ...] #软件包间空格隔开\n\n#查询软件包的描述信息\nrpm -qi openssh-server\n\n#查询已经安装的软件包的文件列表(即查询软件包的安装目录)\nrpm -ql 软件包名称\n\n#查询某个文件所属的软件包\nrpm -qf 文件\n\n#安装软件包\nrpm -ivh 软件包名称\nrpm -ivh jdk-8u221-linux-x64.rpm\n\n#卸载软件包\nrpm -e 软件包名称\n\n\n\n\n\n\n\n\n\nrpm 安装软件包过程总结(以安装 jdk8 为例)\n1、把 jdk 解压到“/usr/java/jdk1.8.0_221-amd64”。\n2、在“/etc/alternatives/”创建链接指向解压目录“/usr/java/jdk1.8.0_221-amd64”。\n3、然后在“/usr/bin/”目录下创建链接指向“/etc/alternatives/”。\n4、由于“/usr/bin/”已经被添加到环境变量里面去，我们可以直接使用。\nyum\nyum（ Yellow dog Updater, Modified）是一个在 Fedora 和 RedHat 以及 SUSE 中的 Shell 前端软件包管理器。基于 RPM 包管理，能够从指定的服务器自动下载 RPM 包并且安装，可以自动处理依赖性关系，并且一次安装所有依赖的软件包，无须繁琐地一次次下载、安装。\nyum 提供了查找、安装、删除某一个、一组甚至全部软件包的命令，而且命令简洁而又好记。\nyum [options] [command] [package ...]\n\n\toptions：可选，选项包括-h（帮助），-y（当安装过程提示选择全部为 \"yes\"），-q（不显示安装的过程）等等。\n\tcommand：要进行的操作。\n\tpackage：安装的包名。\n\n#yum常用命令\n#1. 列出所有可更新的软件清单命令：\nyum check-update\n\n#2. 更新所有软件命令：\nyum update\n\n#3. 仅安装指定的软件命令：\nyum install &lt;package_name>\n\n#4. 仅更新指定的软件命令：\nyum update &lt;package_name>\n\n#5. 列出所有可安裝的软件清单命令：\nyum list\n\n#6. 删除软件包命令：\nyum remove &lt;package_name>\n\n#7. 查找软件包命令：\nyum search &lt;keyword>\n\n#8. 清除缓存命令:\nyum clean packages: 清除缓存目录下的软件包\nyum clean headers: 清除缓存目录下的 headers\nyum clean oldheaders: 清除缓存目录下旧的 headers\nyum clean, yum clean all (= yum clean packages; yum clean oldheaders) :清除缓存目录下的软件包及旧的 headers\nDebian、Ubuntu\ndpkg\ndpkg 命令的英文全称是“Debian package”，故名意思是 Debian Linux 系统用来安装、创建和管理软件包的实用工具。能直接本地安装*.deb的包文件\ndpkg [参数] [包名]\n\n常用参数：\n    -i\t安装软件包\n    -r\t删除软件包\n    -l\t显示已安装软件包列表\n    -L\t显示于软件包关联的文件\n    -c\t显示软件包内文件列表\n\n#安装包\ndpkg -i package.deb\n\n#删除包\ndpkg -r package.deb\n\n#列出当前已安装的包\ndpkg -l\n\n#列出deb包的内容\ndpkg -c package.deb\n\n#配置\ndpkg --configure package\napt\napt（Advanced Packaging Tool）是一个在 Debian 和Ubuntu中的 Shell 前端软件包管理器。\napt 命令提供了查找、安装、升级、删除某一个、一组甚至全部软件包(*.deb)的命令，而且命令简洁而又好记。\napt 命令执行需要超级管理员权限(root)。\napt = apt-get+ apt-cache + apt-config 中最常用命令选项的集合\n基本格式\napt [options] [command] [package ...]\n\n\toptions：可选，选项包括 -h（帮助），-y（当安装过程提示选择全部为\"yes\"），-q（不显示安装的过程）等等。\n\tcommand：要进行的操作。\n\tpackage：安装的包名。\n常用命令:\n#列出所有可更新的软件清单命令,刷新存储库索引\nsudo apt update\n\n#列出可更新的软件包及版本信息：\napt list --upgradeable\n\n#升级所有可升级的软件包\nsudo apt upgrade\n\n#升级软件包，在升级软件包时自动处理依赖关系：\nsudo apt full-upgrade\n\n#安装指定的软件命令：\nsudo apt install &lt;package_name>\n\n#安装多个软件包：\nsudo apt install &lt;package_1> &lt;package_2> &lt;package_3>\n\n#更新指定的软件命令：\nsudo apt update &lt;package_name>\n\n#显示软件包具体信息,例如：版本号，安装大小，依赖关系等等：\nsudo apt show &lt;package_name>\n\n#删除软件包命令：\nsudo apt remove &lt;package_name>\n\n#清理不再使用的依赖和库文件:\nsudo apt autoremove\n\n#移除软件包及配置文件:\nsudo apt purge &lt;package_name>\n\n#自动删除不需要的包\nsudo apt autoremove\n\n#查找软件包命令：\nsudo apt search &lt;keyword>\n\n#列出所有已安装的包：\napt list --installed\n\n#列出所有已安装的包的版本信息：\napt list --all-versions\n挂载\n挂载在 Linux 系统中是一个比较重要的操作，我们 使用 CentOS 使需要插入 U 盘了，由于我们使用的是命令行不像 Windows 有图形用户界面，那 么直观的帮助用户使用。或者当我们的硬盘满了的时候，我们可能就需要加硬盘,这个需要使用挂载这个功能。\n挂载点\n由于 Linux 操作系统只有一个根目录(/)，所以当向系统中添加新的存储设备时，不会像 Windows 操作系统那样出现一个新的根目录或者盘符（比如：K 盘，L 盘等）。因此，在 Linux 下 访问新存储设备时需要首先创建挂载点。\n所谓的挂载点就是文件系统中存在的一个目录,通常情况下，创建在/mnt 目录下，挂载成功后,访问挂载点就是访问新的存储设备。挂载点应该是空目录,否则原来该挂载点中存在的文件将会被隐藏。而且,挂载点在实施挂载操作之前就应该存在。\nfdisk\nLinux fdisk 是一个创建和维护分区表的命令，它兼容 DOS 类型的分区表、BSD 或者 SUN 类型的 磁盘列表。fdisk 能划分的最大分区为**2T**\nfdisk [必要参数][选择参数]\n\n必要参数：\n\t-l 列出所有分区表\n\t-u 与 -l 搭配使用，显示分区数目\n\n选择参数：\n\t-s&lt;分区编号> 指定分区\n\t-v 版本信息\n\n\n我们可以发现系统中有两块硬盘分别是：/dev/sda1 与/dev/sda2，大小分别是 19.1G 与 2G 左 右，前面的是“根节点‘/’”，后面的分区是交换区。\n#输入\nfdisk /指定设备\n#可进入该设备以执行分区的相关操作\n\nparted\n\n\nparted 命令可以创建全局惟一的标识符分区表 GPT，而 fdisk 和 cfdisk 则仅限于 DOS 分区表。\n\n\n更大的磁盘： DOS 分区表可以格式化最多 2TB 的磁盘空间，尽管在某些情况下最多可以达到 16TB。然而，一个 GPT 分区表可以处理最多 8ZB 的空间。\n\n\n更多的分区： 使用主分区和扩展分区，DOS 分区表只允许 16 个分区。在 GPT 中，默认情况下您可以得到 128 个分区，并且可以选择更多的分区。\n\n\n可靠性： 在 DOS 分区表中，只保存了一份分区表备份，在 GPT 中保留了两份分区表的备份（在磁盘的起始和结束部分），同时 GPT 还使用了 CRC 校验和来检查分区表的完整性，在 DOS 分区中并没有实现。\n1、列出分区\n使用 parted -l 来标识你要进行分区的设备。一般来说，第一个硬盘 （/dev/sda 或 /dev/vda ）保存着操作系统， 因此要寻找另一个磁盘，以找到你想要分区的磁盘 (例如，/dev/sdb、/dev/sdc、 /dev/vdb、/dev/vdc 等)。\n$ sudo parted -l\n[sudo] password for daniel:\nModel: ATA RevuAhn_850X1TU5 (scsi)\nDisk /dev/vdc: 512GB\nSector size (logical/physical): 512B/512B\nPartition Table: msdos\nDisk Flags:\nNumber  Start   End    Size   Type     File system  Flags\n 1      1049kB  525MB  524MB  primary  ext4         boot\n 2      525MB   512GB  512GB  primary               lvm\n2、打开存储设备\n使用 parted 选中要分区的设备。在这里例子中，是虚拟系统上的第三个磁盘（/dev/vdc）。指明要使用哪一个设备非常重要。 如果你仅仅输入了 parted 命令而没有指定设备名字， 它会随机选择一个设备进行操作。\n$ sudo parted /dev/vdc\nGNU Parted 3.2\nUsing /dev/vdc\nWelcome to GNU Parted! Type 'help' to view a list of commands.\n(parted)\n3、 设定分区表\n设置分区表为 GPT ，然后输入 Yes 开始执行。\n(parted) mklabel gpt\nWarning: the existing disk label on /dev/vdc will be destroyed\nand all data on this disk will be lost. Do you want to continue?\nYes/No? Yes\nmklabel 和 mktable 命令用于相同的目的（在存储设备上创建分区表）。支持的分区表有：aix、amiga、bsd、dvh、gpt、mac、ms-dos、pc98、sun 和 loop。记住 mklabel 不会创建一个分区，而是创建一个分区表。\n4、 检查分区表\n查看存储设备信息:\n(parted) print\nModel: Virtio Block Device (virtblk)\nDisk /dev/vdc: 1396MB\nSector size (logical/physical): 512B/512B\nPartition Table: gpt\nDisk Flags:\nNumber Start End Size File system Name Flags\n5、 获取帮助\n为了知道如何去创建一个新分区，输入： (parted) help mkpart 。\n(parted) help mkpart\n  mkpart PART-TYPE [FS-TYPE] START END     make a partition\n        PART-TYPE is one of: primary, logical, extended\n        FS-TYPE is one of: btrfs, nilfs2, ext4, ext3, ext2, fat32, fat16, hfsx, hfs+, hfs, jfs, swsusp,\n        linux-swap(v1), linux-swap(v0), ntfs, reiserfs, hp-ufs, sun-ufs, xfs, apfs2, apfs1, asfs, amufs5,\n        amufs4, amufs3, amufs2, amufs1, amufs0, amufs, affs7, affs6, affs5, affs4, affs3, affs2, affs1,\n        affs0, linux-swap, linux-swap(new), linux-swap(old)\n        START and END are disk locations, such as 4GB or 10%.  Negative values count from the end of the\n        disk.  For example, -1s specifies exactly the last sector.\n        'mkpart' makes a partition without creating a new file system on the partition.  FS-TYPE may be\n        specified to set an appropriate partition ID.\n6、 创建分区\n为了创建一个新分区（在这个例子中，分区 0 有 1396MB），输入下面的命令：\n(parted) mkpart primary 0 1396MB\nWarning: The resulting partition is not properly aligned for best performance\nIgnore/Cancel? I\n(parted) print\nModel: Virtio Block Device (virtblk)\nDisk /dev/vdc: 1396MB\nSector size (logical/physical): 512B/512B\nPartition Table: gpt\nDisk Flags:\nNumber Start   End     Size    File system Name Flags\n1      17.4kB  1396MB  1396MB  primary\n文件系统类型（fstype）并不是在 /dev/vdc1上创建 ext4 文件系统。 DOS 分区表的分区类型是主分区 primary、逻辑分区 logical 和扩展分区 extended。 在 GPT 分区表中，分区类型用作分区名称。 在 GPT 下必须提供分区名称；在上例中，primary 是分区名称，而不是分区类型。\n7、 保存退出\n当你退出 parted 时，修改会自动保存。退出请输入如下命令：\n(parted) quit\nInformation: You may need to update /etc/fstab.\n$\n\n\nmount\n在 Linux 中使用 mount 这个命令来挂载文件系统。\nmount [选项] [设备名] [挂载点]\n\n 选项：\n\t-r： 以只读方式挂载文件系统。\n\t-w：以读写方式挂载文件系统，默认选项。\n\tmount不加任何参数，会列出系统中所有已经挂载的文件系统。\n\n比如：“/dev/mapper/centos-root on / type xfs (rw,relatime,seclabel,attr2,inode64,noquota)”，表示“/dev/mapper/centos-root”挂载到“/”下 面了，并且文件类型是“xfs”。\n挂载 u 盘\n使用 fdisk 命令查看 U 盘的分区：\n\n# 创建一个目录用于挂载U盘（创建挂载点）。\nmkdir /root/upan\n# 将U盘所在分区挂载到我们刚刚创建的目录下面。\nmount /dev/sdb /root/upan/\n# 对U盘里面的文件进行查看或者操作\nls -hl /root/upan/\n# 卸载U盘\numount /dev/sdb\n如果挂载的时候出现“mount: unknown filesystem type ‘(null)’\n# 格式化U盘所在的分区,window的文件系统类型linux无法识别\nmkfs.ext4 /dev/sdb\numount\n在 Linux 中使用 umount 这个命令来解挂文件系统。如果某个文件系统你不需要使用了，就可以 使用 umount 命令来进行卸载。这个命令可以把文件系统从 Linux 系统中分离。\numount [设备名]\n服务\n服务的概念\n服务是指执行指定系统功能的程序、或者进程，以便于支持其它程序的运行，尤其是接近底层 （接近硬件）的程序，比如：FTP、HTTP、防火墙、网络等服务。服务的管理包括：开启、查 看、重启、停止等操作\n服务的分类\nLinux 系统的服务分为独立运行的服务和受 xinetd 管理的服务两大类。独立运行的服务在系统 启动后可以独立运行并直接进行管理，这种服务与运行级别有关；而 xinetd，其本身是一个独立 运行的服务，它负责管理一些不常用的服务，当这些不常用的服务被请求时，由 xinetd 服务负责 启动运行，完成服务请求，再结束该服务的运行，以减少系统资源的占用，这些服务的启动和停 止都由 xinetd 控制。\nxinetd 服务的配置文件是“/etc/xinetd.conf”，受 xinetd 服务管理的服务在“/etc/xinetd.d”目 录下有相应的配置脚本文件。例如，telnet 服务就是一个受 xinetd 管理的服务。\n服务的启动脚本\n在管理服务时，Linux 中的每个服务都有相应的启动脚本，可用于设置启动、停止、重启和查 询服务等功能。所有的服务脚本都保存在“/etc/rc.d/init.d”目录中，脚本名称和服务器名称相对 应。在服务的启动脚本中，一般还有对该脚本文件的有效期和使用方法的描述，可以使用查看命 令来查看。\nsystemctl 命令\n服务在使用过程中可以进行启动、状态查询、停止、重启，实现服务自启动状态设置，禁用服 务等操作。在 Linux 中对服务的管理可以通过 systemctl 命令来实现。之前版本的 CentOS7 使用 service命令和chkconfig命令实现对服务的状态设置和自启动设置，目前 CentOS Linux 7 使用 systemctl替换了原有命令。\nsystemctl [start|stop|status|restart|reload] 服务名\n\n 参数说明:\n \tstart：启动服务。\n\tstop：停止服务。\n\tstatus：查看服务运行情况。\n\trestart：重启服务。\n\treload：重新加载服务，加载更新后的配置文件（并不是所有服务都支持这个选项)。用户可以使用该命令管理服务，systemctl命令会自动到/etc/rc.d/init.d/下查找并执行相应的服\n务脚本。\n服务名一般以**“.service”**结尾，这些服务是被 systemctl 监视的进程，如果要求启动或停止的某 个服务不存在，系统将会寻找同名的初始化脚本，即去掉.service 后缀的服务脚本。这主要用于 与传统的 Linux 系统兼容。\n设置服务自启动\nsystemctl 设置自启动\n查看服务是不是自启动\nsystemctl is-enable 服务名称\n设置服务自启动/取消自启动\nsystemctl enable/disable 服务名\n\n#enable：表示设置服务随着系统启动而启动。\n#disable：表示设置取消服务随系统启动而启动。\n进程\n进程的概念\n进程(Process)：是指操作系统中一个独立运行的程序（这里强调的是运行中的程序，如果程 序不运行，仅仅保存在硬盘上就不能称为进程）。例如在 windows 中，同时运行着 Winxin、 Word、QQ，那么 Winxin 程序是一个进程，Word 程序也是一个进程。在 Windows 操作系统中的 任务管理器中，就可以清晰的看到当前操作系统中正在运行的进程信息。\n进程，也称任务，所有支持多个进程同时执行的操作系统就被称作多进程操作系统或多任务操作系统，现在主流的操作系统都属于这种类型。\n进程的分类\n进程一般分为交互进程、批处理进程和守护进程三类。\n\n\n交互进程指 Shell 下通过执行程序产生的进程，可在前台运行，也可在后台运行。\n\n\n批处理进程是进程的序列，在执行批处理进程时是不需要人机交互的。\n\n\n守护进程总是活跃的，一般在后台运行（也叫后台进程）。守护进程一般是由系统在开机时 通过脚本自动启动或者由 root 用户启动的。由于守护进程是一直运行着的，所以它所处的 状态是等待请求处理任务。比如，httpd 服务一直在运行，等待着用户来访问，也就是等待 需要处理的任务。\n\n\n进程的查看\nps\n用于查看系统进程的信息的命令。\n#查找指定进程的信息\nps [options] [| grep 进程名]\noptions:\n    -A\t显示所有的进程，跟-e的效果相同\n    -a\t显示现行终端机下的所有进程，包括其他用户的进程\n    -u\t显示当前用户的进程状态\n    -x\t通常与 a 这个参数一起使用，可列出较完整信息\n    -l\t较长、较详细的将该PID的信息列出\n    -j\t工作的格式(jobs format)\n    -f\t把进程的所有信息都显示出来\n    -e\t表示显示所有继承\n    -p：显示由进程ID指定的进程的信息。\n\n# 获得所有用户进程的信息\nps -aux\n\n# 跟more/less一起使用\nps -aux | more\n\n# 查看pid=1号进程的信息\nps -p 1\n\n# 查看MySQL进程的运行情况\nps -ef | grep mysql\n\n\n\n\n\n\n\n\n\n\nps 只能显示进程的瞬时状态,如果要动态监控进程状态则使用一个’top’指令​ 进程名后的 d​ mysqld​ firewalld​ 是后台进程(守护进程的意思) daemon\n查看指定端口的进程\nss [options] [| grep 端口号]\n\nss 是 Socket Statistics 的缩写\noptions:\n -h, –help 帮助\n -V, –version 显示版本号\n -t, –tcp 显示 TCP 协议的 sockets\n -u, –udp 显示 UDP 协议的 sockets\n -x, –unix 显示 unix domain sockets，与 -f 选项相同\n -n, –numeric 不解析服务的名称，如 “22” 端口不会显示成 “ssh”\n -l, –listening 只显示处于监听状态的端口\n -p, –processes 显示监听端口的进程(Ubuntu 上需要 sudo)\n -a, –all 对 TCP 协议来说，既包含监听的端口，也包含建立的连接\n -r, –resolve 把 IP 解释为域名，把端口号解释为协议名称\n\n# 输出所有建立的连接不包含端口\nss | more\n\n# 查看主机监听的端口。\nss -tnl\n\n# 使用 -p查看监听端口的程序名称\nss -tlp\n\n# 过滤SSH进程的信息。\nss -tlp | grep ssh\nss -tnlp | grep ssh\n终止进程\nkill\nkill [信号代码] 进程编号\nkill 命令可将指定的信息送至程序。预设的信息 SIGTERM(15)，可将指定进程终止。若仍无法 终止该进程，可使用 SIGKILL(9)，尝试强制删除进程。kill 命令的工作原理是：**向 Linux 系统的内 核发送一个系统操作信号和某个进程的进程标志号，然后系统内核就可以对该进程进行操作。**一 般情况下，kill 命令与 ps、grep 命令结合在一起使用（因为要查询进程的编号）。\nkillall\nkillall [信号代码] 进程名\n\n#关闭sshd所有的进程\nkillall sshd\n查看被文件被哪个进程占用(拓展)\nlsof\nlsof 是 List Open File 的缩写, 它主要用来获取被进程打开文件的信息，我们都知道，在 Linux 中，一切皆文件，lsof 命令可以查看所有已经打开了的文件，比如: 普通文件，目录，特殊的块文件，管道，socket 套接字，设备，Unix 域套接字等等，同时，它还可以结合 grep 以及 ps 命令进行更多的高级搜索\n安装\nlsof 命令默认是没有安装的，而且它的使用需要有 root 权限或者赋予普通用于 sudo 权限, 使用以下命令安装\nyum install -y lsof\nlsof 命令有很多可选参数,以下是一些常用的场景\n列出所有打开的文件\n不带任何参数执行 lsof 命令会输出当前所有活跃进程打开的所有文件\n[root@ecs-centos-7 ~]# lsof | more\nCOMMAND     PID   TID    USER   FD      TYPE             DEVICE  SIZE/OFF       NODE NAME\nsystemd       1          root  cwd       DIR              253,1      4096          2 /\nsystemd       1          root  rtd       DIR              253,1      4096          2 /\nsystemd       1          root  txt       REG              253,1   1624520     530313 /usr/lib/systemd/systemd\nsystemd       1          root  mem       REG              253,1     20064     528340 /usr/lib64/libuuid.so.1.3.0\nsystemd       1          root  mem       REG              253,1    265600     532853 /usr/lib64/libblkid.so.1.1.0\nsystemd       1          root  mem       REG              253,1     90248     525942 /usr/lib64/libz.so.1.2.7\nsystemd       1          root  mem       REG              253,1    157424     525955 /usr/lib64/liblzma.so.5.2.2\nsystemd       1          root  mem       REG              253,1     23968     526159 /usr/lib64/libcap-ng.so.0.0.0\nsystemd       1          root  mem       REG              253,1     19896     526135 /usr/lib64/libattr.so.1.1.0\nsystemd       1          root  mem       REG              253,1     19288     525996 /usr/lib64/libdl-2.17.so\nsystemd       1          root  mem       REG              253,1    402384     525931 /usr/lib64/libpcre.so.1.2.0\nsystemd       1          root  mem       REG              253,1   2156160\n由于lsof命令会输出很多信息，所以上面例子中使用了 lsof | more 来分页显示命令输出结果\n输出结果中，第一列中 systemd 的进程 ID 是 1,它是一个守护进程\n其中列 COMMAND 、PID、USER 分别表示进程名、进程 ID、所属用户\n列 FD 是文件描述符，下面是可能的类型以及说明\n\n\n\nFD\n说明\n\n\n\n\ncwd\n当前目录\n\n\ntxt\ntxt 文件\n\n\nrtd\nroot 目录\n\n\nmem\n内存映射文件\n\n\n\n列 TYPE 是文件类型，下面是可能的值以及说明\n\n\n\nTYPE\n说明\n\n\n\n\nDIR\n目录\n\n\nREG\n普通文件\n\n\nCHR\n字符\n\n\na_inode\nInode 文件\n\n\nFIFO\n管道或者 socket 文件\n\n\nnetlink\n网络\n\n\nunknown\n未知\n\n\n\n列 DEVICE 表示设备 ID\n列 SIZE/OFF 表示进程大小\n列 NODE 表示文件的 Inode 号\n列NAME 表示路径或者链接\n列出指定用户已打开的文件\n使用 -u 选项可以列出指定用户已经打开的文件，该选项后面可以接多个用户名，每个用户名之间用空格隔开，表示列出所有指定用户已打开的所有文件\n[root@ecs-centos-7 ~]# lsof -u tt | more\nCOMMAND   PID USER   FD   TYPE DEVICE  SIZE/OFF   NODE NAME\nbash    27789   tt  cwd    DIR  253,1      4096 131090 /home/tt\nbash    27789   tt  rtd    DIR  253,1      4096      2 /\nbash    27789   tt  txt    REG  253,1    964600 525779 /usr/bin/bash\nvim     27813   tt  txt    REG  253,1   2337192 531847 /usr/bin/vim\nvim     27813   tt    4u   REG  253,1     12288 131167 /home/tt/.p.txt.swp\n上面的例子中，lsof -u tt 命令表示列出 tt 用户已经打开了的文件，从结果可以看出，用户打开了 /home/tt、/、/usr/bin/bash、/usr/bin/vim、/home/tt/.p.txt.swp 这几个文件\n如果要排除指定用户已经打开的文件，可以在用户名前加 ^ 符号，下面的命令会列出除tt用户外其他所有用户已打开了的文件\nlsof -u ^tt | more\n找出打开着但已被删除了的文件\n有这样一种场景，有一个服务正在往日志文件中写日志，这个时候，不小心把正在写入的日志文件删除了\n上面的场景中，日志文件虽然被删除了，但是文件仍然是打开着的，它仍然占用文件系统的空间，我们可以结合 grep 命令找出这种打开着，但是已经被删除的文件\n[root@ecs-centos-7 ~]# lsof -u tt | grep deleted\nvim     27813   tt    4u   REG  253,1    12288 131167 /home/tt/.p.txt.swp(deleted)\n上面例子中使用 lsof -u tt | grep deleted 命令查看用户 tt打开着的确被删除的文件\n从结果可以看出，在往 p.txt写入内容的时候，文件被删除了\n列出所有打开了的网络文件\n[root@ecs-centos-7 ~]# lsof -i\nCOMMAND    PID  USER   FD   TYPE DEVICE SIZE&#x2F;OFF NODE NAME\nntpd       567   ntp   18u  IPv4  12657      0t0  UDP localhost:ntp\nntpd       567   ntp   22u  IPv6  16095      0t0  UDP ecs-centos-7.4-64bit-20200212:ntp\ndhclient   651  root    6u  IPv4  14594      0t0  UDP *:bootpc\nmaster     960  root   13u  IPv4  15791      0t0  TCP localhost:smtp (LISTEN)\nmaster     960  root   14u  IPv6  15792      0t0  TCP localhost:smtp (LISTEN)\nmysqld    1053 mysql   13u  IPv6  15147      0t0  TCP *:mysql (LISTEN)\nsshd      1348  root    3u  IPv4  16698      0t0  TCP *:ssh (LISTEN)\n\n\n列出所有 IPV4/6 网络文件\n\n\n列出所有已经打开了的 ipv4 网络文件\n[root@ecs-centos-7 ~]# lsof -i 4\nCOMMAND    PID USER   FD   TYPE DEVICE SIZE/OFF NODE NAME\nntpd       567  ntp   16u  IPv4  12651      0t0  UDP *:ntp\nntpd       567  ntp   18u  IPv4  12657      0t0  UDP localhost:ntp\nntpd       567  ntp   21u  IPv4  16094      0t0  UDP ecs-centos-7.4-64bit-20200212:ntp\ndhclient   651 root    6u  IPv4  14594      0t0  UDP *:bootpc\nmaster     960 root   13u  IPv4  15791      0t0  TCP localhost:smtp (LISTEN)\nsshd      1348 root    3u  IPv4  16698      0t0  TCP *:ssh (LISTEN)\n所有已经打开了的 ipv6 网络文件\n[root@ecs-centos-7 ~]# lsof -i 6\nCOMMAND  PID  USER   FD   TYPE DEVICE SIZE/OFF NODE NAME\nntpd     567   ntp   17u  IPv6  12652      0t0  UDP *:ntp\nntpd     567   ntp   19u  IPv6  12658      0t0  UDP localhost:ntp\nntpd     567   ntp   22u  IPv6  16095      0t0  UDP ecs-centos-7.4-64bit-20200212:ntp\nmaster   960  root   14u  IPv6  15792      0t0  TCP localhost:smtp (LISTEN)\nmysqld  1053 mysql   13u  IPv6  15147      0t0  TCP *:mysql (LISTEN)\nsshd    1348  root    4u  IPv6  16700      0t0  TCP *:ssh (LISTEN)\n\n\n列出在指定端口上打开的文件\n\n\n使用 lsof -i:端口号 可以获得所有在指定端口号上打开的文件\n[root@ecs-centos-7 ~]# lsof -i:22\nCOMMAND   PID USER   FD   TYPE DEVICE SIZE/OFF NODE NAME\nsshd     1348 root    3u  IPv4  16698      0t0  TCP *:ssh (LISTEN)\nsshd     1348 root    4u  IPv6  16700      0t0  TCP *:ssh (LISTEN)\nsshd    27741 root    3u  IPv4 458958      0t0  TCP ecs-centos-7.4-64bit-20200212:ssh->113.118.121.220:42395 (ESTABLISHED)\nsshd    27819 root    3u  IPv4 459250      0t0  TCP ecs-centos-7.4-64bit-20200212:ssh->113.118.121.220:19807 (ESTABLISHED)\nsshd    27895 root    3u  IPv4 459828      0t0  TCP\n上面例子列出了所有在 22 号端口上打开的文件\n在服务器开发中，经常会部署一个网关或者代理程序，用来和客户端通讯，网关或者代理程序需要开放一个固定的端口供客户端连接用\n如果客户端连接不上网关或者代理程序，我们可以用上述命令检查网关或代理程序的端口是否开启，来排除因为端口关闭了导致连接不上网关的情况\n\n\n列出使用了指定协议(TCP/UDP) 的文件\n\n\n使用 lsof -i TCP/UDP 列出使用了 TCP 或 UDP 协议的文件\n[root@cghost8 /home/cgyx]# lsof -i TCP | more\nCOMMAND      PID   USER   FD   TYPE  DEVICE SIZE/OFF NODE NAME\nsshd        1704   root    3u  IPv4   13593      0t0  TCP *:ssh (LISTEN)\nsshd        1704   root    4u  IPv6   13595      0t0  TCP *:ssh (LISTEN)\nredis-serer   1725   root    4u  IPv4   19773      0t0  TCP localhost:6380 (LISTEN)\nnc          2067   cgyx    4u  IPv4   39167      0t0  TCP *:60600 (LISTEN)\nmysqld      3020  mysql    4u  IPv6 5514608      0t0  TCP 192.168.70.10:mysql->192.168.70.10:37084 (ESTABLISHED)\n使用 lsof -i TCP:3306 列出使用了 TCP 协议并且端口为 3306 的文件\n[root@cghost8 /home/cgyx]# lsof -i TCP:3306\nCOMMAND      PID  USER   FD   TYPE  DEVICE SIZE/OFF NODE NAME\nmysqld      3020 mysql    4u  IPv6 5514608      0t0  TCP 192.168.70.10:mysql->192.168.70.10:37084 (ESTABLISHED)\n使用 lsof -i TCP:1-1024 列出使用了 TCP 协议并且端口范围为 1 到 1024 的文件\n[root@cghost8 /home/cgyx]# lsof -i TCP:1-1024\nCOMMAND   PID   USER   FD   TYPE  DEVICE SIZE/OFF NODE NAME\nsshd     1704   root    3u  IPv4   13593      0t0  TCP *:ssh (LISTEN)\nsshd     1704   root    4u  IPv6   13595      0t0  TCP *:ssh (LISTEN)\ncupsd    1709   root   12u  IPv6   39148      0t0  TCP localhost:ipp (LISTEN)\ncupsd    1709   root   13u  IPv4   39149      0t0  TCP localhost:ipp (LISTEN)\nsmbd     1824   root   35u  IPv6   17658      0t0  TCP *:microsoft-ds (LISTEN)\nsmbd     1824   root   36u  IPv6   17659      0t0  TCP *:netbios-ssn (LISTEN)\nsmbd     1824   root   37u  IPv4   17660      0t0  TCP *:microsoft-ds (LISTEN)\nsmbd     1824   root   38u  IPv4   17661      0t0  TCP *:netbios-ssn (LISTEN)\n列出目录中所有打开的文件\n可以使用lsof命令列出指定目录中的所有打开文件\n现有一个data目录 ,结构如下：\n[root@ecs-centos-7 tt]# tree data/\ndata/\n├── dira\n│   └── a.txt\n└── d.s\n\n1 directory, 2 files\n列出 data 目录中打开的文件\n[root@ecs-centos-7 tt]# lsof +D ./data/\nCOMMAND   PID USER   FD   TYPE DEVICE SIZE/OFF   NODE NAME\nbash    28473 root  cwd    DIR  253,1     4096 131146 ./data\nbash    28502 root  cwd    DIR  253,1     4096 131172 ./data/dira\nvim     28530 root  cwd    DIR  253,1     4096 131172 ./data/dira\nvim     28530 root    4u   REG  253,1    12288 131174 ./data/dira/.a.txt.swp\n\n[root@ecs-centos-7 tt]# lsof +d ./data/\nCOMMAND   PID USER   FD   TYPE DEVICE SIZE/OFF   NODE NAME\nbash    28473 root  cwd    DIR  253,1     4096 131146 ./data\nbash    28502 root  cwd    DIR  253,1     4096 131172 ./data/dira\nvim     28530 root  cwd    DIR  253,1     4096 131172 ./data/dira\n上面例子中，+D 和 +d 选项都是列出目录中打开的文件\n+D 选项会列出一个目录和其子目录中打开的文件，而 +d 选项只会列出当前目录下已打开的文件\n列出指定进程 ID 打开的文件\n进程 ID 是操作系统进程的唯一标识，以下命令列出了进程 ID 为 1053 相关的文件, 从结果中可以知道这个进程 ID 对应的进程是 MySQL\n[root@ecs-centos-7 ~]# lsof -p 1053\nCOMMAND  PID  USER   FD   TYPE             DEVICE  SIZE/OFF    NODE NAME\nmysqld  1053 mysql  cwd    DIR              253,1      4096 1055765 /var/lib/mysql\nmysqld  1053 mysql  rtd    DIR              253,1      4096       2 /\nmysqld  1053 mysql  txt    REG              253,1 251841448  534935 /usr/sbin/mysqld\nmysqld  1053 mysql  mem    REG              253,1    209512  659436 /usr/lib64/mysql/plugin/validate_password.so\nmysqld  1053 mysql    1w   REG              253,1    206658  924771 /var/log/mysqld.log\nmysqld  1053 mysql    2w   REG              253,1    206658  924771 /var/log/mysqld.log\n上述命令中，-p 选项后面可以指定多个进程 ID，每个进程 ID 之间用逗号分隔，如果想排除掉某个进程打开的文件，可以在该进程 ID 前面加上 ^符号\nlsof -p 1,2,3,^4\n上述命令会列出进程 1，进程 2，进程 3 打开的所有文件，同时忽略进程 4 打开的文件\n使用文件或文件结构识别进程\nfuser\n用于报告进程使用的文件和网络套接字。fuser 命令列出了本地进程的进程号，那些本地进程使用 file，参数指定的本地或远程文件。每个进程号后面都跟随一个字母，该字母指示进程如何使用文件。\n\n\nc ：指示进程的工作目录。\n\n\ne ：指示该文件为进程的可执行文件(即进程由该文件拉起)。\n\n\nf ：指示该文件被进程打开，默认情况下 f 字符不显示。\n\n\nF ：指示该文件被进程打开进行写入，默认情况下 F 字符不显示。\n\n\nr ：指示该目录为进程的根目录。\n\n\nm ：指示进程使用该文件进行内存映射，抑或该文件为共享库文件，被进程映射进内存。\n\n\n语法\nfuser(选项)(参数)\n\n选项:\n\t-a：显示命令行中指定的所有文件；\n\t-k：杀死访问指定文件的所有进程；\n\t-i：杀死进程前需要用户进行确认；\n\t-l：列出所有已知信号名；\n\t-m：指定一个被加载的文件系统或一个被加载的块设备；\n\t-n：选择不同的名称空间；\n\t-u：在每个进程后显示所属的用户名。\n\n参数:\n\t文件：可以是文件名或者TCP、UDP端口号。\n实例\n要列出使用/etc/passwd文件的本地进程的进程号，请输入：\nfuser /etc/passwd\n要列出使用/etc/filesystems文件的进程的进程号和用户登录名，请输入：\nfuser -u /etc/filesystems\n要终止使用给定文件系统的所有进程，请输入：\nfuser -k -x -u -c /dev/hd1  或者  fuser -kxuc /home\n任一命令都列出了进程号和用户名，然后终止每个正在使用/dev/hd1 (/home)文件系统的进程。仅有 root 用户能终止属于另一用户的进程。如果您正在试图卸下/dev/hd1文件系统，而一个正在访问/dev/hd1文件系统的进程不允许这样，您可能希望使用此命令。\n要列出正在使用已从给定文件系统删除的文件的全部进程，请输入：\nfuser -d /usr文件\n/dev/kmem 用于系统映像。\n/dev/mem 也用于系统映像。\n杀死指定用户的所有进程\n前面介绍了列出指定用户所有打开的文件，我们可以组合 kill 命令一起使用，实现杀死指定用户的所有进程的功能，具体的命令如下\nkill -9 `lsof -t -u tt`\n上述命令中，lsof -u tt 是列出tt用户所有打开的文件，加上 -t 选项之后表示结果只列出 PID 列，也就是进程 ID 列，其他列都忽略，前面的 kill -9 表示强制结束指定的进程 ID\nshell\necho\n用于字符串的输出\necho string\n\n#1.显示字符串\necho \"It is a test\"\n#这里的双引号完全可以省略，以下命令与上面实例效果一致\necho It is a test\n\n#2.显示转义字符\necho \"\\\"It is a test\\\"\"\n#结果\n\"It is a test\"\n\n#3.显示变量\n#read 命令从标准输入中读取一行,并把输入行的每个字段的值指定给 shell 变量\n#!/bin/sh\nread name\necho \"$name It is a test\"\n#以上代码保存为 test.sh，name 接收标准输入的变量，结果将是:\n[root@www ~]# sh test.sh\nOK                     #标准输入\nOK It is a test        #输出\n\n\n#4.显示换行\necho -e \"OK! \\n\" # -e 开启转义\necho \"It is a test\"\n#输出结果：\nOK!\n\nIt is a test\n\n\n#6.显示结果定向至文件\necho \"It is a test\" > myfile\n\n#7.原样输出字符串，不进行转义或取变量(用单引号)\necho '$name\\\"'\n#输出结果:\n$name\\\"\n\n\n#8.显示命令执行结果(使用反引号)\necho `date`\n\n后台运行任务\n任务日志打印\n0:标准输入 操作重定向符为&lt;\n1:标准输出(不指定的话默认省略)\n2:错误输出\n\n\n\n重定向操作符\n说明\n\n\n\n\n&gt;\n指定标准输出文件(即无报错输出)，若有则覆盖\n\n\n&gt;&gt;\n指定标准输出文件，若有则追加\n\n\n2&gt;\n错误重定向，如果重定向文件存在，则覆盖\n\n\n2&gt;&gt;\n错误重定向，如果重定向文件存在，则追加\n\n\n&amp;&gt;\n错误重定向和标准输出重定向一起操作，如果重定向文件存在，则覆盖\n\n\n&amp;&gt;&gt;\n错误重定向和标准输出重定向一起操作，如果重定向文件存在，则追加\n\n\n\n这个命令可以实现两个文件的合并\ncat helloWord1.txt >> helloWord2.txt\n&amp;1 表示标准输出的引用，所以 2&gt;&amp;1 是指把标准错误输出重定向到标准输出的引用，即也重定向到 file\n\n\n\n重定向操作符\n说明\n\n\n\n\ncmd &gt; filename 2&gt;&amp;1\n把标准输出和标准错误一起重定向到一个文件中。\n\n\ncmd &gt;&gt; filename 2&gt;&amp;1\n把标准输出和标准错误一起重定向到一个文件中(追加)。\n\n\ncmd &lt; filename\n输入重定向，命令的输入不是通过键盘来完成，而是通过其它方式实 现。cmd 命令以 filename 文件作为标准输入。\n\n\ncmd &lt; filename &gt; filename2\n把 cmd 命令以 filename 文件作为标准输入，以 filename2 文件作为标准 输出。\n\n\n\nnohup\n使进程后台不挂起运行（即用户退出登录后，进程仍然运行）\nnohup command [Args...] [&amp;]\n\ncommand ： 需要执行的命令\n[Args...] : 些参数，可以指定输出文件\n&amp; ：让命令在后台执行，终端正常退出后命令仍旧执行,即使用exit命令\n创建定时任务\ncron 和 crontab\ncron 是系统主要的非常好用的调度进程，它可以在无需人工干预的情况下运行作业。我们可以 通过 crontab 的命令提交、编辑或删除相应的作业。每一个用户都可以有一个 crontab 文件来保存 调度信息。可以使用它运行任意一个 shell 脚本或某个命令，可以是每小时运行一次，每一天、或 一周一次，这完全取决于用户自己。每一个用户都可以有自己的 crontab 文件，但在一个较大的 系统中，系统管理员一般会禁止这些文件，而只在整个系统保留一个这样的文件。系统管理员是 通过**/etc/cron.deny和/etc/cron.allow**这两个文件来禁止或允许用户拥有自己的 crontab 文件。\n如果我们把 test 用户加入到**/etc/cron.deny**文件中去：\n\n如果我们以 test 用户登录，然后配置 crontab，会得到下面的提示：\n\ncrontab 命令\ncrontab [-u user] file\n#或者\ncrontab [ -u user ] &#123; -l | -r | -e &#125;\n\nOptions:\n\t-u：用户名，一般不用，都是自己管理自己的crontab任务。\n\t-e：编辑(edit)crontab文件。\n\t-l：列出(list)crontab文件中的内容。\n\t-r：删除(remove)crontab文件。\n\n#如果使用自己的名字登录，就不用使用-u选项，因为在执行crontab命令时，该命令能够知道当前的用户。\ncrontab 的域\n为了能够在特定的时间运行作业，需要了解 crontab 文件每个条目的格式，以及其中各个域的 意义。下面就是这些域：\n\n\n\n列\n说明\n\n\n\n\n第 1 列\n分钟 1 ～ 59\n\n\n第 2 列\n小时 0 ～ 23（0 表示子夜）\n\n\n第 3 列\n日期 1 ～ 31\n\n\n第 4 列\n月份 1 ～ 12\n\n\n第 5 列\n星期 0 ～ 6（注意：0 表示星期天）\n\n\n第 6 列\n要运行的命令或者脚本\n\n\n\n下面是 crontab 的格式：\n分 时 日 月 星期几 要运行的命令或者要执行的脚本\n在这些域中，可以用横杠-来表示一个时间范围，例如你希望星期一至星期五运行某个作业， 那么可以在星期域使用1 - 5来表示。还可以在这些域中使用逗号,，例如你希望星期一和星期四 运行某个作业，只需要使用1, 4来表示。如果你对某个表示时间域没有特别的限定，也应该在该 域填入*。该文件的每一个条目必须含有 5 个时间域，而且每个域之间要用空格分隔。该文件中所有的注释行要在行首用#来表示。\n案例:\n# 表示每晚的21:30运行主目录目录下的cleanup.sh。\n30 21 * * * ~/cleanup.sh\n# 表示每月1、10、22日的4:45运行主目录目录下的backup.sh。\n45 4 1,10,22 * * ~/backup.sh\n# 表示每周六、周日的1:10运行一个find命令，查询日志文件然后删除\n10 1 * * 6,0 /bin/find / -name \"*.log\" -exec rm &#123;&#125; \\;\n# 表示在每天18:00至23:00之间每隔30分钟运行主目录目录下的check.sh。\n0,30 18-23 * * * ~/check.sh\n# 表示每星期六的23:59进行系统的重启(执行命令得写命令的绝对路径)\n59 23 * * 6 /sbin/reboot\n# 表示每分钟执行一次时钟同步。\n*/1 * * * * /usr/sbin/ntpdate ntp4.aliyun.com\n注意：如果是执行命令，请写命令的绝对路径，比如上面的 reboot、find 命令。 即/sbin/reboot,/bin/find\n其中当 第一列 为 _/n 时表示每 n 分钟个时间间隔执行一次，第二列为 _/n 表示每 n 小时个时间间隔执行一次，其余类推\n创建新的 crontab\n创建新的 crontab 可以直接编辑 crontab，也可以创建一个文件把 crontab 的内容写进入， 然后进行提交。\n创建一个文件“mycron”，然后输入下面的内容：\n# 每隔一分钟将当前时间写入主目录下面的system.log文件\n*/1 * * * * /bin/echo `date` >> ~/system.log\n向“crontab”提交 mycron 文件\ncrontab mycron\nat\nat 命令允许用户向 cron 守护进程提交作业，使其在稍后的时间运行。这里稍后的时间可能是指 10min 以后，也可能是指几天以后。如果你希望在一个月或更长的时间以后运行，最好还是使用 crontab 文件。\n一旦一个作业被提交， at 命令将会保留所有当前的环境变量，包括路径，不象 crontab，只提 供缺省的环境。该作业的所有输出都将以电子邮件的形式发送给用户，除非你对其输出进行了重 定向，绝大多数情况下是重定向到某个文件中。\nat 在系统中可能是没有安装的,如果需要使用,则需要使用yum或者apt进行安装,然后使用systemctl开启atd服务,并最好设置其随着系统启动而启动\n# 安装at。\nyum -y install at\n# 设置atd服务随机启动\nsystemctl enable atd\n# 启动atd服务\nsystemctl start atd\n语法\nat [options] [-f file] [time] [date]\n\n\tOptions:\n\t\t-V：显示作业将被执行的时间。\n\t\t-q：选队列名称，队列名称可以是a-z和A-Z之间的任意字母。队列字母顺序越高，则队列优\n先级别越低。\n\t\t-f：从文件中读取命令或Shell脚本。\n\t\t-l：(list)列出当前所有等待运行的作业。atq命令具有相同的作用。\n\t\t-r：(remove)清除作业。为了清除某个作业，还要提供相应的作业标识(id)。\n\t\t-m：执行完作业后发送电子邮件到用户。\n\t  date：日期格式可以是月份数或日期数，而且at命令还能够识别诸如today、tomorrow这\n样的词。\n      time：设定作业执行的时间。time选项可以是下面格式中的任何一种。\n        1、HH:MM格式，例如04:00，代表4:00AM。如果时间已过，就会在第二天的这一时间执\n行。\n        2、midnight代表12:00AM、teatime代表4:00PM。\n        3、英文月名日期年份格式，例如 January 15 2022，代表2022年1月15\n\t\t4、MMDDYY、MM/DD/YY 或 MM.DD.YY格式，如051522，代表2022年5月15日。\n\t\t5、now +时间格式，时间以minutes、hours、day或 weeks为单位。如now +5 days，代\n表命令应该在5天之后的此时此刻执行。此种格式可以写为“时间＋偏移量”的形式，偏移量\n的单位是minutes、 hours和 days。\nat 提交命令或脚本\n使用 at 命令提交作业有几种不同的形式，可以通过命令行方式，也可以使用at 命令提示符。一 般来说在提交若干行的系统命令时，我使用 at 命令提示符方式，而在提交 shell 脚本时，使用命令 行方式。\n如果你想提交若干行的命令，可以在 at 命令后面跟上日期/时间并回车。然后就进入了 at 命令提 示符，这时只需逐条输入相应的命令，然后按“CTRL - D”退出。\n1.打印当前时间到主目录下面的 system.log 文件。\n# 设要执行的时间\nat -m 00:02\n# 设置要执行的语句\necho `date` >> ~/system.log\n\n其中， 就是。在 00:02 系统将执行我们指定的命令。你应当已经注意到，我所提交的作业被分 配了一个唯一标识 job4。并且提示我们了，这个 job 具体的执行时间。该命令在完成以后会将全 部结果以邮件的形式发送给我。\n2.如果希望向 at 命令提交一个 shell 脚本，使用其命令行方式即可，在提交脚本时使用-f 选项。\n# 将下面的内容写入~/my_at.sh文件\nfind / -name \"*.txt\" > ~/result.log\n\n# 今天晚上的23:59执行主目录下面的my_at.sh\nat 23:59 -f ~/my_at.sh\n3.可以使用管道符来提交 at 作业\nfind /root/ -name \"*.txt\" | at now +1 minute\n下面这些日期/时间格式都是 at 命令可以接受的：\n# 四月16号的早上6:45分触发\nat 6:45am April 16\n# 晚上的10:10触发\nat 10:10pm\n# 两分钟后触发\nat now + 2 minutes\n# 一个小时后触发\nat now + 1 hour\n# 明天上午九点触发\nat 9:00am tomorrow\n\n# yesterda是无效的。\nat 9:00am yesterday\n列出所提交的作业\nat -l\n#或\natq\n\n**注意：**其中，第一列是作业标识也就是 ID，后面是作业运行的日期/时间。第三列 a 代表 at，最后 一列代表谁提交的作业。如果作业已经运行完了，这里面是看不见的，也就是里面的 id 为什么不 连贯的原因。\n当提交一个作业后，它就被拷贝到**/var/spool/at**目录中，准备在要求的时间运行。我们发现 里面正好有四个文件，就对应我们提交的四个作业。\necho &amp;变量名\n\n\n# 定义变量\nhello=\"world\"\n\n# 打印变量\necho $hello\nset\nunset variable_name\n文件\n文件的基本属性\nd rw- rw- r--   1   nd_ljq   nd_ljq   110   Sep 12 18:20   javaTest\n\n\n第一个字符代表这个文件是目录,文件,链接文件等\n\n\nd 目录\n- 文件\nl 链接文件\nb 可供存取的接口设备\nc 表示串行的端口设备\n\n\n接下来的三组都是以 rwx的三个参数的组合(没有权限则是-号)\n\n\nr代表可读(readable) 4\nw代表可写(writable) 2\nx代表可执行(executable) 1\n第一组rwx:所有者权限(owner)\n第二组rwx:组权限(group)\n第三组rwx:其他用户权限(other)\n为文件添加软/硬链接\n#在linux中链接相当于windows中的快捷方式\n#在linux中存在两种不同的链接:分别是`软链接`和`硬链接`\n硬链接:是指同一个系统中的两个文件修改其中一个文件内容另一个文件也会改变 即两个文件指向一个node\n\n软链接:又被称作符号链接,他是一个指向文件的指针,这个指针代表一个初始状态与指向文件一致的文件,修改软链接的内容,指向文件的内容不变\n\n简而言之，硬链接是指两个文件指向同一个 inode，而软链接是指一个文件指向另一个文件的路径(更像快捷方式)\n\nln [-s] source_path target_path\n\n -s :soft 创建软链接\n\n\n例:\nifcfg-ens33文件用于配置网络信，但是这个文件目录比较深，所以我们可以设置这个文件的链接文件。\n\nln -s /etc/sysconfig/network-scripts/ifcfg-ens33 my-ifcfg-ens33\n修改文件权限\n符号格式:\nchmod [who]operator[permission] filename\n\nwho的选项是\n\tu:文件属主的权限\n\tg:同组用户权限\n\to:其他用户权限\n\ta:所有用户权限\n\noperator的选项是:\n\t+ :增加权限\n\t- :取消权限\n\t= :设定权限\n\npermission的选项是:\n\tr :读权限(4)\n\tw :写权限(2)\n\tx :执行权限(1)\n\n\n绝对模式:\nchmod 第一组权限数字(累加)第二组权限数字(累加)第三组权限数字(累加) fileName\n修改文件所属用户/组\n#更改所有者\nchown [-options] userName fileName\n\n#更改所属组\nchgrp [-options] groupName fileName\n\noptions:\n\tR: 对所有子目录下的文件都进行同样操作\n\th: 改变符号链接文件的属主不影响\n查看当前目录绝对路径\npwd;\n拷贝文件/文件夹到指定目录\ncp [options] source dest\ncp [options] source dir\n\noptions:\n    -a：此选项通常在复制目录时使用，它保留链接、文件属性，并复制目录下的所有内容。其作用等于dpR参数组合。\n    -d：复制时保留链接。这里所说的链接相当于 Windows 系统中的快捷方式。\n    -f：覆盖已经存在的目标文件而不给出提示。\n    -i：与 -f 选项相反，在覆盖目标文件之前给出提示，要求用户确认是否覆盖，回答 y 时目标文件将被覆盖。\n    -p：除复制文件的内容外，还把修改时间和访问权限也复制到新文件中。\n    -r：若给出的源文件是一个目录文件，此时将复制该目录下所有的子目录和文件。\n    -l：不复制文件，只是生成链接文件。\n拷贝文件到远程服务器\nscp [options] fileName/dir targetPath\n\noptions:\n\t-C:使用压缩\n\t-P:指定远程主机号\n\t-p:保留文件最后修改时间,最后访问时间和权限模式\n\t-q:不显示复制进程\n\t-r:以递归的方式复制\n\n# 普通文件\nscp source user@hostname:filePath(fileName)\n# 拷贝目录需要使用-r。\nscp -r source user@hostname:filePath(fileName)\n# 除了使用主机名也可以用IP地址\nscp -r source user@ip:filePath(fileName)\n剪切文件/文件夹\nmv [options] source dest\n\noptions:\n\t-b: 当目标文件或目录存在时，在执行覆盖前，会为其创建一个备份。\n\t-i: 如果指定移动的源目录或文件与目标的目录或文件同名，则会先询问是否覆盖旧文件，输\n入 y 表示直接覆盖，输入 n 表示取消该操作。\n\t-f: 如果指定移动的源目录或文件与目标的目录或文件同名，不会询问，直接覆盖旧文件。\n\t-n: 不覆盖任何已存在的文件或目录。\n\t-u：当源文件比目标文件新或者目标文件不存在时，才执行移动操作\n查看当前目录下的文件/文件夹信息\nls [options] fileName/condition\n\noptions:\n\t-l:除文件名其文件的所有信息全部列出(文件形态,权限,拥有者,文件大小等)  ==> ll = ls -l\n\t-t:按照创建时间依次列出\n\t-a:列出目录下所有文件夹名(包括隐藏文件)\n\t-R:递归显示当前目录下的文件和子目录\n  \t-h:以人类可读的方式显示当前目录中的文件和目录大小\n创建文件/文件夹\n创建文件:\nvim fileName\ntouch fileName1 [fileName2 ...]\n\n创建目录(文件夹):\nmkdir dirName\n删除文件夹/文件\nrm [options] fileName/dirName\n\noptions:\n\t-i:删除前逐个询问\n\t-r:将目录以及以下的文件遍历删除\n\t-f:即使文件为只可读也直接删除,无需确认 (-force)\n统计目录/文件大小\ndu [-options] [fileName/dirName]\n\noptions:\n\ta或-all 显示目录中个别文件的大小。\n\tb或-bytes 显示目录或文件大小时，以byte为单位。\n\th或--human-readable 以K，M，G为单位，提高信息的可读性。\n\tk或--kilobytes 以1024 bytes为单位。\n\tl或--count-links 重复计算硬件连接的文件。\n\tm或--megabytes 以1MB为单位。\n\ts或--summarize 仅显示总计。\n\t--exclude=&lt;目录或文件> 略过指定的目录或文件。\n\t--max-depth=&lt;目录层数> 超过指定层数的目录后，予以忽略。\n\t--help 显示帮助。\n查找文件\nfind\nfind命令与locate命令相比各有各的优缺点，locate命令的优点就是查找速度比find命令快的多，但是缺点也比较明显，locate命令无法查找最新添加的文件/目录以及会查找出来已经过期的文件/目录。\n相反find命令的优点就是可以按照自定义的方法查找任何文件，缺点就是查询速度比较慢，因为是通过遍历硬盘来查找而不像locate命令事先建立好数据库来进行查找。\nfind path -options [-print] [-exec command /-ok command &#123;&#125; \\ ]\n\n\t-exec: 将前面查询到的文件交给 exec后的命令完成\n\t-ok:将前面查询到的文件交给 ok 后的命令完成 (安全,执行一次,询问一次)\n\t但是性能较低,做一次操作创建一个进程,而且有参数长度限制(文件过多执行出错)\n\t推荐使用:\n\t\tfind path -options | xargs command\n\t\t在使用xargs命令时，究竟是一次获取所有的参数，还是分批取得参数，以及每一次获取参数的数目都会根据该命令的选项及系统内核中相应的可调参数来确定。\n\n\n\noptions:\n\tname/iname : 文件名符合name的文件,iname会忽略大小写\n\tpath/ipath : 路径名符合p的文件,ipath会忽略大小写\n\tempty : 空的文件夹,或者是空目录\n\tsize [+/-]n:文件大小是(大于/小于)n的文件\n\ttype c:文件类型是c的文件,类型:f(文件),d(目录),l(链接)\n\tuser : 按照文件属于的用户来查找文件\n    nouser : 查找无效用户的文件(userdel删除用户时没有-r)\n    group : 按照文件所属的组来查找文件\n    mtime -/+ n :按照文件的更改时间来查找文件(-n表示距离现在n天以内 +n代表更改时间距现在n天以前)\n\tperm : 按照文件权限来查找文件\n\n\n例:\n\t想要在/etc目录中查找文件名以host开头的文件\n\tfind /etc -name \"host*\"\n\nlocate\nlocate命令要比其他查找文件命令（例如:find）快得多，原因在于它不搜索具体目录，而是搜索一个数据库/var/lib/mlocate/mlocate.db。\n/var/lib/mlocate/mlocate.db这个数据库中含有本地所有文件信息。Linux 系统自动创建这个数据库，并且每天自动更新一次，因此，我们在用locate查找文件时，有时会找到已经被删除的数据，或者刚刚建立文件，却无法查找到，原因就是因为数据库文件没有被更新。为了避免这种情况，可以在使用locate之前，先使用**updatedb**命令，手动更新数据库。\nlocate　命令参数　文件/目录\n\n\t参数列表:\n\t\t-c, --count            只输出找到的数量；\n\t\t-d, --database DBPATH  使用DBPATH指定的数据库，而不是默认数据库/var/lib/mlocate/mlocate.db；\n\t\t-i, --ignore-case      忽略大小写；\n\t\t-q, --quiet            安静模式，不会显示任何错误讯息；\n\t\t-e, --existing         只显示当前存在的文件条目；\n案例演示1：\n搜索etc目录下以pass开头的文件或目录，具体使用如下命令：\nlocate /etc/pass\n案例演示２：\n搜索包含passwd字母的文件或目录总个数，具体使用如下命令：\nlocate -c passwd\n管道符\nsomecommand |\n查看文件\n查看文件类型\nfile filePath\n\n[nd_ljq@ROOT ~]$ file part-r-00000\npart-r-00000: ASCII text\n[nd_ljq@ROOT ~]$ type ifconfig\nifconfig is /usr/sbin/ifconfig\n[nd_ljq@ROOT ~]$ file /usr/sbin/ifconfig\n/usr/sbin/ifconfig: ELF 64-bit LSB shared object, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, for GNU/Linux 3.2.0, BuildID[sha1]=96ce19fd01f2ed4f0a677a4b412ba28142d7ac3b, stripped, too many notes (256)\n\nps: ELF全称为(Executable and Linkable Format)\n\t相当于window中的exe可执行文件\n查找文件位置\nwhich\nwhich命令主要是用来查找系统PATH目录下的可执行文件，说白了就是查找那些我们已经安装好的可以直接执行的命令。\nwhich命令用于查找并显示给定命令的绝对路径，环境变量PATH中保存了查找命令时需要遍历的目录。which指令会在环境变量$PATH设置的目录里查找符合条件的文件。也就是说，使用which命令，就可以看到某个系统命令是否存在，以及执行的到底是哪一个位置的命令。\nwhich是shell内建命令，内建命令要比系统论命令有比较高的执行效率。\nwhich　需要查找的命令\nwhereis\nwhereis命令可以用来查找二进制（命令）、源文件、man文件。与which不同的是这条命令可以是通过文件索引数据库而非PATH来查找的，所以查找的面比which要广。\nwhereis [options] [-B &lt;目录>...] [-M &lt;目录>...] [-S &lt;目录>...] [文件...]\n\noptions:\n-b 　只查找二进制文件。\n-f 　不显示文件名前的路径名称。\n-m 　只查找说明文件。\n-s 　只查找原始代码文件。\n-u 　查找不包含指定类型的文件。\n\n-B&lt;目录> 　只在设置的目录下查找二进制文件。\n-M&lt;目录> 　只在设置的目录下查找说明文件。\n-S&lt;目录> 　只在设置的目录下查找原始代码文件。\n\nps:该指令只能用于查找二进制文件、源代码文件和man手册页\n\n查看(小)文件内容并打印到控制台\ncat [options] fileName\n\noptions:\n\t-n:显示行号\n\t-b:只显示有内容行的行号,忽略无内容行\n查看(大)文件内容并打印到控制台\nless [options] fileName\n\n按Q键退出less命令\n/字符串：向下搜索\"字符串\"的功能\n?字符串：向上搜索\"字符串\"的功能\nn：重复前一个搜索（与 / 或 ? 有关）\nN：反向重复前一个搜索（与 / 或 ? 有关）\nb 向上翻一页\nd 向后翻半页\nh 显示帮助界面\nQ 退出less 命令\nu 向前滚动半页\ny 向前滚动一行\n空格键 滚动一页\n回车键 滚动一行\noptions:\n\t-i:忽略大小写\n\t-e:文件显示完自动退出\n\t-g:只显示搜索到的最后一个关键词\n\t-N:显示每行行号\n查看文件头/尾\nhead/tail [options] fileName\n\noptions:\n\t-c number:只查看前/后number个字符\n查看文件尾\n在屏幕上显示指定文件的末尾若干行\ntail 命令 用于输入文件中的尾部内容。\n\n\n默认在屏幕上显示指定文件的末尾 10 行。\n\n\n处理多个文件时会在各个文件之前附加含有文件名的行。\n\n\n如果没有指定文件或者文件名为-，则读取标准输入。\n\n\n如果表示字节或行数的NUM值之前有一个+号，则从文件开头的第NUM项开始显示，而不是显示文件的最后NUM项。\n\n\nNUM值后面可以有后缀：\n\nb : 512\nkB : 1000\nk : 1024\nMB : 1000 * 1000\nM : 1024 * 1024\nGB : 1000 _ 1000 _ 1000\nG : 1024 _ 1024 _ 1024\nT、P、E、Z、Y等以此类推。\n\n\n\n语法\ntail (选项) fileName\n\n选项:\n\t-c, --bytes=NUM                 输出文件尾部的NUM（NUM为整数）个字节内容。\n\t-f, --follow[=&#123;name|descript&#125;]  显示文件最新追加的内容。“name”表示以文件名的方式监视文件的变化。\n\t-F                              与 “--follow=name --retry” 功能相同。\n\t-n, --line=NUM                  输出文件的尾部NUM（NUM位数字）行内容。\n\t--pid=&lt;进程号>                  与“-f”选项连用，当指定的进程号的进程终止后，自动退出tail命令。\n\t-q, --quiet, --silent           当有多个文件参数时，不输出各个文件名。\n\t--retry                         即是在tail命令启动时，文件不可访问或者文件稍后变得不可访问，都始终尝试打开文件。使用此选项时需要与选项“--follow=name”连用。\n\t-s, --sleep-interal=&lt;秒数>      与“-f”选项连用，指定监视文件变化时间隔的秒数。\n\t-v, --verbose                   当有多个文件参数时，总是输出各个文件名。\n\t--help                          显示指令的帮助信息。\n\t--version                       显示指令的版本信息。\n实例\ntail file #（显示文件file的最后10行）\ntail -n +20 file #（显示文件file的内容，从第20行至文件末尾）\ntail -c 10 file #（显示文件file的最后10个字节）\n\ntail -25 mail.log # 显示 mail.log 最后的 25 行\ntail -f mail.log # 等同于--follow=descriptor，根据文件描述符进行追踪，当文件改名或被删除，追踪停止\ntail -F mail.log # 等同于--follow=name --retry，根据文件名进行追踪，并保持重试，即该文件被删除或改名后，如果再次创建相同的文件\n拓展:\ntailf命令\n在屏幕上显示指定文件的末尾若干行内容，通常用于日志文件的跟踪输出\n补充说明\ntailf 命令几乎等同于tail -f，严格说来应该与tail --follow=name更相似些。当文件改名之后它也能继续跟踪，特别适合于日志文件的跟踪（follow the growth of a log file）。与tail -f不同的是，如果文件不增长，它不会去访问磁盘文件。tailf 特别适合那些便携机上跟踪日志文件，因为它能省电，因为减少了磁盘访问。tailf 命令不是个脚本，而是一个用 C 代码编译后的二进制执行文件，某些 Linux 安装之后没有这个命令。\ntailf 和 tail -f 的区别\n\n\ntailf 总是从文件开头一点一点的读， 而 tail -f 则是从文件尾部开始读\n\n\ntailf check 文件增长时，使用的是文件名， 用 stat 系统调用；而 tail -f 则使用的是已打开的文件描述符； 注：tail 也可以做到类似跟踪文件名的效果； 但是 tail 总是使用 fstat 系统调用，而不是 stat 系统调用；结果就是：默认情况下，当 tail 的文件被偷偷删除时，tail 是不知道的，而 tailf 是知道的。\n\n\n语法\ntailf logfile # 动态跟踪日志文件logfile，最初的时候打印文件的最后10行内容。\n选项\n-n, --lines NUMBER  # 输出最后数行\n-NUMBER             # 与NUMBER相同 `-n NUMBER'\n-V, --version       # 输出版本信息并退出\n-h, --help          # 显示帮助并退出\n参数\n目标：指定目标日志。\n实例\ntailf log/WEB.LOG\ntailf -n 5 log2014.log   # 显示文件最后5行内容\n统计文件行数/单词数/字节数\nwc [options] fileName\n\noptions:\n\t-l:仅查看行数\n\t-w:仅查看单词数\n\t-c:仅查看bytes数\n编辑文件\n创建文件/修改文件修改时间\ntouch fileName\nvim [options] path fileName\n有该文件则编辑,无该文件则创建\n\noptions:\n\t+:进入vim后直接定位到文件的最后一行\n\t\"+\"+number:定位到第number行\n\n按I进入插入模式\n按ESC退出插入模式,进入命令模式\n\n:x 保存退出\n:w 保存\n:q 退出\ndd 删除光标所在的一行\n:number 定位到第number行\n:set nu 显示行号\n文件的归档\ngzip\ngzip [options] [&lt;压缩效率>] [--best/fast] [文件/目录]\n\noptions:\n\t-d:(decompress/uncompress)解开压缩文件。\n\t-f:(force)强行压缩文件,不理会文件名称或硬链接是否存在,以及改文件是否为符号连接\n\t-l:(list)列出压缩文件的相关信息\n\t-n:(no-name)压缩文件时，不保存原来的文件名称及时间戳记。\n\t-N:(name)压缩文件时，保存原来的文件名称及时间戳记。\n\t-r:(recursive)递归处理，将指定目录下的所有文件及子目录一并处理。注意他的递归是把单个文件压缩,而不是一个整包\n\t-v:(verbose)显示指令执行过程\n\n#压缩效率\n\t压缩效率是一个介于1~9的数值,预设值为`6`,指定越大的数,压缩程度越高,速度越慢\ntar\ntar [options] fileName\noptions:\n\t-z:使用gzip处理压缩文件\n\t-x:(extract)从压缩文件中还原文件\n\t-v:(verbose)显示指令执行过程\n\t-j: 支持bzip2解压文件\n\t-f:指定归档文件名称\n\t在参数 f 之后的文件档名是自己取的，我们习惯上都用 .tar 来作为辨识。 如果加 z 参数，则以 .tar.gz 或 .tgz 来代表 gzip 压缩过的 tar包； 如果加 j 参数，则以 .tar.bz2 来作为tar包名。\n\t-c:(create)建立新的归档文件。\n\t-t:显示tar包中的文件列表\n文本的操作\n正则表达式\n元字符集\n\n\n\n元字符\n说明\n\n\n\n\n^\n只匹配行首\n\n\n$\n只匹配行尾\n\n\n.\n匹配任意字符串\n\n\n[]\n匹配[]内字符.可以是一个单字符串符，也可以是字符序列。可以使用-表示[ ]内字符序 列范围，如用[1-5]代替[12345]。[A-Z]\n\n\n\\\n转义字符，因为有时在 Linux 中一些元字符有特殊含义。”\\“可以使其失去应有意 义。\n\n\n\ngrep\ngrep(全局正则表达式)\ngrep [OPTIONS] PATTERN [FILE...]\n\nOPTIONS:\n\t-c：只输出匹配行的计数。\n\t-i：不区分大小写（只适用于单字符）。\n\t-h：查询多文件时不显示文件名。\n\t-l：查询多文件时只输出包含匹配字符的文件名。\n\t-n：显示匹配行及行号。\n\t-s：不显示不存在或无匹配文本的错误信息。\n\t-v：显示不包含匹配文本的所有行。\npattern 正则表达式主要参数\n\n\n\npattern\n含义\n\n\n\n\n\\\n忽略正则表达式中特殊字符的原有含义，用于转义\n\n\n^\n匹配正则表达式的开始行。\n\n\n$\n匹配正则表达式的结束行。\n\n\n&lt;\n从匹配正则表达式的开始。\n\n\n&gt;\n到匹配正则表达式的结束。\n\n\n[]\n单个字符，如[A]即 A 符合要求 。\n\n\n[-]\n范围，如[A-Z]，即 A、B、C 一直到 Z 都符合要求 。\n\n\n.\n所有的单个字符。\n\n\n*\n有字符，长度可以为 0。\n\n\n\n双引号引用\n在 grep 命令中输入字符串参数时，最好将其用双引号括起来。例如：“mystring”。这样做有两 个原因，一是以防被误解为 shell 命令，二是可以用来查找多个单词组成的字符串，例如：“my string”，如果不用双引号将其括起来，那么单词 string 将被误认为是一个文件，查询结果将返回 “文件不存在”的错误信息。\n查询多个文件\n如果要在当前目录下所有. txt 文件中查找字符串“test”，我们可以使用通配符，方法如下：\ngrep \"test\" *.txt\n行匹配数\n我们可以使用”-c“来查询匹配到的行数据。\n案例：查询 data.txt 文件中出现 48 的行数。\ngrep -c \"48\" data.txt\n显示行数据\n显示满足匹配模式的所有行行数。\n案例：查询 data.txt 文件中出现 48 的行的数据\ngrep -n \"48\" data.txt\n精确匹配\n在上一例中，抽取字符串“48”，返回结果包含诸如 484 和 483 等包含“48”的 其他字符串，实际上应精确抽取只包含 48 的各行。注意在每个匹配模式中抽取字符串后有一个 Tab 键，所以应操作如下：\n# 使用grep抽取精确匹配的方式是在抽取字符串后加”\\>”。\ngrep \"48\\>\" data.txt\n模式出现机率\n\n抽取包含数字 4 至少重复出现两次的所有行\n# 以前可以这么写\ngrep '44' data.txt\n# 也可以这么写。\ngrep '4\\&#123;2,\\&#125;' data.txt\n与/或模式\ngrep 命令加-E 参数，这一扩展允许使用扩展模式匹配。\n案例：要获取城市代码为 219 或 216。\n# 这么写不行。\ngrep \"[219][216]\" data.txt\n#\ngrep -E '219|216' data.txt\n查询文件名\n有时候按照一定个格式去查找对应的文件，是一件很常用的使用场景，比如我们只是依稀记得 文件名，但是不知道它在哪里，这个时候就可以结合 grep 来进行查找。\n案例 1：查找系统中所有的文件，并且这些文件的文件名要求：”以小写字母开头，然后接数字者 字母最多十位，然后一个点，文件的后缀是 2 到 4 位的小字母“，比如”test1.docx“\n# 第一步：查询到文件\nfind / -type f\n# 第二步：获取文件的文件名\nfind / -type f -exec basename &#123;&#125; \\;\n# 第三步：进行文件名的过滤。\nfind / -type f -exec basename &#123;&#125; \\; | grep '[a-z][a-zA-Z0-9]\\&#123;1,9\\&#125;\\.\n[a-z]\\&#123;2,4\\&#125;'\n# 第4步：进行前后的限定。\nfind / -type f -exec basename &#123;&#125; \\; | grep '^[a-z][a-zA-Z0-9]\\&#123;1,9\\&#125;\\.\n[a-z]\\&#123;2,4\\&#125;$'\n\n类名\n我们上面查找文件的时候，文件名可以是数字或者大小写字母，我们写的正则表达式是”[a-zA-Z0-9]“，这种写法其实是比较麻烦的，grep 允许使用国际字符模式匹配或匹配模式的类名形式。\n类名及其等价的正则表达式\n\n\n\n类\n等价的正则表达式\n\n\n\n\n[[:upper:]]\n[A-Z]\n\n\n[[:lower:]]\n[a-z]\n\n\n[[:digit:]]\n[0-9]\n\n\n[[:alnum:]]\n[0-9a-zA-Z\n\n\n[[:alpha:]]\n[a-zA-Z]\n\n\n[[:space:]]\n空格或 tab 键\n\n\n\ngrep 命令的应用\n要查询其他用户和其他用户组成员有可执行权限的文件集合。\nls -al | grep '^\\-.....x..x'\nawk\nawk 是所有 shell 文本过滤工具\n语法\nawk [OPTION] 'script' var=value file(s) [> filename]\n或\nawk [OPTION] -f scriptfile var=value file(s) [> filename]\n\nOPTION:\n\t-F fs:指定输入文件折分隔符，fs是一个字符串或者是一个正则表达式，如-F:。\n\t-v var=value:赋值一个用户定义变量。\n\t-f scripfile:从脚本文件中读取awk命令。\n\t-W re-interval:允许间隔正则表达式的使用，参考(grep中的Posix字符类)，如括号表达式[[:alpha:]]\n\n\tfile(s):可以是一个文件,也可以是多个文件\n\t[> filename]:将前面输出在控制台的内容存入指定文件中\n如果设置了 -F 选项，则 awk 每次读一条记录或一行，并使用指定的 分隔符 分隔指定域，如果未设 置-F 选项，awk 假定 空格 为域分隔符，以这种格式读取数据，一直这么读取数据一直到文件末尾。\n48 Dec 3BC1997 LPSX 68.00 LVX2A 138\n483 Sept 5AP1996 USP 65.00 LVX2c 189\n47 Oct 3ZL1998 LPSX 43.00 KVM9D 512\n219 dec 2CC1999 CAD 23.00 PLV2C 68\n484 nov 7PL1996 CAD 49.00 PLV2C 234\n483 may 5PA1998 USP 37.00 KVM9D 644\n216 sept 3ZL1998 USP 86.00 KVM9E 234\n参照上表，awk 每次在文件中读一行，找到域分隔符（这里是符号 '\\t' ），设置其为域 n，直至一 新行（这里是缺省记录分隔符），然后，划分这一行作为一条记录，接着 awk 再次启动下一行读进程。\n模式和动作\nawk 语句都由模式 和 动作 组成。在一个 awk 脚本中可能有许多语句，模式部分决定动作语句何时 触发，模式部分可以省略。处理即对数据进行的操作。\n模式可以是任何条件语句或复合语句或正则表达式。模式包括两个特殊字段 BEGIN 和 END 。使用 BEGIN 语句设置 计数 和 打印头 。BEGIN 语句使用在任何文本浏览动作之前，之后文本浏览动作依据 输入文件开始执行。END 语句用来在 awk 完成文本浏览动作后 输出文本总数 和 结尾状态标志 。如果 不特别指明模式， awk 总是匹配或打印行数。\n实际动作在大括号 &#123;&#125; 内指明。动作大多数用来打印，但是还有些更长的代码诸如 if 和循环 （looping）语句及循环退出结构。如果不指明采取动作，awk 将打印出所有浏览出来的记录。\n域和记录\nawk 执行时，其浏览域标记为 $1，$2…$n。这种方法称为域标识。使用这些域标识将更容易对域 进行进一步处理。使用$1,$2 表示参照第 1 和第 2 域，注意这里用逗号做域分隔。如果希望打印一个有 7 个域的记录的所有域，不必指明$1, $2, $3, $4, $5, $6, $7，可使用$0 即所有域。\n如果要打印一个域或所有域，使用 print 命令，其这是一个 awk 动作（动作语法用大括号‘{}’括起 来）。\n#以tab来切割data.txt，然后获取第1个域的值\nawk -F '\\t' '&#123;print $1&#125;' data.txt\n\n#由于tab其实也是空格，所以我们不指定-F也行，所以也可以这么写。\nawk -F '&#123;print $1&#125;' data.txt\n\n#在上面的例子为基础进行修改，我们取第一，第二，第三个域。\nawk '&#123;print $1,$2,$3&#125;' data.txt\n\n\n\nps:$0表示所有域\n头部与尾部\n我们上面使用了 TAB 来进行域之间的分隔，也可以为输出文本加入信息头与尾信息，打印信息头放 置在 BEGIN 模式部分，因为打印信息头被界定为一个动作，必须用大括号括起来。如果要打印尾部信 息我们可以使用 END 语句。END 语句在所有文本处理动作执行完之后才被执行。\n#打印月份与价格的域信息，并且添加头与尾部的信息\nawk 'BEGIN &#123;print \"Month\\tPrice\"&#125; &#123;print $2\"\\t\"$5&#125;' data.txt\n\n#加入尾部信息：\nawk 'BEGIN &#123;print \"Month\\tPrice\"&#125; &#123;print $2\"\\t\"$4&#125; END &#123;print \"end...\"&#125;' data.txt\n当第一次使用 awk 时，如果出现错误可能不知所措，但是使用久了就会发现，可总结出以下规则， 可以帮助我们减少错误的出现。\n\n\n确保整个 awk 命令用单引号括起来。\n\n\n确保命令内所有引号成对出现。\n\n\n确保用花括号括起动作语句，用圆括号括起条件语句。\n\n\nAWK 中的正则表达式\n元字符\nawk 中正则表达式匹配操作中经常用到的字符，这些字符是有特殊含义的，\n\\ ^ $ . [] | () * + ?\n这里有两个字符前面的章节提到过讲到，注意它们只适用于 awk。\n\n\n\n元字符\n说明\n\n\n\n\n+\n使用+匹配一个或多个字符。\n\n\n?\n匹配模式出现频率。例如使用/XY?Z/匹配 XYZ 或 XZ。\n\n\n\n条件操作符\n\n\n\n操作符\n描述\n\n\n\n\n&lt;\n小于\n\n\n&gt;\n大于\n\n\n&lt;=\n小于等于\n\n\n&gt;=\n大于等于\n\n\n==\n等于\n\n\n!=\n不等于\n\n\n~\n匹配正则表达式\n\n\n!~\n不匹配正则表达式(与上面条件相反)\n\n\n\n为使域匹配正则表达式，使用符号‘～’后紧跟正则表达式，也可以用 i f 语句。awk 中 if 后面的条件用 ()括起来。\n案例：查询月份为”sept“的行信息。\nawk '&#123; if($2~/sept/) print $0 &#125;' data.txt\n精确匹配 48，使用等号==，并用单引号括起条件。例如$3 == “48”，这样确保只有 48 号得以匹 配，其余则不行\nawk '&#123; if($1==\"48\") print $0 &#125;' data.txt\n或\nawk '$1==\"48\" &#123; print $0 &#125;' data.txt\n上面我们通过/[Ss]ept/实现了 Sept 与 sept 的匹配，我们其实也可以使用 或关系匹配 ，使用竖线 符|，意为匹配| 两边模式之一。注意：使用竖线符时，语句必须用圆括号括起来。\nawk '&#123; if($2~/(Sept|sept)/) print $0 &#125;' data.txt\n# 或者\nawk '$2~/(Sept|sept)/' data.txt\n# 或者\nawk '&#123; if($2 == \"Sept\" || $2 == \"sept\") print $0 &#125;' data.txt\n# 或者\nawk '$2 == \"Sept\" || $2 == \"sept\"' data.txt\n\n//不加任何动作默认输出所有匹配\n匹配价格大于 50 的，并且库存大于 200 的。\nawk '&#123; if($5 > 50 &amp;&amp; $7 > 200) print $0 &#125;' data.txt\n# 或者\nawk '$5 > 50 &amp;&amp; $7 > 200' data.txt\nawk 内置变量\n\n\n\n变量名\n说明\n\n\n\n\nARGC\n命令行参数个数\n\n\nARGV\n命令行参数排列\n\n\nENVIRON\n支持队列中系统环境变量的使用\n\n\nFILENAME\nawk 浏览的文件名\n\n\nFNR\n浏览文件的记录数\n\n\nFS\n设置输入域分隔符，等价于命令行-F 选项\n\n\nNF\n浏览记录的域个数(总共多少列)\n\n\nNR\n已读的记录数(当前行号)\n\n\nOFS\n输出域分隔符\n\n\nORS\n输出记录分隔符\n\n\nRS\n控制记录分隔符\n\n\n\n\n\nARGC 支持命令行中传入 awk 脚本的参数个数。ARGV 是 ARGC 的参数排列数组，其中每一元素表 示为 ARGV[n]，n 为期望访问的命令行参数。\n\n\nENVIRON 支持系统设置的环境变量，要访问单独变量，使用实际变量名，例如： ENVIRON[“EDITOR”] =“Vi”。\n\n\nFILENAME 支持 awk 脚本实际操作的输入文件。因为 awk 可以同时处理许多文件，因此如果访问 了这个变量，将告之系统目前正在浏览的实际文件。\n\n\nFNR 支持 awk 目前操作的记录数。其变量值小于等于 NR。如果脚本正在访问许多文件，每一新 输入文件都将重新设置此变量。\n\n\nFS 用来在 awk 中设置域分隔符，与命令行中-F 选项功能相同。缺省情况下为空格。如果用逗号来 作域分隔符，设置 FS=“,”。\n\n\nNF 支持记录域个数，在记录被读之后再设置。\n\n\nOFS 允许指定输出域分隔符，缺省为空格。如果想设置为#，写入 OFS=“#”。\n\n\nORS 为输出记录分隔符，缺省为新行（\\n）。\n\n\nRS 是记录分隔符，缺省为新行(\\n)。\n\n\n测试 NR, NF, FILENAME 这几个内置变量的使用。\nawk '&#123; print NR, NF, $0&#125; END&#123; print FILENAME &#125;' data.txt\n\n之前有个案例是匹配价格大于五十的数据，具体如下：\nawk '&#123; if($5 > 50) print $0 &#125;' data.txt\n有的时候有这一种情况，那就是如果由于数据不完整，某一行没有五个域，这个时候就会有问题， 这个时候我们就可以先通过 NF 来进行判断，代码可以改成这样：\nawk '&#123; if(NF > 5 &amp;&amp; $5 > 50) print $0 &#125;' data.txt\n或\nawk 'NF > 5 &amp;&amp; $5 > 50' data.txt\nawk 操作符\n在 awk 中使用操作符，基本表达式可以划分为数字型、字符串型、变量型、域及数组元素\n数据准备：雇员(emp)信息，由于上面的案例数据有的力不从心，我们引入以前数据库里面的一份数据。\n\n\n\nNO\n列名\n类型\n描述\n\n\n\n\n1\nempno\nint\n雇员编号\n\n\n2\nename\nvarchar(10)\n雇员姓名\n\n\n3\njob\nvarchar(9)\n职位\n\n\n4\nmgr\nint\n雇员直属上司\n\n\n5\nhiredate\ndate\n雇员雇佣日期\n\n\n6\nsal\ndecimal(7,2)\n雇员的薪水，有五位整数两位小数组成\n\n\n7\ncomm\ndecimal(7,2)\n雇员的佣金(提成)，有五位整数两位小数组成\n\n\n8\ndeptno\nint\n雇员所属的部门号\n\n\n\n数据:\n7369,SMITH,CLERK,7902,1980-12-17,800.00,0,20\n7499,ALLEN,SALESMAN,7698,1981-02-20,1600.00,300.00,30\n7521,WARD,SALESMAN,7698,1981-02-22,1250.00,500.00,30\n7566,JONES,MANAGER,7839,1981-04-02,2975.00,0,20\n7654,MARTIN,SALESMAN,7698,1981-09-28,1250.00,1400.00,30\n7698,BLAKE,MANAGER,7839,1981-05-01,2850.00,0,30\n7782,CLARK,MANAGER,7839,1981-06-09,2450.00,0,10\n7788,SCOTT,ANALYST,7566,1987-04-19,3000.00,0,20\n7839,KING,PRESIDENT,,1981-11-17,5000.00,0,10\n7844,TURNER,SALESMAN,7698,1981-09-08,1500.00,0.00,30\n7876,ADAMS,CLERK,7788,1987-05-23,1100.00,0,20\n7900,JAMES,CLERK,7698,1981-12-03,950.00,0,30\n7902,FORD,ANALYST,7566,1981-12-03,3000.00,0,20\n7934,MILLER,CLERK,7782,1982-01-23,1300.00,0,10\n设置域到域变量名\n在 awk 中，设置有意义的域名是一种好习惯，在进行模式匹配或关系操作时更容易理解。一般的变 量名设置方式为 name=$n，这里 name 为引用的域变量名，n 为实际域号。例如设置学生域名为 name，年龄的域名为 age，操作为 name=$1; age=$2。注意分号的使用，它分隔 awk 命令。下面例 子中，重新赋值月份名域为 month，价格域为 price。查询价格大于 50 的记录，并最终打印月份和价格。\nawk '&#123;if($5>50) print $2, $5 &#125;' data.txt\n#\nawk '&#123;month=$2; price=$5; if(price>50) print month, price &#125;' data.txt\n也可以在 BEGIN 部分给变量赋值，然后再后面使用：\nawk '&#123; if($5 > 50) print $0 &#125;' data.txt\n\nawk 'BEGIN &#123; PRICE = 50 &#125; &#123; if($5 > PRICE) print $0 &#125;' data.txt\n修改数值域取值\n当在 awk 中修改任何域时，重要的一点是要记住实际输入文件是不可修改的，修改的只是保存在缓 存里的 awk 复本。awk 会在变量 NR 或 NF 变量中反映出修改痕迹。为修改数值域，简单的给域标识重 赋新值，如：$1=$1+5，会将域$1 数值加 5\nsort\nsort 命令用于对文件内容进行排序，我们可以可以指定按指定的域来进行排序，也可以通过参 数来控制排序的规则。\nsort [选项] 文件\n\n参数：\n-b：忽略每行前面开始出的空格字符。\n-c：检查内容有没有排序，没有输出意味着已经排序了。\n-d：排序时，处理英文字母、数字及空格字符外，忽略其他的字符。\n-M：将前面3个字母依照月份（比如：JAN）的缩写进行排序。\n-m：将几个排序好的文件进行合并。\n-n：按照数值的大小进行排序\n-o：&lt;输出文件> 将排序后的结果存入指定的文件。\n-r：以倒序的形式来进行排序。\n-t：&lt;分隔字符> 指定排序时所用的域的分隔符（默认是空格）。\n-h：以人类可视化的单位来进行排序（针对于文件大小单位：kB, MB, GB等）\n[-k field1[, field2]]：按指定的列进行排序。\n大数据\nHDFS 的基本操作\n开启/关闭分布式\nstart-dfs.sh\nstop-dfs.sh\n在分布式文件系统中创建映射文件夹\nhdfs dfs -mkdir Mapping_Folder_Path\n在分布式文件系统中创建文件\nhdfs dfs -touchz Mapping_Folder_Path/file_Name\n查询文件列表\nhdfs dfs -ls Mapping_Folder_Path\n查找文件\nhdfs dfs -find Mapping_Folder_Path -name 表达式\n例:\nhdfs dfs -find /input -name wc*   -- input映射文件夹中名字中带有wc的文件\n打印文件\nhdfs dfs -cat Mapping_Folder_Path/file_name\n移动文件夹/文件\nhdfs dfs -mv Source_Mapping_Folder_Path  target_Mapping_Folder_Path\n删除文件夹/文件\nhdfs dfs -rm &lt;-r> &lt;-skipTrash> Mapping_Folder_Path/file_name\n-r 递归删除\n-skipTrash 彻底删除(不进垃圾桶)\n把本地文件追加到映射文件末尾\nhdfs dfs -appendToFile localfile_Path/file_name Mapping_Folder_Path/file_name\n上传文件到分布式文件系统的映射文件夹\nhdfs dfs -put file_Name/file_Path Mapping_Folder_Path --本地文件复制上传\n\nhdfs dfs -movefromLocal file_Name/file_Path Mapping_Folder_Path  --本地文件删除上传\n\n例: hdfs dfs -put hello.txt /input\n从分布式文件系统的映射文件夹下载文件到本地路径\nhdfs dfs -get Mapping_Folder_Path file_Name/file_Path --映射文件复制到本地路径\n","slug":"Linux基本操作","date":"2023-07-18T06:03:34.000Z","categories_index":"运维,Linux","tags_index":"Linux","author_index":"ND_LJQ"},{"id":"e7498051f03c6ed58194e6874f009871","title":"docker的基本使用","content":"Docker的基本使用\ndocker的意思是容器,是基于Go语言的轻量级的虚拟机\nUbuntu安装Docker\nsudo apt install docker.io\n\n#也可以使用wget使用官方脚本来进行安装\ncurl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun\n检查docker是否安装成功\ndocker version\n\n注意这里只显示了Client的信息，下面有一个报错: persission denied…，这个是因为我们安装的时候是用的sudo安装，在这里是没有权限连接docker的服务端，解决办法是把当前用户加入到docker组里面去。\n首先新建一个docker组\nsudo groupadd docker\n但是很可能已经有了docker组了，已有的话就不用管了，继续下一步\n然后把当前用户加入docker组\nsudo gpasswd -a $&#123;USER&#125; docker\n重启docker\nsudo service docker restart\n切换当前会话到新 group\nnewgrp - docker\n最后一步是必须的，如果不切换，组信息不会立刻生效的。\n最后测试下效果\ndocker version\n\n最后的最后，因为国内网速问题，下载镜像比较慢所以可以使用国内大厂提供的加速器，我这里使用的是阿里云提供的加速器，使用镜像加速必须得改一下docker的配置文件 /etc/docker/daemon.json\n#没有则新建\nsudo vim /etc/docker/daemon.json\n\n#在里面加入阿里云镜像加速器地址\n&#123;\n  \"registry-mirrors\": [\"https://4m0bchll.mirror.aliyuncs.com\"]\n&#125;\n刷新设置,重启docker\nsudo systemctl daemon-reload\nsudo systemctl restart docker\n设置docker开机自启\nsystemctl enable docker\nDocker的基本指令\n查看版本\ndocker version\n查看docker信息\ndocker info\n查询镜像信息\ndocker search mirrorName\n\n例子\ndocker search nginx\n镜像给我的感觉就像是安装包\n查询镜像/容器元数据\ndocker inspect [OPTIONS] NAME/ID [NAME/ID...]\n\nOPTIONS：\n\t-f :指定返回值的模板文件。\n\t-s :显示总的文件大小。\n\t--type :为指定类型返回JSON。\n\n#获取镜像mysql:5.6的元信息\ndocker inspect mysql:5.6\n下载镜像\ndocker pull mirrorName[:versionNumber]\n\n[]里为可选\n不加具体版本的话默认下载最新版本\n查看本地镜像列表\ndocker images\n给镜像打标签\ndocker tag source_image[:tag](就是image查询种对应镜像的id) tartget_image[:tag]\n\n镜像结构 registryname/respositoryname(仓库名)/imagename(镜像名):tagname(标签名)\n\n\n登录docker\ndocker login\n\n#登录后的用户信息会保存在 ~/.docker/config.json种\n将镜像发布到远程\ndocker push userName/imageName:versionTag\n删除镜像\n#删除标签(删除指定版本的镜像)\ndocker rmi repository[:tag]\n\n#强制删除\ndocker rmi -f imageID\n运行镜像(创建容器)\ndocker run [options] image [command] [arguments]\n\noptions:\n\t-i:表示启动一个可交互的容器,并持续打开标准输入,通常与 -t 同时使用\n\t-t:为容器重新分配一个伪输入终端，通常与 -i 同时使用\n\t-d:表示容器放置后台运行\n\t-p: 指定端口映射，格式为：主机(宿主)端口:容器端口\n\t-m :设置容器使用内存最大值；\n\t-h \"mars\": 指定容器的hostname\n\t-v 容器外部目录:容器内部目录 ->绑定一个卷(将容器外部目录映射到容器外部目录)\n\t如果不写容器外部目录,则是匿名挂载\n\t--volumes-from container1 :将容器名为container1的数据卷共享给当前run指令创建的容器\n\t--rm:表示退出后即删除容器\n\t--name:表示定义容器的唯一名称,不指定docker默认分配\n\t--expose=[]: 开放一个端口或一组端口\n\t--cpuset=\"0-2\" or --cpuset=\"0,1,2\": 绑定容器到指定CPU运行\n\t--dns 8.8.8.8: 指定容器使用的DNS服务器，默认和宿主一致；\n\t--dns-search example.com: 指定容器DNS搜索域名，默认和宿主一致；\n\t--restart= 后接1个参数(always:容器退出时总是重启;\n\t\t\t\t\t\t   on-failure:number :若容器的退出状态非0，则docker自动重启容器，还可以指定重启次数，若超过指定次数未能启动容器则放弃;\n\t\t\t\t\t\t   no: 默认值，表示容器退出时，docker不自动重启容器;\n\t\t\t\t\t\t   )\n\timage:表示要运行的镜像\n\tcommand:表示启动容器时要运行的命令\n\t\n\t\n#启动一个交互式容器\n\tdocker run -it hello-world \n更新容器参数\n若在docker run 创建容器时未指定某些参数,可以通过docker update 命令进行更新一个或多个容器\ndocker update [...options] CONTAINER_ID/CONTAINER_NAME [...CONTAINER_ID/CONTAINER_NAME]\n\nOPTIONS:\n\t--cpu-shares :更新 cpu-shares。\n\t--kernel-memory :更新内核内存限制。\n\t--memory :更新内存限制。\n\t--restart :更新重启策略。\n退出容器\nexit :容器停止并退出\nctrl+p+q: 容器不停止退出\n查看正在运行的容器列表\ndocker ps [options]\n\noptions:\n\t-a:查询所有容器,包括已经停止的或正在运行的(不加默认列出正在运行种的)\n\t-f:filter filter根据所提供的条件过滤输出\n\t\tformat string使用Go模板漂亮打印容器\n\t-n:last int显示n个最近创建的容器(包括所有状态)(默认为-1)\n\t-l:latest显示最新创建的容器(包括所有状态)\n\t——no-trunc不要截断输出\n\t-q:quiet只显示容器id\n\t-s:size显示文件总大小\n\t\n\t\n#列出已经关闭的容器列表\ndocker ps -f STATUS=exited\n进入后台容器\nexec进入\ndocker exec [options] container(ID/Name) command [args...]\n\noptions:\n\t-d :分离模式: 在后台运行\n\t-i :即使没有附加也保持STDIN(标准输入)打开\n\t-t :分配一个伪终端\n\t\t\n\n每次连接到容器,相当于重新创建一个终端\nattach进入\ndocker attach container\n\n#但在，使用该命令有一个问题。当多个窗口同时使用该命令进入该容器时，所有的窗口都会同步显示。如果有一个窗口阻塞了，那么其他窗口也无法再进行操作。\n因为这个原因，所以docker attach命令不太适合于生产环境，平时自己开发应用时可以使用该命令。\n区别:\ndocker exec: 进入容器就开启一个新的终端(常用),执行exit时不会停止容器\ndocker attach:进入容器正在执行的终端 exit退出会停止容器\n启动已经停止的容器\ndocker start container(ID/name)\n停止正在运行的容器\ndocker stop container(ID/name)\n重启容器\ndocker restart container(ID/name)\n删除已经停止的容器\ndocker rm [OPTIONS] container(ID/name)\n\nOPTIONS:\n\t--force , -f:强制删除正在运行的容器（使用 SIGKILL）\n\t--link , -l:删除指定的链接\n\t--volumes , -v:删除与容器关联的匿名卷\n\n#删除所有已经停止的容器\ndocker rm $(docker ps -qf status=exited)\n查看容器日志\ndocker logs [options] container(ID/name)\n\noptions:\n\t-f:跟踪日志输出\n\t--since:显示某个开始时间的所有日志\n\t-t:显示时间戳\n\t--tail:仅列出最新n条容器内容\n\n#跟踪查看容器mynginx的日志输出。\n docker logs -f mynginx\n\n#查看容器mynginx从2016年7月1日后的最新10条日志。\ndocker logs --since=\"2016-07-01\" --tail=10 mynginx\n镜像管理\n将容器制作成镜像\ndocker commit [options] container(ID/name) [REPOSITORY[:TAG]]\n\noptions:\n\t-a :提交的镜像作者；\n\t-c :使用Dockerfile指令来创建镜像；\n\t-m :提交时的说明文字；\n\t-p :在commit时，将容器暂停。\n将指定docker对象保存成归档文件\n基于save保存镜像与基于load加载镜像\n将指定镜像保存为归档文件\ndocker save [options] image [image...]\n\noptions:\n\t-o:输出到的文件\n\t\n#将镜像 runoob/ubuntu:v3 生成 my_ubuntu_v3.tar 文档\n1.\ndocker save -o my_ubuntu_v3.tar runoob/ubuntu:v3\n\n2.\ndocker save runoob/ubuntu:v3 > my_ubuntu_v3.tar \n\n归档文件解压成镜像\ndocker load [options]\n\noptions:\n\t-i : 指定导入的文件，代替 STDIN。\n\t-q : 精简输出信息。\n\t\n\ndocker load &lt; busybox.tar.gz\n\n\ndocker load -i fedora.tar\n导入导出容器\n将指定容器导出为归档文件\ndocker export [OPTIONS] CONTAINER\n\nOPTIONS:\n\t--output , -o: 输出到的文件\n\n\ndocker export -o busybox.tar busyboxContainer \n\ndocker export busyboxContainer > busybox.tar\n将归档文件导入并命名为指定镜像\ndocker import fileUrl imageName\n\ndocker import busybox.tar busyboxContainer:v1\ndocker export和docker save的区别\n首先，两者的操作对象不同。docker save是将一个镜像保存为一个tar包，而docker export是将一个容器快照保存为一个tar包。\n然后，docker export导出的容器快照文件将丢弃所有的历史记录和元数据信息，即仅保存容器当时的快照状态；而docker save保存的镜像存储文件将保存完整记录，体积也要大。下图就能够很好的说明，ubuntu:test仅仅占97.8MB而ubuntu:latest却占了120MB。\n\nDockerfile\n使用commit构建一个镜像，由于commit在构建镜像时，很容易将无关内容添加到镜像且维护起来十分困难。所以不推荐使用commit来构建一个镜像。官方推荐使用Dockerfile来构建一个镜像\nDockerfile简介\n镜像的定制实际上就是定制每一层所添加的配置、文件。那么如果我们可以把每一层修改、安装、构建、操作的命令都写入一个脚本，用这个脚本来构建、定制镜像，那么之前提及的无法重复的问题、镜像构建透明性的问题、体积的问题就都会解决。这个脚本就是Dockerfile。\nDockerfile描述了组装镜像的步骤，其中每一条命令都是单独执行的，除了FROM指令外，其他每一条指令都在上一条指定所生成的镜像基础上执行，执行完会生成一个新的镜像层，新的镜像层覆盖在原来的镜像层之上，从而形成了新的镜像。Dockerfile所生成的最终镜像就是在基础叠加镜像上一层层的镜像层组成的。\n在Dockerfile中，指令不区分大小写，但是为了与参数区分，推荐大写。Docker会顺序执行Dockerfile中的指令，第一条必须是FROM指令，它用于指定构建镜像的基础镜像。在Dockerfile中，以#开头的行是注释。\nFROM指令和RUN指令\n●FROM指定基础镜像； 格式：FROM &lt;image&gt;或 FROM &lt;image&gt;:&lt;tag&gt;。\nFROM指令的功能是为后面的指令提供基础镜像，因此一个有效的Dockerfile必须以FROM指令作为第一条非注解指令。若FROM指令中tag参数为空，则tag默认为latest；若参数image或tag指定镜像不存在，则返回错误。\n●RUN执行命令； 格式：RUN &lt;command&gt;（shell格式）或RUN [“executable”, “param1“, “param2”]（exec格式，非常推荐）。\nRUN 指令是用来执行命令行命令的。RUN指令会在前一条命令创建出的镜像的基础上创建一个容器，并在容器中运行命令。在命令结束运行后提交新容器为新镜像，新镜像被Dockerfile的下一条指令使用。\n之前说过，Dockerfile中每一个指令都会建立一个镜像层，RUN也不例外。每一个RUN 的行为，就和之前学习的docker commit定制镜像的过程一样：在之前镜像的基础上创建一个容器，在其上执行这些命令，执行结束后，最后 commit 这一层的修改，构成新的镜像。\n下面举一个实例，使用Dockerfile构建一个名为testimage的镜像，该镜像具备ubuntu:latest的运行环境，而且在镜像的/目录下创建了一个dir1文件夹。\n#先创建一个新的空文件夹\nmkdir newdir\n\n#进入这个新文件夹中\ncd newdir\n\n#创建一个Dockerfile文件\ntouch Dockerfile\n\n#补全Dockerfile的内容（为了方便展示，这里用的是echo向Dockerfile中输入内容）\necho \"FROM ubuntu:latest\" > Dockerfile\necho \"RUN mkdir /dir1\" >> Dockerfile\n\n#使用该Dockerfile构建一个名为testimage的镜像\ndocker build -t testimage .\nDockerfile构建镜像的过程详解\n上面的实例创建了一个Dockerfile文件，Dockerfile的内容如下：\nFROM ubuntu:latestRUN \nmkdir /dir1\n执行docker build命令，指定使用Dockerfile构建一个镜像。执行结果如下所示：\n[root@localhost newdir]# docker build -t testimage .\nSending build context to Docker daemon 2.048 kB\nStep 1/2 : FROM ubuntu \n ---> 14f60031763d\nStep 2/2 : RUN mkdir dir1 \n ---> Running in c5117d908931 \n ---> cb0193727724\nRemoving intermediate container c5117d908931\nSuccessfully built cb0193727724\nDocker指令是从上到下一层一层执行的，所以在使用这个Dockerfile构建镜像时，首先执行FROM ubuntu:latest这条指令。\nFROM ubuntu:latest指定ubuntu:latest作为基础镜像，也就是将ubuntu:latest镜像的所有镜像层放置在testimage镜像的最下面。\n然后执行RUN mkdir dir1指令，前面我们说过，执行RUN指令时，会在之前指令创建出的镜像的基础上创建一个临时容器，在这里的容器Id为c5117d908931，并在容器中运行命令。在命令结束运行后提交新容器为新镜像，并删除临时创建的容器c5117d908931。\n在Dockerfile的所有指令执行完后，新镜像就构建完成了\n注意事项，谨慎使用RUN\n修改前的Dokcerfile文件\n既然RUN就像 Shell 脚本一样可以执行命令，那么是否就可以像Shell 脚本一样把每个命令对应一个RUN呢？比如这样：\nFROM debian:jessie\nRUN apt-get update\nRUN apt-get install -y gcc libc6-dev make\nRUN wget -O redis.tar.gz \"http://download.redis.io/releases/redis-3.2.5.tar.gz\"\nRUN mkdir -p /usr/src/redis\nRUN tar -xzf redis.tar.gz -C /usr/src/redis --strip-components=1\nRUN make -C /usr/src/redis\nRUN make -C /usr/src/redis install\n上面这个Dockerfile是为了编译、安装 redis可执行文件。虽然它能够完成了所需的功能，但是正如之前说过，Dockerfile中每一个指令都会建立一层，RUN 也不例外。每一个RUN的行为，都会创建一个新的镜像层。\n而上面的这种写法，创建了8层镜像（1层基础镜像+7层由RUN执行创建的镜像）。这是完全没有意义的，而且很多运行时不需要的东西，都被装进了镜像里，比如编译环境、更新的软件包等等。结果就是产生非常臃肿、非常多层的镜像，不仅仅增加了构建部署的时间，也很容易出错。\n修改后的Dockerfile文件\n因为之前所有的命令只有一个目的，就是编译、安装 redis 可执行文件。因此没有必要建立很多层，这只是一层的事情。因此，修改之后的Dockerfile文件并没有使用很多个RUN指令，而仅仅使用一个RUN 指令，并使用 &amp;&amp;将各个命令串联起来。除此以外，把redis的编译环境、更新的软件包也通通清除掉了，减少镜像占用的存储空间。如下所示，修改之后的Dockerfile构建完成后是就只会有2层镜像了（1层基础镜像+1层由RUN执行创建的镜像）。\nFROM debian:jessie\nRUN buildDeps='gcc libc6-dev make' \\\n&amp;&amp; apt-get update \\\n&amp;&amp; apt-get install -y $buildDeps \\\n&amp;&amp; wget -O redis.tar.gz \"http://download.redis.io/releases/redis-3.2.5.tar.gz\" \\\n&amp;&amp; mkdir -p /usr/src/redis \\\n&amp;&amp; tar -xzf redis.tar.gz -C /usr/src/redis --strip-components=1 \\\n&amp;&amp; make -C /usr/src/redis \\\n&amp;&amp; make -C /usr/src/redis install \\\n&amp;&amp; rm -rf /var/lib/apt/lists/* \\\n&amp;&amp; rm redis.tar.gz \\\n&amp;&amp; rm -r /usr/src/redis \\\n&amp;&amp; apt-get purge -y --auto-remove $buildDeps\n在Dockerfile的编写过程中一定要牢记一点：镜像的每一层构建完就不会再发生改变，后一层上的任何改变只发生在自己这一层。删除前一层文件的操作，实际不是真的删除前一层的文件，而是仅在当前层标记为该文件已删除。在最终容器运行的时候，虽然不会看到这个文件，但是实际上该文件会一直跟随镜像。\ndocker build\nDockerfile创建完成后，可以使用docker build命令根据Dockerfile构建一个镜像。\ndocker build [OPTIONS] 上下文路径|URL\n\nOPTIONS:\n\t-f:显示指定Dockerfile,如果不使用-f，则默认将上下文路径下的名为Dockerfile的文件认为是构建镜像的“Dockerfile”\n\t-t:指定镜像名称\n\t上下文路径|URL： 指定构建镜像的上下文的路径，构建镜像的过程中，可以且只可以引用上下文中的任何文件。\n现在让我们在看看docker build -t myimage .这条命令，在这条命令中，使用-t指定了镜像名为myimage，由于没有使用-f指令，所以默认使用上下文路径下名为Dockerfile的文件认为是构建镜像的“Dockerfile”。最后指定上下文路径，在这条命令中，上下文路径是.。\n.代表着当前目录。所以docker build -t myimage .中小数点.其实就是将当前目录设置为上下文路径。\n执行docker build后，会首先将上下文目录的所有文件都打包，然后传给Docker daemon，这样Docker daemon收到这个上下文包后，展开就会获得构建镜像所需的一切文件。\n如下图所示，在执行完docker build后，会首先sending build context to Deckor daemon，也就是将上下文目录下所有文件打包发给Docker daemon。所以在使用Dockerfile文件时构建镜像时，一般将它放在一个空文件夹下，就是为了防止将其他多余的文件传出去。然后依次执行Dockerfile的指令，如果指令正确执行，则继续执行下一条，直到所有指令执行正确完毕，镜像构建完成；如果指令执行出错，终止镜像构建。\n\n主机和docker的交互\n主机和docker文件中的相互拷贝\n#容器->主机\ndocker cp [options] container(ID\\name):source_path 主机path\n\n#主机->容器\ndocker cp [options] 主机path container(ID\\name):source_path \n\noptions:\n\t-L:保持源目标中的链接\n\t\n#将主机/www/runoob目录拷贝到容器96f7f14e99ab的/www目录下。\ndocker cp /www/runoob 96f7f14e99ab:/www/\n\n#将主机/www/runoob目录拷贝到容器96f7f14e99ab中，目录重命名为www。\ndocker cp /www/runoob 96f7f14e99ab:/www\n\n#将容器96f7f14e99ab的/www目录拷贝到主机的/tmp目录中。\ndocker cp  96f7f14e99ab:/www /tmp/\n将主机中的目录映射到容器中\ndocker volume COMMAND\n\nCommands:\n  create:挂载数据卷\n  \tOptions:\n  \t-d, --driver string   Specify volume driver name (default \"local\")\n      --label list      Set metadata for a volume\n  \t-o, --opt map         Set driver specific options (default map[])\n  \n  inspect [options]: 查看volume数据卷的详细信息(挂载点等等)。\n  \tOptions:\n  \t\t-f, --format string   Format the output using the given Go template\n  \n  \n  ls [options]:查看本地所有数据卷(volume)\n  \tOptions:\n  \t\t-f, --filter filter   Provide filter values (e.g. 'dangling=true')\n      \t--format string   Pretty-print volumes using a Go template\n \t\t-q, --quiet:只需要展示数据卷的名称\n  \n  prune [options]:移除未使用的数据卷。\n  \t Options:\n  \t \t--filter :filter   Provide filter values (e.g. 'label=&lt;label>')\n  \t\t-f, --force :Do not prompt for confirmation\n  \n  \n  \n  rm [OPTIONS] VOLUME [VOLUME...]:移除一个或多个数据卷，不能移除被容器使用的数据卷。\n  \tOptions:\n  \t\t -f, --force:Force the removal of one or more volumes\n  \t\t \n  \t\t \n  #输出容器container1创建的数据卷的名字\n  docker inspect --type container --format='&#123;&#123;range .Mounts&#125;&#125;&#123;&#123;.Name&#125;&#125;&#123;&#123;end&#125;&#125;' container1\n  \n  \n","slug":"docker的基本使用","date":"2023-07-18T05:39:37.000Z","categories_index":"运维,Docker","tags_index":"Docker","author_index":"ND_LJQ"},{"id":"4f1b28a46122dcbfdd696db503d86e97","title":"软件工程基础","content":"软件工程\n软件工程的概念和思想\n何为软件工程\n1968年,北大西洋公约组织(NATO)科学委员会在西德召开的研讨会上着重讨论如何应对软件危机,会上人们首次提出\"软件工程\"概念,进而开启了软件工程的研究与实践\n\n根据IEEE给出的定义,软件工程是指:\n\n①将系统的、规范的、可量化的方法应用于软件开发、运行和维护的过程\n\n②以及以上方法的研究\n这一概念定义给出了软件工程的两个方面的内涵,以是软件工程要提供系统的、规范的、可量化的方法来指导软件的开发、运行和维护,而是软件工程要研究方法本身\n软件工程的三要素\n软件工程的三方面的核心要素是:过程、方法学和工具\n过程\n该要素主要是从管理的视角,回答软件开发、运行和维护需要做哪些工作、如何管理好这些工作等问题,关注软件项目的规范化组织和可量化实施\n至今,软件工程已提出了诸多软件开发过程模型,包括瀑布模型、增量模型、原型模型、迭代模型、螺旋模型。每一种模型都反映了软件开发的不同理解和认识,进而采用不同的过程。此外,软件工程还提供了一组开发方法,如敏捷方法(agile method)、群体化开发方法(crowd-based development)、DevOps方法等。他们为软件开发过程中的开发和维护活动、软件制品的交付方式、软件开发人员的组织和协同等提供指导思想、原则和策略\n方法学\n该要素主要是从技术的视角,回答软件开发、运行和维护如何做的问题。方法学旨在为软件开发过程中的各项开发和维护活动提供系统、规范的技术支持,包括:如何理解和认识软件模型,如何用不同抽象层次的模型描述不同开发活动所产生的软件制品,采用什么样的建模语言描述软件模型,提供什么样的编程语言实现软件模型,提供什么样的策略和原则指导各项活动的开展,如何确保开发活动、维护活动和软件制品的质量等。至今,软件工程已提出诸多人软件开发方法学,如`结构化软件开发方法学`、`面向对象软件开发方法学`、`基于构件的软件开发方法学`、`面向主体的软件开发方法学`。\n工具\n该要素主要是从工具辅助的视角,回答如何借助工具来辅助软件开发、运行和维护的问题\n软件工程的目标\n软件工程的整体目标是在成本、进度、资源等约束下,帮助软件开发人员开发出满足用户要求的足够好的软件系统。软件开发、运行和维护是一项极为复杂的工作,涉及多方的利益相关者,包括客户、用户、开发者、维护者、管理者等,他们会从各自的角度提出各自的诉求。软件工程就是要站在这些利益相关者的角度实现以下目标:\n\n\n\n指导开发、运行和维护\n\n\n满足工程约束\n\n\n确保软件质量\n对软件客户、用户而言,所谓的足够好是指软件具有正确性、友好性、可靠性、易用性等特点;而对于软件开发者、维护者、管理者而言,所谓的足够好是指软件具有可维护性、可理解性、可重用性,互操作性等\n\n\n软件工程的原则\n\n\n抽象和建模\n\n\n模块化\n\n\n软件重用\n\n\n信息隐藏\n\n\n关注点分离\n\n\n分治\n\n\n双向追踪\n\n\n工具辅助\n\n\n开源软件\n何为开源软件\n开源软件是一种源代码可以自由获取和传播的计算机软件,其拥有者通过开源许可证赋予被许可人对软件进行使用、修改和传播的权利。开源软件采用群体化的思想和理念,代表了一种新的软件开发方法\n开源软件实践\n第一次重大变化发生在新闻组出现之后。\n第二次重大变化是发生在万维网技术出现之后。许多开源软件分别建立了各自独立的开发社区,如 Linux、Apache、Eclipse 以及 Mozilla 等\n第三次变化以 SourceForge 平台上线为标志。它极大的降低了开源软件开发者的参与门槛,使软件开源开发从面向技术精英逐步扩展到所有感兴趣的开发者,极大的激励发了广大软件开发者参与开源实践的创作激情\n第四次变化以 GitHub、Stack Overflow 等独立功能平台上线为标志。2008 年 GitHub 开始投入运营,以托管软件开源项目、辅助群体化的分布式协同开发。同年 Stack Overflow 投入运营以支持开发者群体交流和分享软件开发知识,如讨论开发问题,交流开发经验等\n政府组织\n开源组织\n①Apache 基金会。该组织成立于 1999 年\n②Linux 基金会。该组织成立于 2007 年\n③Eclipse 基金会。该组织成立于 2004 年\n④Open Source Initiative。该组织成立于 1998 年\n⑤ 开放原子开源基金会。该组织与 2020 年 6 月在我国登记注册\n企业开发者\n个人开发者\n开源软件的优势\n\n\n采购和开发成本更低\n\n\n软件质量更高、更安全\n\n\n软件研制和交付更快\n\n\n软件功能更全面,更具创新性\n\n\n开源许可证\n宽松式开源许可证\n特点:代码使用没有任何限制,用户自己承担代码质量的风险,用户使用开源软件时必须披露原作者。BSD、Apache、MIT 等都属于这一类许可证\nCopyleft 开源许可证\n指可不经允许随意复制,特点有许多,如分发二进制代码时必须提供源代码,修改后所产生的开源软件须与修改前全检保持一致的许可证,不得在原始许可证以外附加其他限制等。GPL、MPL 等属于这一类许可证。\n\n开源软件的利用\n\n\n学习开源软件\n\n\n参与开源建设,掌握开源技术,理解开源文化\n\n\n重用开源代码\n\n\n软件过程模型\n代表性的软件过程模型\n瀑布模型\n瀑布模型将软件开发过程分为若干步骤和活动,包括`需求分析`、`软件设计`、`编码实现`、`软件测试`和`运行维护`。这些步骤严格按照先后次序和逻辑关系来组织,每个阶段的末尾需要对该阶段产生的软件制品(文档、模型和代码等)进行评审,以发现和纠正软件制品中的问题和缺陷,以防有问题的软件制品进入下一步骤。\n\n该模型适合那些需求易于定义、不易变动的软件系统的开发\n\n瀑布模型及其改进模型还有一个不足,软件开发人员要等后期阶段才能产生可运行的软件系统,此时用户才可以接触和使用可运行软件,了解软件的功能和行为,发现软件中存在的质量问题,如果用户界面不太友好,实现功能与需求不太一致,反应速度太慢等如果此时用提出软件改进要求将会对软件开发和管理带来很大的冲击\n原型模型\n在日常生活和工作中,人们经常会构造一些系统的原型,以便为用户直观地展示所关心的内容。所谓原型,是指产品开发前期所产生的产品雏形或仿真产品。相较于实际产品,原型具有可直观展示产品的特性、贴近业务应用、能自然地反映产品需求等特点。\n\n基于原型的上述特点,人们将原型思想引入软件工程领域,在软件开发早期(通常在需求分析阶段)根据用户的初步需求构件软件原型并将其交给用户使用,获得用户的评价和反馈,帮助用户导出软件需求、发现开发人员与用户之间的需求认识偏差,进而有效地支持软件需求分析。这一过程即为原型模型\n\n原型模型适合于那些软件需求难以导出、不易确定且持续变动的软件系统。由于软件原型的修改和完善,需要多次和迭代进行,这一开发模型给软件项目的管理带来了一定的困难\n增量模型\n瀑布模型要等到软件开发后期才能给用户提供可运行的软件系统,这一点往往不利于用户使用。此外,滞后的软件交付和使用必然会导致软件缺陷和问题的滞后发现,加大软件开发的成本和工作量,影响软件质量,出现这一状况的根本原因在于,获取软件需求后瀑布模型要求一次性实现所有软件需求,这势必导致软件设计和实现的工作量大,开发周期长,使软件交付延后\n\n针对这一问题,增量模型做了适当的改进骂他不在要求软件开发人员一次性实现所有的软件需求,而是在软件需求和总体设计确定好后,采用增量开发的模式渐进式地实现软件系统的所有功能\n\n**增量模型的一个显著的优点是允许软件开发人员平行地开发软件、实现软件系统的各个独立模块,从而提高软件开发效率,加快交付目标软件系统的进度**\n\n迭代模型\n不要求一次性地开发出完整的软件系统，将软件开发视为一个逐步获取用广需求、完善软件产品的过程\n\n适用于需求难以确定、不断变更的软件系统\n增量模型和迭代模型的区别与联系：\n增量通常和迭代混为一谈，但是其实两者是有区别的。\n增量是逐块建造的概念，例如画一幅人物画，我们可以先画 人的头部，再画身体，再画手脚……\n迭代是反复求精的概念，同样是画人物画，我们可以采用先画整体轮廓，再勾勒出基本雏形，再细化、着色。\n基于构件的过程模型\n\n螺旋模型\n\nUP 模型\nUP 模型是一种用例驱动、以体系结构为核心、借助 UML 语言的迭代式软件过程模型\n\n在 UP 模型中同一个工作流在不同阶段任务强度是不一样的\n\n\n\n模型名称\n指导思想\n关注点\n适用软件\n管理难度\n\n\n\n\n瀑布模型\n为软件开发提供系统性的指导\n与软甲生存周期相一致的软件开发过程\n需求变动不大、较为明确、可预先定义的应用\n易\n\n\n原型模型\n以原型为媒介指导用户的需求导出和评价\n需求获取、导出和确认\n需求难以表述清楚、不易导出和获取的应用\n易\n\n\n增量模型\n快速交付和并行开发软件系统\n软件详细设计、编码和测试的增量完成\n需求变动不大、较为明确、可预先定义的应用\n易\n\n\n迭代模型\n多次迭代，每次仅针对部分明确的软件需求\n分多次迭代来开发软件,每次仅关注部分需求\n软件需求变动大,难以一次说清楚的应用\n中等\n\n\n基于构件的过程模型\n基于和构建重用来开发软件\n构件的搜索、选择、构件和组装\n需求明确,具有丰富构件库的应用\n中等\n\n\n螺旋模型\n集成迭代模型和原型模型，引入风险分析等管理活动\n软件计划制定和实施，软件风险管理,基于原型的迭代式开发\n开发风险大,需求难以明确的应用\n难\n\n\nUP 模型\n集成迭代过程模型和面向对象最佳实践\n参考最佳实践，借助面向对象最佳实践来指导迭代开发\n软件需求不明确且经常变化的应用\n难\n\n\n\n软件开发方法\n敏捷方法\n何为敏捷方法\n敏捷方法时一类软件开发方法的总称,他们主张软件开发要以代码为中心,快速,轻巧和主动应对需求变化,持续、及时交付可运行的软件系统\n敏捷开发的理念和价值观\n① 较之于过程和工具,应更加重视人和交互的价值。\n② 较之于面面俱到的文档,应更加重视可运行软件的价值\n③ 较之于合同谈判,应更加重视用户合作的价值\n④ 较之于遵循计划,应更加重视响应用户需求的变化的价值\n概括起来敏捷方法具有以下特点:\n① 更加重视可运行软件系统,即代码,弱化软件文档,以可运行软件系统为中心来开展软件开发\n② 以适应变化为目的来推进软件开发,鼓励和支持软件需求的变化,针对变化不断优化和调整软件卡法计划,及时交付软件产品\n③ 软件开发要以人为本,敏捷软件开发是面向人的而不是面向过程的,让方法、技术、工具、过程等来适应人,而不是让人来适应它们\n敏捷方法的实施原则\n12 条敏捷开发原则\n① 尽早和持续地交付有价值的软件,以确保客户满意度\n② 支持客户需求变化,即使到了软件开发后期\n③ 每隔几周或一两个月就须向客户交付可运行软件,交付周期宜短不宜长\n④ 在软件开发全过程,业务人员和开发人员须每天在一起工作\n⑤ 由积极主动的人来承担项目开发,支持和信任他们并提供所需的环境\n⑥ 面对面交谈是团队内部最有效和高效的传递方式\n⑦ 交付可运行软件你作为衡量开发进度的首要衡量标准\n⑧ 项目负责人、开发方和用户方应保持长期、稳定和可持续的开发速度\n⑨ 追求卓越的开发技术和良好的软件设计,增强团队和个体的敏捷能力\n⑩ 在保证质量的前提下采用简单的方法来完成开发任务\n⑪ 组建自组织的开发团队,以出色地完成软件架构、需求和设计等工作\n⑫ 团队应反思如何提高工作效率,并以此调整个体和团队的行为\n支持敏捷方法的开发技术和管理手段\n从管理的角度来看,敏捷开发方法的应用对软件项目管理提出以下一组要求:\n① 管理软件需求,支持需求的变化和跟踪\n② 选择和构件合适的软件开发过程,支持迭代式软件开发和持续性软件交付\n③ 管理开发团队,加强开发人员之间、开发人员与用户之间的交流、沟通和反馈\n④ 开发人员和用户一起参与项目计划的制定和实施\n⑤ 加强跟踪和监督,及时化解软件风险\n极限编程\n极限编程是由 Kent Beck 提出的一种特殊的敏捷方法,与敏捷方法相比较,极限编程的核心理念和价值观更为具体明确:\n① 交流。交流对于软件开发非常重要,鼓励基于口头、直接和平等的交流\n② 反馈。从团队内外获得持续和明确的反馈,获得软件及其开发状态,它对软件项目的成功实施至关重要\n③ 简单。用尽可能简单的过程和技术来指导开发、解决开发问题\n④ 勇气。勇于制定个体决策、快速开发,并在必要时具有重新开发的信心\n在上述价值观和理念的基础上极限编程制定了一组更具体,更易于操作的实施原则,以指导其应用:\n① 计划游戏。计划游戏旨在帮助开发团队快速制定下次迭代的软件开发计划\n② 隐喻。简单而言,隐喻是指用业务相关的术语来描述和交流软件需求促使软件开发人员和业务人员就软件需求达成共同一致的理解\n③ 小型发布。经常给用户发布可运行的软件系统,每次发布的软件仅增加少量的功能\n④ 简单设计。所谓的简单设计是指保持软件设计方案的简单性,不添加任何不必要的设计元素。\n⑤ 测试驱动开发。采用测试驱动的方法来开发软件和测试程序\n⑥ 重构。重构是指在不改变程序代码功能的前提下,改进代码设计和结构,使程序代码具有更高的质量,如更加简单、易于拓展、更加健壮\n⑦ 结对编程\n⑧ 集体拥有代码。\n⑨ 持续集成。新代码一旦经过验证后就可集成到整个软件系统之中,代码集成应经常进行,周期尽可能短\n⑩ 每周 40 小时工作日。\n⑪ 现场用户。让用户和业务人员成为团队成员参与软件开发的全过程\n⑫ 编码标准。依据行业或组织的编码标准来编写程序代码,力求代码遵循编码风格,具有良好的可读性、可理解性和可维护性\nScrum\n软件需求工程基础\n面相对象的需求分析方法学\n基本概念和思想\n面向对象的软件工程认为,无论是现实世界(应用问题)还是计算机世界(软件系统),他们都是由多样化的对象所构成的,每个对象都有其状态并可提供功能和服务,不同对象之间通过交互来开展协作、展示行为、实现功能和提供服务。\n\n具体地,面向对象的需求分析方法学提供了以下一组的核心概念:\n对象(object)\n对象既可以表示现实世界中的个体、事物或者实体,也可以表示在计算机软件中的某个运行元素或单元(如运行实例)。每个对象都有其属性和方法,属性表示对象的性质,属性的值定义了对象的状态;方法表示对象所能提供的服务,它定义了对象的行为。对象的方法作用于对象的属性之上,使得属性的取值发生变化,导致对象状态发生变化\n类(class)\n顾名思义,类是一种分类和组织机制。它是对一组具有相同特征对象的抽象。通俗地将,通过类可以将不同的对象进行分类\n消息(message)\n每个对象都不应是孤立的,他们之间需要进行交互以获得对方的服务,通过相互协作来共同解决问题。对象之间通过消息传递进行交互,消息传递是对象间的唯一通信方式,一个对象通过向另一个对象发送消息,从而请求相应的服务\n继承(inheritance)\n继承描述了类与类之间的一般与特殊关系,它本质上是对现实世界不同实体间遗传关系的一种直观表示,也是对计算机软件中不同类进行层次化组织的一种机制\n关联(association)\n描述了类与类之间的关系,他有多种形式,如聚合、组合等\n多态(polymorphism)\n多态是针对类的方法而言的,它是指同一个方法作用于不同的对象上可以有不同的解释,并产生不同的执行结果。\n覆盖(override)\n一个子类可以通过继承来获得父类的属性和方法。当然子类也可以在自己的类中增加或者重新定义所继承的属性和方法,从而用新定义的属性和方法来覆盖所继承的来自父类的属性或方法\n重载(overload)\n一个类中允许有多个名称相同但是参数不同的方法,由于这些方法在具体的参数数目及类型上有所区别,因而系统将根据收到的消息的实参来引用不同的方法\n面相对象建模语言 UML\n本质上 UML 是一种可视化的建模语言,它提供了图形化的语言机制,包括语法、语义和语用\n以及相应的规则、约束和拓展机制。\nUML 的主要视图\n\n\n\n视点\n视图\n建模内容\n支持的开发阶段\n\n\n\n\n结构\n包图\n系统高层结构\n需求分析、软件设计\n\n\n结构\n类图\n系统类结构\n需求分析、软件设计\n\n\n结构\n对象图\n系统在特定时刻的对象结构\n需求分析、软件设计\n\n\n结构\n构件图\n系统构件组成\n软件设计\n\n\n行为\n状态图\n对象状态及其变化\n需求分析、软件设计\n\n\n行为\n活动图\n系统为完成某项功能而事实的操作\n需求分析、软件设计\n\n\n行为\n交互图\n系统中的对象间如何通过消息传递来实现系统功能\n需求分析、软件设计\n\n\n部署\n部署图\n软件系统制品及其运行环境\n软件设计、部署和运行\n\n\n用例\n用例图\n软件系统的功能\n需求分析\n\n\n\n软件设计基础\n面向对象的软件设计方法学\n基本思想\n面向对象的软件设计过程\n面向对象的软件设计遵循先整体后局部,先抽象后具体的设计原则,借助模块化软件设计的基本思想和策略,先展开软件体系结构设计,明确软件系统的整体架构,在此基础上开展用户界面设计。上述两项设计完成后,将开展一系列详细设计工作,包括用例设计、构件/子系统设计、数据设计、类设计等,最终将这些设计进行整合,形成完整的软件设计方案\n面向对象的软件设计建模语言\nUML\n面向对象的软件设计原则\n面向对象的软件设计方法学提供了一组原则以指导软件设计,提高设计水平,产生高质量的软件设计模型\n单一职责原则\n单一职责原则要求每个类值承担一项责任,也即类的职责要单一化,它充分体现了软件模块化设计的思想。该原则有助于控制类的粒度大小,提高类设计的模块化程度以及类的内聚性,降低类实现的规模和复杂性,减少类变更的因素和频率\n开闭原则\n开闭原则要求每个类对于扩展是开放的,对于修改时封闭的。所谓的\"拓展的开放性\"是指类的功能是可拓展的。\n\n该设计原则有助于提高软件设计的灵活性、可重用性和可维护性。但是,该原则的应用也必然会给软件设计带来额外的抽象和设计成本\n里氏替换原则\n确保父类所拥有的性质在子类中仍成立,或者说,对于父类在软件中出现的所有地方,均可由子类进行替代,反之则不成立。这项原则是面向对象程序设计语言中继承机制的理论基础,也是遵循开闭原则的前提条件。\n\n这一原则要求子类可以拓展父类功能,但不能改变父类原有功能。这就要求子类继承父类时除了添加新的方法完成新增功能外,尽量不要重写父类的方法。\n接口隔离原则\n基本思想是尽量将臃肿庞大的接口拆分成更小和更具体的接口,让接口中只包含使用者感兴趣的方法,即根据使用者的需要定义接口\n依赖倒置原则\n基本思想是:高层模块不应该依赖底层模块,两者都应该其抽象;抽象不应该依赖细节,细节应该依赖抽象。这里的抽象是指面向对象设计中的接口或抽象类,他们均不能直接实例化,细节是指具体的类。因此,依赖倒置原则更为直接的描述为:高层的类不应该依赖底层的类,接口或抽象类不应该依赖具体的实现类,具体的实现类应依赖接口或抽象类。\n\n该原则有助于降低变化带来的影响,同时该原则提高了高层模块的可重用性、可拓展性,减少了类之间的耦合度,是软件系统的稳定性得到提升,并提高了代码的可理解性和可维护性\n最少知识原则\n基本思想:只与你的直接朋友交谈,不与陌生人说话。也即一个类只对与自己存在耦合关系的类进行狡猾,尽可能少的与其他不相关的类发生交互。这意味着一个类应该为与其发生交互关系的其他类提供最少的知识\n\n最少知识原则有助于实现类间解耦,使每个类与其他类是弱耦合甚至无耦合,从而提高类的可重用性。但这势必会提高软件系统带来的复杂性,给软件维护带来难度\n面向对象的软件设计优势\n\n\n高层抽象和自然过渡\n\n\n多种形式和粗粒度的软件重用\n\n\n系统化的软件设计\n\n\n支持软件的拓展和变更\n\n\n软件体系结构设计\n软件体系结构模型的表示方法\n包图\n软件测试\n软件测试过程\n单元测试\n集成测试\n确认测试\n系统测试\n软件测试技术\n黑盒测试技术\n该测试技术的前提是已知软件模块的功能,但是不知道该软件模块的内部实现细节(如其内部的控制流程和实现算法)这种情况下针对该软件模块设计和运行测试用例,测试软件模块的运行是否正常,测试软件模块的运行是否正常,能否满足用户的需求。通常,`集成测试`和`确认测试`大多采用黑盒测试技术,典型的黑盒测试技术包括`等价分类法`和`边界取值法`\n\n软件测试不仅要进行功能测试,如单元测试、集成测试和确认测试等,而且还需要进行非功能测试,如压力测试、兼容性测试、可靠性测试、容量测试。\n\n在软件测试的过程中,为了尽可能发现软件系统中潜在的缺陷和错误,软件测试应应对不同测试目的,遵循以下原则来设计测试用例。\n\n①需求(功能)覆盖。确保软件系统的所有需求或功能都被测试用例覆盖到。某个测试用例覆盖了某项功能,是指该测试数据的输入导致被测试的对象运行了实现某项功能的程序代码\n\n②模块覆盖。确保软件系统的所有程序模块(如过程、函数)都被测试用例覆盖到\n\n③语句覆盖。确保软件系统的所有程序语句都被测试用例覆盖到。\n\n④分支覆盖。程序中的控制结构(如 if语句或者while语句)通常具有多个不同的执行分支,分支覆盖是要确保待测试对象的所有分支都被测试用例覆盖到\n\n⑤条件覆盖。程序中控制结构的逻辑表达式即可取TRUE,也可取FALSE。条件覆盖是要确保控制结构中逻辑表达式的所有取值都被测试到\n\n⑥多条件覆盖。确保程序中所有控制结构的逻辑表达式中,每个子表达式取值的组合都被测试用例覆盖到\n\n⑦条件/分支覆盖。该原则是由条件覆盖和分支覆盖组合而成\n\n⑧路径覆盖。程序模块中的一条路径是指从入口语句(该模块的第一条执行语句)到出口语句(该模块的最后一条语句,如return语句)的语句序列。路径覆盖是要确保模块中的每一天路径都被测试用例覆盖到\n\n⑨基本路径覆盖。基本路径是指至少引入一个新语句或者新判断的路径。基本路径覆盖是要确保模块中的每一条基本路径都被测试用例覆盖到。\n白盒测试技术\n白盒测试的前提是已知程序的内部控制结构,以此作为依据来设计软件测试用例下面基本路径测试技术来介绍白盒测试技术\nvoid Func(int nPosX, int nPosY)&#123;\n    while(nPosX > 0)&#123;\n        int nSum = nPosX + nPosY;\n        if(nSum > 1)&#123;\n            nPosX--;\n            nPosY--;\n        &#125;else&#123;\n            if(nSum &lt; -1)&#123;\n                nPosX -= 2;\n            &#125;else&#123;\n                nPosX -= 4;\n            &#125;\n        &#125;\n    &#125;\n&#125;\n1.根据模块详细设计绘出模块的流程图\n\n2.将流程图转换为流图\n①增加控制结构,将流程图中的结合点转换为流图中的一个节点。所谓的结合点是指条件语句的汇聚点。如上图中的9号和10号位置就是结合点\n\n②讲流程图中的过程块合并为流图中的一个节点。所谓&quot;过程块&quot;是指一组必然会顺序执行的语句集。例如上图中的2号和3号,4号和5号分别构成了一个过程块\n\n经过上述转换,可得以下流图\n\n3.确定基本路径集合\n针对转换得到的流图,计算该图的复杂度为\n复杂度 &#x3D; Edge(D) - Node(D) + 2\n所得的复杂度就是该图所具有的基本路径数量\n所以上图中的复杂度为 11 - 9 + 2 = 4\n基于上图的理解,该模块基本路径如下:\n基本路径 1:1→11\n基本路径 2:1→2,3→6→7→9→10→1→11\n基本路径 3:1→2,3→6→8→9→10→1→11\n基本路径 4:1→2,3→6→4,5→10→11\n软件的维护演化\n课后习题\n第二章\n1.软件工程的&quot;工程&quot;指的是什么含义?他反映了软件工程具有什么样的基本理念和思想?\n①将系统的、规范的、可量化的方法应用于软件开发、运行和维护的过程\n\n②以及上述方法的研究\n\n基本理念和思想:一是软件工程要提供系统的、规范的可量化的的方法来指导软件的开发、运行和维护,二是研究方法本身\n2.软件工程要为软件开发和运维提供系统的可量化的、规范的方法。请诠释&quot;系统的可量化的、规范的&quot;有何含义\n系统的。是指软件工程关心的是软件全声明周期的开发问题\n\n规范的。是指软件工程所提供的方法可为软件开发活动及其所产生的软件制品提供可准确描述的、标准化的指南\n可量化的。软件工程采用可量化的手段,基于定量的数据来支持软件的开发\n3.软件工程三要素存在什么样的关系?说明面向对象工程的三个构成要素的具体内涵\n这些要素从不同的工程视角关注软件的开发、运行和维护的问题,为软件质量保证提供了不同的支持,构成了&quot;系统、规范和可量化&quot;的方法\n\n\n\n*过程*:\n\n\t从管理的视角,回答软件开发、运行和维护需要做哪些工作、如何管理好这些工作,关注软件的规范化组织和可量化实施\n\n*方法学*:\n\n\t从技术的视角,回答软件开发、运行和维护如何做的问题。\n\n*工具*:\n\n\t从工具辅助的视角,回答如何借助工具来辅助软件开发、运行和维护的问题\n\n4.面向对象程序设计体现了哪些软件工程的基本原则?请举例说明\n抽象和建模：面向对象程序设计通过抽象和建模来描述和解决问题。它将现实世界的事物抽象为类和对象，并定义它们之间的关系和行为。这样可以更好地理解问题领域，使设计更符合实际需求。\n\n模块化：面向对象的程序设计鼓励将代码组织成模块化的、可重用的单元，即类。每个类都封装了相关的数据和方法，提供了一种结构化的方式来组织代码。这符合软件工程中的模块化原则，将系统划分为相互独立且可测试的模块，提高代码的可维护性和可重用性。\n\n软件重用：面向对象程序设计通过继承、组合和接口等机制来实现代码的重用。通过定义通用的类和接口，可以在不同的项目中重用已有的代码，提高开发效率和代码质量。\n\n信息隐藏：面向对象程序设计通过封装来隐藏类的内部实现细节，仅暴露必要的接口给其他模块使用。这样的信息隐藏有助于提高系统的可维护性和可扩展性，同时保护了数据的完整性。\n\n第三章\n1.软件过程模型和软件生存周期这两个概念有何区别和联系？\n软件生存周期是针对软件而言的，它是指软件从提出开发开始到最终退役所经历的阶段\n\n软件过程模型是针对软件开发而言的，他关注的是指导软件开法的相关步骤和活动\n\n2.对比分析迭代模型、增量模型、螺旋模型、UP 模型之间的差异性\n\n\n\n模型名称\n指导思想\n关注点\n适用软件\n管理难度\n\n\n\n\n瀑布模型\n为软件开发提供系统性的指导\n与软件生存周期相一致的软件开发过程\n需求变动不大、较为明确、可预先定义的应用\n易\n\n\n原型模型\n以原型为媒介指导用户的需求导出和评价\n需求获取、导出和确认\n需求难以表述清楚、不易导出和获取的应用\n易\n\n\n增量模型\n快速交付和并行开发软件系统\n软件详细设计、编码和测试的增量完成\n需求变动不大、较为明确、可预先定义的应用\n易\n\n\n迭代模型\n多次迭代，每次仅针对部分明确的软件需求\n分多次迭代来开发软件,每次仅关注部分需求\n软件需求变动大,难以一次说清楚的应用\n中等\n\n\n基于构件的过程模型\n基于和构建重用来开发软件\n构件的搜索、选择、构件和组装\n需求明确,具有丰富构件库的应用\n中等\n\n\n螺旋模型\n集成迭代模型和原型模型，引入风险分析等管理活动\n软件计划制定和实施，软件风险管理,基于原型的迭代式开发\n开发风险大,需求难以明确的应用\n难\n\n\nUP 模型\n集成迭代过程模型和面向对象最佳实践\n参考最佳实践，借助面向对象最佳实践来指导迭代开发\n软件需求不明确且经常变化的应用\n难\n\n\n\n3.开发一个软件项目为什么需要软件过程模型？如果没有过程模型的指导，会产生什么样的情况？\n软件过程定义了软件开发和维护的一组有序活动集合，它为相关人员参与软件开发、完成开发任务提供了规范化路线\n\n没有过程模型的指导，会产生\n1）不可预测的开发过程\n2）风险无法控制\n3）低质量的交付\n4.当开发一个软件项目时，应考虑哪些方面的因素来选择或指定合适的软件过程模型\n考虑软件项目的特点\n考虑软件项目开发的风险\n考虑团队的经验水平\n5.如果要开发一个军用软件项目，用户方有明确的需求，对软件质量提出非常高的要求，请问采用哪种开发过程模型和方法较为适合？为什么？\n\n\n瀑布模型：瀑布模型是一种线性顺序的开发过程模型，包括需求定义、系统设计、编码、测试和部署等阶段。对于军用软件项目，明确的需求和高软件质量要求可以与瀑布模型的严格阶段性和文档化要求相匹配。瀑布模型有助于详尽地定义和分析需求，进行全面的系统设计和严格的软件测试，从而提供高质量和可靠的软件交付。\n\n\n\n\n增量模型：增量模型强调在迭代和增量的基础上进行软件开发。每个增量都是一个完整的软件版本，包括设计、编码、测试和部署等活动。这种模型可以快速交付部分功能，以便用户方早期验证和反馈。对于军用软件项目，采用增量模型可以确保及时响应用户需求、减少风险和提供高质量的软件交付。\n\n\n任选其一\n6.如果要开发一个业务信息系统项目，系统的需求来自一线业务工作人员，需要不断进行及交流和反馈，请问采用哪种开发过程模型和方法较为适合？为什么？\n\n\n敏捷方法（如 Scrum）：敏捷方法适合需要灵活性、快速反馈和持续交付的项目。由于业务信息系统项目的需求可能会频繁变化和调整，采用敏捷方法可以通过短期迭代和增量交付的方式，不断进行交流和反馈。敏捷方法强调与业务工作人员的紧密合作，他们可以参与到项目开发中，提供及时的需求反馈和验证，从而确保系统符合业务需求。\n\n\n增量模型：增量模型适合需要快速交付可用功能的项目。对于业务信息系统项目，用户对系统功能的反馈和验证非常重要。采用增量模型可以在每个增量中交付一部分功能，使业务工作人员能够及时使用并提供反馈。这样可以确保系统开发的正确性和符合业务需求，同时减少开发过程中的风险。\n\n\n迭代模型：迭代模型强调通过反复迭代的方式逐步完善系统。业务信息系统项目通常具有复杂的需求和较长的生命周期，通过采用迭代模型，可以在每个迭代中集中精力开发和验证一部分功能。业务工作人员可以参与每个迭代的需求讨论和验证过程，确保系统开发与业务需求保持一致。\n\n\n原型模型：原型模型适合在项目初期需要进行需求探索和验证的情况。通过快速构建原型，与业务工作人员进行交流和演示，可以及时捕捉需求细节和调整。原型模型有助于提高业务工作人员对系统的理解和参与度，从而确保系统满足其实际需求。\n\n\n任选其一\n7.软件开发方法与软件过程模型二者有何差别?请结合迭代模型和敏捷方法,说明他们之间的区别的和联系\n8.为什么说传统的软件过程模型是重型的,体现在哪里?为什么说敏捷方法是轻型的,体现在哪里?\n传统的软件过程模型他们都以文档为中心指导软件开发\n体现在:软件开发和运维的大量工作用于撰写和评审文档而非编写程序代码\n软件需要变化是常态,一旦需求发生变化,开发人员不得不首先去修改软件需求文档,并据此来调整其它文档,最后再根据修改后的文档来修改程序代码\n\n敏捷方法以代码为中心,快速、轻巧和主动应对需求变化,持续、及时交付可运行的软件系统,体现在:\n① 较之于过程和工具,应更加重视人和交互的价值。\n② 较之于面面俱到的文档,应更加重视可运行软件的价值\n③ 较之于合同谈判,应更加重视用户合作的价值\n④ 较之于遵循计划,应更加重视响应用户需求的变化的价值\n第十五章\n1.何为软件维护,何为软件演化?这两个概念有何区别和联系?\n软件维护是指软件交付给用户使用后修改软件系统及其他部件的过程,以修复缺陷,提高性能或者其他属性,增强软件功能以及适应变化的环境。\n\n软件演化是指针对软件的大规模功能增强和结构调整,以实现变化的软件需求或者提高软件系统的质量。\n\n\n\n\n\n交付后的软件依然还会经历变更,而其中仅有少数变更属于真正意义上的&quot;软件维护&quot;范畴,更多的变更则属于&quot;软件演化&quot;的范畴\n\n2.软件维护有哪几种形式\n\n\n\n类别\n起因\n目的\n维护行为\n\n\n\n\n纠正性维护\n软件存在缺陷\n诊断、纠正和修复软件缺陷\n修改代码和调整文档\n\n\n改善性维护\n增强软件的功能和服务\n满足用户增长和变化的软件需求\n编写代码和撰写文档\n\n\n适应性维护\n软件运行所依赖的环境发生了变化\n适应软件运行的变化和发展\n编写代码和撰写文档\n\n\n预防性维护\n软件质量出现了下降\n提高软件系统的质量,尤其是内部质量\n重组代码和撰写文档\n\n\n\n3.软件维护通常会面临哪些困难和挑战\n同步性\n周期长\n费用高\n难度大\n4.为什么软件不会有物理层面的老化现象,但会出现逻辑层面的老化现象?请举例说明\n软件部署在某个计算环境下运行,运行次数和运行持续时间不会对软件系统的物理特性产生影响,所以不会产生物理层面的老化现象,而随着软件在维护和演化的过程中出现用户满意度降低、质量逐渐下降、变更成本不断上升等现象,这种现象发生在逻辑层面而不在物理层面\n5.为什么说软件逻辑老化不可避免,只要有维护就必然会导致软件逻辑老化?能否通过软件维护来解决软件逻辑老化的问题?\n软件维护虽然可以解决软件中潜藏的某些缺陷,但也会引入新的缺陷,在对软件进行改善性维护的同时,尽管增加了新的功能,但也会破坏软件架构,引入新的软件问题,使得整个软件不易于维护.软件架构变得脆弱。因此,随着对软件的不断维护,必然会导致整个软件逻辑老化\n能,基于软件系统的可维护性以及软件系统的价值,采取以下 4 种方式和策略来应对\n维护。如果软件系统的价值较低,但是软件系统的可维护性较好,软件维护团队可以对软件系统进行有限的维护工作\n\n抛弃。如果软件系统的价值较低,且软件系统的可维护性低,软件团队可以逐步抛弃对软件系统的维护\n\n再工程。如果软件系统的价值较高,但软件系统的可维护性低,此时软件维护团队可以主动采取再工程的为胡策略。如对软件系统进行重组\n\n演化。如果软件系统的价值较高,可维护性好,软件维护团队可以采取积极和主动的演化策略\n\n6.软件重构、重组、逆向工程和再工程有何区别?请举例说明\n","slug":"软件工程基础","date":"2023-07-18T03:21:00.000Z","categories_index":"计算机基础,软件工程","tags_index":"软件工程","author_index":"ND_LJQ"},{"id":"29e4dbba1d3f967e673873a69efe5305","title":"计算机组成原理基础","content":"计算机的系统概述计算机的层次结构计算机系统的组成 硬件系统和软件系统共同构成了一个完整的计算机系统。硬件是指有形的物理设备,是计算机系统重实际物理装置的总称。软件是指在硬件上运行的程序和相关的数据及文档\n计算机硬件冯诺依曼机的基本思想 冯诺依曼在研究 EDVAC 机时提出了&quot;存储程序&quot;的概念,存储程序的思想奠定了现代计算机的基本结构,以此概念为基础的各类计算机通称为冯诺依曼机其特点如下 👇:\n\n采用&quot;存储程序&quot;的工作方式,基本工作方式为控制流驱动方式\n计算机硬件系统由运算器、存储器、控制器、输入设备和输出设备5 大部件组成\n指令和数据以同等地位存储中,形式上没有区别,但计算机等区分他们\n指令和数据均用二进制代码表示。指令由操作码和地址码组成,操作码指出操作的类型,地址码指出操作数的地址\n\n\n\n\n\n\n\n\n\n\n🙋‍♂️存储程序的基本思想是:\n 将事先编写好的程序和原始数据送入主存后才能执行,一旦程序成功执行,就无须操作人员干预,计算机会自动逐条执行指令,直至程序执行结束\n计算机的功能部件后面详细介绍\n输入设备\n输出设备\n存储器\n运算器\n控制器\n冯诺依曼结构的模型机示意图 👇\n\n计算机软件系统软件和应用软件软件按其功能分类,可分为系统软件和应用软件\n系统软件是一组保证计算机系统高效、正确运行的基础软件,通常作为系统资源提供给用户使用\n系统软件主要有:\n 操作系统(OS)、数据库管理系统(DBMS)、语言处理程序、分布式软件系统、网络软件系统、标准库程序、服务性程序\n应用软件是指用户为解决某个应用领域中的各类问题而编制的程序,如各种科学计算类程序、工业设计类程序、数据统计与处理程序\n三个级别的语言1️⃣机器语言\n 二进制代码语言。==机器语言是计算机唯一可以直接识别和执行的语言==\n2️⃣汇编语言\n 汇编语言用英文单词或其缩写替代二进制指令代码,更容易为人们记忆和理解.使用汇编语言编写的那些的程序,必须经过一个称为汇编程序的系统软件的翻译,将其转换为机器语言程序后,才能在计算机的硬件系统上执行\n3️⃣高级语言\n高级语言需要经过汇编程序编译成汇编语言程序,然后经过汇编操作得到机器语言程序,或直接由高级语言翻译成机器语言程序\n由于计算机无法直接理解和执行高级语言程序,需要将高级语言程序转化为机器语言程序,通常把进行这种转换的软件统称为翻译程序。翻译程序由以下三类 👇:\n\n汇编程序(汇编器)。将汇编语言程序翻译成机器语言程序。\n解释程序(解释器)。将源程序中的语句按执行顺序逐条翻译成机器指令并立即执行\n编译程序(编译器)。将高级语言程序翻译成汇编语言或机器语言程序\n\n\n\n\n\n\n\n\n\n\n🙋‍♂️硬件和软件的逻辑功能等价性即对某一功能来说,既可以由硬件实现,又可以用软件实现\n硬件实现具有更高的执行速度,软件实现具有更好的灵活性,执行频繁、硬件实现代价不是很高的功能通常由硬件实现\n计算机的层次结构计算机是一个硬软件组成的综合体。由于软/硬件的设计者和使用者从不同的角度、用不同的语言来对待同一个计算机系统,因此他们看到的计算机系统的属性,对计算机系统提出的要求也就各不相同。\n以下是计算机系统的多级层次机构示意图 👇:\n\n第 1 级是微程序机器层,这是一个实在的硬件层,它由机器硬件直接执行微指令\n第 2 级是传统机器语言层,它也是一个实在的硬件层,它由微程序解释机器指令系统\n第 3 级是操作系统层,它由操作系统程序实现。操作系统程序是由机器指令和广义指令组成的,所以这一层也被称为混合层\n第 4 级是汇编语言层,它为用户提供一种符号化的语言,借此可编写汇编语言源程序。这一层由汇编程序支持和执行\n第 5 级是高级语言层,它是面向用户的,是为了方便用户编写以应用程序而设置的,该层由各种高级语言编译程序支持和执行\n高级语言层之上还可以由应用程序层,它由解决实际问题和应用问题的处理程序组成,如文字处理软件、数据库软件、多媒体处理软件和办公自动化软件\n没有配备软件的纯硬件系统称为裸机。第 3 层~第 5 层称为虚拟机,简单来说就是软件实现的机器,虚拟机只对该层的观察者存在\n层次之间关系紧密,下层是上层的基础,上层是下层的拓展\n\n\n\n\n\n\n\n\n\n🙋‍♂️计算机组成原理主要讨论传统机器 M1 和微程序机器 M0 的组成原理和设计思想\n计算机的性能指标计算机的主要系统指标🥖字长\n 指计算机进行一次整数运算(即定点整数运算)所能处理的二进制数据的位数,通常与 CPU 的寄存器位数、加法器有关。因此字长一般等于内部寄存器的大小,字长越长,数的表示范围越大,计算精度越高。计算机字长通常选定为字节(8 位)的整数倍\n\n\n\n\n\n\n\n\n\n🤔字、字长、机器字长、指令字长、存储字长的区别和联系是什么?\n 在通常所说的&quot;某32位或64位机器&quot;中,32、64 指的是字长,也称机器字长。所谓字长,通常是指 CPU 内部用于证书运算的数据通路的宽度,因此字长等于 CPU 内部用于整数运算的运算器位数和通用寄存器宽度,它反应了计算机处理信息的能力。字和字长概念不同。字用来表示被处理信息的单位,用来度量数据类型的宽度,如 x86 机器中将一个字定义为 16 位\n 指令字长:一个指令字中包含的二进制代码的位数\n 存储字长:一个存储单元存储的二进制代码的长度\n指令字长一般取存储字长的整数倍,若指令字长等于存储字长的 2 倍,则需要两个存储周期来取出一条指令;若指令字长等于存储字长,则取指周期等于机器周期\n他们必须是字节的整数倍\n📼数据通路带宽\n数据带宽是指数据总线一次所能并行传送信息的位数。这里说的数据通路宽度是指外部数据总线的宽度,它与 CPU 内部的数据总线的宽度(内部寄存器的大小)有可能不同\n\n\n\n\n\n\n\n\n\n🙋‍♂️ 各个子系统通过数据总线连接形成的数据传送路径称为数据通路\n🍼主存容量\n主存容量是指主存储器所能存储信息的最大容量,通常以字节来衡量,也可以用字数 × 字长(如 512K×16 位)来表示存储容量。其中 MAR 的位数反映存储单元可寻址范围的最大值(而不一定是实际存储器的存储容量)\n\n\n\n\n\n\n\n\n\n例如,MAR 为 16 位,表示 2^16^=65536,即此存储体内有 65536 个存储单元(可称为 64K 内存,1K=1024)\n🚅运算速度\n==吞吐量和响应时间==\n\n吞吐量\n系统在单位时间内处理请求的数量。它取决于信息能多快地输入内存,CPU 能多快地取指令,数据能多快地动内存取出或读入,以及所得结果能多快地从内存送给一台外部设备。每一步都涉及主存。因此系统吞吐量主要取决于主存的存取周期\n\n响应时间\n指从用户向计算机发送一个请求,到系统对该请求做出的响应并获得所需结果的等待时间。通常包括 CPU 时间(运行一个程序所花费的时间)与等待时间(用于磁盘访问、存储器访问、I/O 访问、操作系统开销等的时间)\n\n\n==主频和 CPU 时钟周期==\n\nCPU 时钟周期\n通常为节拍脉冲(被称之为节拍或者拍)或者 T 周期,即主频的倒数,它是 CPU 中最小的时间单位,执行指令的每个动作至少需要 1 个时钟周期\n\n主频(CPU 时钟频率)\n机器内部主时钟的频率,是衡量机器速度的重要参数。对于同一个型号的计算机,其主频越高完成一个执行步骤的时间越短\n\n\n\n\n\n\n\n\n\n\n\n🙋‍♂️CPU 时钟周期 = 1/主频,主频通常以 Hz 时(赫兹)为单位,1Hz 表示每秒一次\n🤔时钟周期、机器周期与指令周期的概念与联系是什么?\n指令周期:\n CPU 从存储器中取出并执行一条指令所需的全部时间称之为指令周期。\n计算机每执行一条指令的过程，可分解为如下步骤：\n\nInstruction Fetch（取指令：指令放在存储器，通过 PC 寄存器和指令寄存器取出指令的过程，由控制器（Control Unit）操作。 从 PC 寄存器找到对应指令地址，据指令地址从内存把具体指令加载到指令寄存器，然后 PC 寄存器自增；\nInstruction Decode（译码：据指令寄存器里面的指令，是哪一种类型的指令，解析成要进行什么操作，具体要操作哪些寄存器、数据或内存地址。该阶段也是由控制器执行；\nExecute（执行）：实际执行算术逻辑操作、数据传输或者直接的地址跳转操作。无论是算术操作、逻辑操作的指令，还是数据传输、条件分支的指令，都由算术逻辑单元（ALU）操作，即由运算器处理。如果是一个简单的无条件地址跳转，那可直接在控制器里完成，无需运算器\n\n重复 1 ～ 3 的过程，这个循环完成的时间即指令周期。\n机器周期:\n 又称为CPU 周期（CPU Cycle）。一个机器周期内包含若干时钟周期，包含时钟周期的个数称之为机器周期的时间宽度。\n\n总结:\n==一个指令周期包含多个机器周期，而一个机器周期包含多个时钟周期==\n==CPI==\n CPI(Clock cycle Per Instruction),即执行一条指令所需要的时钟周期数\n\n\n\n\n\n\n\n\n\n🙋‍♂️ 不同指令的时钟周期数可能不同,因此对于一个程序或一台机器来说,其 CPI 是指该程序或机器啊指令集中所有指令执行所需的平均时钟周期数,,此时 CPI 是一个平均值\n==CPU 执行时间==\n 指运行一个程序所要花费的时间\nCPU执行时间 = CPU时钟周期数/主频 = (指令条数×CPI)/主频\n\n\n\n\n\n\n\n\n\n🙋‍♂️ 上式表 CPU 性能(CPU 执行时间)取决于三个要素:① 主频(时钟频率);② 每条指令执行所用的时钟周期数;③ 指令条数\n主频、CPI 和指令条数时相互制约的,例如,更改指令集可以减少程序所含指令的条数,但可能会引起 CPU 结构的调整,从而可能会增加时钟周期的宽度(降低主频)\n==MIPS==\n 每秒执行多少百万条指令\n==MFLOPS、GFLOPS、TFLOPS、PFLOPS、ZFLOPS 和 EFLOPS==\n 每秒执行多少百万、千万….条浮点指令\n\n\n\n\n\n\n\n\n\n🚨 在描述容量存储容量、文件大小等时,K、M、G、T 通常用 2 的幂次来表示,例如 1Kb = 2^10^b;\n 在描述速率、频率等时 k、M、G、T 通常用 10 的幂次方表示,如 1kb/s = 10^3^b/s。通常前者用大写的 K,后者用小写的 k,但其他前缀均为大写,表示含义取决于所用场景\n👨‍💻基准程序\n 基准程序是专门用来进行性能评价的一组程序,能够很好的反映机器在运行实际负载时的性能,可以通过在不同机器上运行相同的基准程序来比较在不同机器上的运行时间,从而评价其性能\n几个专业术语\n系列机:具有基本相同的体系结构,使用相同的基本指令系统的多个不同型号的计算机组成的一个产品系列。\n兼容:指软件或硬件的通用性,即运行在某个型号的计算机系统重的硬件/软件也应用于另一个型号的计算机系统时,称这两台计算机在硬件或软件上存在兼容性\n-\n\n软件可移植性:指把某个系列计算机中的软件直接或进行很少的修改就能运行在另一个系列计算机中的可能性\n\n固件:将程序固话在ROM中组成的部件称为固件。固件是一种具有软件特性的硬件,吸收了软/硬件各自的优点,其执行速度快于软件,灵活优于硬件,是软/硬结合的产物\n透明性:在计算机领域中,站在某类用户的角度,若感觉不到某个事物或者属性的存在,即”看”不到某个事物或者属性,则称为”对该用户而言,某个事物或属性是透明的”,这与日常生活中”透明”的概念(公开、看得见)正好相反\n例如:对于高级语言程序员来说,浮点数格式、乘法指令等这些指令的格式、数据如何在运算器中运算等都是透明的,而对于机器语言或者汇编语言程序员来说,指令的格式、机器结构、数据格式等则不是透明的\n在 CPU 中IR、MAR和MDR对各类程序员都是透明的\n\n\n\n\n\n\n\n\n\n\n\n🤔计算机体系结构和计算机组成的区别是和联系是什么?\n计算机体系结构是指机器语言或汇编语言程序员所看到的传统机器的属性,包括指令集、数据类型、存储器寻址技术等,大多都属于抽象的属性。\n计算机组成是指如何实现计算机体系结构所体现的属性,它包含对许多程序员类说透明的硬件细节。\n例如:指令系统属于结构的问题,但指令的实现即如何取指令、分析指令、如何运算等都属于组成的问题。因此,当两台机器指令系统相同时,只能认为他们具有相同的结构,至于这两台机器如何实现其指令,完全可以\n数据的表示和运算==数制与编码==进位计数制及其相互转换进位计数法常用的进位计数法有十进制、二进制、八进制、十六进制等\n一个r进制数(K~n~K~n-1~…K~0~K~-1~…K~-m~)的数值可表示为:\n$Kn r^n+K{n-1} r^{n-1}+\\cdots+K0 r^0+K{-1} r^{-1}+\\cdots+K{-m} r^{-m}=\\sum{i=n}^{-m} K_i r^i$\n其中r是==基数==;r^i^是第 i 位的位权(整数位最低位规定为第 0 位);K~i~的取值可以是 0,1,…,r-1 共 r 个数码中的任意一个\n数制的表示有 2 种方法，一种表示方法是数字下标法，对于不同进制的数可以将它们加上括号再用数字下标表示进制：\n例如：（110010011111）2 代表二进制数 ； （6137）8 代表八进制数\n另一种是用后缀字母表示进制：\n二进制 B (binary)八进制 O (octal)十进制 D (decimal)十六进制 H (hexadecimal)\n例如：（3AB）H 代表十六进制数；（2654）O 代表八进制数\n\n\n\n\n\n\n\n\n\n当没有下标或后缀时默认为十进制数。\n\n二进制。计算机中用得最多的是基数为 2 的计数制,即 2 进制\n八进制。只有 0~7 共 8 位数字,计数”逢八进一”,因为 r = 2^3^所以只要把二进制中的 3 位数码编为一组就是一位八进制数\n\n举个 🌰:将二进制数 1111000010.011101 转为 8 进制数\n\n所以对应的 8 进制数为(1702.32)~8~\n\n十六进制数。也是二进制的一种常用的书写方式,其基数为 16,”逢十六进一”。每个十六进制数位可以取 0~9、A、B、C、D、E、F,A~F 表示 10~15。因为 r = 16 = 2^4^,所以只要把二进制中的 4 位数码编写为一组就是一位十六进制数\n\n举个 🌰:将二进制数 1111000010.011101 转为 16 进制数\n\n所以对应的 16 进制数为(3C2.68)~16~\n将任意进制数转换为十进制数\n将任意一个进制数的各位数码与他们的权值相乘,再把乘积相加,就得到了一个十进制数。这种方法称为按权展开相加法\n举个 🌰:将二进制数 11011.1 转为 10 进制数\n(11011.1)~2~ = 1×2^4^ + 1×2^3^ + 1×2^1^ + 1×2^0^ + 1×2^-1^ = 27.5\n将十进制数转换为任意进制数\n一个十进制数转换为任意进制数,其整数部分常采用除基取余法,余数部分常采用乘基取余法\n==除基取余法==\n整数部分除基取余,最先取得的余数为数的最低位,最后取得的余数为数的最高位,商为 0 时结束\n==乘基取整法==\n小数部分乘基取整,最先取得的整数为数的最高位,最后取得的整数为数的最低位,乘积为 1.0(或满足精度要求)时结束\n举个 🌰:将十进制数 123.6875 转为 2 进制数\n整数部分:除基取余\n\n小数部分:乘基取整\n\n所以(123.6875)~10~ = (1111011.1011)~2~\n\n\n\n\n\n\n\n\n\n🚨 在计算机中,小数和整数不一样,整数可以连续表示,但小数是离散的,所以并不是每一个十进制小数都可以准确地用二进制表示。例如 0.3。但任意一个二进制小数都可以用十进制小数表示\n真值和机器数\n在计算机中,通常将数的符号和数值部分一起编码,将数据的符号数字化,通常使用&quot;0&quot;表示&quot;正&quot;,用&quot;1&quot;表示&quot;负&quot;。这种把符号”数字化”的数称为机器数。常用的有原码、补码和反码表示法。如 0,101(这里的逗号”,”仅为区分符号位与数值位)表示+5\n定点数的编码表示 根据小数点的位置是否固定,在计算机中有两种数据格式:==定点表示==和==浮点表示==。在现代计算机中,通常用定点补码整数表示整数,用定点原码小数表示浮点数的尾数部分,用移码表示浮点数的阶码部分。\n机器数的定点表示定点小数:\n\n定点整数:\n\n\n\n\n\n\n\n\n\n\n🙋‍♂️ 上图中的小数点其实并不真实存在,而是隐含位,是由计算机硬件进行处理的\n定点数编码表示法主要有以下 4 种:==原码==、==补码==、==反码==和==移码==\n原码、补码、反码、移码原码表示法\n纯小数原码定义\n\n$[x]{\\text{原}} = \\begin{cases} x &amp; 1 &gt; x \\geq 0 \\ 1 - x = 1 + | x | &amp; 0 \\geq x &gt; - 1 \\end{cases} ( [ x ]  { 原 }\\text{是原码机器数,x 是真值})$\n例如,若 x~1~ = +0.1101, x~2~ = -0.1101,字长为 8 位,则其原码表示为[x~1~]~原~ = 0.1101000,[x~2~]~原~ = 1.1101000\n若字长为 n+1,则原码小数的表示范围为 -(1-2^-n^) &lt;= x &lt;= 1-2^-n^(关于原点对称)\n\n纯整数原码定义^*^\n\n$[x]_\\text{原}=\\begin{cases}0,x&amp;2^n&gt;x\\geq0\\2^n-x=2^n+|x|&amp;0\\geq x&gt;-2^n\\end{cases}(x+\\text{是真值,}n\\text{ 是整数位数)}$\n\n\n\n\n\n\n\n\n\n🚨 真值零的原码表示有正零和负零两种形式,即[+0]~原~ = 00000 和[-0]~原~ = 10000\n原码的优点是 与真值的对应关系简单、直观,与真值的转换简单,并且用原码实现乘除运算比较简单。\n缺点是,0 的表示不唯一,更重要的是原码加减运算比较复杂(其复杂体现在对于两个不同符号数的加法(或同符号数的减法),先要比较两个数绝对值大小,再用绝对值大的数减去绝对值小的数,最后还要给结果选择合适的符号)\n补码表示法补码的加减运算同一用加法操作实现\n\n纯小数补码定义(了解)\n\n$[x]_{\\text{补}}=\\begin{cases}x&amp;1&gt;x\\geq0\\2+x=2-\\mid x\\mid&amp;0&gt;x\\geq-1\\end{cases}({\\mathrm{mod}}2)$\n若字长为 n+1,则补码表示范围为-1 &lt;= x &lt;= 1-2^-n^ (比原码多表示-1)\n\n纯整数的补码定义\n\n$[x]_\\text{补}=\\begin{cases}0,x&amp;2^n&gt;x\\geq0\\2^{n+1}+x=2^{n+1}-\\mid x\\mid&amp;0\\geq x\\geq-2^n\\end{cases}\\pmod{2^{n+1}}$\n若字长为 n+1,则补码的表示范围为-2^n^ &lt;= x &lt;= 2^n-1^ (比原码多-2^n^)\n补码计算法定义：非负数的补码是其原码本身；负数的补码是其绝对值的原码最高位符号位不变，其它位取反，再加 1。\n一个字节 8 位，如果采用原码表示正整数（含 0），可以表达 0-255，即 2^8^=256，一共 256 种状态，从全 0 到全 1 的各种排列组合。如果要表示负数，则符号位需要占用一位（最高位，1 代表负数，0 代表正数），因此其绝对值最大范围为 0-127，即 2^7^=128，一共正负各 128 种状态，如果不采用特殊处理，这时候 0 占用 2 个编码（10000000 和 00000000），数据表示范围为-127 到-0 及+0 到 127，这样总体上一个字节只有 255 种状态，因为其中 0 具有正 0 和负 0 之分，这不符合数学意义也浪费一个编码。\n  除了以上的弊端，还有个原因是，早期硬件很昂贵，一位或者一个编码的浪费都是不可饶恕的，因此人们想到了另一种编码把负0利用起来，即当遇到负数时，采用补码来表示就可以解决这个问题，而遇到正数或0时还是保留原码表示。因此这个负0通过补码算法处理后自然而然地被利用起来，用来表示-128.\n\n补码的算法为：绝对值的原码各位取反后加1.\n例1：负1的补码：\n    绝对值的8位原码为00000001\n    取反：11111110\n    加1 ：11111111\n    此时最高位被处理为1，满足高位为1代表负数的定义。\n例2：负128的补码：\n    绝对值的8位原码为10000000\n    取反：01111111\n    加1 ：10000000\n此时同样的最高位被置为 1，同样满足高位为 1 代表负数的定义,同时原先表示负 0 的编码被利用起来表示-128。因此一个字节的有符号整数范围为-128 到 127。\n综上为：\n 原码+反码：8位原码和反码能够表示数的范围是-127~127；\n\n 补码：8位补码能够表示数的范围是 -128~127。\n\n（在补码中用(-128)代替了(-0)，所以补码的表示范围为：(-128~0~127)共256个）\n\n变形补码\n\n变形补码,又称模 4 补码,双符号位的补码小数\n概念:\n 用两个二进制位来表示符号位，其余位与补码相同，【例如模 2 补码的-3 为 1101,模 2 用 1 位，这里是最高位表示符号位，剩下 3 位是 3 的补码，同样模 4 补码表示-3 为 11_101,模 4 用两位表示符号位，这里是最高两位 11，其余 3 位为 3 的补码】总的说来就是符号位左边那一位表示正确的符号(这就说明了选择题里面存储模 4 补码只需要一个符号位是正确的，因为任意一个正确的数值，模 4 补码的符号位两个都是一样的，只需存储一个就行了)，0 为正，1 为负；右边那一位如果和左边的相同，如 “00”表示正且无溢出，”11”表示负且无溢出。如果右边那一位与左边那一位不一样，则表示有溢出。\n\n\n\n\n\n\n\n\n\n对任意的x,若已知[x]补,则把[x]补连同符号位的每一位都取反再加1即可得到[-x]补\n反码表示法反码表示法的定义就是,负数补码的最后一位减 1,整正数反码的的定义与相应的补码(或原码)表示相同\n0 的表示不唯一\n移码表示法移码常用来表示浮点数的阶码,他只能表示整数\n移码就是真值 X 上加上一个常数(偏置值),通常这个常数取 2^n^,相当于 X 在数轴上正方向偏移了若干单位,这就是”移码”一词的由来。\n移码的定义为:\n$[x]_{移}=2^{n}+x(2^{n}&gt;x\\geq-2^{n},\\text{ 其中机器字长为 }n+1)$\n若正数 x~1~ = +10101,x~2~ = -10101,字长为 8 位则其移码表示为 x~1 移~ = 2^7^+10101 =&gt; 1,0010101 ;x~2 移~ = 2^7^+(-10101) =&gt; 0,1101011\n一个真值的移码与补码仅差一个符号位,[x]~补~的符号位取反即得[x]~移~\n移码中零的表示唯一\n移码全 0,对应真值的最小值-2^n^;移码全 1 时,对应真值最大值 2^n^-1\n运算方法和运算电路基本运算部件 在计算机中,运算器由算数逻辑单元(Arithmetic Logic Unit, ALU)、移位器、状态寄存器和通用寄存器等组成的。运算器的基本功能包括加减乘除四则运算,与、或、非、异或等逻辑运算,以及移位、求补等操作。ALU的核心部件是加法器\n以下是一些常用的逻辑符号👇:\n\n公式和定理👨‍🏫常量之间的关系:\n$\\begin{aligned}&amp;\\text{公式1} &amp;&amp; 0 \\cdot 0 = 0 \\&amp;\\text{公式}1’ &amp;&amp; 1 + 1 = 1 \\&amp;\\text{公式2} &amp;&amp; 0 \\cdot 1 = 0 \\&amp;\\text{公式}2’ &amp;&amp; 1 + 0 = 1 \\&amp;\\text{公式3} &amp;&amp; 1 \\cdot 1 = 1 \\&amp;\\text{公式}3’ &amp;&amp; 0 + 0 = 0 \\&amp;\\text{公式4} &amp;&amp; \\overline{0} = 1 \\&amp;\\text{公式}4’ &amp;&amp; \\overline{1} = 0 \\\\end{aligned}$\n常量与变量的关系\n$\\begin{aligned}&amp;\\text{公式5} &amp;&amp; A\\cdot1=A \\&amp;\\text{公式}5’ &amp;&amp;  A+0=A \\&amp;\\text{公式6} &amp;&amp; A\\cdot0=0 \\&amp;\\text{公式}6’ &amp;&amp; A+1=1 \\&amp;\\text{公式7} &amp;&amp; A\\cdot\\overline{A}=0 \\&amp;\\text{公式}7’ &amp;&amp; A+\\overline{A}=1 \\end{aligned}$\n与普通代数相似的定理\n$\\begin{aligned}&amp;\\textbf{交换律} \\&amp;\\text{公式8}&amp;&amp; A\\cdot B=B\\cdot A  \\&amp;\\text{公式8}’&amp;&amp; A+B=B+A  \\&amp;\\textbf{结合律} \\&amp;\\text{公式9}&amp;&amp; \\left(A\\cdot B\\right)\\cdot C=A\\cdot\\left(B\\cdot C\\right)  \\&amp;\\text{公式}9’&amp;&amp; \\left(A+B\\right)+C=A+\\left(B+C\\right)  \\&amp;\\textbf{分配律} \\&amp;\\text{公式10}&amp;&amp; A\\cdot\\left(B+C\\right)=A\\cdot B+A\\cdot C  \\&amp;公式10^{\\prime}&amp;&amp; A+B\\cdot C=\\left(A+B\\right)\\cdot\\left(A+C\\right) \\end{aligned}$\n逻辑代数的一些特殊定理\n$\\begin{aligned}&amp;\\textbf{同一律} \\&amp;\\text{公式 11}&amp;&amp; A\\cdot A=A  \\&amp;\\text{公式 11}’&amp;&amp; A+A=A  \\&amp;\\textbf{德·摩根定理} \\&amp;\\text{公式 12}&amp;&amp; \\overline{A\\cdot B}=\\overline{A}+\\overline{B}  \\&amp;\\text{公式 12}’&amp;&amp; \\overline{A+B}=\\overline{A}\\cdot\\overline{B}  \\&amp;\\textbf{还原律} \\&amp;\\text{公式13}&amp;&amp; \\overline{\\overline{A}}=A \\end{aligned}$\n若干常用公式\n$\\begin{aligned} &amp;\\text{公式14} &amp;&amp; A \\cdot B + A \\cdot \\overline{B} = A \\ &amp;\\text{公式15} &amp;&amp; A + A \\cdot B = A \\ &amp;\\text{公式16} &amp;&amp;A+\\overline{A}\\cdot B=A+B\\end{aligned}$\n逻辑函数的公式化简法一、并项法\n利用公式 14 把两个乘积项合并起来,消除一个变量。\n🌰:化简函数 Y = ABC + AB┐C+ ┐AB\nAB C + AB ┐C => AB\nAB + ┐AB => B\n二、吸收法\n利用公式 15,吸收掉多余的乘积项\n🌰:化简函数 Y =┐(AB) + ┐AD+ ┐BE\n利用摩根公式\n┐(AB) = ┐A + ┐B\n┐A + ┐AD => ┐A\n┐B + ┐BE => ┐B\n=> ┐A + ┐B\n三、消去法\n利用公式 16 消去乘积中多余的乘积项\n🌰:化简函数 Y = ┐(AB) + AC+ BD\n利用摩根公式\n┐(AB) = ┐A + ┐B\n=> ┐A + ┐B + C + D\n逻辑函数的图形化简法用卡诺图化简逻辑函数,求最简与或表达式的方式被称为图形化简法。图形化简法有较明确的步骤可以遵循,但是变量超过 6 个以上的时候就没什么实用价值了\n卡诺图化简法\n卡诺图是一种最小项方块图,卡诺图的特点是用几何相邻形象地表示各变量各个最小项在逻辑上的相邻性\n下图为变量 AB 的卡诺图:\n\n\n\n\n\n\n\n\n\n\n🚨 上图中 ┐A┐B 不能画作 ┐(AB)只是画图时连接在了一起,二者并不等价\n之后的图省略 ┐A┐B 等为 0 或 1,在逻辑函数中的最小项有 ┐A┐B 则在 卡诺图中 00 位置 填 1\n\n三变量的卡诺图:\n\n下图为四变量的卡诺图:\n\n五变量的卡诺图:\n\n六变量的卡诺图:\n\n\n\n\n\n\n\n\n\n\n🤔为什么卡诺图中的变量取值是 00 01 11 10 而不是 00 01 10 11?\n 因为卡诺图的画法是按循环码排列变量取值顺序。循环码的特点是相邻编码之间只有 1 位码元不同,而若是 01 10 则有两位码元相同。变量取值之所以按循环码排列,是因为保证卡诺图中,凡是几何相邻的最小项,在逻辑上是相邻的这一重要特点\n卡诺图的化简\n\n几何相邻\n\n相接——紧挨着的方块\n相对——任一行或者一列的两头\n相重——对折起来后位置重合\n\n\n逻辑相邻\n如果两个最小项,除了一个变量的形式不同以外,其余的都相同,那么这两个最小项就称为在逻辑上相邻\n\n\n卡诺图中凡是几何相邻的最小项均可合并,合并时能消除有关变量。两个最小项合并成一项时可以消去一个变量,4 个最小项合并成一项可以消除 2 个变量,8 个最小项合并可以消除 3 个变量。所以一般来说 2^n^个最小项合并时可以消去 n 个变量。(即一次看一列或者一行,若有一个码元发生改变,即消除那个发生改变的码元)\n🌰:用图形化化简函数\n$Y=\\overline{B}CD+B\\overline{C}+\\overline{A}\\:\\overline{C}D+A\\overline{B}C$\n\n\n\n\n\n\n\n\n\n┐A┐CD\n① 画出函数的卡诺图\n观察函数,发现函数只有 4 个不同的变量 ABCD,画出四变量卡诺图,在图中标出 Y 所包含的全部最小项,如下图\n② 合并最小项\n合并原则是:\n- 必须包含函数的所有最小项,并且保证合并后的乘积项的总数最少\n- 相邻的最小项合并时,蕴含的最小项数越多,则合并后的乘积因子最少\n- 每次合并时,为了消去更多变量,可以重复使用函数的最小项,但是必须保证至少包含1个新的最小项(未被重复使用过),以避免冗余项的出现\n 圈要少、圈最大（先少后大）\n 化简中注意的问题:\n ➢ 每一个标 1 的方格必须至少被圈一次;\n ➢ 每个圈中包含的相邻小方格数,必须为 2 的整数次幂;\n ➢ 为了得到尽可 能大的圈，圈与圈之间可以重叠;\n ➢ 若某个圈中的标 1 方格,已经完全被其它圈所覆盖,则该圈为多余的。\n\n结果为:Y = B┐C + ┐A┐BD + A┐BC\n五变量化简卡诺图\n\n因为红圈部分为 ┐E 所独有,则在 ┐E 中的化简中 ┐E 不能消除,绿圈中为 ┐E 和 E 图中共有,则消去 E 变量,再把二图中的所得结果相与则可得出最终答案\n一位全加器全加器(FA)是最基本的加法单元,有加数 A~i~、加数 B~i~与低位传来的进位 C~i-1~共三个输入,有本位和 S~i~与向高位的进位 C~i~共两个输出。\n其真值表为:\n\n\n\n\nA~i~(加数)\nB~i~(加数)\nC~i-1~(低位进位)\nS~i~(本位)\nC~i~(向高位进位)\n\n\n\n\n0\n0\n0\n0\n0\n\n\n0\n0\n1\n1\n0\n\n\n0\n1\n0\n1\n0\n\n\n0\n1\n1\n0\n1\n\n\n1\n0\n0\n1\n0\n\n\n1\n0\n1\n0\n1\n\n\n1\n1\n0\n0\n1\n\n\n1\n1\n1\n1\n1\n\n\n\n\n表中目标值(S~i~、C~i~)为 1 的行保留,其他行舍弃\n可得:\n$\\mathrm S=\\overline{Ai}\\:\\overline{B_i}\\mathrm C{i-1}+\\overline{Ai}\\mathrm B_i\\overline{C{i-1}}+\\mathrm Ai\\overline{B_i}\\:\\overline{C{i-1}} +\\mathrm Ai\\mathrm B_i\\mathrm C{i-1}$\n由卡诺图化简得:\n$\\mathrm{S=Ai\\otimes B_i\\otimes C{i-1}}$\n$\\mathrm C{\\mathrm i}=\\mathrm A_i\\mathrm B_i+\\mathrm B_i\\mathrm C{i-1}+\\mathrm C{i-1}\\mathrm A_i=\\mathrm A_i\\mathrm B_i+(\\mathrm A\\otimes\\mathrm B)\\mathrm C{i-1}$\n可以由此画出一位全加器的逻辑结构为:\n\n由此可以得出N 位串行进位加法器的结构:\n\n\n\n\n\n\n\n\n\n\n🙋‍♂️ 在串行进位加法器的最长运算时间是由产生的进位信号所产生的传递延迟所决定的,位数越多延迟时间越长.所以人们又设计出了并行进位加法器\n并行进位加法器\n由$\\mathrm C{\\mathrm i}=\\mathrm A_i\\mathrm B_i+\\mathrm B_i\\mathrm C{i-1}+\\mathrm C{i-1}\\mathrm A_i=\\mathrm A_i\\mathrm B_i+(\\mathrm A\\otimes\\mathrm B)\\mathrm C{i-1}$,令 G~i~= A~i~B~i~,P~i~=A⊕B,可得 C~i~=G~i~+P~i~C~i-1~\n将 G~i~和 P~i~带入前面的 C~1~~C~4~中可得:\n$\\begin{aligned}&amp;\\text{C1} =G{1}+P{1}C{0}  \\&amp;C{2} =G{2}+P{2}C{1}=G{2}+P{2}G{1}+P{2}P{1}C{0}  \\&amp;C{3} =G{3}+P{3}C{2}=G{3}+P{3}G{2}+P{3}P{2}G{1}+P{3}P{2}P{1}C{0}  \\&amp;C{4} =G{4}+P{4}C{3}  =G{4}+P{4}G{3}+P{4}P{3}G{2}+P{4}P{3}P{2}G{1}+P{4}P{3}P{2}P{1}C{0} \\end{aligned}$\n可知 G~i~在 A~i~B~i~输入时就已得出,唯一需要等待的是 C~0~(因为 C~i~可以用 C~0~推导出)\n所以其他位在 C~0~形成时就可同时生成,但是这样的缺陷是,位数越多,电路越复杂\n定点数的运算定点数的移位运算 移位运算根据操作对象的不同分为算术移位和逻辑移位。有符号数的移位称为算术移位，逻辑移位的操作对象是逻辑代码,可视为无符号数。\n算术移位算术移位的对象是有符号数，在移位过程中符号位保持不变 。\n对于正数，由于[x]~原~ = [x]~补~ = [x]~反~ = 真值，因此移位后出现的空位均以 0 添之。对于负数，由与原码，补码，反码的表示形式不同，因此当机器数移位时，对其空位的添补规则也不同\n\n\n\n\n\n\n\n\n\n🙋‍♂️ 不论是正数还是负数，移位后其符号位均不变，且移位后都相当于对真值补 0，根据补码、反码的特性，所以在负数时填补代码有区别。\n对于原码，左移一位若不产生溢出，相当于乘以 2(与十进制的左移一位相当于乘以 10 类似)，右移一位，若不考虑因移出而舍去的末位尾数，相当于除以 2。\n\n由表 2.1👆 可以得出如下结论。\n正数的原码、补码与反码都相同，因此移位后出现的空位均以 0 添之。对于负数，由于原码、补码和反码的表示形式不同，因此当机器数移位时，对其空位的添补规则也不同。\n\n负数的原码数值部分与真值相同，因此在移位时只要使符号位不变，其空位均添 0。\n负数的反码各位除符号位外与负数的原码正好相反，因此移位后所添的代码应与原码相反，即全部添 1。\n分析由原码得到补码的过程发现，当对其由低位向高位找到第一个“1”时，在此“1”左边的各位均与对应的反码相同，而在此“1”右边的各位（包括此“1”在内）均与对应的原码相同。因此负数的补码左移时，因空位出现在低位，则添补的代码与原码相同，即添 0;右移时因空位出现在高位，则添补的代码应与反码相同，即添 1。\n\n逻辑移位逻辑移位将操作数视为无符号数，移位规则:逻辑左移时，高位移丢，低位添 0;逻辑右移时，低位移丢，高位添 0。\n\n\n\n\n\n\n\n\n\n🙋‍♂️ 逻辑移位不管是左移还是右移，都添 0。\n循环移位分为带进位标志位 CF 的循环移位(大循环）和不带进位标志位的循环移位（小循环)，过程如图 2.7 所示。\n循环移位的主要特点是，移出的数位又被移入数据中，而是否带进位则要看是否将进位标志位加入循环位移。例如，带进位位的循环左移〔见图 2.7(d)]就是数据位连同进位标志位一起左移，数据的最高位移入进位标志位 CF，而进位位则依次移入数据的最低位。\n\n循环移位操作特别适合将数据的低字节数据和高字节数据互换。\n带进位标志位CF的循环左移（大循环）：\n假设有一个8位的二进制数：10101010，进位标志位CF的初始值为0。\n\n带进位标志位CF的循环左移一位：\n\n初始状态：10101010\n左移一位后，数据位与进位标志位一起左移，数据的最高位移入进位标志位CF，而进位位则依次移入数据的最低位：\n新状态：01010101，CF=1\n带进位标志位CF的循环左移三位：\n\n初始状态：10101010\n左移三位后，数据位与进位标志位一起左移，数据的最高位移入进位标志位CF，而进位位则依次移入数据的最低位：\n新状态：01010101，CF=1\n\n\n\n不带进位标志位的循环左移（小循环）：\n假设有一个8位的二进制数：10101010\n\n不带进位标志位的循环左移一位：\n初始状态：10101010\n左移一位后，数据位循环左移，最高位移入最低位，不涉及进位标志位：\n新状态：01010101\n\n不带进位标志位的循环左移三位：\n初始状态：10101010\n左移三位后，数据位循环左移，最高位移入最低位，不涉及进位标志位：\n新状态：01010101\n原码定点数的加减法运算设$[X]\\text{原}=x_s.x_1x_2\\cdots x_n$和$[Y]\\text{原}=y_s.y_1y_2\\cdots y_n$,进行加减运算的规则如下。\n加法规则:先判符号位，若相同，则绝对值相加，结果符号位不变;若不同，则做减法，绝对值大的数减去绝对值小的数，结果符号位与绝对值大的数相同。\n减法规则:两个原码表示的数相减，首先将减数符号取反，然后将被减数与符号取反后的减数按原码加法进行运算。\n\n\n\n\n\n\n\n\n\n🙋‍♂️ 运算时注意机器字长，当左边位出现溢出时，将溢出位丢掉。\n补码定点数加减法运算补码加减运算规则简单，易于实现，因此计算机系统中普遍采用补码加减运算。补码运算的特点如下（设机器字长为 n+1)。\n\n参与运算的两个操作数均用补码表示。\n\n按二进制运算规则运算，逢二进一。\n\n符号位与数值位按同样规则一起参与运算，符号位运算产生的进位要丢掉，结果的符号位由运算得出。\n\n补码加减运算依据下面的公式进行。当参加运算的数是定点小数时，模 M= 2;当参加运算的数是定点整数时，模 M = 2^n^+1。\n\n\n\\begin{cases}{[A+B]_{\\text {补 }}=[A]_{\\text {补 }}+[B]_{\\text {补 }},} & (\\bmod M) \\\\ {[A-B]_{\\text {补 }}=[A]_{\\text {补 }}+[-B]_补,} & (\\bmod M)\\end{cases}\n\n\n\n\n\n\n\n\n🙋‍♂️mod M 运算是为了将溢出位丢掉。\n也就是说，若做加法，则两数的补码直接相加;若做减法，则将被减数与减数的机器负数相加。\n补码运算的结果亦为补码\n设机器字长为 8 位（含 1 位符号位)，A= 15，B=24，求补[A+B]~补~和[A−B]~补~。\n解：\nA=+15=+0001111，B=+24=+0011000;得补[A]~补~= 00001111，[B]~补~=00011000。\n求得[−B]~补~ = 11101000。所以\n[A+B]~补~=00001111+ 00011000 = 00100111，其符号位为 0，对应真值为+39。\n[A−B]~补~=[A]~补~+[−B]~补~=00001111 + 11101000= 11110111，其符号位为 1，对应真值为-9。\n符号扩展 在计算机算术运算中，有时必须把采用给定位数表示的数转换成具有不同位数的某种表示形式。例如，某个程序需要将一个 8 位数与另外一个 32 位数相加，要想得到正确的结果，在将 8 位数与 32 位数相加之前，必须将 8 位数转换成 32 位数形式，这称为“符号扩展”。\n正数的符号扩展非常简单，即原有形式的符号位移动到新形式的符号位上，新表示形式的所有附加位都用 0 进行填充。\n负数的符号扩展方法则根据机器数的不同而不同。原码表示负数的符号扩展方法与正数相同，只不过此时符号位为 1。补码表示负数的符号扩展方法:原有形式的符号位移动到新形式的符号位上，新表示形式的所有附加位都用 1(对于整数）或 0(对于小数）进行填充。反码表示负数的符号扩展方法:原有形式的符号位移动到新形式的符号位上，新表示形式的所有附加位都用 1 进行填充。\n\n\n\n\n\n\n\n\n\n正数相当于位数往左边扩展，负数相当于位数往右边扩展\n溢出概念和判别方法溢出是指运算结果超过了数的表示范围。通常，称大于机器所能表示的最大正数为上溢，称小于机器所能表示的最小负数为下溢。定点小数的表示范围为|x|&lt;1，如图 2.8 所示。\n\n仅当两个符号相同的数相加或两个符号相异的数相减才可能产生溢出，如两个正数相加，而结果的符号位却为 1(结果为负);一个负数减去一个正数，结果的符号位却为 0(结果为正)。定点数加减运算出现溢出时，运算结果是错误的。\n补码定点数加减运算溢出判断的方法有 3 种。\n(1）采用一位符号位\n由于减法运算在机器中是用加法器实现的，因此无论是加法还是减法，只要参加操作的两个数符号相同，结果又与原操作数符号不同，则表示结果溢出。\n设 A 的符号为 A~s~,B 的符号为 B~s~，运算结果的符号为 S~s~,则溢出逻辑表达式为\nV=A_sB_s\\bar{S}_s+\\bar{A}_s\\bar{B}_sS_s若 V = 0，表示无溢出；若 V = 1，表示有溢出\n(2）采用双符号位\n双符号位法也称模 4 补码。运算结果的两个符号位$S{s1}S{s2}$相同，表示未溢出;运算结果的两个符号位$S{s1}S{s2}$不同，表示溢出，此时最高位符号位代表真正的符号。\n符号位$S{s1}S{s2}$的各种情况如下：\n\n$S{s1}S{s2} = 00$:表示结果为正数，无溢出\n$S{s1}S{s2} = 01$:表示结果为正溢出\n$S{s1}S{s2} = 10$:表示结果为负溢出\n$S{s1}S{s2} = 11$:表示结果为负数，无溢出\n\n即$S{s1},S{s2}$相等，无溢出，不等，溢出\n定点数的乘法运算带符号的阵列乘法器\n\n\n\n\n\n\n\n\n\n\n\n🚨 最后的补级输出是，先加上符号后，再求补\n原码一位乘法\n\n \n\n\n\n数据的存储和排列数据的“大端方式”和“小端方式”存储 在存储数据时，数据从低位到高位可以按从左到右排列，也可以按从右到左排列。因此，无法用最左或最右来表征数据的最高位或最低位，通常用最低有效字节(Least Significant Bit,LSB)和最高有效字节(Most Significant Bit,MSB)来分别表示数的低位和高位。例如，在 32 位计算机中，一个 int 型变量 i 的机器数为 0123 4567H，其最高有效字节 MSB= 01H，最低有效字节 LSB=67H。\n 现代计算机基本上都采用字节编址，即每个地址编号中存放 1 字节。不同类型的数据占用的字节数不同，int 和 float 型数据占 4 字节，double 型数据占 8 字节等，而程序中对每个数据只给定一个地址。假设变量 i 的地址为 80 00H，字节 01H、23H、45H、67H 应该各有一个内存地址，那么地址 08 00H 对应 4 字节中哪字节的地址呢?这就是字节排列顺序问题。\n 多字节数据都存放在连续的字节序列中，根据数据中各字节在连续字节序列中的排列顺序不同，可以采用两种排列方式:大端方式(big endian)和小端方式(little endian)，如图 2.9 所示 👇。\n\n大端方式按从最高有效字节到最低有效字节的顺序存储数据，即最高有效字节存放在前面;\n小端方式按从最低有效字节到最高有效字节的顺序存储数据，即最低有效字节存放在前面。\n在检查底层机器级代码时，需要分清各类型数据字节序列的顺序，例如以下是由反汇编器(汇编的逆过程，即将机器代码转换为汇编代码）生成的一行机器级代码的文本表示:\n4004d3:01 05 64 94 04 08 add %eax,0x8049464\n其中，“4004d3”是十六进制表示的地址，“01 05 43 0b 20 00”是指令的机器代码，“add %eax，Ox8049464”是指令的汇编形式，该指令的第二个操作数是一个立即数 0x8049464，执行该指令时，从指令代码的后 4 字节中取出该立即数，立即数存放的字节序列为 64H、94H、04H、08H，正好与操作数的字节顺序相反，即采用的是小端方式存储，得到 08049464H去掉开头的 0，得到值 0x8049464，在阅读小端方式存储的机器代码时，要注意字节是按相反顺序显示的。\n【2019统考真题】某计算机采用大端方式，按字节编址。某指令中操作数的机器数为 1234 FF00H，该操作数采用基址寻址方式，形式地址（用补码表示）为 FF12H，基址寄存器的内容为 F000 0000H， 则该操作数的 LSB（最低有效字节）所在的地址是()\nA.F000 FF12H\nB.F000 FF15H\nC.EFFF FF12H\nD.EFFF FF15H\n\n解：\n由题中给出\n形式地址由补码表示为FF12H(1111 1111 0001 0010B)，所以由对补码求补可得原码为1000 0000 1110 1110B 可知其真值为一个负数\n将符号位提出后为000 0000 1110 1110B 转换为16进制可得 0000(补0)0000 1110 1110B => 00EEH 加上符号位后为 -00EEH\n\n由操作数采用基址寻址可知 EA = (BR) + A = 即 F000 0000H - 0000 00EE\n数据按“边界对齐”方式存储 假设存储字长为 32 位，可按字节、半字和字寻址。对于机器字长为 32 位的计算机，数据以边界对齐方式存放，半字地址一定是 2 的整数倍，字地址一定是 4 的整数倍,这样无论所取的数据是字节、半字还是字，均可一次放存取出。所存储的数据不满足上述要求时，通过填充空白字节使其符合要求。这样虽然浪费了一些存储空间，但可提高取指令和取数的速度。\n 数据不按边界对齐方式存储时，可以充分利用存储空间，但半字长或字长的指令可能会存储在两个存储字中，此时需要两次访存，并且对高低字节的位置进行调整、连接之后才能得到所要的指令或数据，从而影响了指令的执行效率。\n例如，“字节 1、字节 2、字节 3、半字 1、半字 2、半字 3、字 1”的数据按序存放在存储器中，按边界对齐方式和不对齐方式存放时，格式分别如图 2.10 和图 2.11 所示。\n\n边界对齐方式相对边界不对齐方式是一种空间换时间的思想。RISC 如 ARM 采用边界对齐方式，而 CISC 如 x86 对齐和不对齐都支持。因为对齐方式取指令时间相同，因此能适应指令流水。\nc 语言相关基本数据类型所占的字节数\n\n\n\n数据类型\n32 位环境\n64 位环境\n16 位环境\n\n\n\n\nchar\n8 位\n8 位\n8 位\n\n\nunsigned char\n8 位\n8 位\n8 位\n\n\nshort\n16 位\n16 位\n16 位\n\n\nunsigned short\n16 位\n16 位\n16 位\n\n\nint\n32 位\n32 位\n16 位\n\n\nunsigned int\n32 位\n32 位\n16 位\n\n\nlong\n32 位\n64 位\n32 位\n\n\nunsigned long\n32 位\n64 位\n32 位\n\n\nlong long\n64 位\n64 位\n32 位\n\n\nunsigned long long\n64 位\n64 位\n32 位\n\n\nfloat\n32 位\n32 位\n32 位\n\n\ndouble\n64 位\n64 位\n32 位\n\n\nlong double\n96 位\n128 位\n80 位\n\n\n\n\n\n\n\n\n\n\n\n\n\nsizeof(数据类型)会返回字节数 例如 sizeof(double) → 8\n2^8^ = 256\n2^16^ = 65536\n2^32^ = 4294967296\n2^64^ = 18446744073709551616\n【2018统考真题】按字节编址的计算机中，某 double 型数组 A 的首地址为 2000H，使用变址寻址和循环结构访问数组 A，保存数组下标的变址寄存器初值为 0，每次循环取一个数组元素，其偏移地址为变址值乘以 sizeof(double)，取完后变址寄存器内容自动加 1。若某次循环所取元素的地址2100H，则进入该次循环时变址寄存器的内容是()\nA.25\tB.32\tC.64\tD.100\n\nsizeof(double) &#x3D; 8\n2000H + 8*i &#x3D; 2100H\n8*i &#x3D; 100H\nH表示该数为16进制，所以100H &#x3D; 2^8 &#x3D; 256\ni &#x3D; 32\n答案选B\n存储系统存储器概述存储器的分类按在计算机中的层次进行分类\n\n主存\n辅存\n高速缓冲寄存器(cache)\n\n按存储介质分类\n\n磁表面存储器(磁盘、磁带)\n磁芯存储器\n半导体存储器(MOS 型存储器、双极型存储器)\n光盘存储器(光盘)\n\n按存取方式分类\n\n随机存储器(RAM)。存储器的任何一个存储单元都可以随机存取,而且存取时间与存储单元的物理位置无关。其优点是读写方便,使用灵活,主要用于主存或者高速缓冲寄存器。RAM 又分静态RAM和动态RAM\n只读存储器(ROM)。存储器的内容只能随机读出而不能写入。信息一旦写入存储器就固定不变,即使断电,内容也不会丢失。因此,通常用它来存放固定不变的程序、常数和汉字字库等\n\n\n\n\n\n\n\n\n\n\nROM 和 RAM 的存取方式均为随机存取\n\n串行访问存储器。对存取单元进行读写操作时,需按其物理位置的先后顺序寻址,包括顺序存取存储器(磁带 📼),与直接存取存储器(如磁盘 💾、光盘 💿)\n\n\n\n\n\n\n\n\n\n\n顺序存储只能按照某种顺序存取,直接存取介于随机存取和顺序存取之间\n按信息的可保存性分类\n\n易失性存储器:断电后,存储信息即消失的存储器,如 RAM\n非易失性存储器:断电后信息仍然保留的存储器\n\n\n\n\n\n\n\n\n\n\n🙋‍♂️ 破坏性读出:被读单元原存储信息被破坏\n 非破坏性性读出:被读单元原存储信息不被破坏\n 具有破坏性读出性能的存储器,每次读出操作后,都必须有再生操作,以便恢复被破坏的信息\n存储器的性能指标存储容量存储容量 = 存储字数 × 存储字长 (字数表示存储器的地址空间大小,字长表示一次存取操作的数据量)\n单位成本每位价格 = 总成本/总容量\n存储速度存储速度: 数据传输率 = 数据的宽度/存储周期\n\n存取时间(T~a~):存取时间是指从启动一次存储器操作到完成该操作所经历的时间,分为读取时间和写入时间\n存取周期(T~m~):又称读写周期或访问周期,它是指存储器进行一次完整的读写操作所需的全部时间,即连续两次独立访问存储器操作(读或写操作)之间所需的最小时间间隔\n主存带宽(B~m~):又称数据传输率,表示每秒从主存进出信息的最大数量,单位为字每秒、字节每秒(B/s)或位每秒(b/s)\n\n\n\n\n\n\n\n\n\n\n🙋‍♂️ 存储周期通常大于存取时间,因为上面介绍的破坏性读出的机制,存储器需要在信息读出后花费时间来进行再生\n多层次的存储系统基本知识点两个图总结完事:\n\n上一级作为低一层存储器的高速缓存,上一层的内容是下一层部分内容的副本\n主存储器(MM) 主存储器由 DRAM 实现,靠处理器的那一层(Cache)则由 SRAM 实现,他们都属于易失性存储器\nSRAM 和 DRAM 通常把存放一个二进制位的物理器件称为存储元,它是存储器最基本的构件。地址码相同的多个存储元构成一个存储单元。若干存储单元的集合构成存储体\nSRAM静态随机存储器(SRAM)的存储元是用双稳态触发器(六晶体管MOS)记忆信息的,因此即使信息被读出后,它仍然保持其状态而不需要再生(非破坏性读出)\nSRAM 存储速度快,但集成度低,功耗大,价格昂贵,一般用于高速缓冲存储器\nDRAM 动态随机存储器(DRAM)利用存储元电路中的栅极电容上的电荷进行存储信息的,DRAM 的基本存储元通常只使用一个晶体管,所以它比 SRAM 的密度要高得多。相对于 SRAM,DRAM 具有容易集成、位价低、容量大和功耗低等优点,但 DRAM 存取速度比 SRAM 的慢,一般用于大容量主存系统\n DRAM 电容上的电荷一般只能维持 1~2ms,因此即使电源不断电,信息也会自动消失。为此,每个一段时间必须刷新,通常取 2ms,称为刷新周期。常用的刷新方式有 3 种\n\n集中刷新:指在一个刷新周期内,利用好一段固定的时间,依次对存储器所有行进行逐一再生,在此期间停止对存储器的读写操作,称为死时间,又称访存死区。优点是读写操作时不受刷新工作的影响;缺点是在集中刷新期间(死区)不能访问存储器。\n分散刷新:把对每行的刷新分散到各个工作周期中。这样一个存储器的系统工作周期分为两部分,前半部分用于正常读、写或保持,后半部分用于刷新,优点是没有了死区,缺点是加长了系统的存取周期,降低了整机速度\n异步刷新:是前两种方法的结合。将刷新周期除以行数,得到两次刷新操作之间的时间间隔 t,利用逻辑电路每隔时间 t 产生一次刷新请求,这样可以避免 CPU 连续等待过长的时间,减少了刷新次数\n\n存储器芯片的内部结构\nDRAM 采用分时复用的技术,当其选择存储元时,不是由上图 X(A~0~~A~5~)Y(A~6~~A~11~)直接得出,而是所有地址线(A~0~~A~11~)作为行/列,分两次输入,所以相同地址线数下 DRAM 容量很大但是速度没有 SRAM 快\n只读存储器制度存储器 ROM 的特点:\n\n结构简单,所以密度比可读写存储器的高\n具有非易失性,所以可靠性高\n\nROM 的类型:\n\n掩模式只读存储器(MROM):由半导体制造厂在芯片的制造过程中写入,任何人无法改变其内容,优点:可靠性高,集成度高,价格便宜;缺点是灵活性差\n一次可编程只读存储器(PROM):允许用户利用专门的设备(编程器)写入自己的程序,一旦写入,无法改变\n可擦除可编程只读存储器(EPROM):光可擦除 E^2^PROM(电擦除) 允许用户对编程器写入的信息重复改写,但是改写速度慢,改写次数有限\n闪存(Flash 存储器)\n固态硬盘(SSD)\n\n多模块存储器单体多字存储器存储器中只有一个存储体,每个存储单元存储 m 个字,总线宽度也为 m 个字。一次并行读出 m 个字,地址必须顺序排列并处于同一存储器\n多体并行存储器高位交叉编址(顺序方式)\n高位是存储体体号(M~0~~M~3~ =&gt; 0~3),低位是体内地址,访问一串连续的主存地址时,总是先在一个体内访问完后,再转到下一个模块进行访问,所以其本质上还是顺序存储器,存取方式是串行存取,不能提高存储器的吞吐率\n地位交叉编址(交叉方式)\n低位地址为体号,高位为体内地址,由十进制内存地址来确定其存储体号可以使用 体号 = 内存地址 mod 模块数来确定体号\nCPU 同时访问四个模块，由存储器控制部件控制它们分时使用数据总线进行信息传递。 这样，对每一个存储模块来说，从 CPU 给出访存命令直到读出信息仍然使用了一个存取周 期时间；而对 CPU 来说，它可以在一个存取周期内连续访问四个模块。各模块的读写过程 将重叠进行(流水线)，所以多模块交叉存储器是一种并行存储器结构。\n 下面进行定量分析。设模块字长等于数据总线宽度，又假设模块存取一个字的存储周期为T，总线传送周期为τ，存储器的交叉模块数为m，那么为了实现流水线方式存取，应当满足\n\\textit{T}\\leqslant m\\mathbb{\\tau}即成块传送可按 τ 间隔流水方式进行，也就是每经τ时间延迟后启动下一个模块。图 3.25 示出了 m=4 的流水线方式存取示意图。\n m的最小值 m~min~=T/τ 称为交叉存取度。交叉存储器要求其模块数必须大于或等于 m~min~， 以保证启动某模块后经 mτ时间再次启动该模块时，它的上次存取操作已经完成。这样，连续读取 m 个字所需的时间为\nt_1= T+(m-1) \\tau 而顺序方式存储器连续读取 m 个字所需时间为\nt_2= mT\n🌰设存储器容量为 32 字，字长 64 位，模块数 m=4，分别用顺序方式和交叉方式进行组织。存储周期 T=200ns，数据总线宽度为 64 位，总线传送周期τ=50ns。若连续读出 4 个字，问顺序存储器和交叉存储器的带宽各是多少?\n解 顺序存储器和交叉存储器连续读出 m=4 个字的信息总量都是\n\tq=64bit×4=256bit\n   顺序存储器和交叉存储器连续读出 4 个字所需的时间分别是\n\tt2=mT=4×200ns=800ns=8×10^–7s\n\tt1=T+(m–1)τ=200ns+3×50ns=350ns=3.5×10^–7s\n   顺序存储器和交叉存储器的带宽分别是\n\tW2=q/t2=256bit÷(8×10–7)s=320Mbit/s\n\tW1=q/t1=256bit÷(3.5×10–7)s=730Mbit/s\n主存储器与 CPU 的连接连接原理主存储器与 CPU 的连接如下图所示 👇:\n\n存储控制器、存储总线和内存条之间的连接关系 👇:\n\n主存容量的扩展位拓展法 若给定的芯片的字数(地指数)符合要求，但位数较短，不满足设计要求的存储器字长， 则需要进行位扩展，让多片给定芯片并行工作。三组信号线中，地址线和控制线公用而数据线单独分开连接。\n\n字拓展法 若给定的芯片存储容量较小(字数少)，不满足设计要求的总存储容量，则需要进行字 扩展，让多片给定芯片分时工作。三组信号线中给定芯片的地址总线和数据总线公用，读 写控制信号线公用，由地址总线的高位译码产生片选信号，让各个芯片分时工作\n\n\n\n\n\n\n\n\n\n\n图中数据总线每个芯片组都是 D~0~~D~7~\n片选有效性：和$\\overline{\\text{RAS}}(Row Address Select),\\overline{\\text{CAS}}(Column Address Select),\\overline{\\text{WE}}(Write Enable)$一样，都是低电平有效。\n字位扩展若给定的芯片的字数和位数均不符合要求，则需要先进行位扩展，再进行字扩展。\n\n存储器和 CPU 连接以下是存储器与 CPU 连接时需要注意的原则:\n\n地址线的连接:因为存储芯片容量不同,其地址线也不同,而 CPU 的地址线数往往比存储芯片地址线要更多,所以需要注意\n将 CPU 地址线的低位与存储芯片的地址线相连,以选择芯片中的某一单元\n将 CPU 地址线的高位与译码器相连,以实现芯片(组)间的片选\n\n\n数据线的连接:CPU 的数据线数与存储芯片的数据线数不一定相等,相等时可以直接相连;在不相等时必须对存储芯片扩位,使之与 CPU 数据线数相等\n\n外部存储器磁盘存储器优点:\n\n存储容量大,位价格低\n记录介质可重复使用\n记录信息可长时间保存不丢失,甚至可以脱机存档\n非破坏性读出,读出时不需要再生\n\n缺点:\n 存取速度慢,机械结构复杂,对工作环境要求较高\n磁盘设备的组成硬盘存储器的组成\n磁盘驱动器。核心部件是磁头组件和盘片组件\n磁盘控制器。硬盘存储器和主机的接口,主流的标准有 IDE、SCSI、SATA 等\n\n存储区域以下是磁盘存储器的主要结构示意图 👇:\n\n\n\n\n\n\n\n\n\n\n扇区是磁盘读写的最小单位,即磁盘按块存取\n由于扇区的 Size 比较小，数目众多时寻址时比较困难，所以在操作系统中就将相邻的扇区组合在一起，形成一个簇，再对块进行整体的操作。\n如何将一个内存中的簇号来转化为磁盘上的物理地址?\n磁盘的性能指标\n记录密度:记录密度是指盘片单位面积上记录的二进制信息量,通常以道密度,位密度和面密度表示。\n\n道密度是沿磁盘半径方向单位长度上的磁道数\n位密度是磁道单位长度上能记录的二进制代码位数\n面密度是道密度和位密度的乘积\n\n\n磁盘容量:\n\n非格式化容量:指磁记录表面可利用的磁化单元总数,由道密度和位密度计算而来\n格式化容量:按照某种特定记录格式所能存储的信息总量\n\n格式化后的容量比非格式化容量要小\n\n平均存取时间。平均存取时间由三部分构成:\n\n寻道时间:磁头移动到目的磁道的时间\n旋转延迟时间:磁头定位道要读写的扇区的时间\n传输时间:传输数据所花费的时间\n\n\n数据传输率:从盘存储器在单位时间向主机传送数据的字节数\n假设磁盘转速位 r 转/s,每条磁道容量位 N 字节,则数据传输率为: D~r~ = rN\n\n\n磁盘地址\n磁盘阵列 RAID(独立冗余磁盘阵列(又称廉价冗余磁盘阵列))是指将多个独立的物理磁盘罪成一个独立的逻辑盘,数据在多个物理盘上分割交叉存储、并行访问,具有更好的存储性能、可靠性和安全性。\n\nRAID0:无冗余无校验的磁盘阵列(将数据块交叉存放在不同的物理磁盘的扇区中,几个磁盘交叉并行读写)\nRAID1:镜像磁盘阵列(一个使用,一个备份)\nRAID2:采用纠错的海明码的磁盘阵列\nRAID3:位交叉奇偶校验的磁盘阵列\nRAID4:块交叉奇偶校验的磁盘阵列\nRAID5:无独立校验的奇偶校验磁盘阵列\n\n\n\n\n\n\n\n\n\n\n还有 RAID01 和 RAID10\n固态硬盘是一种基于闪存技术的存储器,与 U 盘并没有本质上的差别,只是容量更大,存取性能更好\n\n一个闪存由 B 块组成,每块由 P 页组成。数据是以页为单位读写的。只有在一页所属的块整个被擦除后,才能写这一页。某个块经历了约 10 万次的擦写后,就会损坏,无法使用(坏块),所以闪存翻译层中有一个平均磨损逻辑试图通过将擦除平均分布在所有块上来最大化每个块的寿命\n闪存的随机写很慢,因为首先,擦除块就很慢(1ms 级),比访问页要高一个数量级,其次若要修改一个块中包含数据的一个页,那么就要把这个块中所有含有数据的页复制到一个新(被擦除过的)块中,才能进行对那页的写\n高速缓冲储存器程序的局部性原理:\n\n==空间局部性==:在最近的未来要用的的信息,很可能与正在使用的信息在存储空间上是邻近的,因为指令通常是顺序存放,顺序执行的,数据一本是以向量,数组等形式簇聚地储存在一起的\n==时间局部性==:最近未来要使用到的信息,很可能是现在正在使用的信息,因为程序中存在循环\n\n基于上述的程序的局部性原理,人们制造出了 Cache(高速缓冲寄存器)\nCache 的基本工作原理 Cache 是介于 CPU 和主存 之间的小容量存储器，但存取速度比主存快，容量远小于主存。cache 能高速地向 CPU 提供指令和数据，从而加快了程序的执行速 度。从功能上看，它是主存的缓冲存储器，由高速的 SRAM 组成。为追求高速，包括管理 在内的全部功能由硬件实现，因而对程序员是透明的。\n 为便于 Cache 和主存交换信息,Cache 和主存都被划分为相等的块,Cache块又称为Cache行,所以 Cache 中的块数要远小于主存中的块数,它仅仅保存主存中最活跃的若干块的副本。\n CPU 与 Cache 之间的数据交换以字为单位,而 Cache 与主存之间的数据交换则以Cache块为单位\n问题也随之而来:\n\n数据查找。如何快速判断数据是否在 Cache 中\n地址映射。主存块如何存放在 Cache 中,如何将主存地址转换为 Cache 地址\n替换策略。Cache 满了以后,使用何种策略对 Cache 块进行替换或淘汰\n写入策略。如何既保证主存块和 Cache 块的数据一致性,又尽量提升效率\n\nCache 和主存的映射方式地址映射方式有全相联方式、直接方式和组相联方式三种，下面分别介绍。\n全相联映射我的理解是主存中的任意一个块,可以映射到 Cache 中的任意一行(块)中\n\n CPU 访存指令指定了一个主存地址，为了 快速检索，指令中的块号与 cache 中所有行的标记同时在比较器中进行比较。如果块号命中， 则按字地址从 cache 中读取一个字；如果块号未命中，则按主存地址从主存中读取这个字。 在全相联 cache 中，全部标记用一个相联存储器来实现，全部数据存储用一个普通 RAM 来 实现。全相联方式的主要缺点是高速比较器电路难于设计和实现，因此只适合于小容量 cache 采用。\n\n直接映射 直接映射方式也是一种多对一的映射关系，但一个主存块只能拷贝到 cache 的一个特定 行位置上去。cache 的行号 i 和主存的块号 j 有如下函数关系：\ni=j\\quad\\mathrm{mod}\\quad m 式中，m 为 cache 中的总行数。显然，主存的第 0 块，第 m 块，第 2m 块，…，第 2s –m 块 只能映射到 cache 的第 0 行；而主存的第 1 块，第 m+1 块，第 2m+1 块，…，第 2s –m+1 块\n\n\n 直接映射方式的优点是硬件简单，成本低，地址变换速度快。缺点是每个主存块只有 一个固定的行位置可存放。如果连续访问块号相距 m 整数倍的两个块，因两个块映射到同 一 cache 行时，就会发生冲突。发生冲突时就要将原先存入的行换出去，但很可能过一段时 间又要换入。频繁的置换会使 cache 效率下降。因此直接映射方式适合于需要大容量 cache 的场合，更多的行数可以减小冲突的机会。\n组相联映射我的理解为组内全相联映射,组间直接映射\n这种方式将 cache 分成 u 组，每组 v 行。主存块存放到哪个组是固定的，取决于主存块 在主存区中是第几块。至于存到该组哪一行是灵活的，即有如下函数关系：\n\\begin{aligned}m&=u\\times v\\\\\\text{组号}\\quad q&=j\\quad\\mathrm{mod}\\quad u\\end{aligned}\n\n 组相联映射方式中的每组行数 v 一般取值较小，典型值是 2、4、8、16。这种规模的v 路比较器容易设计和实现。而块在组中的排放又有一定的灵活性，使冲突减少。为强调比 较器的规模和存放的灵活程度，常称之为 v 路组相联 cache。\nv=4 路组相联的内存地址格式如下所示:\n\nCache 中主存块的替换算法\n随机算法(RAND)\n字面意思\n\n先进先出算法(FIFO)\n字面意思\n\n近期最少使用算法(LRU)\nLRU 算法将近期内长久未被访问过的行换出。为此，每行也设置一个计数器，但它们 是 cache 每命中一次，命中行计数器清零，其他各行计数器增 1。当需要替换时，比较各特 定行的计数值，将计数值最大的行换出。这种算法保护了刚复制到 cache 中的新数据行，符 合 cache 工作原理，因而使 cache 有较高的命中率。\n\n最不经常使用算法(LFU):\nLFU 算法认为应将一段时间内被访问次数最少的那行数据换出。为此，每行设置一个 计数器。新行调入后从 0 开始计数，每访问一次，被访行的计数器增 1。当需要替换时，对 这些特定行的计数值进行比较，将计数值最小的行换出，同时将这些特定行的计数器都清 零。这种算法将计数周期限定在两次替换之间的间隔时间内，因而不能严格反映近期访问情况。\n\n\n具体的复习留到操作系统的该知识点\nCache 写策略因为 Cache 中的内容是主存块中的副本,所以当 CPU 对 Cache 中的内容进行更新时,就需要用写策略使 Cache 内容和主存内容保持一致\n对于Cache写命中有两种处理方法\n\n全写法:CPU 对 Cache 写命中时,需要把数据同时下写入 Cache 和主存的对应块中\n缺点是增加了访存次数,降低了 Cache 的效率\n为了减少(缓解)直接写入主存的时间消耗在主存和 Cache 之间加一个写缓冲器(逻辑上为 FIFO 队列),写缓冲虽然可以解决速度不匹配的问题,但若出现频繁写时,会使写缓冲饱和溢出(Cache 和主存速度不匹配)\n\n\n\n增加 L2cache 可以有效避免写缓冲饱和溢出问题\n\n\n回写法:每个 Cache 行设置一个修改位(脏位),CPU 对 Cache 写命中时,只需要把数据写入 Cache 中的某一个块中,当这一个块需要被替换时,检查其脏位是否为 1,为 1 则说明被修改过,将其写回内存,反之,无须写回内存\n\n对于Cache写不命中也有两种处理方法\n\n写分配法:CPU 将块写入主存中,Cache 从主存中将该块调入 Cache 中\n非写分配法:只写主存,不调块\n\n非写分配法——全写法 写分配法——回写法 通常是这两个组合\n虚拟存储器 主存和辅存共同构成了虚拟存储器,二者在硬件和软件系统共同的管理下工作,对于程序员来而言,虚拟存储器是透明的。虚拟存储器具有主存的速度和辅存的容量\n 用户编制程序时使用的地址称为虚地址或逻辑地址，其对应的存储空间称为虚存空间或逻辑地址空间；而计算机物理内存的访问地址则称为实地址或物理地址，其对应的存储空间称为物理存储空间或主存空间。程序进行虚地址到实地址转换的过程称为程序的再定位\n虚存机制也要解决一些关键问题。\n\n调度问题 决定哪些程序和数据应被调入主存。\n\n地址映射问题 在访问主存时把虚地址变为主存物理地址(这一过程称为内地址变 换)；在访问辅存时把虚地址变成辅存的物理地址(这一过程称为外地址变换)，以便换页。 此外还要解决主存分配、存储保护与程序再定位等问题。\n\n替换问题 决定哪些程序和数据应被调出主存。\n\n更新问题 确保主存与辅存的一致性。\n\n\n页式虚拟存储器 页式虚拟存储器以页为基本单位。把虚拟空间和主存空间都划分成一个一个大小相等的页,主存的页被称为实页、页框,虚存的页被称为虚页。我们把虚拟地址分为两个字段,虚页号和页内地址。虚拟地址到物理地址的转换是通过页表来实现的。页表是一张存放虚存号和实存号的对照表,它记录程序的虚页调入主存时被安排在主存中的位置。页表一般长久地保存在内存中。\n页表 页式虚拟存储器以页为基本单位,虚拟空间与主存空间都被划分为相同的大小\n以下为一个页表式例:\n\n有效位也称装入位,用来表示对应页面是否在主存,若为 1 则表示该虚拟页已从外存调入主存,此时页表项存放该页的物理页号;(内页表)若为 0,则表示没有调用主存,此时页表项可以存放该页的磁盘地址(外页表)\n\n脏位也称修改位,,用来表示页面是否被修改过,虚存机制中采用回写策略,利用脏位可判断替换时是否需要写回磁盘\n\n引用位也称使用位,用来配合替换策略进行设置,例如是否实现最先调入(FIFO 位)或最近最少用(LRU 位)策略等\n\n\n CPU 执行指令时将虚拟地址转换为主存物理地址。页表基址寄存器存放进程(每一个进程都有一个页表/段表)的页表首地址,然后根据虚拟地址高位部分的虚拟页号找到对应的页表项,若装入位为 1,则取出物理页号,和虚拟地址低位部分的页内地址拼接,形成实际物理地址;若装入位为 0,则说明缺页,需要操作系统进行缺页处理。\n以下页式虚拟存储器的地址变化过程示意图:\n\n每个进程所需的页数并不固定，所以页表的长度是可变的，因此通常的实现方法是把 页表的基地址保存在寄存器中，而页表本身则放在主存中。由于虚存地址空间可以很大， 因而每个进程的页表有可能非常长。例如，如果一个进程的虚地址空间为 2GB，每页的大 小为 512B，则总的虚页数为 231/29 =222。 为了节省页表本身占用的主存空间，一些系统把页表安排存储在虚存空间，因而页表本身也要进行分页。当一个进程运行时，其页表中一部分在主存中，另一部分则在辅存中 保存。 另一些系统采用二级页表结构。每个进程有一个页目录表，其中的每个表项指向一个 页表。因此，若页目录表的长度(表项数)是 m，每个页表的最大长度(表项数)为 n，则一个 进程最多可以有 m×n 个页\n优点是,页面的长度固定,页面的长度固定,页表简单,调入方便。缺点是,由于程序不可能正好是页面的整数倍,最后一页的零头将无法利用而造成浪费,并且页不是逻辑上独立的实体,所以处理、保护和共享都不及段式虚拟存储器方便\n快表(TLB)地址变换高速缓存(Translation Look-aside Buffer,TLB)\n由于页表通常在主存中，因而即使逻辑页已经在主存中，也至少要访问两次物理存储 器才能实现一次访存，这将使虚拟存储器的存取时间加倍。为了避免对主存访问次数的增 多，可以对页表本身实行二级缓存，把页表中最活跃的部分存放在高速存储器中。这个专用于页表缓存的高速存储部件通常称为转换后援缓冲器(TLB)，又称为快表。而保存在主存中的完整页表则称为慢表。快表的作用是加快地址变换 👇\n\nTLB、页表、Cache、主存之间的访问关系\n简而言之，TLB 是地址缓存，那个 cache 是数据缓存。那么其实就分为了三个情况：\n\nTLB 缺失，要去页表中找地址\n\ncache 缺失，要向内存要数据\n\n缺页，要向磁盘要数据，同时更新 TLB 和 页表\n\n\n先查找 TLB，如果缺失，那么查找页表，还缺就缺页了。如果查找 TLB 命中，那么根据 TLB 获取物理地址，然后查找数据 cache，就算普通的 cache 查找了。\n以下是 TLB 虚拟存储器的 CPU 访存过程 👇:\n\n段式虚拟存储器 段式存储器中的段是按照程序的逻辑结构划分的,各个段的长度因程序而异。把虚拟地址分为两个部分:段号和段内地址。虚拟地址到实地址的变换是通过段表来实现的。段表是程序逻辑段和在主存中存放位置的对照表。段表的每行记录与某个段对应的段号、装入位(有效位)、段起点地址和段长。由于段的长度可变,所以段表中要给出各段的起始位置与段的长度\n CPU 根据虚拟地址访存时，首先根据段号与段表基地址拼接成对应的段表行，然后根据该段表行的装入位判断该段是否已调入主存(装入位为“1”，表示该段已调入主存；装入位为“0”，表示该段不在主存中)。已调入主存时，从段表读出该段在主存中的起始地址，与段内地址(偏移量)相加，得到对应的主存实地址。段式虚拟存储器的地址变换如下图所示:\n\n因为段的长度不固定，段式虚拟存储器也有一些缺点：\n① 主存空间分配比较麻烦。\n② 容易在段间留下许多外碎片，造成存储空间利用率降低。\n③ 由于段长不一定是 2 的整数次幂，因而不能简单地像分页方式那样用虚地址和实地址的最低若干二进制位作为段内偏移量，并与段号进行直接拼接，必须用加法操作通过段起址与段内偏移量的求和运算求得 物理地址。因此，段式存储管理比页式存储管理方式需要更多的硬件支持。\n优点:段的分界与程序的自然分界相对应,因而具有逻辑独立性,使得它易于编译、管理、修改和保护,也便于多道程序的共享\n段页式虚拟存储器 把程序按逻辑结构分段，每段再划分为固定大小的页，主存空间也划分为大小相等的页程序对主存的调入、调出仍以页为基本传送单位，这样的虚拟存储器称为段页式虚拟存像器。在段页式虚拟存储器中，每个程序对应一个段表，每段对应一个页表，段的长度必须是页长的整数倍，段的起点必须是某一页的起点。​ 虚地址分为段号、段内页号、页内地址三部分。CPU 根据虚地址访存时，首先根据段号有到段表地址：然后从段表中取出该段的页表起始地址，与虚地址段内页号合成，得到页表地址；最后从页表中取出实页号，与页内地址拼接形成主存实地址。段页式虚拟存储器的优点是，兼具页式和段式虚拟存储器的优点，可以按段实现共享和像护。缺点是在地址变换过程中需要两次查表，系统开销较大。\n虚拟存储器与 Cache 的比较虚拟存储器与 Cache 既有很多相同之处，又有很多不同之处\n相同之处\n\n最终目标都是为了提高系统性能，两者都有容量、速度、价格的梯度。\n\n都把数据划分为小信息块，并作为基本的传递单位，虚存系统的信息块更大。\n\n都有地址的映射、替换算法、更新策略等问题。\n\n依据程序的局部性原理应用“快速缓存的思想”，将活跃的数据放在相对高速的部件中。\n\n\n不同之处\n\nCache 主要解决系统速度，而虚拟存储器却是为了解决主存容量。\nCache 全由硬件实现，是硬件存体器，对所有程序员透明；而虚拟存储器由 OS 和硬件共同实现，是逻辑上的存储器，对系统程序员不透明，但对应用程序员透明。\n对于不命中性能影响，因为 CPU 的速度的为 Cache 的 10 倍，主存的速度为硬盘的 100 倍以上，因此虚拟存储器系统不命中时对系统性能影响更大。\nCPU 与 Cache 和主存都建立了直接访问的通路.而辅存 CPU 没有直接通路。也就是说在 Cache 不命中时主存能和 CPU 直接通信,同时将数据调入 Cache;而虚拟存储器系统不命中时,只能先由硬盘调入主存，而不能直接和 CPU 通信。\n\n指令系统指令就是计算机执行某种操作的命令。一台计算机所有的指令的集合构成该机的指令系统,也称指令集,指令系统是计算机的主要属性,位于硬件和软件交界面上\n指令的基本形式基本专业词汇:\n一条指令通常包括操作码和地址码字段两部分\n\n\n\n\n操作码字段\n地址码字段\n\n\n\n\n\n\n\n\n\n 操作码指出指令中指令应该执行什么性质的操作以及具有何种功能。操作码是识别指令,了解指令功能及区分操作数地址的组成和使用方法等的关键信息。例如指出的是算数加运算还是算数减运算,是程序转移还是返回操作。\n 地址码给出被操作的信息(指令或数据)的地址,包括参加运算的一个或多个操作数所在的地址、运算结果的保存地址、程序的转移地址、被调用的子程序入口地址等\n 指令的长度是指一条指令中所包含的二进制代码的位数,指令字长取决于操作码长度、操作数地址码的长度和操作数地址的个数。指令长度与机器字长没有固定的关系,它可以等于机器字长,也可以大于或小于机器字长。通常,把指令字长等于机器字长的指令称为单字长指令,指令长度等于半个机器字长的指令称为半字长指令,指令长度等与两个机器字长的指令称为双字长指令\n在一个指令系统中,若所有指令的长度都是相等的,则称为定长指令字结构。定长指令的执行速度快,控制简单。若各种指令的长度随功能而异,则称为变长指令字结构。然而,因为主存一般都是按字节编址的,所以指令字长多为字节的整数倍\n 根据指令中操作数地址码的数目不同,可将指令分为以下几种格式:\n零地址指令\n\n\n\n\nOP\n\n\n\n\n\n\n\n\n\n只给出操作码 OP,没有显式地址,这种指令有两种可能\n\n不需要操作数的指令,如空操作指令、停机指令、关中断指令等。\n零地址的运算类指令仅用在堆栈计算机中。通常参与运算的两个操作数隐含地从栈顶和次栈顶弹出,再送到运算器进行运算,运算结构再隐含地压入堆栈\n\n一地址指令\n\n\n\n\nOP\nA~1~\n\n\n\n\n\n\n\n\n\n这种指令也有两种常见的形态,要根据操作码的含义确定究竟是哪种。\n\n只有目的操作数的单操作指令,按 A~1~的地址读取操作数,进行 OP 操作后,结果存回原地址(A~1~)\n指令含义:OP(A~1~) → A~1~\n如操作码的含义是加 1、减 1、求反、求补等\n\n隐含约定目的地址的双操作数指令,按指令地址 A~1~可读取源操作数,指令可隐含约定另外一个操作数由 ACC(累加器)提供,运算结果也将存放在 ACC 中\n指令含义:(ACC)OP(A~1~) → ACC\n\n\n二地址指令\n\n\n\n\nOP\nA~1~(目的操作数地址)\nA~2~(源操作数地址)\n\n\n\n\n\n\n\n\n\n指令含义: (A~1~)OP(A~2~) → A~1~\n其中目的操作数地址还用来保存此次的运算结果\n三地址指令\n\n\n\n\nOP\nA~1~\nA~2~\nA~3~(结果)\n\n\n\n\n\n\n\n\n\n指令含义: (A~1~)OP(A~2~) → A~3~\n若地址字段均为主存地址,则完成一条三地址需要 4 次访存(取指令 1 次,取两个操作数 2 次,存放结果 1 次)\n四地址指令\n\n\n\n\nOP\nA~1~\nA~2~\nA~3~(结果)\nA~4~(下条需要执行的指令的地址)\n\n\n\n\n\n\n\n\n\n设某等长指令字结构机器的指令长度为 16 位包括 4 位基本操作码字段和 三个 4 位地址字段:\n\n4 位基本操作码若全部用于三地址指令， 则只能安排 16 种三地址指令。通常一个指令系统中指令的地址码个数不一定相同，为了确保指令字长度尽可能统一，可以采用扩展操作码技术，向地址码字段扩展操作码的长度。如 表 4.2 所示，三地址指令的操作码占用 4 位基 本操作码编码空间的 0000 ～ 1110 共 24 –1=15 种组合，剩下一个编码 1111 用于把操作码扩 展到 A1 地址域，即从 4 位操作码扩展到 8 位。 二地址指令的操作码占用 8 位操作码编码空间 的 1111, 0000 ～ 1111, 1101 共 24 –2=14 种，剩 下两个编码 1111, 1110 和 1111, 1111 用于把操 作码扩展到 A2 地址域，即从 8 位操作码扩展 到 12 位。一地址指令的操作码占用 12 位操作 码编码空间的 1111, 1110, 0000 ～ 1111, 1111, 1110 共 25 –1=31 种编码，剩下一个编码 1111,1111,1111 用于把操作码扩展到 A3 地址域，即 从 12 位操作码扩展到 16 位。零地址指令的操作码占用 16 位操作码编码空间的 1111,1111,1111,0000 ～ 1111,1111,1111,1111 共 24 =16 种编码\n\n设计拓展操作码指令格式时啊,必须注意以下两点:\n\n不允许短码是长码的前缀,即短操作码不能与长操作码前面部分的代码相同\n各指令的操作码一定不能重复\n\n通常情况下,对使用频率较高的指令分配较短的操作码,对使用频率较低的指令分配较长的操作码,从而尽可能减少指令译码和分析的时间。\n\n\n\n\n\n\n\n\n\n🤔采用扩展操作码设计方案的目的是?：\n 保持指令字长度不变而增加指令的数量\n指令的操作类型\n数据传送\n传送指令通常有寄存器之间的传送(MOV)、从内存单元读取数据到CPU寄存器(LOAD)、从CPU寄存器写数据到内存单元中是(STORE)等。\n\n算数和逻辑运算\n这类指令主要有加(ADD)、减(SUB)、比较(CMP)、乘(MUL)、除(DIV)、加 1(INC)、减 1(DEC)、与(AND)、或(OR)、取反(NOT)、异或(XOR)等\n\n移位操作\n移位指令主要有算法移位、逻辑移位、循环移位\n\n转移操作\n转移指令主要有无条件转移(JMP)、条件转移(BRANCH)、调用(CALL)、返回(RET)、陷阱(TRAP)等。\n无条件转移指令在任何情况下都执行转移操作\n条件转移一般是某个标志位的值,或几个标志位的组合。\n调用指令和转移指令的区别:执行调用指令时必须保存下一条指令的地址(返回地址),当程序执行结束时,根据返回地址返回到主程序继续执行;而转移指令则不返回执行。\n\n输入输出操作\n用于完成 CPU 与外部设备交换数据或传送控制命令及状态信息\n\n\n指令的寻址方式 寻址方式是寻找指令或操作数有效地址的方式,即确定本条指令的数据地址及下一条待执行指令的地址的方法。寻址方式分为指令寻址和数据寻址两大类\n指令寻址寻找下一条将要执行的指令地址称为指令寻址\n指令寻址有两种方式:一种是顺序寻址方式,另一种是跳跃寻址方式\n顺序寻址\n 通过程序计数器 PC 加 1(一个指令字长),自动形成下一条指令地址\n跳跃寻址\n 通过转移类指令实现。所谓的跳跃是指下一条指令的地址不由程序计算器 PC 自动给出,而由本条指令给出的下条指令地址的计算方式。而是否跳跃可能受到状态寄存器和操作数的控制,跳跃的地址分为绝对地址(由标记符直接得到)和相对地址(相对于当前指令地址的偏移量)。跳跃的结果是当前指令修改 PC 值,所以下一条指令仍然通过 PC 给出。\n数据寻址数据寻址是指如何在指令中表示一个操作数的地址,如何用这种表示得到操作数或怎么样计算出操作数的地址\n数据寻址的方式较多,为区分各种方式,通常在指令字中涉案之一个字段,用来表明属于哪一种寻址方式\n\n\n\n\n操作码\n寻址地址\n形式地址 A(偏移量)\n\n\n\n\n\n\n\n\n\n以下是一些常见的数据寻址方式:\n隐含寻址 这种类型的指令，不是明显地给出操作数的地址，而是在指令中隐含着操作数的地址， 如图所示。例如，单地址的指令格式，就不是明显地在地址字段中指出第二操作数 的地址，而是规定累加寄存器 ACC 作为第二操作数地址。指令格式明显指出的仅是第一操作数的地址 A。因此，累加寄存器 AC 对单地址指令格式来说是隐含地址。\n\n立即数寻址 指令的地址字段指出的不是操作数的地址，而是操作数本身，这种寻址方式称为立即 寻址，如图所示。指令中的操作数称为立即数。立即寻址方式的特点是指令中包含 的操作数立即可用，节省了访问内存的时间。\n\n\n\n\nOP\n立即寻址特征\nA\n\n\n\n\n\n\n\n\n\nA 部分即位立即数本身,以补码的形式存储\n直接寻址 直接寻址是一种基本的寻址方法，其特点是：在指令格式的地址字段中直接指出操作 数在内存的地址 A。由于操作数的地址直接给出而不需要经过某种变换，所以称这种寻址 方式为直接寻址方式。采用直接寻址方式时，指令字中的形式地址 A 就是操作数的有效地址 EA。因此通常把 形式地址 A 又称为直接地址。\n下图是直接寻址方式的示意图 👇\n\n间接寻址 间接寻址是相对于直接寻址而言的，在间接寻址的情况下，指令地址字段中的形式地址 A 不是操作数的真正地址，而是操作数地址有效地址所在的存储单元的地址,也就是操作数地址的地址。间接寻址可以是一次间接寻址,还可以是多次间接寻址\n下面是间接寻址的示意图 👇\n\n由于访问速度过慢,这种寻址方式并不常见。一般问到扩大寻址范围,通常指的是寄存器间接寻址\n寄存器寻址寄存器寻址是指在指令字种直接给出操作数所在的寄存器编号,即 EA = R,其操作数在由 R~i~所指的寄存器内\n\n寄存器间接寻址寄存器 R~i~种给出的不是一个操作数,而是操作数所在的主存单元的地址即 EA = (R~i~)\n\n偏移寻址一种强有力的寻址方式是直接寻址和寄存器间接寻址方式的结合，它有几种形式，我 们称它为偏移寻址。有效地址计算公式为 EA=A+(R)\n常用的三种偏移寻址是相对寻址、基址寻址、变址寻址。\n相对寻址相对寻址是把 PC 的内容加上指令格式中的形式地址 A 而形成操作数的有效地址,即 EA = (PC) +A,其中 A 是相对于前指令地址的偏移量,可正可负,补码表示\n\n\n\n\n\n\n\n\n\n\n\n注意对于转移指令 JMP A,当 CPU 从存储器中取出一字节时,会自动执行(PC) + 1 → PC。若转移指令地址为 X,且占 2B 在取出该指令后 PC 的值会加 2 即(PC) = X+2,这样在执行完该指令后,会自动跳转到 X + 2 + A 的地址继续执行\n🙋‍♂️ 多道程序设计中，各个程序段可能要在内存中浮动，而相对寻址特别利于程序浮动\n基址寻址将 CPU 中基址寄存器(BR)的内容加上指令格式中形式地址 A 而形成的操作数的有效地址,即 EA = (BR) + A。其中基址寄存器既可采用专用寄存器,又可采用通用寄存器\n\n\n\n\n\n\n\n\n\n\n注:基址寄存器是面向操作系统的，其内容由操作系统或管理程序确定。在程序执行过程中，基址寄存器的内容不变(作为基地址)，形式地址可变(作为偏移量)。当采用通用寄存器作为基址寄存器时，可由用户决定哪个寄存器作为基址寄存器，但其内容仍由操作系统确定。\n优点:可扩大寻址范围(基址寄存器的位数大于形式地址 A 的位数) ;用户不必考虑自己的程序存于主存的哪一空间区域，故有利于多道程序设计，以及可用于编制浮动程序。\n变址寻址 地址域引用一个主存地址，被引用的专用寄存器含有对那个地址的正偏移量。这意味着主存地址位数大于寄存器中的偏移量位数，与基址寻址刚好相反。但是二者 有效地址的计算方法是相同的。变址的用途是为重复操作的完成提供一种高效机制。例如， 主存位置 A 处开始放一个数值列表，打算为表的每个元素加 1。我们需要取每个数位，对 它加 1，然后再存回，故需要的有效地址序列是 A, A+1, A+2, …直到最后一个位置。此时 值 A 存入指令地址字段，再用一个变址寄存器 IX(初始化为 0)。每次操作之后，变址寄存器 内容增 1。此时，EA=A+(R)，R←(R+1)\n\n变址寻址的优点是可扩大寻址范围(变址寄存器的位数大于形式地址 A 的位数);在数组处理过程中，可设定 A 为数组的首地址，不断改变变址寄存器 IX 的内容，便可很容易形成数组中任一数据的地址，特别适合编制循环程序。偏移量(变址寄存器 IX)的位数足以表示整个存储空间。\n显然，变址寻址与基址寻址的有效地址形成过程极为相似。但从本质上讲，两者有较大区别。基址寻址面向系统，主要用于为多道程序或数据分配存储空间，因此基址寄存器的内容通常由操作系统或管理程序确定，在程序的执行过程中其值不可变，而指令字中的 A 是可变的:变址寻址立足于用户，主要用于处理数组问题，在变址寻址中，变址寄存器的内容由用户设定，在程序执行过程中其值可变，而指令字中的 A 是不可变的。\n堆栈寻址 堆栈有寄存器堆栈(硬堆栈)和存储器堆栈(软堆栈)两种形式，它们都以后进先出(LIFO)的原理存储数据。不论是寄存器堆栈，还是存储器堆栈，数据的存取都与栈顶地址打交通，为此需要一个隐式或显式的堆栈指示器(寄存器),该寄存器被称为堆栈指针(SP)。数据进栈时使用 PUSH 指令，将数据压入栈顶地址，堆栈指示器减 1；数据退栈时，使用 POP 指令，数据从栈顶地址弹出，堆栈指示器加 1。从而保证了堆栈中数据先进后出的存取顺序。\n各个寻址方式比较\n\n\n\n寻址方式\n有效地址\n访存次数(执行阶段)\n\n\n\n\n隐含寻址\n程序指定\n0\n\n\n立即寻址\nA 即是操作数\n0\n\n\n直接寻址\nEA = A\n1\n\n\n一次间接寻址\nEA = (A)\n2\n\n\n寄存器寻址\nEA = R~i~\n0\n\n\n寄存器一次寻址\nEA = (R~i~)\n1\n\n\n相对寻址\nEA = (PC) + A\n1\n\n\n基址寻址\nEA = (BR) + A\n1\n\n\n变址寻址\nEA = (IX) + A\n1\n\n\n\n\n程序的机器级代码表示常用汇编指令介绍相关寄存器 x86 处理器中有 8 个 32 位的通用寄存器,各寄存器及说明如下图所示。为了向后兼容,EAX、EBX、ECX和EDX的高两位字节和低两位字节可以独立使用,E为Extended(拓展),表示 32 位寄存器;D表示Destination(目标)(Destination Index, DI, 目标索引);S表示Source(源)(Source Index, SI, 源索引)。例如,EAX的低两位称为AX,而AX的高低字节又可以分别作为两个 8 位寄存器,分别称为AH和AL。寄存器的名称与大小写无关,既可以用EAX,又可以用eax。\n\n除了 EBP 和 ESP 外,其他几个寄存器的用途是比较任意的\n汇编指令格式 使用不同编程工具开发程序,用到的汇编程序也不同,一般有两种不同汇编格式:AT&amp;T格式和Intel格式。\n\n\n\n\n\n\n\n\n\nAT&amp;T 格式是一种汇编语言的语法格式，主要用于 Unix 和 Linux 等操作系统中。\n他们的区别主要体现如下:\n以下简称为A 格式和I 格式\n①A 格式的指令只能用小写字母,而 I 格式的指令对大小写不敏感\n② 在 A 格式中,第一个为源操作数,第二个为目的操作数,方向从左到右,合乎日常顺序,I 格式中,第一个为目的操作数,第二个为源操作数,方向由右向左\n③ 在 A 格式中,寄存器需要加前缀”%”,立即数需要加前缀”$”;在 I 格式中,寄存器和立即数都不需要加\n④ 在内存寻址方面,A 格式使用”()”,而 I 格式使用”[]”\n⑤ 在 A 格式中，操作码和源操作数、目标操作数之间用逗号隔开，而在 I 格式中则用空格隔开\n⑥ 在处理负责寻址方式时,例如 A 格式的内存操作数”disp(base,index,scale)“分别表示偏移量(disp)、基址寄存器(base)、变址寄存器(index)和比例因子(scale),如”8(%edx,%eax,2)”表示操作数为 M[R[edx]+R[eax]×2+8],其对应的 I 格式的操作数为”[edx+eax×2+8]”\n\n\n\n\n\n\n\n\n\nM: 表示内存操作，即对内存进行读取或写入操作。\nR[edx]:表示以通用寄存器 edx 的内容作为值参与计算\n比例因子:是一个常数，用于与变址寄存器的值相乘。\nR[eax]×2:将寄存器 eax 的内容乘以 2 作为变址寄存器的偏移量\n⑦ 在指定数据长度方面,A 格式指令操作码的后面紧跟一个字符,表明操作数大小,”b”表示 byte(字节)、”w”表示 word(字)或”l”表示 Long(双字)。I 格式也有类似的语法,他在操作码后面显示地注明 byte ptr、word ptr、dword ptr。\n例子:将一个 16 位的数据保存到内存地址 0x200 处\nAT&amp;T 格式:\nmovb $0x56, 0x200\nIntel 格式\nmov word ptr [0x200], 0x56\n\n\n\n\n\n\n\n\n\n由于 32 位和 64 位都是由 16 位拓展而来,因此用 word(字)表示 16 位\n以下是两种格式指令格式的对比\n\n\n\n\nAT&amp;T 格式\nIntel 格式\n含义\n\n\n\n\nmov $100, %eax\nmov eax, 100\n100 → R[eax]\n\n\nmov %eax, %ebx\nmov ebx, eax\nR[eax] → R[ebx]\n\n\nmov %eax, (%ebx)\nmov [ebx], eax\nR[eax] → M[R[ebx]]\n\n\nmov %eax, -8(%ebp)\nmov [ebp-8], eax\nR[eax] →M[R[ebx]-8]\n\n\nlea 8(%edx, %eax, 2), %eax\nlea eax, [edx+eax*2+8]\nR[edx]+R[eax]×2+8 → R[eax](这个 lea 指令（effective address）的意思是计算有效地址,而不是直接从内存中加载数据到寄存器,所以这里不是 M[R[edx]+R[eax]×2+8])\n\n\nmovl %eax, %ebx\nmov dword ptr ebx, eax\n长度为 4 字节的 R[eax] → R[ebx]\n\n\n\n\n\n\n\n\n\n\n\n\n\nR[r]表示寄存器 r 的内容,M[addr]表示主存单元 addr 的内容,→ 表示信息传送方向\n常用指令汇编指令通常可以分为数据传送指令、逻辑计算指令和控制流指令下面是以 Intel 格式为例的一些重要指令\n以下是一些格式介绍:\n\n&lt;reg&gt;:表示任意寄存器,若其后带有数字,则指定其位数,如\\表示 32 位寄存器(eax、ebx、ecx、edx、esi、edi、ebp、esp);\\代表 16 位寄存器(ax、bx、cx、dx、si、di、bp、sp);\\代表 8 位寄存器(ah、al、bh、bl、ch、cl、dh、dl)\n&lt;mem&gt;:表示内存地址(如[eax]、[var+4]或 dword ptr [eax+ebx])\n&lt;con&gt;:表示 8 位、16 位或 32 位常数。\\表示 8 位常数;\\表示 16 位常数;\\表示 32 位常数\n&lt;cl&gt;:表示要移动的位数，它可以是一个立即数或者是另一个寄存器。\n\nx86 中的指令机器码长度为 1 字节,对同一指令的不同用途有多种编码方式,比如 mov 指令就有 28 种机内编码,用于不同的操作数类型或用于特定的寄存器:\nmov &lt;con16&gt;, ax\t\t\t\t\t\t#机器码为B8H\nmov &lt;con8&gt;, al\t\t\t\t\t\t#机器码为B0H\nmov &lt;reg16&gt;, &lt;reg16&gt;&#x2F;&lt;mem16&gt;\t\t#机器码为89H\nmov &lt;reg8&gt;&lt;mem18&gt;, &lt;reg8&gt;\t\t\t#机器码为8AH\nmov &lt;reg16&gt;&#x2F;&lt;mem16&gt;, &lt;reg16&gt;\t\t#机器码为8BH\n数据传送指令mov 指令将第二个操作数(寄存器的内容,内存中的内容或常数值)复制到第一个操作数(寄存器或内存)。但不能直接用于从内存复制到内存\n其语法如下:\nmov &lt;reg&gt;, &lt;reg&gt;\nmov &lt;reg&gt;, &lt;mem&gt;\nmov &lt;mem&gt;, &lt;reg&gt;\nmov &lt;reg&gt;, &lt;con&gt;\nmov &lt;mem&gt;, &lt;com&gt;\n\n#例子:\nmov eax, ebx \t\t\t\t#将ebx值复制到eax\nmov byte ptr [var], 5\t\t#将5保存到var指示的内存地址的一字节中\npush 指令将操作数压入内存的栈,常用于函数调用。ESP 时栈顶,压栈前先将 ESP 值减 4(栈增长方向与内存地址增长方向相反),然后将操作数压入 ESP 指示的地址\n\n语法如下:\npush &lt;reg32&gt;\npush &lt;mem&gt;\npush &lt;con32&gt;\n\n#例子:\npush eax\t\t#将eax值压栈\npush [var]\t\t#将var值指示的内存地址的4字节值压栈\npop 指令与 push 指令相反,pop 指令执行的是出栈操作,出栈前先将 ESP 指示的地址中的内容出栈,然后将 ESP 的值加 4\n\n语法格式如下:\npop edi\t\t\t#弹出栈顶元素送到edi\npop [ebx] \t\t#弹出栈顶元素送到ebx值指示的内存地址的4字节中\n算数和逻辑运算指令add/sub 指令add指令将两个操作数相加,相加的结果保存到第一个操作数中。sub指令用于两个操作数相减,相减的结果保存到第一个操作数中\nadd &lt;reg&gt;,&lt;reg&gt; &#x2F; sub &lt;reg&gt;,&lt;reg&gt;\nadd &lt;reg&gt;,&lt;mem&gt; &#x2F; sub &lt;reg&gt;,&lt;mem&gt;\nadd &lt;mem&gt;,&lt;reg&gt; &#x2F; sub &lt;mem&gt;,&lt;reg&gt;\nadd &lt;reg&gt;,&lt;con&gt; &#x2F; sub &lt;reg&gt;,&lt;con&gt;\nadd &lt;mem&gt;,&lt;con&gt; &#x2F; sub &lt;mem&gt;,&lt;con&gt;\n\n#例子:\nsub eax, 10\t\t#eax ← eax-10\nadd byte ptr [var], 10 \t\t#10与var值指示的内存地址的1字节的值相加,并将结果保存在var值指示的内存地址的字节中\ninc/dec 指令inc指令是表示将操作数自增 1;dec指令是表示将操作数自减 1\ninc &lt;reg&gt; &#x2F; dec &lt;reg&gt;\ninc &lt;mem&gt; &#x2F; dec &lt;mem&gt;\n\n#例子:\ndec eax\t\t\t#eax的值自减1\ninc dword ptr\t#var所指示的啊内存地址的4字节的值自增1(d double,word 16位)\nimul 指令带符号整数乘法指令,有两种格式:\n① 两个操作数,将两个操作数相乘,将结果保存在第一个操作数中,第一个操作数必须为寄存器\n②3 个操作数,将第二个和第三个操作数相乘,将结果保存在第一个操作数中,第一个操作数必须为寄存器\n其语法格式如下:\nimul &lt;reg32&gt;,&lt;reg32&gt;\nimul &lt;reg32&gt;,&lt;mem&gt;\nimul &lt;reg32&gt;,&lt;reg32&gt;,&lt;con&gt;\nimul &lt;reg32&gt;,&lt;mem&gt;,&lt;con&gt;\n\n\n#例子:\nimul eax, [var]\t\t#eax ← eax * [var]\nimul esi, edi, 25\t#esi ← edi * 25\n乘法操作结果可能溢出,则编译器设置溢出标志 OF=1,以使 CPU 调出溢出异常处理程序。\nidiv 指令带符号整数除法,他只有一个操作数,即除数,而被除数则为 edx:eax 中的内容(64 位整数),操作结果有两部分:商和余数,商送到 eax,余数送到 edx\n其语法如下:\nidiv &lt;reg32&gt;\nidiv &lt;mem&gt;\n\n#例子:\nidiv ebx\nidiv dword ptr [var]\nand/or/xor 指令分别是逻辑与、逻辑或、逻辑异或指令操作,用于操作数的位操作,操作结果放在第一个操作数中\nand &lt;reg&gt;,&lt;reg&gt; &#x2F; or &lt;reg&gt;,&lt;reg&gt; &#x2F; xor &lt;reg&gt;,&lt;reg&gt;\nand &lt;reg&gt;,&lt;mem&gt; &#x2F; or &lt;reg&gt;,&lt;mem&gt; &#x2F; xor &lt;reg&gt;,&lt;mem&gt;\nand &lt;mem&gt;,&lt;reg&gt; &#x2F; or &lt;mem&gt;,&lt;reg&gt; &#x2F; xor &lt;mem&gt;,&lt;reg&gt;\nand &lt;reg&gt;,&lt;con&gt; &#x2F; or &lt;reg&gt;,&lt;con&gt; &#x2F; xor &lt;reg&gt;,&lt;con&gt;\nand &lt;mem&gt;,&lt;con&gt; &#x2F; or &lt;mem&gt;,&lt;con&gt; &#x2F; xor &lt;mem&gt;,&lt;con&gt;\n\n#例子:\nand eax, 0fH\t\t#将eax中的前28位全部置为0,最后4位保持不变,0fH(H表示该数为16进制数)\nxor edx, edx\t\t#置edx中的内容为0\nnot 指令位翻转指令,将操作数中的每一位翻转,即 0 → 1、1 → 0\n其语法如下:\nnot &lt;reg&gt;\nnot &lt;mem&gt;\n\n#例子:\nnot byte ptr [var]\t#将var值指示的内存地址的一字节的所有位翻转\nneg 指令取负指令\nneg &lt;reg&gt;\nneg &lt;mem&gt;\n\n#例子:\nneg eax\t\t\t\t#eax ← eax\nshl/shr 指令逻辑移位指令,shl 为逻辑左移,shr 为逻辑右移,第一个操作数表示被操作数,第二个操作指示移位的位数\nshl &lt;reg&gt;,&lt;con8&gt; &#x2F; shr &lt;reg&gt;,&lt;con8&gt;\nshl &lt;mem&gt;,&lt;con8&gt; &#x2F; shr &lt;mem&gt;,&lt;con8&gt;\nshl &lt;reg&gt;,&lt;cl&gt; &#x2F; shr &lt;reg&gt;,&lt;cl&gt;\nshl &lt;mem&gt;,&lt;cl&gt; &#x2F; shr &lt;mem&gt;,&lt;cl&gt;\n\n#例:\nshl eax, 1\t\t\t#将eax值左移一位,相当于乘2\nshr ebx, cl \t\t#将ebx值右移n位(n为cl中的值),相当于除2\n控制流指令 x86 处理器维持一个指示当前执行指令的指令指针(IP),当一条指令执行后,此指针自动指向下一条指令。IP 寄存器不能直接操作,但可以用控制流指令更新。通常用标签(label)指示程序中的指令地址,在 x86 的汇编代码中,可在任何指令前加入标签。例如:\n\tmov esi, [ebp+8]\nbegin: xor ecx, ecx\n\tmov eax, [esi]\n这样 begin 指示了第二条指令,控制流指令通过标签就可以实现程序指令的跳转\njmp 指令控制 IP 转移到 label 所指示的地址(从 label 中取出指令执行)\njmp &lt;label&gt;\n\n#例子:\njmp begin\t\t\t#跳转到begin标记的指令执行\njcondition 指令条件转移指令,依据 CPU 状态字中的一系列条件状态转移。CPU 状态字中包括指示最后一个算数运算结果是否为 0,运算结果是否为负数等\nje &lt;label&gt;\t(jump when equal)\njne &lt;label&gt;\t(jump when not equal)\njz &lt;label&gt;\t(jump when last result was zero)\njnz &lt;label&gt;\t(jump when result was not zero)\njg &lt;label&gt;\t(jump when greather than)\njge &lt;label&gt;\t(jump when greather than or equal to)\njl &lt;label&gt;\t(jump when less than)\njle &lt;label&gt;\t(jump when less than or equal to)\n\n#例子:\ncmp eax, ebx\njle done \t\t\t#如果eax的值小于等于ebx的值,跳转到done指示的指令执行,否则执行下一条指令\ncmp/test 指令cmp 指令用于比较两个操作数的值(compare),test 指令对两个操作数进行逐位与运算,这两类指令都不保存操作结果,仅根据运算结果设置 CPU 状态字中的条件码\ncmp &lt;reg&gt;,&lt;reg&gt; &#x2F; test &lt;reg&gt;,&lt;reg&gt;\ncmp &lt;mem&gt;,&lt;reg&gt; &#x2F; test &lt;mem&gt;,&lt;reg&gt;\ncmp &lt;reg&gt;,&lt;mem&gt; &#x2F; test &lt;reg&gt;,&lt;mem&gt;\ncmp &lt;reg&gt;,&lt;con&gt; &#x2F; test &lt;reg&gt;,&lt;con&gt;\n\n#cmp和test通常和jcondition指令搭配使用,举例:\ncmp dword ptr [var], 10\t\t#将var指示的主存地址为4字节的内容,与10进行比较\njne loop\t\t\t\t\t#如果相等则顺序执行,如果不相等则跳转到loop处执行\ntest eax, eax\t\t\t\t#测试eax是否为0\njz xxxx\t\t\t\t\t\t#为零则置标志ZF为1,跳转到xxxx处执行\ncall/ret 指令分别用于实现子程序(过程、函数等)的调用及返回\ncall &lt;label&gt;\nret\ncall 指令首先将当前执行指令地址入栈,然后无条件转移到由标签指示的命令。与其他简单的跳转指令不同,call 指令保存调用前的地址信息(当 call 命令结束后,返回调用之前的地址)。\nret 指令实现子程序的返回机制,ret 指令弹出栈中保存的指令地址,然后无条件转移到保存的指令地址执行。\n过程调用的机器级表示上面说 call/ret 指令主要用于过程调用,他们都属于一种无条件转移指令。\n假定过程 P(调用者)调用过程 Q(被调用者),过程调用的执行步骤如下:\n\nP 将入口参数(实参)放在 Q 能够访问到的地方\nP 将返回地址存到特定的地方,然后控制转移到 Q(call 实现)\nQ 保存 P 的现场(通用寄存器的内容),并为自己的非静态局部变量分配空间\n执行过程 Q\nQ 恢复 P 的现场,将返回结果放到 P 能够访问到的地方,并释放局部变量所占空间\nQ 取出返回地址,将控制转移到 P(ret 实现)\n其中寄存器 EAX、ECX 和 EDX 是调用者保存寄存器,其保存和恢复的任务由过程 P 负责,P 调用 Q 时,Q 就可以直接使用这 3 个寄存器\n\n\n寄存器 ESI、EDI、EBX 是被调用者保存寄存器,Q 必须先将他们的值保存在栈中才能使用它们,并在返回 P 之前先恢复它们的值\n每个过程都有自己的栈区,称为栈帧,因此,一个栈由若干帧栈帧组成。帧指针寄存器 EBP 指示当前栈帧的起止位置(栈底),栈指针寄存器 ESP 指示栈顶,栈从高地址向低地址增长,因此当前栈帧的范围在帧指针 EBP 和 ESP 指向的区域之间\n选择语句的机器级表示 常见的选择结构语句有if-then、if-then-else、case(或switch)等。编译器通过条件码(标志位)设置指令和各类转移指令来实现程序中的选择结构语句。\n条件码(标志位)\n 除了整数寄存器,CPU 还维护一组条件码(标志位)寄存器,他们描述了最近的算数或逻辑运算操作的属性。可以检测这些寄存器来执行条件分支指令,最常用的条件码如下:\n\nCF:进(借)位标志,最近无符号整数加(减)运算后的进(借)位情况。有进(借)位时,CF = 1;否则 CF = 0\nZF:零标志。最近的操作的运算结果是否为 0。若结果为 0,ZF = 1;否则 ZF = 0\nSF:符号标志。最近的带符号数运算结果的符号。若为负,SF = 1;否则 SF = 0\nOF:溢出标志。最近的带符号数运算结果是否溢出,若溢出,OF =1;否则 OF = 0\n\n可见,OF 和 SF 对无符号数运算来说没有意义,而 CF 对带符号数运算来说没有意义\nCISC 和 RISC 的基本概念 CISC 复杂指令系统计算机，功能更强大，指令更复杂；RISC 精简指令系统计算机，指令简单，执行速度快。\n RISC 精简指令系统计算机，要求指令系统简化，尽量使用寄存器-寄存器操作指令。指令格式一致，指令长度固定、种类少，寻址方式种类少，指令功能没那么强。\nRISC 采用指令流水线技术，使大部分指令在一个时钟周期内完成。适合流水线的指令系统的特征有 ∶\n ① 指令长度应尽量一致;\n ② 指令格式应尽量规整;\n ③ 保证除 Load/Store 指令外的其他指令都不访问存储器;\n ④数据和指令在存储器中”对齐”存放。\n中央处理器CPU 的功能和基本结构CPU 的功能 指令控制 程序的顺序控制，称为指令控制。由于程序是一个指令序列，这些指令的 相互顺序不能任意颠倒，必须严格按程序规定的顺序进行，因此，保证机器按顺序执行程 序是 CPU 的首要任务。\n 操作控制 一条指令的功能往往是由若干个操作信号的组合来实现的，因此，CPU 管理并产生由内存取出的每条指令的操作信号，把各种操作信号送往相应的部件，从而控制 这些部件按指令的要求进行动作。\n 时间控制 对各种操作实施时间上的定时，称为时间控制。因为在计算机中，各种指令的操作信号均受到时间的严格定时。另外，一条指令的整个执行过程也受到时间的严格 定时。只有这样，计算机才能有条不紊地自动工作。\n 数据加工 所谓数据加工，就是对数据进行算术运算和逻辑运算处理。完成数据的加工处理，是 CPU 的根本任务。因为，原始信息只有经过加工处理后才能对人们有用\n 中断处理 对计算机运行过程中出现的异常情况和特殊请求进行处理\nCPU 的基本结构控制器\n由程序计数器(PC)、指令寄存器(IR)、指令译码器(ID)、时序产生器和操作控制器(OC)组成， 它是发布命令的“决策机构”，即完成协调和指挥整个计算机系统的操作。\n控制器的主要功能有：\n\n从指令 cache 中取出一条指令，并指出下一条指令在指令 cache 中的位置。\n\n对指令进行译码或测试，并产生相应的操作控制信号，以便启动规定的动作。比如， 一次数据 cache 的读/写操作，一个算术逻辑运算操作，或一个输入/输出操作。\n\n指挥并控制 CPU、数据 cache 和输入/输出设备之间数据流动的方向。\n\n\n下面详细介绍一下控制器的组成:\n\n指令寄存器(IR) 指令寄存器用来保存当前正在执行的一条指令。当执行一条指令 时，先把它从指令存储器(简称指存)读出，然后再传送至指令寄存器。指令划分为操作码 和地址码字段，由二进制数字组成。为了执行任何给定的指令，必须对操作码进行测试， 以便识别所要求的操作。一个叫做指令译码器的部件就是做这项工作的。指令寄存器中操 作码字段 OP 的输出就是指令译码器的输入。操作码一经译码后，即可向操作控制器发出具 体操作的特定信号。\n\n程序计数器(PC) 用来指出下一条指令在主存中存放给的地址。在程序开始执行前，必须将它的起始地址，即程序的第一条指令所在的指存单元地址送入 PC，因此 PC 的内容即是从指存提取的第一条指令的地址。当执行指令时，CPU 将自动修改 PC 的内容，以便使其保持的总是将要执行的下一条指令的地址。由于大多数指令都是按 顺序来执行的，所以修改的过程通常只是简单的对 PC 加 1。 但是，当遇到转移指令如 JMP 指令时，那么后继指令的地址(即 PC 的内容)必须从指令寄存器中的地址字段取得。在这种情况下，下一条从指存取出的指令将由转移指令来规定，而不是像通常一样按顺序来取得。因此程序计数器的结构应当是具有寄存器和计数两种功能的结构。汇编程序员可见\n\n存储器地址寄存器(MAR) 用于存放要访问的主存单元的地址\n存储数据寄存器(MDR) 用于存放向主存写入的信息或从主存读出的信息\n时序系统 用于产生各种时序信号,他们都由统一时钟(CLOCK)分频得到\n微操作信号信号发生器 根据 IR 的内容(指令)、PSW 的内容(状态信息)及时序信号,产生控制计算机各个部件所要用到的控制信号\n\n运算器\n由算术逻辑运算单元(ALU)、通用寄存器、数据缓冲寄存器(DR)和程序状态字寄存器(状态条件寄存器，PSWR)组成，它是数据加工处理部件。相对控制器而言，运算器接受控制器的命令而进行动作，即运算器所进行的全部操作都是由控制器发出的控制信号来指挥的，所以它是执行部件。\n运算器有两个主要功能：\n\n执行所有的算术运算。\n\n执行所有的逻辑运算，并进行逻辑测试，如零值测试或两个值的比较。 通常，一个算术操作产生一个运算结果，而一个逻辑操作则产生一个判决。\n\n\n下面详细介绍一下运算器的组成:\n\n算数逻辑单元(ALU): 进行算数/逻辑运算\n\n暂存寄存器: 用于暂存从主存读来的数据,该数据不能存放在通用寄存器中,某则会破坏其原有的内容。暂存寄存器对应用程序员来说是透明的\n\n累加寄存器(ACC):一个通用寄存器,用于暂时存放 ALU 的运算结果,可做加法运算的一个输入端\n\n通用寄存器 在我们的模型中，通用寄存器有 4 个(R0 ～ R3)，其功能是：当算术逻 辑单元(ALU)执行算术或逻辑运算时，为 ALU 提供一个工作区。例如，在执行一次加法运 算时，选择两个操作数(分别放在两个寄存器)相加，所得的结果送回其中一个寄存器(如 R2)中，而 R2 中原有的内容随即被替换。\n 目前 CPU 中的通用寄存器，可多达 64 个，甚至更多。其中任何一个可存放源操作数， 也可存放结果操作数。在这种情况下，需要在指令格式中对寄存器号加以编址。从硬件结 构来讲，需要使用通用寄存器堆结构，以便选择输入信息源。通用寄存器还用作地址指示 器、变址寄存器、堆栈指示器等。\n\n程序状态字寄存器(PSWR) 程序状态字寄存器又称为状态条件寄存器，保存由算术运算指令和逻辑运算指令运算或测试结果建立的各种条件代码，如运算结果进位标志C)，运算结果溢出标志(V)，运算结果为零标志(Z)，运算结果为负标志(N)，等等。这些 标志位通常分别由 1 位触发器保存。 除此之外，状态条件寄存器还保存中断和系统工作状态等信息，以便使 CPU 和系统能 及时了解机器运行状态和程序运行状态。因此，状态条件寄存器是一个由各种状态条件标 志拼凑而成的寄存器。对所有用户可见\n\n移位器 对操作数或运算记过进行移位操作\n\n计数器 控制乘除运算的操作步骤\n\n\n\n\n\n\n\n\n\n\n\n虚拟存储器对系统程序员可见\n以下是哈弗结构的 CPU 模型简略图(数据 cache 和指令 cache 分离)👇:\n\n`\n寄存器和存储器的可见性总结:\n\n\n\n\n寄存器\n描述\n汇编程序员可见\n应用程序员可见\n系统程序员可见\n用户是否可见(可编程)\n\n\n\n\nPSW\n在条件转移指令中使用，以及在程序员使用 CMP 指令时需要用到\n是\n否\n否\n是\n\n\nPC\n跳转指令需要使用 PC+n 来实现\n是\n否\n否\n是\n\n\n通用寄存器\n程序员可以使用通用寄存器 R 写指令\n是\n是\n否\n是\n\n\nMAR\n内存地址寄存器，用于存储要访问的内存地址\n否\n否\n是\n否\n\n\nMDR\n内存数据寄存器，用于存储从内存读取或将数据写入内存的数据\n否\n否\n是\n否\n\n\n累加器 ACC\n用于存储运算结果和进行算术逻辑操作\n是\n否\n否\n是\n\n\nIR\n指令寄存器，用于存储当前正在执行的指令\n否\n否\n否\n否\n\n\nCache\n高速缓存，用于临时存储内存中的数据，以提高访问速度\n否\n否\n是\n否\n\n\n微程序结构和功能\nCPU 内部的微指令，用于控制 CPU 的操作流程\n否\n否\n是\n否\n\n\n暂存寄存器\nCPU 内部用于完成某些操作的寄存器\n否\n否\n是\n否\n\n\n虚拟寄存器\n虚拟机中的寄存器\n否\n是\n是\n否\n\n\n虚拟存储器\n系统程序员通过虚拟存储器来管理内存的使用，以及进行进程之间的隔离和保护。\n否\n否\n是\n否\n\n\n\n\n指令的过程指令周期CPU 从主存中取出并执行一条指令的时间称为指令周期,不同指令的指令周期可能不同。\n指令周期常用若干机器周期来表示,一个机器周期又包含若干个时钟周期(也称节拍或 T 周期,它是 CPU 操作的最基本的单位)。\n\n完整的指令周期：\n\n上述 4 个工作周期都有 CPU 访存操作，只是访存的目的不同。\n取指周期是为了取指令(控制器自动进行，不需要得到相应的指令)\n间址周期是为了取操作数有效地址\n执行周期是为了取操作数并执行运算\n中断周期是为了保存程序断点\n\n\n\n\n\n\n\n\n\n为了区分不同的工作周期,在 CPU 内设置了 4 个标志触发器 FE、IND、EX 和 INT,他们分别对应取指、间址、执行和中断周期,并以”1”状态表示有效\n指令周期的数据流取指周期根据 PC 中的内容从主存中取出指令代码并存放在 IR 中\n取指周期的数据流向如下图 👇:\n\n\n\n\n\n\n\n\n\n\n在取指令开始的时候，PC 存放的是当前指令的地址；取指完成后，PC 中存放的是下一条指令的地址。区别在于 是取指令开始的阶段还是取指令结束的阶段。\n间址周期取操作数的有效地址\n间址周期的数据流向如下图 👇:\n\n为什么有个或？ 因为在取指周期阶段是先把指令放在 MDR 里面，再传到 IR；进入到间址周期， MDR 中内容是暂时还没有改的，里面存的也还是之前的内容。所以 “有个或” 。\n\n\n\n\n\n\n\n\n\nAd(IR)表示取出 IR 中存放指令字的地址字段\n执行周期根据 IR 中的指令的操作码和 MDR 中地址对应的主存的操作数，通过 ALU 操作产生执行结果。不同的指令执行周期操作不同，因此数据流无法统一。\n中断周期处理中断请求。假设程序断点存入堆栈中,并用 SP 指示栈顶地址,并且进栈操作是先修改栈顶指针,后存入数据\n\n只是先暂停任务，去完成其它任务。为了恢复当前任务，需要保存断点。【断点：本来要执行的下一条指令，即 PC 的内容】一般使用 堆栈结构来保存断点，SP 表示栈顶地址。假设 SP 指向栈顶元素，进栈操作是先修改指针后存入数据。【如果是栈顶元素上一个位置，则是先存入数据，再移动指针】\n调整指针是通过 减 1 实现，和平时的方向是相反的，因为在主存中选一片区域做堆栈的时候，是从高地址码向低地址去扩增的。所以进栈用减法，出栈用加法。\n到第 3 步，将 PC 的内容送到 MDR 之后，配合之前写的命令，PC 的内容就会通过数据总线放到存储器中。(MDR)  → M(MAR)\n第 3 步完成后，就完成了中断操作的第一个任务：保存断点（即暂停当前任务）；下一步是要去完成其它任务，怎么开始完成其它任务？把任务要执行的第一条指令地址（即中断服务程序的入口地址）放到 PC 中。这个地址是由向量形成部件产生的（中断章节具体介绍），故该地址又被称为 向量地址。 这样下一步， CPU 还是根据 PC 中的内容去寻找下一条指令，所以就切入到了一个新的程序的运行。\n指令执行方案单指令周期：具体来说，就是不分取指阶段、执行阶段等，而是将指令周期作为一个阶段，就相当于每个指令周期都是一个机器周期。这种模式下，指令和指令之间是串行执行的。因为所有的指令需要统一 一个时间，所以指令周期 取决于执行时间最长的指令的执行时间。\n多指令周期:对不同类型的指令选用不同的执行步骤。指令之间串行执行。\n流水线方案：间隔一定时间启动就启动一条指令，原理是：在不同的机器周期（不同的小步骤下），一条指令所需要的硬件资源是不同的，所以这样的安排相当于多条指令在并行执行，只不过在不同的阶段在使用不同的硬件。\n数据通路的功能和基本结构数据通路的功能数据通路就是数据在功能部件之间传送的路径；\n数据通路描述了信息从哪里开始、中间经过哪些部件、最终传送到哪个寄存器；\n数据通路由 ==控制部件== 控制，控制部件根据每条指令功能的不同生成对数据通路的控制信号；\n数据通路的功能是==实现 CPU 内部的 运算器与寄存器 及 寄存器之间 的数据交换== ；\n数据通路的基本结构数据通路的基本结构包括以下三种：\n① CPU 内部单总线结构\n所有寄存器的输入端和输出端都连接连接到一条公共通路上；\n特点：结构简单、易数据冲突、性能低；\n② CPU 内部三总线结构\n所有寄存的输入输出端链接到多条公共通路上\n③ 专用数据通路方式\n根据指令执行过程中的数据和地址的流动方向安排连接线路；\n特点：避免使用共享的总线，性能高、硬件量大；\n\n\n\n\n\n\n\n\n\n\n字母加”in“表示该部件允许输入控制信号\n字母加”out“表示该部件允许输出控制信号\n注意: 内部总线是指同一部件，如 CPU 内部连接各寄存器及运算部件之间的总线; 系统总线是指同一台计算机系统的各部件，如 CPU、内存、通道和各类 IO 接口间互相连接的总线。\n寄存器之间的数传送寄存器之间的数据传送可通过 CPU 内部总线完成。在图 5.7 中，某寄存器 AX 的输出和输入分别由 AXout 和 AXin 控制。这里以 PC 寄存器为例，把 PC 内容送至 MAR，实现传送操作的流程及控制信号为\nPC→Bus PCout有效，PC内容送总线\nBus→MAR MARin有效，总线内容送MAR\n主存与 CPU 之间的数据传送主存与 CPU 之间的数据传送也要借助 CPU 内部总线完成。现以 CPU 从主存读取指令为例说明数据在数据通路中的传送过程。实现传送操作的流程及控制信号为\nPC→Bus→MAR PCout 和 MARin有效，现行指令地址→MAR\n1→R CU发读命令\nMEM(MAR)→MDR MDRin有效\nMDR→BuS→IR MDRout和 IRin有效，现行指令→IR\n执行算术或逻辑运算执行算术或逻辑操作时，由于 ALU 本身是没有内部存储功能的组合电路，因此如要执行加法运算，相加的两个数必须在 ALU 的两个输入端同时有效。图 5.7 中的暂存器 Y 即用于该目的。先将一个操作数经 CPU 内部总线送入暂存器 Y 保存，Y 的内容在 ALU 的左输入端始终有效，再将另一个操作数经总线直接送到 ALU 的右输入端。这样两个操作数都送入了 ALU，运算结果暂存在暂存器 Z 中。\nAd(IR)→Bus→MAR MDRout和 MARin有效\n1→R CU发读命令\nMEM→数据线→MDR 操作数从存储器→数据线→MDR\nMDR→Bus→Y MDRout 和 Yin有效，操作数→Y\n(ACC)+(Y)→Z ACCout 和 ALUin有效，CU向ALU发加命令，结果→Z\nZ→ACC Zout和 ACCin有效，结果→ACC\n控制器的功能和工作原理控制器的结构和功能从图 5.8 可以看到计算机硬件系统的五大功能部件及其连接关系。它们通过数据总线、地址总线和控制总线连接在一起，其中点画线框内的是控制器部件。\n\n控制器的主要功能有:\n\n从主存中取出一条指令，并指出下一条指令在主存中的位置。\n\n对指令进行译码或测试，产生相应的操作控制信号，以便启动规定的动作。\n\n指挥并控制 CPU、主存、输入和输出设备之间的数据流动方向。\n\n\n根据控制器产生微操作控制信号的方式的不同，控制器可分为硬布线控制器和微程序控制器，两类控制器中的 PC 和 IR 是相同的，但确定和表示指令执行步骤的办法以及给出控制各部件运行所需要的控制信号的方案是不同的。\n硬布线控制器 基本原理是根据指令的要求、当前的时序及外部和内部的状态，按时间的顺序发送一系列微操作控制信号。它由复杂的组合逻辑门电路和一些触发器构成，因此又称组合逻辑控制器。\n\n硬布线控制器的时序系统及微操作1）时钟周期。用时钟信号控制节拍发生器，可以产生节拍，每个节拍的宽度正好对应一个时钟周期。在每个节拍内机器可完成一个或几个需同时执行的操作。\n2）机器周期。机器周期可视为所有指令执行过程中的一个基准时间。不同指令的操作不同，指令周期也不同。访问一次存储器的时间是固定的，因此通常以存取周期作为基准时间，即内存中读取一个指令字的最短时间作为机器周期。在存储字长等于指令字长的前提下，取指周期也可视为机器周期。\n在一个机器周期里可完成若干微操作，每个微操作都需一定的时间，可用时钟信号来控制产生每个微操作命令。\n3）指令周期。\n4）微操作命令分析。控制单元具有发出各种操作命令（控制信号）序列的功能。这些命令与指令有关，而且必须按一定次序发出，才能使机器有序地工作。\n执行程序的过程中，对于不同的指令，控制单元需发出各种不同的微操作命令。一条指令分为 3 个工作周期:取指周期、间址周期和执行周期。下面分析各个子周期的微操作命令。\n\nCPU 的控制方式控制单元控制一条指令执行的过程，实质上是依次执行一个确定的微操作序列的过程。由于不同指令所对应的微操作数及复杂程度不同，因此每条指令和每个微操作所需的执行时间也不同。主要有以下 3 种控制方式。\n\n同步控制方式 。所谓同步控制方式，是指系统有一个统一的时钟，所有的控制信号均来自这个统一的时钟信号。通常以最长的微操作序列和最烦琐的微操作作为标准，采取完全统一的、具有相同时间间隔和相同数目的节拍作为机器周期来运行不同的指令。同步控制方式的优点是控制电路简单，缺点是运行速度慢。\n\n异步控制方式。异步控制方式不存在基准时标信号，各部件按自身固有的速度工作，通过应答方式进行联络。异步控制方式的优点是运行速度快，缺点是控制电路比较复杂。\n\n联合控制方式。联合控制方式是介于同步、异步之间的一种折中。这种方式对各种不同的指令的微操作实行大部分采用同步控制、小部分采用异步控制的办法。\n\n\n硬布线控制单元设计步骤硬布线控制单元设计步骤包括:\n\n列出微操作命令的操作时间表。先根据微操作节拍安排，列出微操作命令的操作时间表。操作时间表中包括各个机器周期、节拍下的每条指令完成的微操作控制信号。表 5.1 列出了 CLA、COM、SHR 等 10 条机器指令微操作命令的操作时间表。表中 FE、IND 和 EX 为 CPU 工作周期标志，T~0~～ T~2~,为节拍，Ⅰ 为间址标志，在取指周期的 T~2~时刻，若测得 I=1，则 IND 触发器置“1”，标志进入间址周期;若 I=0，则 EX 触发器置“1”，标志进入执行周期。同理，在间址周期的 T~2~时刻，若测得 IND=0(表示一次间接寻址)，则 EX 触发器置“1”，进入执行周期;若测得 IND= 1(表示多次间接寻址)，则继续间接寻址。在执行周期的 T~2~时刻，CPU 要向所有中断源发中断查询信号，若检测到有中断请求并满足响应条件，则 INT 触发器置“1”，标志进入中断周期。表中未列出 INT 触发器置“1”的操作和中断周期的微操作。表中第一行对应 10 条指令的操作码，代表不同的指令。若某指令有表中所列出的微操作命令，其对应的单元格内为 1。\n\n进行微操作信号综合。在列出微操作时间表后，即可对它们进行综合分析、归类，根据微操作时间表可写出各微操作控制信号的逻辑表达式并进行适当的简化。表达式一般包括下列因素:\n\n\n微操作控制信号=机器周期 ∧ 节拍 ∧ 脉冲 ∧ 操作码 ∧ 机器状态条件\n根据表 5.1 便可列出每个微操作命令的初始逻辑表达式，经化简、整理可获得能用现有门电路实现的微操作命令逻辑表达式。\n\n例如，根据表 5.1 可写出 M(MAR)–MDR 微操作命令的逻辑表达式:\n$\\begin{aligned} &amp; \\mathrm{M}(\\mathrm{MAR}) \\rightarrow \\mathrm{MDR} \\ &amp; \\quad=\\mathrm{FE} \\cdot T_1+\\mathrm{IND} \\cdot \\mathrm{T}_1(\\mathrm{ADD}+\\mathrm{STA}+\\mathrm{LDA}+\\mathrm{JMP}+\\mathrm{BAN})+\\mathrm{EX} \\cdot T_1(\\mathrm{ADD}+\\mathrm{LDA}) \\ &amp; \\quad=T_1{\\mathrm{FE}+\\mathrm{IND}(\\mathrm{ADD}+\\mathrm{STA}+\\mathrm{LDA}+\\mathrm{JMP}+\\mathrm{BAN})+\\mathrm{EX}(\\mathrm{ADD}+\\mathrm{LDA})}\\end{aligned}$\n式中，ADD、STA、LDA、JMP、BAN 均来自操作码译码器的输出。\n\n画出微操作命令的逻辑图。根据逻辑表达式可画出对应每个微操作信号的逻辑电路图，并用逻辑门电路实现。\n\n例如，M(MAR)-MDR 的逻辑表达式所对应的逻辑图如图 5.10 所示，图中未考虑门的扇入系数。\n\n\n\n\n\n\n\n\n\n\n🤔扇入系数是什么?\n在数字电路设计中，”门的扇入系数”（Fan-in）是指一个逻辑门所能接受的输入数量。每个逻辑门都有一个特定的扇入限制，表示它能够连接的输入信号线的数量。\n 逻辑门的扇入系数取决于特定的逻辑门类型。例如，一个 2 输入的 AND 门具有扇入系数 2，意味着它可以连接两个输入信号线。如果连接了超过 2 个输入信号线，可能会导致电路设计上的问题。\n微程序控制器 微程序控制器采用存储逻辑实现，也就是把微操作信号代码化，使每条机器指令转化成为一段微程序并存入一个专门的存储器（控制存储器）中，微操作控制信号由微指令产生。\n微程序控制的基本概念 微程序设计思想就是将每条机器指令编写成一个微程序，每个微程序包含若干微指令，每条微指令对应一个或几个微操作命令。这些微程序可以存到一个控制存储器中，用寻址用户程序机器指令的办法来寻址每个微程序中的微指令。目前，大多数计算机都采用微程序设计技术。\n微程序设计技术涉及的基本术语如下:\n\n微命令与微操作 。一条机器指令可以分解成一个微操作序列，这些微操作是计算机中最基本的、不可再分解的操作。在微程序控制的计算机中，将控制部件向执行部件发出的各种控制命令称为 微命令微命令 ，它是构成控制序列的最小单位。例如，打开或关闭某个控制门的电位信号、某个寄存器的打入脉冲等。微命令和微操作是一一对应的。微命令是微操作的控制信号，微操作是微命令的执行过程。微命令有相容性和互斥性之分。相容性微命令是指那些可以同时产生、共同完成某一些微操作的微命令;而互斥性微命令是指在机器中不允许同时出现的微命令。相容和互斥都是相对的，一个微命令可以和一些微命令相容，和另一些微命令互斥。\n\n\n\n\n\n\n\n\n\n\n注意:在组合逻辑控制器中也存在微命令与微操作这两个概念，它们并非只是微程序控制器的专有概念。\n\n微指令与微周期。微指令是若干微命令的集合。存放微指令的控制存储器的单元地址称为微地址。一条微指令通常至少包含两大部分信息:\n① 操作控制字段操作控制字段 ，又称微操作码字段，用于产生某一步操作所需的各种操作控制信号。\n② 顺序控制字段顺序控制字段 ，又称微地址码字段，用于控制产生下一条要执行的微指令地址。微周期通常指从控制存储器中读取一条微指令并执行相应的微操作所需的时间。\n\n主存储器与控制存储器。主存储器用于存放程序和数据，在 CPU 外部，用 RAM 实现;控制存储器（CM）用于存放微程序，在 CPU 内部，用 ROM 实现。\n\n程序与微程序。 程序是指令的有序集合指令的有序集合 ，用于完成特定的功能; 微程序微程序是微指令的有序集合微指令的有序集合，一条指令的功能由一段微程序来实现。\n\n\n微程序和程序是两个不同的概念。微程序是由微指令组成的，用于描述机器指令。微程序实际上是机器指令的实时解释器，是由计算机设计者事先编制好并存放在控制存储器中的，一般不提供给用户。对于程序员来说，计算机系统中微程序的结构和功能是透明的，无须知道。而程序最终由机器指令组成，是由软件设计人员事先编制好并存放在主存或辅存中的。\n读者应注意区分以下寄存器:\n①地址寄存器(MAR)。用于存放主存的读/写地址。\n②微地址寄存器(CMAR或μPC)。用于存放控制存储器的读/写微指令的地址。\n③指令寄存器（IR)。用于存放从主存中读出的指令。\n④微指令寄存器（CMDR或μIR)。用于存放从控制存储器中读出的微指令。\n微程序控制器组成和工作过程微程序控制器的基本组成图 5.11 所示为一个微程序控制器的基本结构，主要画出了微程序控制器比组合逻辑控制器多出的部件，包括:\n①控制存储器。它是微程序控制器的核心部件，用于存放各指令对应的微程序，控制存储器可用只读存储器 ROM 构成。\n②微指令寄存器。用于存放从 CM 中取出的微指令，它的位数同微指令字长相等。\n③微地址形成部件。用于产生初始微地址和后继微地址,以保证微指令的连续执行。\n④微地址寄存器。接收微地址形成部件送来的微地址，为在 CM 中读取微指令作准备。\n微程序控制器在结构上通常位于指令译码器和操作控制器之间\n\n\n\n\n\n\n\n\n\n\n图中的控制存储器就是 CM\n微程序控制器的工作过程微程序控制器的工作过程实际上就是在微程序控制器的控制下计算机执行机器指令的过程，这个过程可以描述如下:\n① 执行取微指令公共操作。具体的执行是:在机器开始运行时，自动将取指微程序的入口地址送入 CMAR，并从 CM 中读出相应的微指令送入 CMDR。取指微程序的入口地址一般为 CM 的 0 号单元，当取指微程序执行完后，从主存中取出的机器指令就已存入指令寄存器中。\n② 由机器指令的操作码字段通过微地址形成部件产生该机器指令所对应的微程序的入口地址，并送入 CMAR。\n③ 从 CM 中逐条取出对应的微指令并执行。\n④ 执行完对应于一条机器指令的一个微程序后，又回到取指微程序的入口地址，继续第 ①步，以完成取下一条机器指令的公共操作。\n以上是一条机器指令的执行过程，如此周而复始，直到整个程序执行完毕。\n微程序和机器指令 通常，一条机器指令对应一个微程序。由于任何一条机器指令的取指令操作都是相同的，因此可将取指令操作的微命令统一编成一个微程序，这个微程序只负责将指令从主存单元中取出并送至指令寄存器。\n 此外，也可编出对应间址周期的微程序和中断周期的微程序。这样，控制存储器中的微程序个数应为机器指令数再加上对应取指、间址和中断周期等共用的微程序数。\n\n\n\n\n\n\n\n\n\n注意:若指令系统中具有 n 种机器指令，则控制存储器中的微程序数至少是 n+1(1 为公共的取指微程序)。\n微指令的编码方式微指令的编码方式又称微指令的控制方式，是指如何对微指令的控制字段进行编码，以形成控制信号。编码的目标是在保证速度的情况下，尽量缩短微指令字长。\n直接编码（直接控制）方式 微指令的直接编码方式如图 5.12 所示。直接编码法无须进行译码，微指令的微命令字段中每位都代表一个微命令。设计微指令时，选用或不选用某个微命令，只要将表示该微命令的对应位设置成 1 或 0 即可。每个微命令对应并控制数据通路中的一个微操作。\n这种编码的优点是简单、直观，执行速度快，操作并行性好;缺点是微指令字长过长，n 个微命令就要求微指令的操作字段有 n 位，造成控制存储器容量极大。\n\n以下是一个具体的直接编码样例 👇：\n\n\n\n\n\n\n\n\n\n\n遵循互斥性微命令分在同一段内，相容性微命令分在不同段内。\n字段直接编码方式 将微指令的微命令字段分成若干小字段，把互斥性微命令组合在同一字段中，把相容性微命令组合在不同字段中，每个字段独立编码，每种编码代表一个微命令且各字段编码含义单独定义，与其他字段无关，这就是字段直接编码方式，如图 5.13 所示。\n这种方式可以缩短微指令字长，但因为要通过译码电路后再发出微命令，因此比直接编码方式慢。\n微命令字段分段的原则:\n① 互斥性微命令分在同一段内，相容性微命令分在不同段内。\n\n\n\n\n\n\n\n\n\n所谓相容性的微操作，是指在同时或同一个 CPU 周期内可以并行执行的 微操作。\n所谓相斥性的微操作，是指不能在同时或不能在同一个 CPU 周期内并行执行的微操作。\n② 每个小段中包含的信息位不能太多，否则将增加译码线路的复杂性和译码时间。\n③ 一般每个小段还要留出一个状态，表示本字段不发出任何微命令。因此，当某字段的长度为 3 位时，最多只能表示 7 个互斥的微命令，通常用 000 表示不操作。\n\n 图 5.21 示出了一个简单运算器模型，其中 ALU 为算术逻辑单元，R1、R2、R3 为三个寄存器。三个寄存器的内容都可以通过多路开关从 ALU 的 X 输入端或 Y 输入端送至 ALU，而 ALU 的输出可以送往任何一个寄存器 或同时送往 R1，R2，R3 三个寄存器。在 我们给定的数据通路中，多路开关的每 个控制门仅是一个常闭的开关，它的一个输入端代表来自寄存器的信息，而另一个输入端则作为操作控制端。一旦两 个输入端都有输入信号时，它才产生一个输出信号，从而在控制线能起作用的 一个时间宽度中来控制信息在部件中流 动。图中每个开关门由控制器中相应的 微命令来控制，例如，开关门 4 由控制 器中编号为 4 的微命令控制，开关门 6 由编号为 6 的微命令控制，如此等等。 三个寄存器 R1、R2、R3 的时钟输入端 1、 2、3 也需要加以控制，以便在 ALU 运算 完毕而输出公共总线上电平稳定时，将结果打入到某一寄存器。另外，我们假定 ALU 只有 +，–，M(传送)三种操作。Cy 为最高进位触发器，有进位时该触发器状态为“1”。\n ALU 的操作(加、减、传送)在同一个 CPU 周期中只能选择一种，不能并行，所以+，–， M(传送)三个微操作是相斥性的微操作。类似地，4、6、8 三个微操作是相斥性的，5、7、 9 三个微操作也是相斥性的。ALU 的 X 输入微操作 4、6、8 与 Y 输入的 5、7、9 这两组信号中，任意两个微操作也都是相容性的。\n\n\n\n\n\n\n\n\n\n\n其直接编码格式如上上上图 5.22\n字段间接编码方式 一个字段的某些微命令需由另一个字段中的某些微命令来解释，由于不是靠字段直接译码发出的微命令，因此称为字段间接编码，又称隐式编码。这种方式可进一步缩短微指令字长，但因削弱了微指令的并行控制能力，因此通常作为字段直接编码方式的一种辅助手段。\n微指令的地址形成方式后继微地址的形成主要有以下两大基本类型:\n\n直接由微指令的下地址字段指出。微指令格式中设置一个下地址字段，由微指令的下地址字段直接指出后继微指令的地址，这种方式又称==断定方式==。\n\n根据机器指令的操作码形成。机器指令取至指令寄存器后，微指令的地址由操作码经微地址形成部件形成。\n\n\n实际上，微指令序列地址的形成方式还有以下几种:\n① 增量计数器法，即(CMAR)+1→CMAR，适用于后继微指令的地址连续的情况。\n② 根据各种标志决定微指令分支转移的地址。\n③ 通过网络测试形成。\n④ 由硬件直接产生微程序入口地址。\n电源加电后，第一条微指令的地址可由专门的硬件电路产生，也可由外部直接向 CMAR 输入微指令的地址，这个地址即为取指周期微程序的入口地址。\n微指令的格式微指令格式与微指令的编码方式有关，通常分水平型微指令和垂直型微指令两种。\n水平型微指令\n 从编码方式看，直接编码、字段直接编码、字段间接编码和混合编码都属于水平型微指令。水平型微指令的基本指令格式如图 5.14 所示，指令字中的一位对应一个控制信号，有输出时为 1，否则为 0。一条水平型微指令定义并执行几种并行的基本操作。\n\n水平型微指令的优点是微程序短，执行速度快;缺点是微指令长，编写微程序较麻烦。\n垂直型微指令\n 垂直型微指令的特点是采用类似机器指令操作码的方式，在微指令中设置微操作码字段，采用微操作码编译法，由微操作码规定微指令的功能，其基本的指令格式如图 5.15 所示。一条垂直型微指令只能定义并执行一种基本操作。\n\n垂直型微指令格式的优点是微指令短、简单、规整，便于编写微程序;缺点是微程序长，执行速度慢，工作效率低。\n混合型微指令\n在垂直型的基础上增加一些不太复杂的并行操作。微指令较短，仍便于编写;微程序也不长，执行速度加快。\n水平型微指令和垂直型微指令的对比👇：\n\n\n\n\n特点\n水平型微指令\n垂直型微指令\n\n\n\n\n并行操作能力\n强\n较差\n\n\n效率\n高\n低\n\n\n灵活性\n强\n较差\n\n\n执行时间\n短\n长\n\n\n微指令字长度\n较长\n较短\n\n\n微程序长度\n短\n长\n\n\n用户掌握难度\n高\n相对容易\n\n\n\n\n微程序控制单元的设计步骤微程序控制单元设计的主要任务是编写各条机器指令所对应的微程序。具体的设计步骤如下:\n\n写出对应机器指令的微操作命令及节拍安排。无论是组合逻辑设计还是微程序设计，对应相同的 CPU 结构，两种控制单元的微操作命令和节拍安排都是极相似的。如微程序控制单元在取指阶段发出的微操作命令及节拍安排如下:\n\n\\begin{aligned}T_{0}&:\\quad \\text{PC}\\to\\text{MAR},\\ 1\\to\\text{R}\\\\T_{1}&:\\quad \\text{M(MAR)}\\to\\text{MDR},\\ (\\text{PC})+1\\to\\text{PC}\\\\T_{2}&:\\quad \\text{MDR}\\to\\text{IR},\\ \\text{OP(IR)}\\to\\text{微地址形成部件}\\end{aligned}与硬布线控制单元相比，只在 T~2~节拍内的微操作命令不同。微程序控制单元在 T~2~节拍内要将指令的操作码送至微地址形成部件，即 OP(IR)→ 微地址形成部件，以形成该条机器指令的微程序首地址。而硬布线控制单元在 T~2~,节拍内要将指令的操作码送至指令译码器，以控制 CU 发出相应的微命令，即 OP(IR)→ID。\n若把一个节拍 T 内的微操作安排在一条微指令中完成，上述微操作对应 3 条微指令。但由于微程序控制的所有控制信号都来自微指令，而微指令又存在控制存储器中，因此欲完成上述这些微操作，必须先将微指令从控制存储器中读出，即必须先给出这些微指令的地址。在取指微程序中，除第一条微指令外，其余微指令的地址均由上一条微指令的下地址字段直接给出，因此上述每条微指令都需增加一个将微指令下地址字段送至 CMAR 的微操作，记为 Ad(CMDR)→CMAR。取指微程序的最后一条微指令，其后继微指令的地址是由微地址形成部件形成的，即微地址形成部件 →CMAR。为了反映该地址与操作码有关，因此记为 OP(IR)→ 微地址形成部件 →CMAR。\n综上所述，考虑到需要形成后继微指令地址，上述分析的取指操作共需 6 条微指令完成:\n\n执行阶段的微操作命令及节拍安排，分配原则类似。与硬布线控制 单元微操作命令的节拍安排相比，多了将下一条微指令地址送至 CMAR 的微操作命令，即 Ad(CMDR)→CMAR。其余的微操作命令与硬布线控制单元相同。\n\n\n\n\n\n\n\n\n\n注意:这里为了理解，应将微指令和机器指令相联系，因为每执行完一条微指令后要得到下一条微指令的地址。\n\n确定微指令格式。微指令格式包括微指令的编码方式、后继微指令地址的形成方式和微指令字长等。\n\n根据微操作个数决定采用何种编码方式，以确定微指令的操作控制字段的位数。由微指令数确定微指令的顺序控制字段的位数。最后按操作控制字段位数和顺序控制字段位数就可确定微指令字长。\n\n编写微指令码点。根据操作控制字段每位代表的微操作命令，编写每条微指令的码点。\n\n动态微程序设计和毫微程序设计\n动态微程序设计。在一台微程序控制的计算机中，假如能根据用户的要求改变微程序，则这台机器就具有动态微程序设计功能。\n动态微程序的设计需要可写控制寄存器的支持，否则难以改变微程序的内容。实现动态微程序设计可采用可擦除可编程只读存储器（EPROM)。\n\n毫微程序设计。在普通的微程序计算机中，从主存取出的每条指令是由放在控制存储器中的微程序来解释执行的，通过控制线对硬件进行直接控制。\n若硬件不由微程序直接控制，而是通过存放在第二级控制存储器中的毫微程序来解释的，这个第二级控制存储器就称为毫微存储器，直接控制硬件的是毫微微 指令。\n\n\n硬布线控制器和微程序控制器的比较\n指令流水线 一条指令的执行过程可分解为若干阶段，每个阶段由相应的功能部件完成。如果将各阶段视为相应的流水段，则指令的执行过程就构成了一条指令流水线。采用流水线技术只需增加少量硬件就能把计算机的运算速度提高几倍，因此成为计算机中普遍使用的一种并行处理技术。\n指令流水的定义根据计算机的不同，具体的分法也不同。例如，图 5.16 把一条指令的执行过程分为如下 三个阶段（或过程)。\n\n取指 :根据 PC 内容访问主存储器，取出一条指令送到 IR 中。\n分析 :对指令操作码进行译码，按照给定的寻址方式和地址字段中的内容形成操作数的有效地址 EA，并从有效地址 EA 中取出操作数。\n执行 :根据操作码字段，完成指令规定的功能，即把运算结果写到通用寄存器或主存中。\n当多条指令在处理器中执行时,可以采用以下两种方式。\n\n顺序执行方式。前一条指令执行完后，才启动下一条指令，如图 5.17(a)所示。假设取指、分析、执行三个阶段的时间都相等，用 t 表示，顺序执行 n 条指令所用时间 T 为\n\nT = 3nt传统冯·诺依曼机采用顺序执行方式，又称串行执行方式。其优点是控制简单，硬件代价小;缺点是执行指令的速度较慢，在任何时刻，处理机中只有一条指令在执行，各功能部件的利用率很低。例如取指时内存是忙碌的，而指令执行部件是空闲的。\n\n流水线执行方式。为了提高指令的执行速度，可以把取 k ＋ 1 条指令提前到分析第 k 条指令的期间完成，而将分析第 k ＋ 1 条指令与执行第 k 条指令同时进行，如图 5.17(b)所示。采用此种方式时，执行 n 条指令所用的时间为\n\nT = (2+n)t与顺序执行方式相比，采用流水线执行方式能使指令的执行时间缩短近 2/3，各功能部件的利用率明显提高。但为此需要付出硬件上较大开销的代价，控制过程也更复杂。在理想情况下，每个时钟周期都有一条指令进入流水线，处理机中同时有 3 条指令在执行，每个时钟周期都有一条指令完成，每条指令的时钟周期数（即 CPI）都为 1。\n\n为了进一步获得更高的执行速度，还可以将流水段进一步细分。如将一条指令的执行过程分为 取指令 、 指令译码 、 执行 和 写回 四个阶段，就形成了 四级流水 ;还可进一步分为 取指令(IF) 、 指令译码(ID) 、 执行(EX) 、访存(M) 和 写回(WB) ，就形成了 五级流水。\n\n各缩写的全称\nIF：instruction fetch\nID：instruction decode\nEX：execute\nM：memory\nWB：write back\n\n流水线设计的原则是如下:指令流水段个数以最复杂指令所用的功能段个数为准;流水段的长度以最复杂的操作所花的时间为准。假设某条指令的 5 个阶段所花的时间分别如下。① 取指:200ps;译码:100ps;③ 执行: 150ps;④ 访存 200ps;⑤ 写回 100ps。不考虑数据通路中的各种延迟，该指令的总执行时间为 750ps。按照流水线设计原则，每个流水段的长度为 200ps，所以每条指令的执行时间为 1ns，反正比串行执行时增加了 250ps。假设某程序中有 N 条指令，单周期处理机所用时间为 N×750ns。而流水处理机所用时间为 750ps + (N-1)×200。因此，流水线方式并不能缩短一条指令的执行时间，但是，对于整个程序来说，可以大大增加指令执行的吞吐率。\n为了利于实现指令流水线，指令集应具有如下特征:\n\n指令长度应尽量一致，有利于简化取指令和指令译码操作。否则，取指令所花时间长短不易，使取指部件极其复杂，且也不利于指令译码。\n\n指令格式应尽量规整，尽量保证源寄存器的位置相同，有利于在指令未知时就可取寄存器操作数，否则须译码后才能确定指令中各寄存器编号的位置。\n\n采用 Load/Store 指令，其他指令（如运算指令）都不能访问存储器，这样可把 Load/Store 指令的地址计算和运算指令的执行步骤规整在同一个周期中，有利于减少操作步骤。\n\n数据和指令在存储器中“对齐”存放。这样，有利于减少访存次数，使所需数据在一个流水段内就能从存储器中得到。\n\n\n流水线的表示方法通常用时空图来直观地描述流水线的工作过程，如图 5.18 所示。\n在时空图中，横坐标表示时间，即输入流水线中的各个任务在流水线中所经过的时间。流水线中各个流水段的执行时间都相等时，横坐标就被分割成相等长度的时间段。纵坐标表示空间，即流水线的每个流水段（对应各执行部件)。\n 在图 5.18 中，第一条指令 I1 在时刻 T~0~进入流水线，在时刻 T~4~流出流水线。第二条指令 I——2 在时刻 T~1~进入流水线，在时刻 T~5~流出流水线。以此类推，每经过一个 Δt 时间，便有一条指令进入流水线，从时刻 t4 开始有一条指令流出流水线。\n 从图 5.18 中可以看出，当 t~8~ =8Δt 时，流水线上便有 5 条指令流出。若采用串行方式执行指令，当 t8 =8Δt 时，只能执行 2 条指令，可见使用流水线方式成倍地提高了计算机的速度。\n\n流水线方式的特点与传统的串行执行方式相比，采用流水线方式具有如下特点:\n\n把一个任务（一条指令或一个操作）分解为几个有联系的子任务，每个子任务由一个专门的功能部件来执行，并依靠多个功能部件并行工作来缩短程序的执行时间。\n\n流水线每个功能段部件后面都要有一个缓冲寄存器，或称锁存器，其作用是保存本流水段的执行结果，供给下一流水段使用。\n\n流水线中各功能段的时间应尽量相等，否则将引起堵塞、断流。\n\n只有连续不断地提供同一种任务时才能发挥流水线的效率，所以在流水线中处理的必须是连续任务。在采用流水线方式工作的处理机中，要在软件和硬件设计等多方面尽量为流水线提供连续的任务。\n\n流水线需要有装入时间和排空时间。装入时间是指第一个任务进入流水线到输出流水线的时间。排空时间是指最后一个任务进入流水线到输出流水线的时间。\n\n\n流水线的分类按照不同的分类标准，可以把流水线分成多种不同的种类。下面从几个不同的角度介绍流水线的基本分类方法。\n部件功能级、处理机级和处理机间级流水线根据流水线使用级别的不同，流水线可分为部件功能级流水线、处理机级流水线和处理机间流水线。\n部件功能级流水 将复杂的算术逻辑运算组成流水线工作方式。例如，可将浮点加法操作分成求阶差、对阶、尾数相加及结果规格化等 4 个子过程。\n处理机级流水 把一条指令解释过程分成多个子过程，如前面提到的取指、译码、执行、访存和写回 5 个子过程。\n处理机间流水是一种宏流水，其中每个处理机完成某一专门任务，各个处理机得到的结果需存放在与下一个处理机共享的存储器中。\n单功能流水线和多功能流水线按可以完成的功能，流水线可分为单功能流水线和多功能流水线。\n单功能流水线是指只能实现一种固定的专门功能的流水线; 多功能流水线 是指通过各段间的不同连接方式可以同时或不同时地实现多种功能的流水线。\n动态流水线和静态流水线按同一时间内各段之间的连接方式，流水线可分为静态流水线和动态流水线。\n静态流水线 指在同一时间内，流水线的各段只能按同一种功能的连接方式工作。\n动态流水线 指在同一时间内，当某些段正在实现某种运算时，另一些段却正在进行另一种运算。这样对提高流水线的效率很有好处，但会使流水线控制变得很复杂。\n线性流水线和非线性流水线按流水线的各个功能段之间是否有反馈信号，流水线可分为线性流水线与非线性流水线。\n线性流水线 中，从输入到输出，每个功能段只允许经过一次，不存在反馈回路。 非线性流水线 存在反馈回路，从输入到输出的过程中，某些功能段将数次通过流水线，这种流水线适合进行线性递归的运算。\n流水线的每个子过程由专用的功能段实现，各功能段所需的时间应尽量相等。否则，时间长的功能段将成为流水线的瓶颈。\n==影响流水线的因素==在指令流水线中，可能会遇到一些情况使得流水线无法正确执行后续指令而引起流水线阻塞或停顿，这种现象称为流水线冲突（冒险)。导致流水线冲突的原因主要有 3 种: 结构冒险(资源冲突)、 数据冒险(数据冲突)和 控制冒险(控制冲突)。\n\n\n\n\n\n\n\n\n\n以下还是使用冒险,因为描述的是两个指令之间的关系和隐藏风险，而不是事实上的发生了冲突\n资源冒险由于多条指令在同一时刻争用同一资源而形成的冲突称为资源冲突，即由硬件资源竞争造成的冲突，有以下两种解决办法:\n1）前一指令访存时，使后一条相关指令（以及其后续指令）暂停一个时钟周期。\n2）单独设置数据存储器和指令存储器，使取数和取指令操作各自在不同的存储器中进行。\n事实上，现代计算机都引入了 Cache 机制，而 L1 Cache 通常采用数据 Cache 和指令 Cache 分离的方式，因而也就避免了资源冲突的发生。\n数据冒险在一个程序中，下一条指令会用到当前指令计算出的结果，此时这两条指令即为数据冲突。当多条指令重叠处理时就会发生冲突，数据冲突可分为三类（结合综合题 3 理解):\n\n写后读(Read After Write，RAW)相关:表示当前指令将数据写入寄存器后，下一条指令才能从该寄存器读取数据。否则，先读后写，读到的就是错误（旧）数据。\n\n读后写(Write After Read，WAR）相关:表示当前指令读出数据后，下一条指令才能写该寄存器。否则，先写后读，读到的就是错误（新）数据。\n\n写后写(Write After Write，WAW)相关:表示当前指令写入寄存器后，下一条指令才能写该寄存器。否则，下一条指令在当前指令之前写，将使寄存器的值不是最新值。\n\n\n解决的办法有以下几种:\n\n把遇到数据相关的指令及其后续指令都暂停一至几个时钟周期，直到数据相关问题消失后再继续执行(流水线气泡)，可分为硬件阻塞(stall)和软件插入“NOP”指令(空指令,即不执行任何有用的操作，只是占据了一个时钟周期，以使后续指令延迟进入流水线)两种方法。\n\n设置相关专用通路，即不等前一条指令把计算结果写回寄存器组，下一条指令也不再读寄存器组，而直接把前一条指令的 ALU 的计算结果作为自己的输入数据开始计算过程，使本来需要暂停的操作变得可以继续执行，这称为数据旁路技术(流水线定向)。\n\n通过编译器对数据相关的指令编译优化的方法，调整指令顺序来解决数据相关。\n\n\n控制冲突一条指令要确定下一条指令的位置，例如在执行转移、调用或返回等指令时会改变 PC 值，而造成断流,会引起控制冒险。解决的办法有以下几种:\n\n对转移指令进行分支预测，尽早生成转移目标地址。分支预测分为简单（静态）预测和动态预测。静态预测总是预测条件不满足，即继续执行分支指令的后续指令。动态预测根据程序执行的历史情况，进行动态预测调整，有较高的预测准确率。\n\n预取转移成功和不成功两个控制流方向上的目标指令。\n\n加快和提前形成条件码。\n\n提高转移方向的猜准率。\n\n\n\n\n\n\n\n\n\n\n\n注意:Cache 缺失的处理过程也会引起流水线阻塞。在不过多增加硬件成本的情况下，如何尽可能地提高指令流水线的运行效率是选用指令流水线技术必须解决的关键问题。\n==流水线的性能指标==衡量流水线性能的主要指标有吞吐率、加速比和效率。下面以线性流水线为例分析流水线的主要性能指标，其分析方法和有关公式也适用于非线性流水线。\n吞吐率流水线的吞吐率 TP(Through Put)是指单位时间内流水线所完成的任务数量或输出结果的数量\nTP=\\frac n{T_k}\\qquad\\qquad\\text{(3.1)}其中,n 为任务数,T~k~是处理完 n 个任务所用的时间,这是计算流水线吞吐率的最基本的公式\n各段时间均相等的流水线\n 以下为个段时间均相等(都是 Δt)的线性流水的时空图。这里假设段数为 k,连续输入 n 个任务第一个任务输入后,经过 kΔt 的时间从输出端流出(完成)。此后的 n-1 个 Δt 中,每个 Δt 时间完成一个任务。在这种情况下,流水线完成 n 个连续任务所需要的总时间为\nT_k = k\\Delta t + (n-1)\\Delta t = (k+n-1)\\Delta t \\qquad\\qquad \\text{(3.2)}将式 3.2 带入式 3.1 中得流水线实际吞吐率为:\nTP = \\frac n{(k+n-1)\\Delta t}这种情况下的最大吞吐率为:\nTP_{max}=\\lim\\limits_{x \\to \\infty} \\frac n{(k+n-1)\\Delta t} = \\frac 1{\\Delta t}\n由以上式子可知流水线的实际吞吐率总是小于最大吞吐率\n各段不完全相等的流水线\n 在下图(a)所示的流水线中，各段时间不完全相等。其中 S~1~S~2~S~3~,S~5~各段的时间都是 Δt,S~4~的时间是 3Δt ,是其他各段时间的 3 倍。S~4~是该流水线的瓶颈段。除了第一个任务外,其余(n-1)个任务必须按瓶颈段的时间间隔 max(Δt~1~ ,Δt~2~,…,Δt~k~)连续流入流水线。图(b)是该流水线的时空图，图中的灰色方格表示相应流水段在这一段时间内是空闲的。\n\n实际吞吐率为:\n\\mathrm{TP}=\\frac{n}{\\sum\\limits^k\\Delta t_i+(n-1)\\max(\\Delta t_1,\\Delta t_2,\\cdot\\cdot\\cdot,\\Delta t_k)}\n\n\n\n\n\n\n\n\nmax(Δt~1~ ,Δt~2~,…,Δt~k~)为得出 Δt~1~ ,Δt~2~,…,Δt~k~之间的最大值带入计算\n其中 Δt~i~为第 i 段的时间，共有 k 个段。分母中的第一部分是流水线完成第一个任务所用的时间;第二部分是完成其余 n-1 个任务所用的时间。\n流水线最大吞吐率为:\nTP_{\\max}=\\frac1{\\max(\\Delta t_1,\\Delta t_2,\\cdotp\\cdotp\\cdotp\\Delta t_k)}对于上图的例子.最大吞吐率为:\nTP_{\\max}=\\frac1{3\\Delta t}从上式可以看出，当流水线各段的时间不完全相等时，流水线的最大吞吐率和实际吞吐率由时间最长的那个段决定,这个段就成了整条流水线的瓶颈。这时，瓶颈段一直处于忙碌状态，而其余各段则在许多时间内都是空闲的，硬件使用效率低。\n可以用下面两种方法来消除瓶颈段(将其转换为各段时间相等的流水线)。\n细分瓶颈法\n 把流水线中的瓶颈段切分为几个独立的功能段,从而使流水线各段的处理时间都相等。把瓶颈段 S~4~细分为 3 个子流水线段：S~4-1~，S~4-2~，S~4-3~。这样所产生的流水线各段时间均为 Δt,即每隔 Δt 流出一个结果\n\n重复设置瓶颈段\n 如果无法把瓶颈段再细分，就可以采用重复设置瓶颈段的方法来解决问题。重复设置的段并行工作，在时间上依次错开处理任务。这种方法的缺点是控制逻辑比较复杂，所需要的硬件也增加了。​ 下图给出了把 S~4~,重复设置后的流水线及时空图。这里，从 S~3~到并列的 S~4a~,S~4b~,S~4c~之间需要设置一个数据分配器，它把从 S~3~输出的第一个任务分配给 S~4a~,第二个任务分配给 S~4b~,第三个任务分配给 S~4c~之后按此重复。而在 S~4a~,S~4b~,S~4c~到 S~5~之间需要设置一个数据收集器、依次分时将数据收集到 S~5~中。改进后的流水线能做到每隔 Δt 流出一个结果。\n重复设置瓶颈段示意图 👇：\n\n对应的流水时空图 👇：\n\n上述两种方法都能使改进后的流水线最大吞吐率达到\nTP_{max} = \\frac 1{\\Delta t}加速比完成同样一批任务，不使用流水线所用的时间与使用流水线所用的时间之比，称为流水线的加速比。\n不使用流水线（即顺序执行）所用的时间为 T~s~，使用流水线后所用的时间为 T~k~，则该流水线的加速比为：\nS=\\frac{T_s}{T_k}若流水线各段执行的时间都相等，则一条 k 段流水线完成 n 个任务所需的时间为$T_k=(k+n-1)\\Delta t$。而不使用流水线，即顺序执行 n 个任务时，所需的时间为$T_k=kn\\Delta t$。将和值代入上式，得实际加速比为\nS=\\frac{kn\\Delta t}{(k+n-1)\\Delta t}=\\frac{kn}{(k+n-1)}当$n\\to \\infty$时，最大加速比为 S~max~ = k\n效率 流水线的设备利用率称为流水线的效率。在时空图上，流水线的效率定义为完成 n 个任务占用的时空区有效面积，与 n 个任务所用的时间及 k 个流水段所围成的时空区总面积之比。因此，流水线的效率包含了时间和空间两个因素。\n n 个任务占用的时空区有效面积就是顺序执行 n 个任务所使用的总时间 T~0~，而 n 个任务所用的时间与 k 个流水段所围成的时空区总面积为 kT~k~，其中 T~k~是流水线完成 n 个任务所使用的总时间，因此计算流水线效率（E)的一般公式为\nE=\\frac {n个任务占用的时空区有效面积}{n个任务所用时间与k个流水段所围成的时空区总面积} = \\frac {T_0}{kT_k}若流水线的各段执行时间相等，上式中的分子部分是 n 个任务实际占用的有效面积，分母部分是完成 n 个任务所用的时间与 k 个流水段所围成的总面积。因此，通过时空图来计算流水线的效率非常方便。\n流水线的各段执行时间均相等，当连续输入的任务数 n→∞ 时，最高效率为 E=1。\n==五段式指令流水线==\n\n运算类指令重点关注 运算类指令 各阶段的操作；\n\nLOAD 指令\nSTORE 指令\n条件转移指令\n无条件转移指令\n高级流水技术有两种增加指令级并行的策略：\n一种是多发射技术，它通过采用多个内部功能部件，使流水线功能段能同时处理多条指令，处理及一次可以发射多条指令进入流水线执行\n另一种是超流水线技术，它通过增加流水线级数来使更多的指令同时在流水线中重叠执行\n超标量流水线技术每个时钟周期内可并发多条独立指令，即以并行操作方式将两条或多条指令编译并执行，为此需配置多个功能部件。\n超标量计算机不能调整指令的执行顺序，因此通过编译优化技术，把可并行执行的指令搭配起来，挖掘更多的指令并行性，如图 5.20 所示。\n\n超长指令字又称静态发射技术，由编译程序挖掘出指令间潜在的并行性，将多条能并行操作的指令组合成一条具有多个操作码字段的超长指令字（可达几百位)，为此需要采用多个处理部件。\n超流水线技术 流水线功能划分得越多,时钟周期就越短，指令吞吐率也就越高,因此超流水线技术是通过提高流水线主频得方式来提升流水线的性能。但是流水线级数越多，用于流水线寄存器的开销也就越大，因而流水线级数是有限制的，并不是越多越好\n\n超流水线 CPU 在流水线充满后，每个时钟周期还是执行一条指令，CPI=1，但其主频更高\n多发射流水线 CPU 每个时钟周期可以处理多条指令，CPI&lt;1，相对而言，多发射里露水线成本更高，控制更复杂\n下列给出的处理器类型中理想情况下 CPI 为 1 的是:()\nI、单周期 CPU；II、多周期 CPU ；III、基本流水线 CPU； IV 超标量流水线 CPU\nA、I，II； B、I,III; C、II,IV; D、III,IV；\n\n解析：\n理想情况下 CPI（Cycle Per Instruction）为 1 表示每个指令在理想情况下只需要一个时钟周期来执行。根据给出的处理器类型，我们来分析每种类型的 CPU 是否满足 CPI 为 1。\n\nI. 单周期 CPU：在单周期 CPU 中，每条指令都需要相同数量的时钟周期来执行，因此 CPI 可能为 1。因此，I 是一个可能满足 CPI 为 1 的选项。\n\nII. 多周期 CPU：在多周期 CPU 中，不同类型的指令可能需要不同数量的时钟周期来执行，因此 CPI 不一定为 1。因此，II 不满足 CPI 为 1。\n\nIII. 基本流水线 CPU：在基本流水线 CPU 中，指令被划分为多个阶段，并且多个指令可以同时执行。在理想情况下，每个阶段只需要一个时钟周期，因此 CPI 可能为 1。因此，III 是一个可能满足 CPI 为 1 的选项。\n\nIV. 超标量流水线 CPU：在超标量流水线 CPU 中，多个指令可以同时执行，但每个指令可能需要多个时钟周期来执行完整的流水线流程。因此，CPI 不一定为 1。因此，IV 不满足 CPI 为 1。\n\n综上所述，满足 CPI 为 1 的选项是 B、I,III。因此，答案是 B。其中，单周期 CPU (I) 和基本流水线 CPU (III) 是理想情况下 CPI 为 1 的处理器类型。\n多处理器的基本概念SISD、SIMD、MIMD基于指令流的数量和数据流的数量，计算机体系结构的分类。\n单指令流单数据流结构(SISD)(Single Instruction Single Data,SISD)\n 传统的串行计算机结构，通常只包含一个处理器和一个存储器。有些使用流水线的方式，所以有时会设置多个功能部件，并采用多模块交叉方式组织存储器。（之前介绍的大多都是 SISD 结构）\n\n单指令流多数据流结构（SIMD）(Single Instruction Multiple Data,SIMD)\n一个指令流同时对多个数据流进行处理，一般称为数据级并行技术。通常是由一个指令控制部件、多个处理单元组成。每个处理单元虽然执行的都是同一条指令，但每个单元都有自己的地址寄存器，就有了不同的数据地址。一个顺序应用程序被编译之后，可能按照 SISD 组织并运行与串行硬件上，也可能按 SIMD 组织并运行于并行硬件上。\nfor 循环效率高，但 switch 或 case 时效率低。\n\n向量处理器也是 SIMD 的变体，是一种实现了直接操作一维数组（向量）指令集的 CPU。\n\n多指令流单数据流结构（MISD）同时执行多条指令，处理同一个数据，实际上不存在这样的计算机。\n多指令流多数据流结构（MIMD）(Multiple Instruction Multiple Data,MIMD)\n同时执行多条指令，处理多个不同的数据。分为多计算机系统和多处理器系统。多计算机系统：每个计算机节点都具有各自的私有存储器，并且具有独立的主存地址空间，不能通过存取指令来访问不同节点的私有存储器，而要通过消息传递进行数据传送，也称为消息传递 MIMD。\n\n多处理器系统：共享存储多处理器（SMP）系统的简称，它具有共享的单一地址空间，通过访存指令来访问系统中的所有存储器，也称共享存储 MIMD\n\nSIMD 和 MIMD 是两种并行计算模式，其中SIMD 是一种数据级并行模式，而MIMD 是一种并行程度更高的线程级并行或线程级以上并行计算模式。\n硬件多线程的基本概念在传统的 CPU 中，线程的切换包含了一系列开销，频繁切换回极大影响系统性能，为了减少这些开销，便诞生了硬件多线程。\n硬件多线程中必须为每个线程提供单独的通用寄存器组、单独的程序计数器等，线程的激活只需要激活选中的寄存器，从而省略了与存储器数据交换的环节，节省了开销。\n三种实现方式：\n\n细粒度多线程\n多个线程之间轮流交叉执行指令，多个线程之间的指令是互不相关的，可以乱序并行执行。该方式下，处理器能在每个时钟周期切换线程。\n\n粗粒度多线程\n仅在一个线程出现较大开销的阻塞时，才切换线程，如 Cache 缺失。当发生流水线阻塞的时候，必须清除被阻塞的流水线，新线程的指令开始执行前需要重载流水线，开销较上一种较大。\n\n同时多线程（SMT）\nSMT 是上述两种多线程技术的变体。它是实现指令级并行的同时，实现线程级的并行，即在同一时钟周期内，发射不同线程中的多条指令执行。\nIntel 处理器中的超线程即使 SMT，在一个单处理器或的那个核中设置了两套线程状态部件，共享高速缓存和功能部件。\n\n\n\n\n多核处理器的基本概念将多个处理单元集成到单个 CPU 中，每个处理单元称为一个核（core）。每个核可以有自己的 Cache，也可以共享一个 Cache。所有核一般都是对称的，并且共享主存，因此多核属于共享存储的对称多处理器。\n在多核计算机系统中，若要充分发挥硬件的性能，必须采用多线程执行，使每个核在同一时刻都有线程在执行，这是真正的并行执行。\n共享内存多处理器的基本概念具有共享的单一物理地址空间的多处理器被称为共享内存多处理器（SMP）。处理器通过存储器中的共享变量相互通信，所有处理器都能通过存取指令访存任何存储器的位置。（即使这些系统共享同一个物理地址空间，它们仍然可以在自己的虚拟地址空间中单独地运行程序）\n单一地址空间的多处理器分类：\n\n统一存储访问（UMA）多处理器：根据处理器与共享存储器之间的连接方式，分为基于总线、基于交叉开关网络和基于多级交换网络连接等几种处理器。（每个处理器对所有存储单元的访问时间都是大致相同的）\n\n非统一存储访问（NUMA）多处理器：处理器中不带高速缓存时，被称为 NC-NUMA；处理器中带有一致性高速缓存时，被称为 CC-NUMA，（某些访问请求要比其他的快）\n\n\n总线总线概述 随着计算机的发展和应用领域的不断扩大，IO 设备的种类和数量也越来越多。为了更好地解决 IO 设备和主机之间连接的灵活性问题，计算机的结构从分散连接发展为总线连接。为了进一步简化设计，又提出了各类总线标准。\n总线基本概念总线的定义总线是一组能为多个部件分时共享的公共信息传送线路。分时和共享是总线的两个特点。\n分时是指同一时刻只允许有一个部件向总线发送信息，若系统中有多个部件，则它们只能分时地向总线发送信息。\n共享是指总线上可以挂接多个部件，各个部件之间互相交换的信息都可通过这组线路分时共享。在某一时刻只允许有一个部件向总线发送信息，但多个部件可同时从总线上接收相同的信息。\n总线设备总线上所连接的设备，按其对总线有无控制功能可分为主设备和从设备两种。\n主设备 ：总线的主设备是指获得总线控制权的设备。\n从设备 ：总线的从设备是指被主设备访问的设备，它只能响应从主设备发来的各种总线命令。\n总线特性总线特性是指机械特性（尺寸、形状)、 电气特性（传输方向和有效的电平范围)、 功能特性（每根传输线的功能）和 时间特性 （信号和时序的关系)。\n==总线的猝发传输方式==在一个总线周期内传输存储地址连续的多个数据字的总线传输方式，称为猝发传送 。\n\n又称突发传输\n传送一个起始地址之后，可以连续读取连续的地址的内容\n没有突发传输的话，后面的内容每一次都要传送地址\n\n【2012统考真题】某同步总线的时钟频率为100MHz，宽度为32位，地址/数据线复用，每传输一个地址或数据占用一个时钟周期。若该总线支持突发（猝发）传输方式，则一次“主存写”总线事务传输128位数据所需要的时间至少是（）.\nA. 20ns\tB.40ns\tC.50ns\tD. 80ns\n\n解析\n3.C\n\n由于总线频率为100MHz，因此时钟周期为 10ns。总线位宽与存储字长都是32位，因此每个时钟周期可传送一个32位存储字。猝发式发送可以连续传送地址连续的数据，因此总传送时间为:传送地址10ns，传送128位数据40ns，共需50ns。\n总线的分类计算机系统中的总线，按功能划分为以下 3 类。\n片内总线片内总线是芯片内部的总线，它是 CPU 芯片内部寄存器与寄存器之间、寄存器与 ALU 之间的公共连接线。\n系统总线系统总线是计算机系统内各功能部件(CPU、主存、I/O 接口)之间相互连接的总线。按系统总线传输信息内容的不同，又可分为 3 类：数据总线、地址总线和控制总线。\n\n数据总线 用来传输各功能部件之间的数据信息，它是双向传输总线，其位数与机器字长、存储字长有关。\n\n地址总线 用来指出数据总线上的源数据或目的数据所在的 主存单元 或 I/O端口的地址 ，它是单向传输总线，地址总线的位数与主存地址空间的大小有关。\n\n控制总线 传输的是控制信息，包括 CPU 送出的控制命令和主存（或外设）返回 CPU 的反馈信号。\n\n\n\n\n\n\n\n\n\n\n\n注意区分数据通路和数据总线:各个功能部件通过数据总线连接形成的数据传输路径称为数据通路。数据通路表示的是数据流经的路径，而 数据总线是承载的媒介。\n通信总线通信总线是在计算机系统之间或计算机系统与其他系统（如远程通信设备、测试设备）之间传送信息的总线，通信总线也称外部总线。\n此外，按时序控制方式可将总线划分为 同步总线 和 异步总线 ，还可按数据传输格式将总线划分为 并行总线 和 串行总线 。\n系统总线的结构总线结构通常分为单总线结构、双总线结构和三总线结构等。\n单总线结构 单总线结构将 CPU、主存、IO 设备（通过 IO 接口）都挂在一组总线上，允许 IO 设备之间、IO 设备与主存之间直接交换信息，如图 6.1 所示。CPU 与主存、CPU 与外设之间可直接进行信息交换，而无须经过中间设备的干预。\n\n\n\n\n\n\n\n\n\n注意，单总线并不是指只有一根信号线，系统总线按传送信息的不同可细分为地址总线、数据总线和控制总线。\n优点:结构简单，成本低，易于接入新的设备;缺点:带宽低、负载重，多个部件只能争用唯一的总线，且不支持并发传送操作。\n\n双总线结构 双总线结构有两条总线:一条是 主存总线，用于在 CPU、主存和通道之间传送数据;另一条是IO总线 ，用于在多个外部设备与通道之间传送数据，如图 6.2 所示。\n优点:将低速 IO 设备从单总线上分离出来，实现了存储器总线和 IO 总线分离。缺点:需要增加通道等硬件设备。\n三总线结构 三总线结构是在计算机系统各部件之间采用 3 条各自独立的总线来构成信息通路，这 3 条总线分别为主存总线、 IO总线 和 直接内存访问(Direct Memory Access,DMA)总线，如图 6.3 所示。\n 主存总线用于在 CPU 和内存之间传送地址、数据和控制信息。IO 总线用于在 CPU 和各类外设之间通信。DMA 总线用于在内存和高速外设之间直接传送数据。\n优点:提高了 IO 设备的性能，使其更快地响应命令，提高系统吞吐量。缺点:系统工作效率较低。\n\n==总线的性能指标==\n总线的传输周期 。指一次总线操作所需的时间（包括申请阶段、寻址阶段、传输阶段和结束阶段)，简称总线周期。总线传输周期通常由若干总线时钟周期构成。\n\n总线时钟周期 。即机器的时钟周期。计算机有一个统一的时钟，以控制整个计算机的各个部件，总线也要受此时钟的控制。\n\n总线的工作频率 。总线上各种操作的频率，为总线周期的倒数。实际上指1 秒内传送几次数据。若总线周期=N 个时钟周期，则总线的工作频率=时钟频率/N。\n\n总线的时钟频率 。即机器的时钟频率，它为时钟周期的倒数。\n\n总线宽度 。又称总线位宽，它是总线上同时能够传输的数据位数，通常指数据总线的根数，如 32 根称为 32 位总线。\n\n总线带宽 。可理解为总线的 数据传输率数据传输率 ，即单位时间内总线上可传输数据的位数，通常用每秒传送信息的字节数来衡量，单位可用字节/秒（B/s）表示。总线带宽=总线工作频率 ×(总线宽度/8)。\n\n\n\n\n\n\n\n\n\n\n\n注意:总线带宽和总线宽度应加以区别。\n\n总线复用 。总线复用是指一种信号线在不同的时间传输不同的信息，因此可以使用较少的线传输更多的信息，从而节省空间和成本。\n\n信号线数 。 地址总线 、 数据总线 和 控制总线 3 种总线数的总和称为信号线数。其中，总线的最主要性能指标为总线宽度、总线（工作）频率、总线带宽，总线带宽是指总线本身所能达到的最高传输速率，它是衡量总线性能的重要指标。\n\n\n三者关系:总线带宽=总线宽度 × 总线频率。\n例如，总线工作频率为 22MHz，总线宽度为 16 位，则总线带宽=22×(16/8)=44MB/s。\n*总线仲裁为解决多个主设备同时竞争总线控制权的问题，应当采用总线仲裁部件，以某种方式选择一个主设备优先获得总线控制权。只有获得了总线控制权的设备，才能开始传送数据。\n总线仲裁方式按其仲裁控制机构的设置可分为集中仲裁方式和分布仲裁方式两种。\n集中仲裁方式总线控制逻辑基本上集中于一个设备（如 CPU)中。将所有的总线请求集中起来，利用一个特定的裁决算法进行裁决，称为集中仲裁方式。集中仲裁方式有链式查询方式、计数器定时查询方式和独立请求方式三种。\n链式查询方式链式查询方式如图 6.4 所示。总线上所有的部件共用一根总线请求线，当有部件请求使用总线时，需经此线发总线请求信号到总线控制器。由总线控制器检查总线是否忙，若总线不忙，则立即发总线响应信号，经总线响应线 BG 串行地从一个部件传送到下一个部件，依次查询。若响应信号到达的部件无总线请求，则该信号立即传送到下一个部件;若响应信号到达的部件有总线请求，则信号被截住，不再传下去。\n\n在链式查询中，部件离总线控制器越近，其优先级越高;部件离总线控制器越远，其优先级越低。\n优点:链式查询方式优先级固定。此外，只需很少几根控制线就能按一定优先次序实现总线控制，结构简单，扩充容易。\n缺点:对硬件电路的故障敏感，且优先级不能改变。当优先级高的部件频繁请求使用总线时，会使优先级较低的部件长期不能使用总线。\n计数器定时查询方式计数器定时查询方式如图 6.5 所示。它采用一个计数器控制总线使用权，相对链式查询方式多了一组设备地址线，少了一根总线响应线 BG。它仍共用一根总线请求线，当总线控制器收到总线请求信号并判断总线空闲时，计数器开始计数，计数值通过设备地址线发向各个部件。当地址线上的计数值与请求使用总线设备的地址一致时，该设备获得总线控制权，同时中止计数器的计数及查询。\n\n优点:计数可从“0”开始，此时一旦设备的优先次序被固定，设备的优先级就按 0,1,⋯,n 的顺序降序排列，而且固定不变;计数也可从上一次的终点开始，即采用一种循环方法，此时设备使用总线的优先级相等;计数器的初值还可由程序设置，因此优先次序可以改变，且这种方式对电路的故障没有链式查询方式敏感。\n缺点:增加了控制线数（若设备有 n 个，则大致需要 ⌈log~2~n⌉+2 条控制线)，控制也比相对链式查询要复杂。\n独立请求方式独立请求方式如图 6.6 所示。每个设备均有一对总线请求线 BR,和总线允许线 BG;。当总线上的部件需要使用总线时，经各自的总线请求线发送总线请求信号，在总线控制器中排队，当总线控制器按一定的优先次序决定批准某个部件的请求时，给该部件发送总线响应信号，该部件接到此信号后就获得了总线使用权，开始传送数据。\n\n优点:响应速度快，总线允许信号 BG 直接从控制器发送到有关设备，而不必在设备间传递或查询,而且对优先次序的控制相当灵活。\n缺点:控制线数量多（设备有 n 个，需要 2n+1 条控制线，其中加的那条控制线为 BS 线，基作用是让设备向总线控制部件反馈已使用完总线)，总线控制逻辑更复杂。为方便记忆，下面归纳了 3 种集中仲裁方式的区别与联系（假设设备有 n 个)，如表 6.1 所示。\n\n分布仲裁方式分布仲裁方式不需要中央仲裁器，每个潜在的主模块都有自己的仲裁号和仲裁器。当它们有总线请求时，就会把它们各自唯一的仲裁号发送到共享的仲裁总线上，每个仲裁器将从仲裁总线上得到的仲裁号与自己的仲裁号进行比较。若仲裁总线上的仲裁号优先级高，则它的总线请求不予响应，并撤销它的仲裁号。最后，获胜者的仲裁号保留在仲裁总线上。\n常见的总线标准目前，典型的总线标准有ISA、EISA、VESA、PCI、PCI-Express、AGP、RS-232C、USB等。它们的主要区别是总线宽度、带宽、时钟频率、寻址能力、是否支持突发传送等。\n\nISA。ISA (Industry Standard Architecture，工业标准体系结构）总线是最早出现的微型计算机的系统总线，应用在 IBM 的 AT 机上。\n\nEISA。EISA (Extended Industry Standard Architecture，扩展的 ISA）总线是为配合 32 位 CPU 而设计的扩展总线，EISA 对 ISA 完全兼容。\n\nVESA。VESA (Video Electronics Standards Association，视频电子标准协会）总线是一个 32 位标准的计算机局部总线，是针对多媒体 PC 要求高速传送活动图像的大量数据应运而生的。\n\nPCI。PCI (Peripheral Component Interconnect，外部设备互连）总线是高性能的 32 位或 64 位总线，是专为高度集成的外围部件、扩充插板和处理器/存储器系统设计的互连机制。目前常用的 PCI 适配器有显卡、声卡、网卡等。PCI 总线支持即插即用。PCI 总线是一个与处理器时钟频率无关的高速外围总线，属于局部总线。PCI 总线可通过桥连接实现多层 PCI 总线。\n\nPCI-Express (PCI-E)。PCI-Express 是最新的总线和接口标准，它将全面取代现行的 PCI 和 AGP，最终统一总线标准。\n\nAGP。AGP (Accelerated Graphics Port，加速图形接口）是一种视频接口标准，专用于连接主存和图形存储器，属于局部总线。AGP 技术为传输视频和三维图形数据提供了切实可行的解决方案。\n\nRS-232C。RS-232C (Recommended Standard，RS）是由美国电子工业协会（EIA）推荐的一种串行通信总线，是应用于串行二进制交换的数据终端设备（DTE）和数据通信设备(DCE）之间的标准接口。\n\nUSB。USB (Universal Serial Bus，通用串行总线）是一种连接外部设备的 IO 总线，属于设备总线。具有即插即用、热插拔等优点，有很强的连接能力。\n\nPCMCIA。PCMCIA (Personal Computer Memory Card International Association）是广泛应用于笔记本电脑的一种接口标准，是一个用于扩展功能的小型插槽。PCMCIA 具有即插即用功能。\n\nIDE。IDE (Integrated Drive Electronics，集成设备电路)，更准确地称为 ATA，是一种 IDE 接口磁盘驱动器接口类型，硬盘和光驱通过 IDE 接口与主板连接。\n\nSCSI。SCSI (Small Computer System Interface，小型计算机系统接口）是一种用于计算机和智能设备之间（硬盘、软驱、光驱、打印机等）系统级接口的独立处理器标准。SCSI 是一种智能的通用接口标准。\n\nSATA。SATA (Serial Advanced Technology Attachment，串行高级技术附件）是一种基于行业标准的串行硬件驱动器接口，是由 Intel、IBM、Dell、APT、Maxtor 和 Seagate 公司共同提出的硬盘接口规范。\n\n\n总线事务和定时总线事务 从请求总线到完成总线使用的操作序列称为总线事务,它是在一个总线周期中发生的一系列活动。典型的总线事务包括请求操作、仲裁操作、地址传输、数据传输和总线释放\n\n请求阶段。 主设备(CPU 或 DMA)发出总线传输请求,并且获得总线控制权\n仲裁阶段。 总线冲裁机构决定将下一个传输周期的总线使用权授予某个申请者\n\n寻址阶段 。取得使用权的主模块通过总线发出本次要访问的从模块（或从设备）的地址及有关命令，启动参与本次传输的从模块。\n\n传输阶段 。主模块和从模块进行数据交换，可单向或双向进行数据传送。\n\n结束阶段。主模块的有关信息均从系统总线上撤除，让出总线使用权。\n\n\n\n\n\n\n\n\n\n\n\n突发(猝发)传送方式能够进行连续成组数据的传送,其寻址阶段发送的是连续数据单元的首地址,在传输阶段传送多个连续单元的数据,每个时钟周期可以传送一个字长的信息,但是不释放总线,直到一组数据全部传送完毕后,再释放总线\n同步定时方式 所谓同步定时方式，是指系统采用一个统一的时钟信号来协调发送和接收双方的传送定时关系。时钟产生相等的时间间隔，每个间隔构成一个总线周期。在一个总线周期中，发送方和接收方可以进行一次数据传送。因为采用统一的时钟，每个部件或设备发送或接收信息都在固定的总线传送周期中，一个总线的传送周期结束，下一个总线的传送周期开始。\n 优点:传送速度快，具有较高的传输速率;总线控制逻辑简单。\n 缺点:主从设备属于强制性同步;不能及时进行数据通信的有效性检验，可靠性较差。\n 同步通信适用于总线长度较短及总线所接部件的存取时间比较接近的系统。\n异步定时方式 在异步定时方式中，没有统一的时钟，也没有固定的时间间隔，完全依靠传送双方相互制约的“握手”信号来实现定时控制。通常，把交换信息的两个部件或设备分为主设备和从设备，主设备提出交换信息的“请求”信号，经接口传送到从设备;从设备接到主设备的请求后，通过接口向主设备发出“回答”信号。\n 优点:总线周期长度可变，能保证两个工作速度相差很大的部件或设备之间可靠地进行信息交换，自动适应时间的配合。\n 缺点:比同步控制方式稍复杂一些，速度比同步定时方式慢。\n根据“请求”和“回答”信号的撤销是否互锁，异步定时方式又分为以下 3 种类型。\n\n不互锁方式 。主设备发出“请求”信号后，不必等到接到从设备的“回答”信号，而是经过一段时间便撤销“请求”信号。而从设备在接到“请求”信号后，发出“回答”信号，并经过一段时间后自动撤销“回答”信号。双方不存在互锁关系，如图 6.7(a)所示。\n\n2) 半互锁方式。主设备发出“请求”信号后，必须在接到从设备的“回答”信号后，才撤销“请求”信号，有互锁的关系。而从设备在接到“请求”信号后，发出“回答”信号，但不必等待获知主设备的“请求”信号已经撤销，而是隔一段时间后自动撤销“回答”信号，不存在互锁关系。半互锁方式如图 6.7(b)所示。\n3) 全互锁方式 。主设备发出“请求”信号后，必须在从设备“回答”后才撤销“请求”信号;从设备发出“回答”信号后，必须在获知主设备“请求”信号已撤销后，再撤销其“回答”信号。双方存在互锁关系，如图 6.7(c)所示。\n\n思考\n\n\n\n\n\n\n\n\n\n🤔引入总线结构有什么好处?\n① 简化了系统结构，便于系统设计制造。\n② 大大减少了连线数目，便于布线，减小体积，提高系统的可靠性。\n③ 便于接口设计，所有与总线连接的设备均采用类似的接口。\n④ 便于系统的扩充、更新与灵活配置，易于实现系统的模块化。\n⑤ 便于设备的软件设计，所有接口的软件对不同的接口地址进行操作。\n⑥ 便于故障诊断和维修，同时也能降低成本。\n输入输出系统*I/O 系统基本概念输入/输出系统输入/输出是以主机为中心而言的，将信息从外部设备传送到主机称为输入，反之称为输出。输入/输出系统解决的主要问题是对各种形式的信息进行输入和输出的控制。\nI/O 系统中的几个基本概念如下:\n\n外部设备 。包括输入/输出设备及通过输入/输出接口才能访问的外存储设备。\n\n接口接口。在各个外设与主机之间传输数据时进行各种协调工作的逻辑部件。协调包括传输过程中速度的匹配、电平和格式转换等。\n\n输入设备 。用于向计算机系统输入命令和文本、数据等信息的部件。键盘和鼠标是最基本的输入设备。\n\n输出设备 。用于将计算机系统中的信息输出到计算机外部进行显示、交换等的部件。显示器和打印机是最基本的输出设备。\n\n外存设备。指除计算机内存及 CPU 缓存等外的存储器。硬磁盘、光盘等是最基本的外存设备。\n\n\n一般来说，I/O 系统由 I/O 软件和 I/O 硬件两部分构成:\n\nI/O 软件 。包括驱动程序、用户程序、管理程序、升级补丁等。通常采用 I/O 指令和通道指令实现 CPU 与 I/O 设备的信息交换。\n\nI/O 硬件。包括外部设备、设备控制器和接口、I/O 总线等。通过设备控制器来控制 I/O 设备的具体动作;通过 I/O 接口与主机（总线）相连。\n\n\nI/O 控制方式在输入/输出系统中，经常需要进行大量的数据传输，而传输过程中有各种不同的 I/O 控制方式，基本的控制方式主要有以下 4 种:\n\n程序查询方式。由 CPU 通过程序不断查询 I/O 设备是否已做好准备，从而控制 I/O 设备与主机交换信息。\n\n程序中断方式 。只在 I/O 设备准备就绪并向 CPU 发出中断请求时才予以响应。\n\nDMA方式 。主存和 I/O 设备之间有一条直接数据通路，当主存和 I/O 设备交换信息时，无须调用中断服务程序。\n\n通道方式 。在系统中设有通道控制部件，每个通道都挂接若干外设，主机在执行 I/O 命令时，只需启动有关通道，通道将执行通道程序，从而完成 I/O 操作。\n\n\n其中，方式 1 和方式 2 主要用于数据传输率较低的外部设备，方式 3 和方式 4 主要用于数据传输率较高的设备。\n外部设备外部设备也称外围设备，是除主机外的能直接或间接与计算机交换信息的装置。最基本的外部设备主要有键盘、鼠标、显示器、打印机、磁盘存储器和光盘存储器等。\n输入设备键盘键盘是最常用的输入设备，通过它可发出命令或输入数据。\n键盘通常以矩阵的形式排列按键，每个键用符号标明其含义和作用。每个键相当于一个开关，按下键时，电信号连通;松开键时，弹簧弹起键，电信号断开。\n键盘输入信息可分为 3 个步骤:① 查出按下的是哪个键;② 将该键翻译成能被主机接收的编码，如 ASCII 码;③ 将编码传送给主机。\n鼠标鼠标是常用的定位输入设备，它把用户的操作与计算机屏幕上的位置信息相联系。常用的鼠标有 机械式机械式 和 光电式光电式 两种。\n工作原理:鼠标在平面上移动时，其底部传感器把运动的方向和距离检测出来，从而控制光标做相应的运动。\n输出设备显示器显示设备种类繁多，按显示设备所用的显示器件分类，有阴极射线管（CRT）显示器、液晶显示器（LCD）、发光二极管（LED）显示器等。按所显示的信息内容分类，有字符显示器、图形显示器和图像显示器 3 大类。显示器属于用点阵方式运行的设备，有以下主要参数。\n\n屏幕大小 :以对角线长度表示，常用的有 12 ～ 29 英寸等。\n\n分辨率 :所能表示的像素个数，屏幕上的每个光点就是一个像素，以宽和高的像素数的乘积表示，如 800×600、1024×768 和 1280×1024 等。\n\n灰度级 :灰度级是指黑白显示器中所显示的像素点的亮暗差别，在彩色显示器中则表现为颜色的不同，灰度级越多，图像层次越清楚、逼真，典型的有 8 位（256 级）、16 位等。\n\n刷新 :光点只能保持极短的时间便会消失，为此必须在光点消失之前再重新扫描显示一遍，这个过程称为刷新。\n\n刷新频率 :指单位时间内扫描整个屏幕内容的次数。按照人的视觉生理，刷新频率大于 30Hz 时才不会感到闪烁，通常显示器的刷新频率为 60 ～ 120Hz。\n\n显示存储器(VRAM):也称刷新存储器，为了不断提高刷新图像的信号，必须把一帧图像信息存储在刷新存储器中。其存储容量由图像分辨率和灰度级决定，分辨率越高，灰度级越多，刷新存储器容量越大。\n\n\nVRAM容量=分辨率×灰度级位数(1) 阴极射线管（CRT）显示器\nCRT 显示器主要由电子枪、偏转线圈、荫罩、高压石墨电极、荧光粉涂层和玻璃外壳 5 部分组成，具有可视角度大、无坏点、色彩还原度高、色度均匀、可调节的多分辨率模式、响应时间极短等目前 LCD 难以超过的优点。\n按显示信息内容不同，可分为字符显示器、图形显示器和图像显示器;按扫描方式不同，可分为光栅扫描和随机扫描两种显示器。下面简要介绍字符显示器和图形显示器。\n ①字符显示器。显示字符的方法以点阵为基础。点阵是指由 m×n 个点组成的阵列。点阵的多少取决于显示字符的质量和字符窗口的大小。字符窗口是指每个字符在屏幕上所占的点数，它包括字符显示点阵和字符间隔。\n将点阵存入由 ROM 构成的字符发生器中，在 CRT 进行光栅扫描的过程中，从字符发生器中依次读出某个字符的点阵，按照点阵中 О 和 1 代码的不同控制扫描电子束的开或关，从而在屏幕上显示字符。对应于每个字符窗口，所需显示字符的 ASCII 代码被存放在视频存储器 VRAM 中，以备刷新。\n ②图形显示器。将所显示图形的一组坐标点和绘图命令组成显示文件存放在缓冲存储器中，缓存中的显示文件传送给矢量（线段）产生器，产生相应的模拟电压，直接控制电子束在屏幕上的移动。为在屏幕上保留持久稳定的图像，需按一定的频率对屏幕反复刷新。这种显示器的优点是分辨率高且显示的曲线平滑。目前高质量的图形显示器采用这种随机扫描方式。缺点是当显示复杂图形时，会有闪烁感。\n(2)液晶显示器（LCD）\n原理:利用液晶的电光效应，由图像信号电压直接控制薄膜晶体管，再间接控制液晶分子的光学特性来实现图像的显示。\n特点:体积小、重量轻、省电、无辐射、绿色环保、画面柔和、不伤眼等。\n(3)LED（发光二极管）显示器\n原理:通过控制半导体发光二极管来显示文字、图形、图像等各种信息。\nLCD 与 LED 是两种不同的显示技术。LCD 是由液态晶体组成的显示屏，而 LED 则是由发光二极管组成的显示屏。与 LCD 相比，LED 显示器在亮度、功耗、可视角度和刷新速率等方面都更具优势。\n打印机打印机是计算机的输出设备之一，用于将计算机的处理结果打印在相关介质上。\n按工作原理，打印机分为击打式和非击打式两大类;按工作方式，打印机分为点阵打印机、针式打印机、喷墨式打印机、激光打印机等。\n（1）针式打印机\n原理:在联机状态下，主机发出打印命令，经接口、检测和控制电路，间歇驱动纵向送纸和打印头横向移动，同时驱动打印机间歇冲击色带，在纸上打印出所需的内容。\n特点:针式打印机擅长“多层复写打印”，实现各种票据或蜡纸等的打印。其工作原理简单，造价低廉，耗材（色带）便宜，但打印分辨率和打印速度不够高。\n（2）喷墨式打印机\n原理:带电的喷墨雾点经过电极偏转后，直接在纸上形成所需字形。彩色喷墨打印机基于三基色原理，即分别喷射 3 种颜色的墨滴，按一定的比例混合出所要求的颜色。\n特点:打印噪声小，可实现高质量彩色打印，通常打印速度比针式打印机快;但防水性差，高质量打印需要专用打印纸。\n（3）激光打印机\n原理:计算机输出的二进制信息，经过调制后的激光束扫描，在感光鼓上形成潜像，再经过显影、转印和定影，在纸上得到所需的字符或图像。\n特点:打印质量高、速度快、噪声小、处理能力强;但耗材多、价格较贵、不能复写打印多份，且对纸张的要求高。\n激光打印机是将激光技术和电子显像技术相结合的产物。感光鼓（也称硒鼓）是激光打印机的核心部件。\nI/O 接口 I/O 接口（I/O 控制器）是主机和外设之间的交接界面，通过接口可以实现主机和外设之间的信息交换。主机和外设具有各自的工作特点，它们在信息形式和工作速度上具有很大的差异，接口正是为了解决这些差异而设置的。\nI/O 接口的功能I/O 接口的主要功能如下:\n\n实现主机和外设的通信联络控制。解决主机与外设时序配合问题，协调不同工作速度的外设和主机之间交换信息，以保证整个计算机系统能统一、协调地工作。\n\n进行 地址译码和设备选择 。CPU 送来选择外设的地址码后，接口必须对地址进行译码以产生设备选择信息，使主机能和指定外设交换信息。\n\n实现数据缓冲 。CPU 与外设之间的速度往往不匹配，为消除速度差异，接口必须设置数据缓冲寄存器，用于数据的暂存，以避免因速度不一致而丢失数据。\n\n信号格式的转换 。外设与主机两者的电平、数据格式都可能存在差异，接口应提供计算机与外设的信号格式的转换功能，如电平转换、并/串或串/并转换、模/数或数/模转换等。\n\n传送控制命令和状态信息 。CPU 要启动某一外设时，通过接口中的命令寄存器向外设发出启动命令;外设准备就绪时，则将“准备好”状态信息送回接口中的状态寄存器，并反馈给 CPU。外设向 CPU 提出中断请求时，CPU 也应有相应的响应信号反馈给外设。\n\n\nI/O 接口的基本结构 如图 7.3 所示，I/O 接口在主机侧通过 I/O 总线与内存、CPU 相连。通过数据总线，在 数据缓冲寄存器与内存或 CPU 的寄存器之间进行数据传送。同时接口和设备的状态信息被记录在状态寄存器中，通过数据线将状态信息送到 CPU。CPU 对外设的控制命令也通过数据线传送，一般将其送到 I/O 接口的控制寄存器。状态寄存器和控制寄存器在传送方向上是相反的。\n\n接口中的地址线用于给出要访问的 I/O 接口中的寄存器的地址，它和读/写控制信号一起被送到 I/O 接口的控制逻辑部件，其中地址信息用以选择和主机交换信息的寄存器，通过控制线传送来的读/写信号确认是读寄存器还是写寄存器，此外控制线还会传送一些仲裁信号和握手信号。\n接口中的 I/O 控制逻辑还要能对控制寄存器中的命令字进行译码，并将译码得到的控制信号通过外设界面控制逻辑送到外设，同时将数据缓冲寄存器的数据发送到外设或从外设接收数据到数据缓冲寄存器。另外，它还要具有收集外设状态到状态寄存器的功能。\n对数据缓冲寄存器、状态/控制寄存器的访问操作是通过相应的指令来完成的，通常称这类指令为 I/O 指令，I/O 指令只能在操作系统内核的底层 I/O 软件中使用，它们是一种特权指令。\n\n\n\n\n\n\n\n\n\n注意:接口和端口是两个不同的概念。端口是指接口电路中可以进行读/写的寄存器，若干端口加上相应的控制逻辑才可以组成接口。\nI/O 接口的类型从不同的角度看，I/O 接口可以分为不同的类型。\n1）按数据传送方式可分为 并行接口（一字节或一个字的所有位同时传送）和串行接口（一位一位地传送），接口要完成数据格式的转换。\n\n\n\n\n\n\n\n\n\n注意:这里所说的数据传送方式指的是外设和接口一侧的传送方式，而在主机和接口一侧，数据总是并行传送的。\n2）按主机访问 I/O 设备的控制方式可分为 程序查询接口、 中断接口 和 DMA接口 等。\n3）按功能选择的灵活性可分为可编程接口 和 不可编程接口 。\nI/O 端口及其编址 I/O 端口是指接口电路中可被 CPU 直接访问的寄存器，主要有数据端口、 状态端口 和 控制端口 ，若干端口加上相应的控制逻辑电路组成接口。通常，CPU 能对数据端口执行读写操作，但对状态端口只能执行读操作，对控制端口只能执行写操作。\nI/O 端口要想能够被 CPU 访问，就必须要对各个端口进行编号，每个端口对应一个端口地址。而对 I/O 端口的编址方式有与存储器统一编址和独立编址两种。\n\n统一编址 ，又称存储器映射方式，是指把 I/O 端口当作存储器的单元进行地址分配，这种方式 CPU 不需要设置专门的 I/O 指令，用统一的 访存指令访存指令 就可以访问 I/O 端口。\n优点:不需要专门的输入/输出指令，可使 CPU 访问 I/O 的操作更灵活、更方便，还可使端口有较大的编址空间。\n缺点:端口占用存储器地址，使内存容量变小，而且利用存储器编址的 I/O 设备进行数据输入/输出操作，执行速度较慢。\n\n独立编址 ，又称 I/O 映射方式，I/O 端口的地址空间与主存地址空间是两个独立的地址空间，因而无法从地址码的形式上区分，需要设置专门的/O 指令来访问 I/O 端口。\n优点:输入/输出指令与存储器指令有明显区别，程序编制清晰，便于理解。\n缺点:输入/输出指令少，一般只能对端口进行传送操作，尤其需要 CPU 提供存储器读/写、I/O 设备读/写两组控制信号，增加了控制的复杂性。\n\n\nI/O 方式 输入/输出系统实现主机与 I/O 设备之间的数据传送，可以采用不同的控制方式，各种方式在代价、性能、解决问题的着重点等方面各不相同，常用的 I/O 方式有程序查询 、 程序中断、 DMA 和通道等，其中前两种方式更依赖于 CPU 中程序指令的执行。\n程序查询方式 信息交换的控制完全由主机执行程序实现，程序查询方式接口中设置一个数据缓冲寄存器（数据端口）和一个设备状态寄存器（状态端口）。主机进行 I/O 操作时，先发出询问信号，读取设备的状态并根据设备状态决定下一步操作究竟是进行数据传送还是等待。\n程序查询方式的工作流程如下（见图 7.4）\n① CPU 执行初始化程序，并预置传送参数。\n② 向 I/O 接口发出命令字，启动 I/O 设备。\n③ 从外设接口读取其状态信息。\n④ CPU 不断查询 I/O 设备状态，直到外设准备就绪。\n⑤ 传送一次数据。\n⑥ 修改地址和计数器参数。\n⑦ 判断传送是否结束，若未结束转第 ③ 步，直到计数器为 0。\n\n在这种控制方式下，CPU 一旦启动 I/O，就必须停止现行程序的运行，并在现行程序中插入一段程序。程序查询方式的主要特点是 CPU 有“踏步”等待现象，CPU 与 I/O 串行工作。这种方式的接口设计简单、设备量少，但 CPU 在信息传送过程中要花费很多时间来查询和等待，而且在一段时间内只能和一台外设交换信息，效率大大降低。\n==程序中断方式== 现代计算机系统中都配有完善的异常和中断处理系统，CPU 的数据通路中有相应的异常和中断的检测和响应逻辑，在外设接口中有相应的中断请求和控制逻辑，操作系统中有相应的中断服务程序。这些中断硬件线路和中断服务程序有机结合，共同完成异常和中断的处理过程。\n异常和中断异常 异常是指由CPU内部异常引起的意外事件，分为硬故障中断 和程序性异常。硬故障中断是由硬连线出现异常引起的，如电源掉电 、存储器线路错等。 程序性异常也称 软中断 ，是指在 CPU 内部因执行指令而引起的异常事件。如整除0、溢出、断点 、单步跟踪、非法指令 、 栈溢出 、 地址越界 、缺页 、分时系统中的 时间片中断 及用户态到核心态的切换等。按发生异常的报告方式和返回方式不同， 内部异常 可分为故障（Fault）、 自陷（Trap）和 终止 （Abort）三类。\n① 故障（Fault）\n 指在引起故障等指令启动后、执行结束前被检测到的异常事件。例如，指令译码时，出现“非法操作码”;取数据时，发生“缺段”或“缺页”;执行整数除法指令时，发现“除数为 0”等。对于“缺段”“缺页”等异常处理后，已将所需的段或页面从磁盘调入主存，可回到发生故障的指令继续执行，断点为当前发生故障的指令;对于“非法操作码”“除数为 0”等， 因为无法通过异常处理程序恢复故障 ，因此不能回到原断点执行，必须终止进程的执行。\n② 自陷（Trap）\n 自陷也称陷阱或陷入，它是预先安排的一种“异常”事件，就像预先设定的“陷阱”一样。通常的做法是:事先在程序中用一条特殊指令或通过某种方式设定特殊控制标志来人为设置一个“陷阱”，当执行到被设置了“陷阱”的指令时，CPU 在执行完自陷指令后，自动根据不同“陷阱”类型进行相应的处理，然后返回到自陷指令的下一条指令执行。注意，当自陷指令是转移指令时，并不是返回到下一条指令执行，而是返回到转移目标指令执行。\n 在 80x86 中，用于程序调试的“ 断点设置 ”功能就是通过自陷方式实现的。此外，系统调用指令、条件自陷指令（如 MIPS 中 teq、teqi、tne、tnei 等一组按条件进入陷阱的指令）等都属于陷阱指令，执行到这些指令时，无条件或有条件地自动调出操作系统内核程序进行执行。\n③ 终止（Abort）\n 如果在执行指令的过程中发生了使计算机无法继续执行的硬件故障，如电源掉电、线路故障等，那么程序将无法继续执行，只能终止，此时，调出中断服务程序来重启系统。这种异常与故障和自陷不同，不是由特定指令产生的，而是随机发生的。\n外部中断外中断是指来自 CPU 外部、与 CPU 执行指令无关的事件引起的中断，包括I/O设备发出的 I/O 中断（如键盘输入、打印机缺纸等）、外部信号中断（如用户按 Esc 键），以及各种定时器引起的时钟中断等。外中断在狭义上一般称为中断（书中若未说明，一般是指外中断）。\n外中断和内部异常在本质上是一样的，但它们之间有以下两个重要的不同点:\n\n“缺页”或“溢出”等异常事件是由特定指令在执行过程中产生的，而中断不和任何指令相关联，也不阻止任何指令的完成。\n\n异常的检测是由 CPU 自身完成的，不必通过外部的某个信号通知 CPU。对于中断，CPU 必须通过总线获取中断源的标识信息，才能获知哪个设备发生了何种中断。\n\n\n\n\n\n\n\n\n\n\n\n有些教材也将异常和中断统称为中断，将由 CPU 内部产生的异常称为内中断，将通过中断请求线 INTR 和 NMI 从 CPU 外部发出的中断请求称为外中断。\n中断的基本概念 程序中断是指在计算机执行现行程序的过程中，出现某些急需处理的异常情况或特殊请求，CPU 暂时中止现行程序，而转去对这些异常情况或特殊请求进行处理，在处理完毕后 CPU 又自动返回到现行程序的断点处，继续执行原程序。\n程序中断的作用如下:\n ① 实现 CPU 与 I/O 设备的并行工作。\n ② 处理硬件故障和软件错误。\n ③ 实现人机交互，用户干预机器需要用到中断系统。\n ④ 实现多道程序、分时操作，多道程序的切换需借助于中断系统。\n ⑤ 实时处理需要借助中断系统来实现快速响应。\n ⑥ 实现应用程序和操作系统（管态程序）的切换，称为“软中断”。\n ⑦ 多处理器系统中各处理器之间的 信息交流信息交流 和 任务切换任务切换 。\n程序中断方式的思想:CPU 在程序中安排好于某个时刻启动某台外设，然后 CPU 继续执行原来的程序，不需要像查询方式那样一直等待外设准备就绪。一旦外设完成数据传送的准备工作，就主动向 CPU 发出中断请求，请求 CPU 为自己服务。在可以响应中断的条件下，CPU 暂时中止正在执行的程序，转去执行中断服务程序为外设服务，在中断服务程序中完成一次主机与外设之间的数据传送，传送完成后，CPU 返回原来的程序，如图 7.5 所示。\n\n程序中断方式工作流程中断请求 中断源是请求 CPU 中断的设备或事件，一台计算机允许有多个中断源。每个中断源向 CPU 发出中断请求的时间是随机的。为记录中断事件并区分不同的中断源，中断系统需对每个中断源设置中断请求标记触发器 INTR，当其状态为“1”时，表示中断源有请求。这些触发器可组成中断请求标记寄存器，该寄存器可集中在 CPU 中，也可分散在各个中断源中。\n内中断皆为不可屏蔽中断 。通过 INTR 信号线发出的外中断是可屏蔽中断 ，在关中断（IF =1）的情况下不会被响应;而通过 NMI 信号发出的是不可屏蔽中断，即使在关中断（IF=0）的情况下也会被响应。不可屏蔽中断的处理优先级最高，任何时候只要发生不可屏蔽中断，都要中止现行程序的执行，转到不可屏蔽中断处理程序执行。\n中断判优 中断系统在任一瞬间只能响应一个中断源的请求。由于许多中断源提出中断请求的时间都是随机的，因此当多个中断源同时提出请求时，需通过中断判优逻辑确定响应哪个中断源的请求，例如故障中断的优先级别较高，然后是 I/O 中断。\n 中断判优既可以用硬件实现，又可用软件实现。硬件实现是通过硬件排队器实现的，它既可以设置在 CPU 中，又可以分散在各个中断源中，软件实现是通过查询程序实现的。\n 一般来说，硬件故障中断属于最高级，其次是软件中断，不可屏蔽中断优于可屏蔽中断，DMA 请求优于 I/O 设备传送的中断请求，高速设备优于低速设备，输入设备优于输出设备，实时设备优于普通设备等。\nCPU 响应中断的条件CPU 在满足一定的条件下响应中断源发出的中断请求，并经过一些特定的操作，转去执行中断服务程序。CPU 响应中断必须满足以下 3 个条件:\n ① 中断源有中断请求。\n ② CPU 允许中断及开中断。\n ③ 一条指令执行完毕，且没有更紧迫的任务。\n\n\n\n\n\n\n\n\n\n注意:I/O 设备的就绪时间是随机的，而 CPU 在统一的时刻即每条指令执行阶段结束前向接口发出中断查询信号，以获取 I/O 的中断请求，也就是说，CPU 响应中断的时间是在每条指令执行阶段的结束时刻。这里说的中断仅指外中断，内中断不属于此类情况。\n中断响应CPU 响应中断后，经过某些操作，转去执行中断服务程序。这些操作是由硬件直接实现的，我们将它称为中断隐指令 。中断隐指令并不是指令系统中的一条真正的指令，它没有操作码，所以中断隐指令是一种不允许也不可能为用户使用的特殊指令。它所完成的操作如下:\n ① 关中断 。CPU 响应中断后，首先要保护程序的断点和现场信息，在保护断点和现场的过程中，CPU 不能响应更高级中断源的中断请求。\n ② 保存断点 。为保证在中断服务程序执行完毕后能正确地返回到原来的程序，必须将原来程序的断点（指令无法直接读取的 PC 和 PSWR 等的内容）保存起来。\n ③ 引出中断服务程序 。实质是取出中断服务程序的入口地址并传送给程序计数器（PC）。\n中断向量 每个中断都有一个类型号，每个中断类型号都对应一个中断服务程序，每个中断服务程序都有一个入口地址，CPU 必须找到入口地址，即中断向量，把系统中的全部中断向量集中存放到存储器的某个区域内，这个存放中断向量的存储区就称为中断向量表。\n CPU 响应中断后，中断硬件会自动将中断向量地址传送到 CPU，由 CPU 实现程序的切换，这种方法称为中断向量法，采用中断向量法的中断称为向量中断。\n\n\n\n\n\n\n\n\n\n注意: 中断向量是中断服务程序的入口地址，中断向量地址是指 中断服务程序的入口地址的地址 。\n中断处理过程不同计算机的中断处理过程各具特色，就其多数而论，中断处理流程如图 7.6 所示。\n中断处理流程如下:\n① 关中断 。在保护断点和现场期间不能被新的中断所打断，必须关中断。否则，若断点或现场保存不完整，在中断服务程序结束后，就不能正确地恢复并继续执行现行程序。\n② 保存断点 。断点可以压入堆栈，也可以存入主存的特定单元中。\n③ 引出中断服务程序 。通常有两种方法寻址中断服务程序的入口地址: 硬件向量法 和 软件查询法 。硬件向量法通过硬件产生中断向量地址，再由中断向量地址找到中断服务程序的入口地址。软件查询法用软件编程的办法寻找入口地址。\n\n\n\n\n\n\n\n\n\n注意:硬件产生的实际上是中断类型号，而中断类型号指出了中断向量存放的地址，因此能产生中断向量地址。\n④保存现场和屏蔽字 。进入中断服务程序后首先要保存现场和中断屏蔽字，现场信息是指用户可见的工作寄存器的内容，它存放着程序执行到断点处的现行值。\n\n\n\n\n\n\n\n\n\n注意:现场和断点，这两类信息都不能被中断服务程序破坏。现场信息因为用指令可直接访问，所以通常在中断服务程序中通过指令把它们保存到栈中，即由软件实现;而断点信息由 CPU 在中断响应开始时自动保存到栈或专门的寄存器中，即由硬件实现。\n⑤ 开中断 。允许更高级中断请求得到响应，实现中断嵌套。\n⑥ 执行中断服务程序 。这是中断请求的目的。\n⑦ 关中断 。保证在恢复现场和屏蔽字时不被中断。\n⑧ 恢复现场和屏蔽字 。将现场和屏蔽字恢复到原来的状态。\n⑨ 开中断、中断返回 。中断服务程序的最后一条指令通常是一条中断返回指令，使其返回到原程序的断点处，以便继续执行原程序。\n其中，①③ 在 CPU 进入中断周期后，由中断隐指令（硬件自动）完成;④⑨ 由中断服务程序完成。\n\n\n\n\n\n\n\n\n\n注意: 恢复现场是指在中断返回之前，中断服务程序必须将寄存器的内容恢复到中断处理之前的状态。这一步骤由中断服务程序完成。而中断返回则由中断服务程序的最后一条中断返回指令来完成。\n\n多重中断和中断屏蔽技术 若 CPU 在执行中断服务程序的过程中，又出现了新的更高优先级的中断请求，而 CPU 对新的中断请求不予响应，则这种中断称为单重中断，如图 7.7（a）所示。若 CPU 暂停现行的中断服务程序，转去处理新的中断请求，则这种中断称为多重中断，又称中断嵌套，如图 7.7（b）所示。\n中断屏蔽技术主要用于多重中断。CPU 要具备多重中断的功能，必须满足下列条件:\n① 在中断服务程序中提前设置开中断指令。\n② 优先级别高的中断源有权中断优先级别低的中断源。\n每个中断源都有一个 屏蔽触发器， 1 表示屏蔽该中断源的请求， 0 表示可以正常申请，所有屏蔽触发器组合在一起便构成一个屏蔽字寄存器，屏蔽字寄存器的内容称为屏蔽字。\n关于中断屏蔽字的设置及多重中断程序执行的轨迹，下面通过实例说明。\n\n例题:\n\nDMA 方式 DMA(Direct Memory Access)方式是一种完全由硬件进行成组信息传送的控制方式，它具有程序中断方式的优点，即在数据准备阶段，CPU 与外设并行工作。DMA 方式在外设与内存之间开辟一条“直接数据通道”，信息传送不再经过 CPU，降低了 CPU 在传送数据时的开销，因此称为直接存储器存取方式。由于数据传送不经过 CPU，也就不需要保护、恢复 CPU 现场等烦琐操作。\n这种方式适用于磁盘机、磁带机等高速设备大批量数据的传送，它的硬件开销比较大。在 DMA 方式中，中断的作用仅限于故障和正常传送结束时的处理 。\nDMA 方式的特点 主存和 DMA 接口之间有一条直接数据通路。由于 DMA 方式传送数据不需要经过 CPU,因此不必中断现行程序，I/O 与主机并行工作，程序和传送并行工作。\nDMA 方式具有下列特点:\n① 它使主存与 CPU 的固定联系脱钩，主存既可被 CPU 访问，又可被外设访问。\n② 在数据块传送时，主存地址的确定、传送数据的计数等都由硬件电路直接实现。\n③ 主存中要开辟专用缓冲区，及时供给和接收外设的数据。\n④ DMA 传送速度快，CPU 和外设并行工作，提高了系统效率。\n⑤ DMA 在传送开始前要通过程序进行预处理，结束后要通过中断方式进行后处理。\nDMA 控制器的组成 在 DMA 方式中，对数据传送过程进行控制的硬件称为 DMA 控制器（DMA 接口）。当 I/O 设备需要进行数据传送时，通过 DMA 控制器向 CPU 提出 DMA 传送请求，CPU 响应之后将让出系统总线，由 DMA 控制器接管总线进行数据传送。其主要功能如下:\n\n接受外设发出的 DMA 请求，并向 CPU 发出总线请求。\n\nCPU 响应此总线请求，发出总线响应信号，接管总线控制权，进入 DMA 操作周期。\n\n确定传送数据的主存单元地址及长度，并自动修改主存地址计数和传送长度计数。\n\n规定数据在主存和外设间的传送方向，发出读写等控制信号，执行数据传送操作。\n\n向 CPU 报告 DMA 操作的结束。\n\n\n图 7.10 给出了一个简单的 DMA 控制器。\n\n\n主存地址计数器:存放要交换数据的主存地址。\n传送长度计数器:记录传送数据的长度，计数溢出时，数据即传送完毕，自动发中断请求信号。\n数据缓冲寄存器:暂存每次传送的数据。\nDMA请求触发器:每当 I/O 设备准备好数据后，给出一个控制信号，使 DMA 请求触发器置位。\n“控制/状态”逻辑:由控制和时序电路及状态标志组成，用于指定传送方向，修改传送参数，并对 DMA 请求信号和 CPU 响应信号进行协调和同步。\n中断机构:当一个数据块传送完毕后触发中断机构，向 CPU 提出中断请求。\n\n在 DMA 传送过程中，DMA 控制器将接管 CPU 的地址总线、数据总线和控制总线，CPU 的主存控制信号被禁止使用。而当 DMA 传送结束后，将恢复 CPU 的一切权利并开始执行其操作。由此可见，DMA 控制器必须具有控制系统总线的能力。\nDMA 的传送方式 主存和 I/O 设备之间交换信息时，不通过 CPU。但当 I/O 设备和 CPU 同时访问主存时，可能发生冲突，为了有效地使用主存，DMA 控制器与 CPU 通常采用以下 3 种方式使用主存:\n\n停止 CPU 访存。当 I/O 设备有 DMA 请求时，由 DMA 控制器向 CPU 发送一个停止信号，使 CPU 脱离总线，停止访问主存，直到 DMA 传送一块数据结束。数据传送结束后，DMA 控制器通知 CPU 可以使用主存，并把总线控制权交还给 CPU。\n周期挪用（或周期窃取）。当 I/O 设备有 DMA 请求时，会遇到 3 种情况:\n此时 CPU 不在访存（如 CPU 正在执行乘法指令），因此 I/O 的访存请求与 CPU 未发生冲突;\nCPU 正在访存，此时必须待存取周期结束后，CPU 再将总线占有权让出;\nI/O 和 CPU 同时请求访存，出现访存冲突，此时 CPU 要暂时放弃总线占有权。I/O 访存优先级高于 CPU 访存，因为 I/O 不立即访存就可能丢失数据，此时由 I/O 设备挪用一个或几个存取周期，传送完一个数据后立即释放总线，是一种单字传送方式。\n\n\nDMA 与 CPU 交替访存。这种方式适用于 CPU 的工作周期比主存存取周期长的情况。例如，若 CPU 的工作周期是 1.2μs，主存的存取周期小于 0.6μs，则可将一个 CPU 周期分为 C~1~和 C~2~,两个周期，其中 C~1~专供 DMA 访存，C~2~专供 CPU 访存。这种方式不需要总线使用权的申请、建立和归还过程，总线使用权是通过 C~1~和 C~2~分时控制的。\n\nDMA 的传送过程DMA 的数据传送过程分为预处理、数据传送和后处理 3 个阶段:\n\n预处理。由 CPU 完成一些必要的准备工作。首先，CPU 执行几条 I/O 指令，用以测试 I/O 设备状态，向 DMA 控制器的有关寄存器置初值、设置传送方向、启动该设备等。然后，CPU 继续执行原来的程序，直到 I/O 设备准备好发送的数据（输入情况）或接收的数据（输出情况）时，I/O 设备向 DMA 控制器发送 DMA 请求，再由 DMA 控制器向 CPU 发送总线请求（有时将这两个过程统称为 DMA 请求），用以传输数据。\n\n数据传送 。DMA 的数据传输可以以单字节（或字）为基本单位，也可以以数据块为基本单位。对于以数据块为单位的传送（如硬盘），DMA 占用总线后的数据输入和输出操作都是通过循环来实现的。需要指出的是，这一循环也是由 DMA 控制器（而非通过 CPU 执行程序）实现的，即数据传送阶段完全由 DMA（硬件）控制。\n\n后处理。DMA 控制器向 CPU 发送中断请求，CPU 执行中断服务程序做 DMA 结束处理，包括校验送入主存的数据是否正确、测试传送过程中是否出错（错误则转入诊断程序）及决定是否继续使用 DMA 传送其他数据块等。DMA 的传送流程如图 7.11 所示。\n\n\n\nDMA 方式和中断方式的区别DMA 方式和中断方式的重要区别如下:\n① 中断方式是程序的切换，需要保护和恢复现场;而 DMA 方式除了预处理和后处理，其他时候不占用 CPU 的任何资源。\n② 对中断请求的响应只能发生在每条指令执行完毕时（即指令的执行周期后）;而对 DMA 请求的响应可以发生在每个机器周期结束时（在取指周期、间址周期、执行周期后均可），只要 CPU 不占用总线就可被响应。\n③ 中断传送过程需要 CPU 的干预;而 DMA 传送过程不需要 CPU 的干预，因此数据传输率非常高，适合于高速外设的成组数据传送。\n④ DMA 请求的优先级高于中断请求。\n⑤ 中断方式具有对异常事件的处理能力，而 DMA 方式仅局限于传送数据块的 I/O 操作。\n⑥ 从数据传送来看，中断方式靠程序传送，DMA 方式靠硬件传送。\n总结CPU 响应中断应具备哪些条件?在 CPU 内部设置的中断屏蔽触发器必须是开放的。\n① 外设有中断请求时，中断请求触发器必须处于“1”状态，保持中断请求信号。\n② 外设（接口）中断允许触发器必须为“1”，这样才能把外设中断请求送至 CPU.\n③ 具备上述三个条件时，CPU 在现行指令结束的最后一个状态周期响应中断。\n中断响应优先级和中断处理优先级分别指什么?中断响应优先级是由硬件排队线路或中断查询程序的查询顺序决定的，不可动态改变;而中断处理优先级可以由中断屏蔽字来改变，反映的是正在处理的中断是否比新发生的中断的处理优先级低（屏蔽位为“0”，对新中断开放），若是，则中止正在处理的中断，转到新中断去处理，处理完后再回到刚才被中止的中断继续处理。\n","slug":"计算机组成原理基础","date":"2023-07-17T16:34:59.000Z","categories_index":"计算机基础,计算机组成原理","tags_index":"计算机组成原理","author_index":"ND_LJQ"},{"id":"39e060b2ecf9b6c38002033a50780461","title":"计算机网络基础","content":"计算机网络体系概述\n计算机网络是&quot;以能够相互共享资源的方式互联起来的自治计算机系统的集合体&quot;\n计算机网络的组成\n\n\n组成成分: 硬件、软件、协议\n\n\n工作方式: 边缘部分和核心部分\n\n\n功能组成:通信子网和资源子网\n\n\n计算机网络的功能\n数据通信(最基本最重要的功能)\n资源共享,分布式处理,提高可靠性,负载均衡\n计算机网络的分类\n按分布范围分类\n广域网(WAN)、城域网(MAN) 5-50km\n局域网(LAN)、个人区域网(PAN) 10m\n按传输技术分类\n广播式网络(局域网、广域网中的无线,卫星通信)\n点对点网络:采用存储转发和路由选择机制(广域网基本属于点对点网络)\n按拓扑结构分类\n总线型\n\n星型\n\n环形\n\n树型\n\n网状\n\n按使用者分类\n电路交换网络\n报文交换网络\n分组交换网络\n按传输介质分类\n有线网络\n\n\n双绞线网络\n\n\n同轴电缆网络\n\n\n无线网络\n\n\n蓝牙\n\n\n微波\n\n\n无线电\n\n\n计算机网络的性能指标\n带宽\n(即数字信道所能传送的&quot;最高数据率&quot;的同义词)\n单位: 在通信领域为赫兹(Hz)\n在计算机网络中是(b/s)\n时延\n发送时延:分组长度/信道宽度\n传播时延:信道长度/电磁波在信道上的传播速率\n处理时延:提取数据报首数据部分,解析首部,查找合适路由所需时间\n排队时延:分组进入路由器输入队列等待处理,然后在路由器的输入队列中等待处理\n时延带宽积\n表示当第一个发送的比特到达终点后信道的比特量\n带宽 × 传输时延\n往返时延(RRT Round Trip Time)\n发送端收到接受端的确认报文所需的时间\n吞吐量\n单位时间内通过某个网络所需的时间\n速率(传输速率、数据率、比特率)\n单位为 b/s 或 bit/s(bps bit per second)\nk=103 M=106 G=109 T=1012 P=1015 Z=1018 E=1021\n需要注意的是在计算机存储中 k=210 M=220 G=230…\n信道利用率\n某一时间段内有数据通过的时间占这一段时间的百分比\n协议、服务、接口\n协议\n\n\n语法:传输数据的格式\n\n\n语义:所需要完成的功能(发出何种控制信息,完成何种动作,已经做出何种相应)\n\n\n同步:事件实现顺序的说明\n\n\n接口\n上层通过接口来访问下层提供的服务\n服务\n下层为上层提供功能的调用,它是垂直的\n服务原语:\n\n\n请求(request):服务用户发往服务提供者,请求完成某项工作\n\n\n指示(indication):服务提供者发往服务用户,指示服务用户做某件事\n\n\n响应(response):服务用户发往服务提供者,作为对指示的响应\n\n\n证实(confirmation):由服务提供者发往服务用户作为对请求的证实\n\n\n服务的种类\n\n\n\n面向连接的服务:通信前双方必须先建立连接,分配相应的资源(如缓冲区),以确保通信的正常进行\n无连接的服务(尽最大努力交付):不需要建立连接,直接发送数据\n\n\n\n\n可靠服务:网络具有纠错、检错、应答机制,能保证数据正确可靠的到达目的地\n不可靠服务:尽量可靠、正确的传输,是一种尽力而为的服务\n\n\n\n\n有应答服务:接受方收到数据后向发送方给出相应的应答(文件传输服务)\n无应答服务:接受方收到数据后不给出相应应答,若需要应答也是由高层来实现(www 服务)\n\n\n\nOSI 与 TCP/IP 模型\n\n物理层\n传输单位:比特\n任务:透明传输比特流\n功能:在物理媒体上为数据端设备透明传输比特流\n物理层协议(物理层接口标准,物理层规程):EIA-232C、EIA/TIA RS-449、CCITT的X.21\n注意 传输信息所用的物理媒介(双绞线,光纤,无线信道)并不处于物理层协议之内而处于物理层协议之下\n数据链路层\n传输单位:帧\n任务: 将网络层传来的数据报封装成帧\n功能:封装成帧,差错控制,流量控制,传输管理\n典型协议:SDLC、HDLC、SLIP→PPP、STP\n注意实际上数据链路层分为两个子层:MAC 子层和高级数据链路控制子层\n网络层\n传输单位:数据包\n任务:把网络层的协议数据单元(分组)从源端到目的端,为分组交换网络上的不同主机提供通信服务\n功能:实现路由选择、流量控制、拥塞控制、差错控制、网际互连等功能\n典型协议:IP、ICMP、IPX、IGMP、ARP(Address Resolution Protocol) 、RARP、OSPF\n传输层\n传输单位:报文段或者用户数据报\nTCP UDP\n任务:负责不同主机中的两个进程之间的通信,提供端到端的可靠的传输服务\n功能:为端到端的服务提供流量控制、差错控制、服务质量、数据传输管理\n典型协议:TCP、UDP\n会话层\n允许不同主机上的各个进程进行会话,建立、管理以及终止进程间的会话\n校验点技术使通信会话在通信失效时从校验点继续恢复通信,实现数据同步\n表示层\n不同机器采用的编码和表示方法不同,表示层采用标准编码形式,功能为数据压缩,加密和解密\n应用层\n用户与网络的接口,最复杂的一层\n典型协议:FTP、SMTP、HTTP、DNS、RTP\nOSI 模型与 TCP/IP 模型的区别\n\n\nOSI 模型网络层支持无连接和面向连接的服务,传输层只支持面向连接的服务(TCP,SPX)\n\n\nTCP/IP 模型网络层仅支持无连接的服务(IP),传输层提供面向连接(TCP)和无连接的服务(UDP)\n\n\n物理层\n**模拟信号(数据)😗*连续变换的数据\n\n数字信号(数据):取值仅有有限的几个离散数据: 01001101001\n信源、信宿、信道\n信源:产生和发送数据的源头\n信宿:接受数据的终点\n信道:数据的传输媒介\n数字信号传输(基带传输)\n模拟信号在模拟信道中传输(宽带传输)\n通信双方的交互方式\n\n\n单向通信\n\n\n半双工通信(通信双方在同一时间)\n\n\n全双工通信\n\n\n速率、波特与带宽\n速率:数据传输速率\n- 码元传输速率(波特率) Baud →代表每秒发生的信号变化次数\n- 信息传输速率 b/s\n带宽: 指信号所具有频带的宽 HZ 同时表示单位时间内的最高数据率\n所以三者可以互相转换\n奈氏准则和香农定律\n奈氏准则\n在理想低通的信道(没有噪声,带宽有限)\n理想低通信道下的极限数据传输速率:\n\n极限码元速率:2W Baud\n香农定律\n在带宽受限且有高斯白噪音干扰的信道的极限传输速率,当用此速率进行传输时,可以做到不产生误差\n\n信噪比: S/N,10log10(S/N) (dB)\n\n\n\n\n\n\n\n\n\n🤔**信噪比为 S/N,为什么还要取对数 10log10(S/N)**❓\n\n以数字信号表示,即一般数值.如噪声功率为 1,信号功率为 100,信噪比为 100/1=100.\n以分贝形式表示,同样还是上述数字,分贝形式表示的信噪比为 10log10(100/1) = 20dB\n\n两者的区别在于,前者(数值)是没有单位的,后者必须加 dB,代表分贝.两者数值上等价\n采用分贝表示的原因是,很多时候信号要比噪声强得多,比如信号比噪声强 10 亿倍,使\n用分贝表示则不容易丢失 0\n编码与调制\n编码:将数字数据编码为数字信号\n\n调制:数字信号调制为模拟信号\n正交振幅调制(QAM)\n\n\n调频:幅移键控(FSK)\n\n\n调幅:频移键控(ASK)\n\n\n调相:相移键控(PSK)\n\n\n采用 m 个相位,每个相位 n 种振幅\n即 log2(mn)为每一波特(Baud)所携带的比特数\n模拟信号编码为数字信号\n采样、量化和编码\n采样定理:奈奎斯特定理\n模拟信号转换为数字信号时**原始信号中的最大频率为 f,那么采样频率 f采样必须大于等于最大频率的两倍,才能保证采样后的数字信号完整保留原始模拟信号的信息\n电路交换,报文交换与分组交换\n电路交换\n进行数据传输前,两结点之间必须建立一条专用的物理通信路径\n连接建立 → 数据传输 → 连接释放\n报文交换\n数据交换的单位是报文,报文携带有目标地址,源地址\n报文交换节点采用的是存储转发的传输方式\n(主要使用在早期的电报通信网中)\n分组交换\n同样采用存储转发方式,但限制了每一次传输数据块大小,把大的数据块划分成合理的小数据块,然后添加一些必要的控制信息(源地址、目的地址、编号信息),构成一个个分组(Packet)\n\n\n数据报\n\n发送分组前不需要建立连接\n最大努力交付\n\n\n\n虚电路\n\n虚电路的建立:建立一条逻辑通路\n数据传输,进行双向的数据传输\n虚电路的释放:发送释放请求,逐段断开整个连接\n\n\n\n分组交换和报文交付时间比较\n所有链路的数据传输速率为 100Mbps,分组大小为 1000B,其中分组头大小为 20B,若主机 H1 向主机 H2 发送一个大小为 980000B 的文件,在不考虑分组拆装时间和传播时延的情况下,H1 发送开始到 H2 接受为止,需要的时间是多少?\n网络拓扑图如下 👇\n\n报文交换时间\n文件从 H1 发送到 R1 所用的时间为:\nt1 = (980000×8)/(100×106)\n所以 H1 到 H2 中要经过 3 段路程\nt总 = t1 × 3\n分组交换时间\n分析:\n一个分组 1000B,分组头 20B =&gt; 一个分组中数据部分为 980B\n分组数 =&gt; 980000B / 980B = 1000 组\n分析前三个分组的传送时间\n\n可得时间示意图\n\n\n\n\n\n\n\n\n\n\n可类比计算机组成原理中的流水线\n当分组 1 到 R1 时\nt = (1000 × 8)/(100×106)\n则分组 1 到 H2 的时间为\nt~1 总~ = t × 3\n所以可得 T总为\nT总 = 分组 1 到达时间 + (1000 - 1)×t =&gt; T总 = t~1 总~ + (1000 - 1)×t\n传输介质\n双绞线、同轴电缆、光纤与无线传输介质\n双绞线\n屏蔽双绞线(STP)\nshielded twisted pair\nF/UTP(FTP,U/FTP) U 代表整条电缆不再加另外的屏蔽层\n铝箔屏蔽\n无屏蔽双绞线(UTP)\nunshielded twisted pair\n同轴电缆\n50Ω 同轴电缆(基带同轴电缆):基带数字信号传送(局域网应用广泛)\n75Ω 同轴电缆(宽带同轴电缆):宽带信号(有线电视系统)\n光纤\n可见光的频率约为 108MHZ 因此光纤通信带宽范围极大\n多模光纤:利用光的全反射,只适合近距离传输\n\n单模光纤:适合远距离传输\n\n无线传输介质\n无线电波\n有较强的穿透能力可以传输很长的距离\n应用场景:\n无线手机通信\n无线局域网(WLAN)\n微波、红外线和激光\n高带宽,地面传输距离有限\n卫星通信利用地球同步卫星作为中继器转发\n三颗同步卫星(120°)能基本实现全球通信\n(传播时延长、保密性差)\n物理接口层的特性\n\n\n机械特性:指明接口所用接线器形状、尺寸、引脚数目、排列、固定和锁定装置\n\n\n电气特性:接口电缆中各条线上的电压范围\n\n\n功能特性:某条件上出现的某一电平和电压的意义\n\n\n过程特性(规程特性):对不同功能的各种可能事件的出现顺序\n\n\n接口标准\n物理层设备\n中继器\n将信号整形后放大再转发出去\n中继器两端都是网段而不是子网\n中继器不能连接两个不同速率的局域网,且需要为同一协议\n\n\n\n\n\n\n\n\n\n如果某个网络设备具有&quot;存储转发&quot;的功能\n那么可以认为它能连接两个不同的协议\n在采用粗同轴电缆的 10BASE5 的以太网规范中\n规定:5-4-3 规则\n互相串联的中继器个数不能超过4个,而且用4个中继器串联的5段通信介质中,只有3段可以挂接计算机\n\n\n\n\n\n\n\n\n\n\n放大器与中继器功能类似\n但是放大器是放大的模拟信号,原理是将衰减的信号放大\n中继器是放大的数据信号,原理是将衰减的信号整形再生\n集线器\n实质是一个多端口的中继器\n如果两个或以上的端口同时发送数据那么其所有数据都无效\n即所有集线器的端口都属于一个冲突域\n即 1 个 10M 带宽的集线器连接 8 台计算机时每台计算机工作时的真正带宽为 10/8 = 1.25Mb/s\nQ.A\n\n\n\n\n\n\n\n\n\n传输媒介并不是物理层\n其在物理层下面\n传输媒体传输的是信号,即传输不知道所传输的信号代表什么\n但物理层规定了功能特性,所以能识别信号的意义\n\n\n\n\n\n\n\n\n\n\n什么是基带传输,频带传输和宽带传输?三者的区别是什么?\n基带传输→ 在计算机内部或在相邻设备近距离传输时可以不经过调制直接传输数字信号\n频带传输→ 用数字信号对特定频率的载波进行调制,将其变为适合传送的信号后再进行传输(远距离/无线传输)\n宽带传输→ 借助频带传输,可将链路容量分解为多个信道,每个信道可以携带不同的信号(频分复用)\n数据链路层\n数据链路层的功能\n将物理层提供的可能出错的物理连接改造为逻辑上无差错的数据链路\n使其对网络层表现为一条无差错的链路\n为网络层提供的服务\n1)无确认的无连接的服务\n适用于实时通信,误码率较低的网络(以太网)\n2)有确认无连接的服务\n适用于误码率较高的通信(无线通信)\n3)有确认的面向连接的服务\n适用于通信要求较高的场合(可靠性,实时性)\n\n\n\n\n\n\n\n\n\n有连接就一定有确认\n链路的管理\n数据链路层连接的建立、维持和释放的过程称为链路管理\n帧定界、帧同步、透明传输\n在 HDLC 协议中(高级数据链路控制协议)\n\n流量控制(OSI 体系结构)\n限制发送方的数据流量,使其发送速率不超过接收方的接受能力\n对数据链路层来说,控制的是相邻两节点之间的数据链接的流量\n差错控制\n通过 CRC(循环冗余校验)方式发现位错,通过自动重传请求(Automatic Repeat Request,aARQ)\n检错编码\n奇偶校验码\nn-1 位的信息元后+1 位的校验元\n如果是奇校验码,则代表码长为 n 种有&quot;1&quot;的个数为奇数\n偶 偶\n不足:只能校验奇/偶位数的错误\n循环冗余码(CRC)\n发送方和接受方事先商定一个多项式(多项式的最高位和最低位必须为 1)\n除数由多项式可得:例如 CRC = X3 + X2 + 1\n则除数为 1101\n被除数为待校验数后加上述多项式最大阶个 0\n余数长度为多项式最大阶的位数(Xn+…+1 即 n 位)\n除法中相减为模2运算(异或运算 → 同 0 异 1)\n最后的发送的帧或报文结构为待校验数+余数(FCS)\n接受方用收到的帧除以商定的多项式 G(x),若能整除,那么认为无差错\n\n\n\n\n\n\n\n\n\n循环冗余码(CRC)是具有纠错功能的,只是数据链路层只使用了它的检错功能\n检测到错误的帧直接丢弃,是为了方便协议的实现\n纠错编码\n海明码\n\n\n确定海明码位数\n\n\n设 n 为有效信息位数,k 为校验位的位数\n则信息位 n 和校验位 k 应满足\nn+k ≤ 2k-1\n\n\n\n\n\n\n\n\n\n因为他只能校验一位错误\n即为编码后错误的情况的个数\n为 n+k 位 每 1 个单独的位出错情况,还有一种情况为每一位均无错的情况\n所以总的出错的情况有 n+k+1 种\n校验位 k 位能表示的错误情况为 2k个\nk 位校验码表示的错误数应大于 n+k+1 的情况\n\n\n确定校验码在原码的位置\n设原信息码为 1010\n\n\n校验位在海明码的 2i-1(海明码位数为信息位数+校验位数)\n则有 4 位信息位,3 位校验位\n海明码为 H7H6H5H4H3H2H1\n校验码位置:P1 = 2 1-1→ 第 1 位 P2 = 22-1 → 第 2 位 P33-1 = 4 → 第 4 位\n\nD 为信息位\nP 为校验码所处的位置\n\n\n分组以形成校验关系\n\n\n\n按照 Pi的 i 位上的数去找信息位上相同位来进行分组,若 Pi的 i 位上的数与信息位 i 位上的数相同,则为一组\n即 GP1 = D1D2D4 GP2 = D1D3D4 GP3 = D2D3D4\n\n\n检验位取值\n\n\nPi的值为其组的信息位去异或(同 0 异 1)所得\n即:\nP1 = D1 ⊕ D2 ⊕ D4 = 0 ⊕ 1 ⊕ 1 = 0\nP2 = D1 ⊕ D3 ⊕ D4 = 0 ⊕ 0 ⊕ 1 = 1\nP1 = D2 ⊕ D3 ⊕ D4 = 1 ⊕ 0 ⊕ 1 = 1\n则最后所得的海明码为:1010010\n\n\n\n\n\n\n\n\n\n校验原理:每个校验组与该校验位进行异或操作后结果为 0,则该校验组正确\n海明码纠错 d 位需要码距 2d+1\n检错 d+1\n组帧\n把比特组合成以帧为单位进行传输,为了在出错时只重发出错的帧而不用重发全部数据,从而提高效率\n组帧主要解决三个问题\n帧定界、帧同步、透明传输\n帧定界\n字符计数法\n在帧的头部使用一个计数字段来表明帧内字符数\n字符填充法\nSOH代表一帧的开始\nEOT代表一帧的结束\n\n\n\n\n\n\n\n\n\n若帧的数据字段中包含有SOH和EOT则在其前插入ESC(转义字符),若有ESC则在ESC前插入ESC\n零比特填充法\n以01111110来标志一帧的开始或结束\n\n\n\n\n\n\n\n\n\n在信息位中 5 个连续的 1 后加一个 0 以此区分01111110\n流量控制与可靠传输机制\n停止等待流量控制\n发送方每发送一帧都要等待对方的应答信号才能发送下一帧\n接收方每接受一帧都要反馈一个应答信号接收下一帧\n滑动窗口流量控制\n发送方每收到一个确认帧,发送窗口就往后滑动一帧位置\n接受方每发送一个确认帧,接受窗口就往后滑动一帧位置\n多帧滑动窗口与后退 N 帧协议(GBN→Go-Back-N)\n当发送方发送了 N 个帧后,该 N 帧的前一个帧在计时器超时后仍未被确认\n则发送方重传该出错帧以及发送的 N 帧\n为了减少开销,GBN 规定可以在连续收到几个正确的帧后,才对最后一个数据帧发送确认信息(累积确认)\n(即表明该数据帧和此前收到的帧已均被正确无误的收到)\n\n\n\n\n\n\n\n\n\n序号：因为可靠数据传输的重传机制，所以必不可免的会产生重复帧问题，这时就需要对发送方的数据帧和接收方的确认帧标明序号。一般序号采用 n 位二进制的形式，比如 3 位二进制(000-111)可以表示序号 0-7，所以可以使用的序号空间大小为 8。如果 n 位二进制，则序号空间大小为 2n，序号最大值 MAX_SEQ 为 2n-1。\n\n🤔为什么发送窗口max ≤ 序号空间大小-1❓\n假设一种实际情况，发送方发送了 0-7 号数据帧，过了不久收到了来自接收方的 7 号确认帧，然后发送方又连续发了新的 0-7 号数据帧，然后过不久又收到了来自接收方对 7 号的确认帧,此时便出现了问题，发送方无法分辨：\n\n\n7 号确认帧是对之前的一组 0-7 号数据帧的确认，而新发送的数据全部丢失了\n\n\n7 号帧是对新发送的一组数据进行确认\n\n\n多帧滑动窗口与选择重传协议(SR→Selective Repeat)\n选择重传中，接收窗口是大于 1 的，接收方设有缓存，这也就意味着接收方可以不再是按序接收，只要接收到的数据帧在接收窗口的范围内，即可被接收，即使是乱序到达的，仍然放入缓存，等都按序到达一起提交。为了实现只重传某些数据帧，所以与回退 N 不同，选择重传的接收方对接收到的每个数据帧单独确认（收到谁确认谁），发送方只重传没有收到 ACK 的帧，并为每个帧设定一个定时器。\n\n\n\n\n\n\n\n\n\n发送窗口 + 接收窗口 &lt;= 序号空间\n发送窗口与接收窗口大小相同时，发送窗口MAX &lt;= （序号空间 / 2）\n🤔为什么❓\n假设序列号空间仍为 8(0-7)，发送窗口大小为 7，避免了回退 N 帧中的问题。接收窗口与发送窗口大小相同。假设发送方连续发送 0-6 号帧后，等待确认帧。接收方成功接收到 0-6 号帧，向前移动窗口如图，回复对接收数据的确认帧。现在假设一种极端情况 0-6 号确认帧全部丢失，发送方直到 0 号数据帧定时器超时未收到确认，重发 0 号数据帧，接收方收到 0 号数据帧恰好落在自己的接收窗口，当做新帧放入缓存，接收方此时希望接收到的最小数据帧为 7 号帧，直到接收方收到一个 7 号帧后，一起交付给网络层，但是这一批并不是正确的帧，而是包含与之前已提交的 0-6 号重复的数据，故产生了错误。在这种情况下，接收方无法分辨到来的 0 号帧是对之前帧的重传还是新帧的到来，因为接收方的新老窗口序号发生了重叠\n\n信道利用率\n有效地发送数据的时间占整个发送周期的比率\n\n\n\n\n\n\n\n\n\n发送周期:发送方从开始发送数据到收到第一个确认帧的周期\n信道吞吐率\n信道利用率 × 发送方的发送速率\n介质访问控制(MAC 子层)\n信道划介质访问控制\n信道复用技术\n频分复用(FDM)\nFrequency-division multiplexing\n系统传输效率高,由于技术较为成熟,实现也较为容易\n时分复用(TDM)\nTime-division multiplexing\n\n所以可知若线路传输速率为 800Mb/s\n则 A、B、C、D 每个用户的最高速率为 200Mb/s\n统计时分复用(STDM)\n动态分配每个用户的时间片\n则上述每个用户的最高速率为 800Mb/s\n波分多路复用(WDM)\n光的频分多路复用\n码分复用(CDM)\n例题:共有四个站点进行码分多址通信,四个站的码片分别为:\n\nA(-1,-1,-1,+1,+1,-1,+1,+1)\nB(-1,-1,+1,-1,+1,+1,+1,-1)\nC(-1,+1,-1,+1,+1,+1,-1,-1)\nD(-1,+1,-1,-1,-1,-1,+1,-1)\n\n现收到这样的码片序列(-1,+1,-3,+1,-1,+3,+1,+1)请问哪个站发送了数据,发送的是0还是1?\n\n解:\n设: K1为A站发送的数据\n\tK2为B站发送的数据\n\tK3为C站发送的数据\n\tK4为D站发送的数据\n\n即可得四元一次方程组:\n\tK1×(-1)+K2×(-1)+K3×(-1)+K4×(-1) = -1\n\tK1×(-1)+K2×(-1)+K3×1+K4×1 = 1\n\tK1×(-1)+K2×1+K3×(-1)+K4×(-1) = -3\n\tK1×1+K2×1+K3×1+K4×(-1) = 1\n\n\t可解得:K1 = 1;K2 = -1;K3 = 0;K4 = 1\n    即AD发送原码,B发送反码,C没有发送\n\n\n\n\n\n\n\n\n\n\n\n随机访问介质访问控制\n为了解决随机接入发生的碰撞,每个用户需要按照一定的规则反复重传他的帧,直到该帧无碰撞地通过\n常用的协议\nALOHA 协议\n全称:Additive Link One-Line Hawaii System\n\n\n纯 ALOHA 协议\n\n\n思想:想发就发,不监听信道,不按时间槽发送,超时/收到 NAK 否认帧后随机重发\n\n\n时隙 ALOHA 协议\n思想:把各个站点的时间同步,再划分时间片,所有用户只能在时间片的开始发送数据\n遇到冲突的情况也只能在时间片的开始发\n\n\nCSMA 协议\n载波监听多路访问协议\n\n\n1-坚持 CSMA\n\n\n侦听到信道忙,继续侦听信道,侦听到信道空闲立刻发送数据,若冲突,随机等待,再重新监听\n\n\n非坚持 CSMA(0-坚持 CSMA)\n\n\n发送数据时,首先侦听信道,如果信道空闲,立即发送,如果信道繁忙,放弃侦听,等待一个随机时间后重复\n\n\nP-坚持 CSMA\n\n\n(用于时分信道)\n持续监听信道,若信道空闲则有 P 概率发送数据,1-P 的概率推迟到下一个时隙\nCSMA/CD 协议\n基于冲突检测的载波监听多路访问技术\n802.3 中的核心，应用在 10M/100M 的半双工有线网络中(总线型局域网(以太网))\n主要思想:\n先听后发,边听边发,冲突停发,随机重发\n在冲突发生时，为了使两个站点都能及时正确接受到冲突发生的信号，要满足传输一帧的时间大于 2 倍的信道传输时延\nCSMA/CD 协议下最小帧长的计算:\n最小帧长 = [RRT](###往返时延(RRT Round Trip Time)) × 数据发送速率\n争用期为 RRT\n\n\n\n\n\n\n\n\n\n随机重发:\n二进制指数退避算法\n思想:\n1.定义参数 K(K 为重传次数) K 的取值为[重传次数,10]\n当重传次数超过 10 后,K 就一直取 10\n2.从整数集合[0,1,…,2k-1]中随机取一个数 r\n重传所退避的时间为 rRRT\n重传 16 次说明此时网络太拥挤,认为此帧无法发送,抛弃此帧\nCSMA/CA 协议\n载波监听多点接入 / 碰撞避免 协议\n应用于 802.11 无线局域网\n令牌传递协议\n用于令牌环网\n一个站点只有取得令牌(token)后才能发送数据,因此不会产生冲突\n令牌和数据传输的过程为\n\n\n网络空闲,令牌循环传递\n\n\n令牌到有数据要发送的站点,该站点修改令牌的一个标志位并在令牌中附加自己需要传输的数据帧,将令牌变为一个数据帧发送出去\n\n\n源站通过返回的帧来检验是否要重传\n\n\n无错后源站重新产生一个令牌,交出信道控制权\n\n\n局域网\n局域网的基本概念和体系结构\n局域网（Local Area Network）：简称 LAN，是指在某一区域内由多台计算机互联成的计算机组，使用广播信道。\n特点 1：覆盖的地理范围较小，只在一个相对独立的局部范围内联，如一座或集中的建筑群内。\n特点 2：使用专门铺设的传输介质（双绞线、同轴电缆）进行联网，数据传输速率高（10Mb/s~10Gb/s）。\n特点 3：通信延迟时间端，误码率低，可靠性较高。\n特定 4：各站为平等关系，共享传输信道。\n特点 5：多采用分布式控制和广播式通信，能进行广播和组播。\n决定局域网的主要要素为：网络拓扑，传输介质与介质访问控制方法。\n三种特殊局域网拓扑:\n以太网\n使用范围最广\n逻辑拓扑为总线型结构\n物理拓扑为星型或者拓展星型\n以太网采用两项措施以简化通信\n\n\n采用无连接的工作方式,不对发送的数据帧编号,也不要求接受方发送确认,即以太网尽最大努力交付数据,提供的是不可靠服务,对于差错的纠正则由高层完成\n\n\n\n\n\n\n\n\n\n\n\n🙋‍♂️ 严格来说以太网是指符合 DIX Ethernet V2 标准的以太网,但 DIX Ethernet V2 与 802.3 标准只有很小的差距\n所以将 802.3 局域网简称为以太网\n令牌环\nIEEE 802.5\n逻辑拓扑为环形结构\n物理拓扑是星型结构\nFDDI\n光纤分布数字接口\nIEEE802.8\n逻辑拓扑为环形结构\n物理拓扑为双环结构\n\n\n\n\n\n\n\n\n\n🙋‍♂️IEEE802 标准定义的局域网参考模型只对应 OSI 模型中的数据链路层和物理层\n并将数据链路层拆分为两个子层:逻辑链路控制(LLC)子层和媒体接入控制(MAC)子层\n与接入媒体有关的内容都放在 MAC 子层,它向上屏蔽对物理层访问的各种差异,提供对物理层的统一访问\n由于以太网在局域网市场取得垄断地位,几乎称为局域网代名词\n而 802 协会制定的 LLC 子层的作用已经不大,因此现在许多网卡仅装有 MAC 协议而没有 LLC 协议\n以太网\n以太网传输介质与网卡\n传输介质\n各种传输介质以及其情况:\n\n\n\n参数\n10BASE5\n10BASE2\n10BASE-T\n10BASE-FL\n\n\n\n\n传输媒体\n基带同轴电缆(粗缆)\n基带同轴电缆(细缆)\n非屏蔽双绞线\n光纤对(850nm)\n\n\n编码\n曼彻斯特编码\n曼彻斯特编码\n曼彻斯特编码\n曼彻斯特编码\n\n\n拓扑结构\n总线型\n总线型\n星型\n点对点\n\n\n最大段长\n500m\n185m\n100m\n2000m\n\n\n最多节点数\n100\n30\n2\n2\n\n\n\n10是 10Mbit/s 的传输速率 BASE表示使用基带传输 T代表双绞线 FL代表光纤\n\n\n\n\n\n\n\n\n\n🙋‍♂️10BASE-T 非屏蔽双绞线以太网拓扑结构为星型,星型网中心为集线器,但使用集线器的以太网在逻辑上仍然是一个总线型网,属于一个冲突域\n上表的内容是常识,题目中不会显示告诉你上述信息\n网卡\n计算机与外部局域网的连接是通过主板上的网络接口板[又称网络适配器(Adapter)或者网络接口卡(Network Interface Card,NIC)]来实现的\n网卡与局域网之间的通信是通过电缆或双绞线以串行的方式进行的,而网卡和计算机的通信是通过计算机主板上的 I/O 总线以并行的方式进行的,\n所以网卡的重要功能就是:进行数据的串并转换\n网卡不仅能实现与局域网传输媒介之间的物理连接和电信号匹配,还涉及到帧的发送与接收,帧的封装与拆封,介质访问控制,数据的编码与解码,及数据缓冲功能\n全世界的每块网卡出厂时都有一块唯一的代码,称为介质访问控制(MAC)地址,这个地址控制主机在网络中的数据通信\n数据链路层设备(网桥,交换机等)都使用各个网卡的 MAC 地址\n所以网卡工作在数据链路层和物理层\n以太网的 MAC 帧\nMAC 地址(物理地址)\nMAC 地址长 6 字节,一般为连字符或冒号分隔\n12 个十六进制数表示如:\n02-60-8c-e4-b1-21\n高 24 位为厂商代码\n低 24 位为厂商自行分配的网卡序列号\nDIX Ethernet V2 MAC 帧\n\n地址:通常使用 6 字节(48bit)的数据(MAC 地址)\n类型:2 字节指出出数据域中携带的数据应交给哪个协议实体处理\n数据:包含高层的协议消息,数据较小的时候进行填充\n\n\n\n\n\n\n\n\n\n由以上图可知以太网的最小帧长为 64 字节\n🤔这个数据位为什么最小为 64 字节❓\n规定 10Mbit/s 的以太网争用期为 51.2μs,然后考虑到传输过程中的干扰最小帧长为 64B,MAC 头部和尾部占用 18 字节,所以数据位最小长度为 46B,而 1500 是规定的,没有为什么\n\n\n\n\n\n\n\n\n\n循环冗余校验码需要校验包括数据部分(最后加上)\n802.3 MAC 帧\n\n802.3 帧格式与 DIX 以太帧的格式不同之处在于,使用了长度域替代了 DIX 中的类型域,指出数据域的长度\n\n\n\n\n\n\n\n\n\n但是在实践中,上述长度/类型两种机制可以并存,由于 IEEE802.3 数据段的最大字节数为 1500\n所以长度段的最大值是 1500,因此从 1501→65535 的值可用于类型段标识符\nIEEE802.11 无线局域网(wifi)\n无线局域网课分为两大类:\n有固定基础设施的无线局域网和无固定基础设施的移动自组织网络\n有固定基础设施的无线局域网\n对于固定基础设施的无线局域网,IEEE 指定了无线局域网的 802.11 系列协议标准\n包括 802.11a/b/g/n 等.使用 XIN 星型拓扑,其中心称为接入点(Access Point, AP),在 MAC 层使用 CSMA/CA 协议.使用 802.11 系列协议的局域网又称 Wi-Fi\n802.11 标准规定无线局域网最小构件是基本服务集BSS(Basic Service Set).一个基本服务集包括一个接入点和若干个移动站.各站在本 BSS 内之间通信,或与本 BSS 外部站的通信,都必须通过本 BSS 的 AP,安装 AP 时没必须为该 AP 分配一个不超过 32 字节的服务集标识符(Service Set IDentifier, SSID)和一个信道.SSID 是指使用该 AP 的无线局域网的名字,一个基本服务集覆盖的地理范围称为一个基本服务区(Basic Service Area,BSA),无线局域网的基本服务区范围直径一般不超过 100m\n一个基本服务集可以是孤立的,也可以通过 AP 连接到一个分配系统(Distribution System,DS),然后再连接到另一个基本服务集,就构成了一个拓展服务集(Extended Service Set, ESS).分配系统的作用就是使拓展服务集对上层表现的就像一个基本服务集一样,ESS 还可以通过一种称为 Portal(门户)的设备为无线用户提供到有线连接的以太网的接入,门户的作用相当于一个网桥\n\n上图中 AP1 中的移动站如需要跟 AP2 中的移动站进行通信,就必须经过 AP1 和 AP2,即 A→AP1→AP2→B.\n若移动站 A 从某个基本服务集漫游到另一个基本服务集时,仍可以和 B 进行通信,但 A 在不同服务集中使用的 AP 改变了\n无固定基础设施移动自组织网络\n又称自组网络(ad hoc network).自组网络没有上述基本服务集中的 AP,而是由一些平等状态的移动站相互通信组成的临时网络,各节点直接地位平等,中间节点都为转发节点,因此都具有路由器的功能\n802.11 MAC 帧\n\n802.11 帧最重要的是 4 个地址字段,上述地址都是 MAC 硬件地址,这里仅讨论前三个地址字段(第四个地址字段用于自组网络).这三个地址字段的内容取决于帧控制字段中的去往AP和来自AP这两个字段的数值\n地址 1 是接收地址,地址 2 是发送地址,下表给出了 802.11 帧地址字段的最常用的两种情况\n\n\n\n去往 AP\n来自 AP\n地址 1\n地址 2\n地址 3\n地址 4\n\n\n\n\n0\n1\n接收地址=目的地址\n发送地址=AP 地址\n源地址\n——\n\n\n1\n0\n接收地址=AP 地址\n发送地址=源地址\n目的地址\n——\n\n\n\n\n\n\n\n\n\n\n\n\n🙋‍♂️ 接收地址和目的地址并不等同\n发送地址和源地址并不等同\nVLAN\n通过虚拟局域网(Virtual LAN),可以把一些较大的局域网分割成一些较小的与地理位置无关的的逻辑上的 VLAN,而每个 VLAN 是一个较小的广播域\n802.ac 标准定义支持 VLAN 的以太网帧格式的拓展.它在以太网帧中插入了一个 4 字节的标识符,称为 VLAN 标签,用来指明发送该帧的计算机属于哪个虚拟局域网.\n插入 VLAN 标签的帧被称为802.1Q帧\n\nVLAN 标签的前两个字节置为 0x8100,表示这是一个 802.1Q 帧,在后两个字节中前 4 位无用,后 12 位标识了这个帧属于哪个 VLAN\n高速以太网\n速率达到或者超过 100Mb/s 的以太网被称为高速以太网\n100BASE-T 以太网\n100BASE-T以太网是在双绞线上传输 100Mb/s 基带信号的星型拓扑结构以太网,它使用CSMA/CD协议.\n这种以太网既支持全双工,又支持半双工方式,可在全双工方式下工作无冲突发生.因此,在全双工方式下不使用CSMA/CD协议\nMAC 帧格式仍然是 802.3 标准规定的.保持最短帧长不变,但将一个网段的最大线缆长度减小到 100m.\n帧的时间间隔从原来的 9.6μs 改为现在的 0.96μs.\n吉比特以太网\n又称千兆以太网,允许在 1Gb/s 的速率下使用全双工和半双工两种方式工作.使用 802.3 协议规定的帧格式\n10 吉比特以太网\n不再使用铜线而只使用光纤作为传输媒体,10 吉比特以太网只工作在全双工方式,因此没有争用问题,不适用CSMA/CD协议\n广域网\nWAN,又称外网/公网\n广域网和局域网的区别和联系如下表所示\n\n\n\n\n广域网\n局域网\n\n\n\n\n范围\n广、跨区域\n较小,在一个区域内\n\n\n连接方式\n结点之间点到点连接,一个结点与多个结点交换机相连\n多点接入\n\n\nOSI 参考模型层\n网络层,数据链路层,物理层\n数据链路层,物理层\n\n\n联系与相似点\n1.广域网和局域网都是互联网的重要构成,从互联网的角度上来看,二者平等2.连接到一个局域网或一个广域网上的主机在该网内进行通时,只需要使用其网络的物理地址\n\n\n\n着重点\n强调资源共享\n强调数据传输\n\n\n\n广域网数据链路层协议\nPPP 协议\nPPP(Point-To-Point Protocol)是使用串行线路通信的面向字节的协议,该协议应用在直接连接两个结点的链路上.设计的目的主要是用来通过拨号或者专线方式建立点对点连接发送数据\nPPP 协议有三个组成部分:\n\n\n链路控制协议(LCP)。一种拓展链路控制协议,用于建立、测试和管理数据链路\n\n\n网络控制协议(NCP)。PPP 协议允许同时采用多种网络层协议,每个不同的网络层协议要用一个相应的 NCP 来配置,为网络层协议建立和配置逻辑连接\n\n\n一个将 IP 数据报封装到串行链路的方法,IP 数据报在 PPP 帧中就是其信息部分,这个信息部分的长度受最大传送单元(MTU)的限制\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPPP 提供差错检测但不提供纠错功能,只保证无差错接收(通过硬件进行 CRC 校验)\n\n\n它仅支持点对点的链路通信,不支持多点线路\n\n\nPPP 只支持全双工链路\n\n\nPPP 的两端可以运行不用的网络层协议,但仍然可以使用同一个 PPP 进行通信\n\n\nPPP 是面向字节的,当信息字段出现和标志字段一致的比特组合时,PPP 有两种处理方法:若 PPP 用在异步线路(默认),采用字符填充法\n若 PPP 用在 SONET/SDH 等同步线路,则协议规定采用硬件来完成比特填充\n\n\n\n\n\n\n\n\n\n\n\nTCP/IP 协议族\nSLIP PPP IP ICMP ARP TCP UDP FTP DNS SMTP\n数据链路层设备\n网桥\n工作在链路层的 MAC 子层\n可以使以太网各个网段成为隔离的碰撞域(一个广播域)\n一个网段的故障不会影响另一网段的运行\n局域网交换机\n又称以太网交换机,其实质是一个多端口的网桥\n交换机的每个端口结点所占用的带宽并不会因为端口结点数目的增加而减少\n整个交换机的总带宽会随着端口结点的增加而增加\n利用交换机可以实现虚拟局域网(VLAN)\n不仅可以隔离冲突域也可以隔离广播域\n以太网交换机的特点\n✅ 以太网交换机的每个端口,都直接与单台主机相连,并且一般都工作在全双工方式\n✅ 以太网交换机能同时连接多对端口,使每对相互通信的主机都能像独占通信媒体那样无碰撞地传输数据\n✅ 以太网交换机是一种即插即用设备,其内部的帧的转发表是通过自学习算法自动建立起来的\n✅ 以太网交换机由于使用专用的交换结构芯片,交换效率较高\n✅ 以太网交换机独占传输媒体带宽\n以太网交换机的交换模式\n\n\n直通式交换机,只检查帧的目的地址,这使帧在接收后几乎能被马上转发出去.这种方式速度快,但缺乏智能性和安全性,也不支持具有不同速率的端口的交换\n\n\n存储转发式交换机,先将收到的帧缓存到高速缓冲器中,并检查数据是否正确,确认无误后通过查找转发表转换为成输出端口将该帧转发.如果帧有错,那么将其丢弃.优点是可靠性高,能支持不同速率端口间的转换,缺点是延迟较大\n\n\n交换机的自学习功能\n交换表一开始是空的\n\n具体的流程如下\nsequenceDiagram\n    participant 交换机\n    participant A\n    participant B\n\n    Note over 交换机: 初始状态：交换表为空\n\n    A->>交换机: 发送帧（源MAC地址：A，目标MAC地址：B）\n    Note over 交换机: 接收到帧\n\n    交换机->>交换机: 学习源MAC地址（MAC地址：A，接收端口：端口1）\n    交换机-->>A: 发送帧（源MAC地址：A，目标MAC地址：B）\n    Note over 交换机: 广播，因为未知目标\n\n    B->>交换机: 发送帧（源MAC地址：B，目标MAC地址：A）\n    Note over 交换机: 接收到帧\n\n    交换机->>交换机: 学习源MAC地址（MAC地址：B，接收端口：端口2）\n    交换机-->>A: 发送帧（源MAC地址：B，目标MAC地址：A）\n    Note over 交换机: 知道目标在端口1，转发到端口1\n\n交换两帧后的交换表:\n\n过滤指决定一个帧应该转发到某个接口还是应当丢弃。转发是决定一个帧应该被导向哪个接口。交换机的转发和过滤功能是借助交换机表实现的。交换机表的表项包括：一个 MAC 地址，通向该 MAC 地址的交换机接口以及表项放置在表中的时间。假设一个目的地址为 DD-DD-DD-DD-DD-DD 的帧从交换机接口 x 到达，交换机用 MAC 地址 DD-DD-DD-DD-DD-DD 索引它的表，有三种可能情况 1.表中没有 DD-DD-DD-DD-DD-DD，此时，交换机向除 x 外的所有接口广播该帧 2.表中有 DD-DD-DD-DD-DD-DD，但该表项对应的接口为 x。此时，交换机丢弃该帧 3.表中有 DD-DD-DD-DD-DD-DD，且该表项对应的接口为 y！=x。此时，交换机向接口 y 转发该帧。交换机的自学习\n交换机表初始为空。对于每个接口接收到的每个入帧，该交换机在其表中存储。如果一段时间后没有接收到以该地址为源地址的帧，则会删除该地址。\n交换机和路由器的比较\n1.交换机使用 MAC 地址转发分组，而路由器使用 IP 地址。 2.交换机即插即用，而路由器需要配置 3.交换机对于分组的转发和过滤效率更高。因为交换机只处理至协议栈的第二层，而路由器处理至第三层。 4.为了防止广播帧的循环，交换机的拓扑结构被限制为一颗生成树，而网络寻址是分层次的，且 IP 有特殊字段来限制寿命，因此路由器的拓扑结构没有限制。\nQA\n关于物理层、数据链路层、网络层设备对于隔离冲突域和广播域的总结\n\n\n\n设备名称\n能否隔离冲突域\n能否隔离广播域\n\n\n\n\n集线器\n不能\n不能\n\n\n中继器\n不能\n不能\n\n\n交换机\n能\n不能\n\n\n网桥\n能\n不能\n\n\n路由器\n能\n能\n\n\n\n网络层\n网络层的功能\n向上只提供简单灵活,无连接的,尽最大努力交付的数据报服务(还提供可靠的面向连接的虚电路服务)\n异构网络互联\n将两个以上的计算机网络通过一定的方法,用一些中间设备(又称中继系统)相互连接起来\n根据所在的层次,中继系统分为以下 4 种\n\n\n\n\n\n\n\n\n\n\n🙋‍♂️ 网络的异构性是指传输介质、数据编码、链路控制协议及不同的数据单元格式和转发机制\n路由与转发\n路由器主要完成两个功能:一个是路由选择(确定哪一条路径),二是分组转发(当一个分组到达时所采取的动作)\n路由选择\n按照复杂的分布式算法,根据从各组相邻路由器所得到的关于整个网络拓扑的变化情况,动态地改变所选择的路由\n分组转发\n指路由器根据转发表将用户的 IP 数据报从合适的端口转发出去\n路由表是根据路由选择算法得出的,而转发表是从路由表得出的.转发表结构应当使查找过程最优化,路由表则需要对网络拓扑变化的计算最优化\n讨论路由选择原理时往往不去区分转发表和路由表,而是笼统的使用路由表一词\nSDN(软件定义网络)\n在传统的互联网中,每个路由器既有转发表,又有数据选择软件\n即一个路由器又有数据层面,又有控制层面\n在 SDN 网络中\n路由器之间不再交换信息,网络层面有一个逻辑上的远程控制器\n优点:\n\n\n控制与转发功能分离\n\n\n控制层面集中化\n\n\n接口开放可编程\n\n\n拥塞控制\n判断网络是否进入拥塞控制的方法是:观察网络的吞吐量与网络负载关系\n若随着网络负载的 ↑ 吞吐量明显小于正常吞吐量\n那么可以判断网络出现了轻度拥塞\n若随着网络负载 ↑ 吞吐量 ↓ 则网络出现拥塞\n若随着网络负载 ↑ 吞吐量=0 则网络出现死锁\n路由算法\n\n\n\n\n\n\n\n\n\n路由是指分组从源到目的地时,决定端到端路径的网络范围的进程\n名词介绍:自治系统\n自治系统 AS (Autonomous System) ：\n自治系统就是几个路由器组成了一个小团体 👨‍👩‍👧‍👧，小团体内部使用专用的协议进行通信，而小团体和小团体之间也使用专用的协议进行通信。\n就像这个一样 👇\n\n\n\n\n\n\n\n\n\n\n🙋‍♂️ 值得一提的是，尽管一个 AS 内部使用了路由选择协议，但是一个 AS 对其他 AS 还是相当于两个普通的路由器在通信。\n静态路由\n非适应性路由算法\n由管理员手动配置路由信息\n适用于拓扑变化不大的小网络\n动态路由\n自适应路由算法\n距离-向量路由协议\n每个结点定期将整个路由选择表传送给与之相应的结点\n每个路由选择表包含\n\n\n每条路径的目的地(另一个结点)\n\n\n路径的代价(距离)\n\n\n\n\n\n\n\n\n\n\n\n🙋‍♂️ 这里的距离是一个抽象的概念,如路由信息协议(Routing Information Protocol, RIP)就将距离定义为&quot;跳数&quot;,跳数是指从源端口到达目的端口所经过的路由器的个数,每经过一个路由器,跳数+1\nRIP\n路由信息协议(Routing Information Protocol, RIP)是应用层协议,它使用UDP传输数据(端口 520)\n关于距离的定义：\n\n\n从一个路由器到直接连接的网络的距离定义为 1。\n\n\n从一个路由器到非直接连接的网络的距离定义为所经过的路由器数加 1。\n\n\n“距离” 也称为 “跳数”(hop count)，因为每经过一个路由器，跳数就加 1。\n\n\n这里的“距离”实际上指的是“最短距离”。\n\n\nRIP 规定:\n🔢 一条路径最多只能包含 15 个路由器。\n⏲ 默认为任意两个使用 RIP 的路由器每30s广播一次 RIP 路由更新信息,如果180s没有收到相邻路由器的更新那么将其距离设置为 16(不可达)\n⭐RIP 认为一个好的路由就是它通过的路由器的数目少，即“距离短”。但这这意味着 RIP 只会选择一个具有最少路由器的路由（即最短路由），哪怕还存在另一条高速(低时延)但路由器较多的路由。\n📢 在 RIP 中不支持子网掩码的 RIP 广播,所以 RIP 中每个网络的子网掩码必须相同,但在新的 RIP2 中,支持变长子网掩码和 CIDR\nRIP 协议的三个特点\n1️⃣ 仅和相邻路由器交换信息。\n2️⃣ 交换的信息是当前本路由器所知道的全部信息，即自己的路由表。\n3️⃣ 按固定的时间间隔交换路由信息，例如，每隔 30 秒。\nRIP 路由表更新\n假定网络中的路由器 B 的路由表有如下的项目（这三列分别表示“目的网络”、“距离”和“下一跳路由器”）：\nB 的路由表\n\n\n\n目的网络\n距离\n下一跳路由器\n\n\n\n\nN1\n7\nA\n\n\nN2\n2\nC\n\n\nN6\n8\nF\n\n\nN8\n4\nE\n\n\nN9\n4\nF\n\n\n\n现在 B 收到从 C 发来的路由信息（这两列分别表示“目的网络”“距离”）：\nB 收到 C 发来的路由信息\n\n\n\n目的网络\n距离\n\n\n\n\nN2\n4\n\n\nN3\n8\n\n\nN6\n4\n\n\nN8\n3\n\n\nN9\n5\n\n\n\nB 将收到的信息进行整理可得\n\n\n\n目的网络\n距离\n下一跳路由器\n\n\n\n\nN2\n4+1 = 5\nC\n\n\nN3\n8+1 =9\nC\n\n\nN6\n4+1 = 5\nC\n\n\nN8\n3+1 =4\nC\n\n\nN9\n5+1 =6\nC\n\n\n\n因为 B 距离 C 有一跳所以在 C 发来的路由信息中需要加一跳\nB 将整理后的路由表与原表进行对比,选出到目的网络最短的距离后,得出最终表\n\n\n\n目的网络\n距离\n下一跳路由器\n备注\n\n\n\n\nN1\n7\nA\n无新信息，不改变\n\n\nN2\n5\nC\n相同的下一跳，更新\n\n\nN3\n9\nC\n新的项目，添加进来\n\n\nN6\n5\nC\n不同的下一跳，距离更短，更新\n\n\nN8\n4\nE\n不同的下一跳，距离一样，不改变\n\n\nN9\n4\nF\n不同的下一跳，距离更大，不改变\n\n\n\n\n\n\n\n\n\n\n\n\n相同的下一跳，且更新后的距离不变,不更新\nRIP 缺点\n1️⃣ RIP 限制了网络的规模,他能使用的最大距离为 15(16 表示不可达)\n2️⃣ 路由器之间交换的是路由器中的完整路由表,因此网络规模越大,开销越大\n3️⃣ 网络出现故障时,会出现&quot;慢收敛&quot;现象\n\n\n\n\n\n\n\n\n\n🤔为什么 RIP 会出现好消息传送得快,坏消息传的慢这种现象❓\n即网络出故障的传播时间往往需要较长的时间(例如数分钟)\n当网络出现故障时，要经过较长的时间才能将此信息传送到所有的路由器，即“慢收敛”。\n“收敛”就是在自治系统中所有的结点都得到正确的路由选择信息的过程。\n&quot;慢收敛&quot;又被称为路由回路\n\n当出现坏消息时，比如网 1 出现了故障：\n\n这个时候 R1 是知道是无法到达的，则其到网 1 的距离为 16，并且为直接交付。但是 R2 在收到 R1 报文之前，即在 R2 并不知道 R1 出故障时，发送了原来的报文，1 2 R1。于是，R1 收到 R2 更新报文后，误以为可以经过 R2 到网 1，于是更新自己的路由表，1 3 R2，并且将次更新信息发送给 R2.\n然后 R2 以后又跟新自己的路由表为 1 4 R1, 30s 后，又把这个信息发送给 R1.\n……………………\n然后就这样一直循环\n一直到知道了距离等于 16 为止，R2 将网 1 标记为不可到达(即距离为 16)。\n链路状态路由协议\n一个结点检查自身所有直通链路状态,并将所得的状态信息发送给网络上所有的结点\n每当结点收到链路状态报文,结点就利用状态去更新字节的网络拓扑和状态,一但链路状态发生改变就对网络图利用Dijkstra算法重新计算\n特点:\n1️⃣ 向自治系统的所有路由器发送信息。使用的是洪泛法即路由器通过所有端口向所有相邻路由器发送信息,每个相邻路由器又将消息发送给其相邻的路由器(不包括刚发送信息的路由器)。\n2️⃣ 发送的信息是与路由器相邻的所有路由器的链路状态,但这只是路由器所知道的部分信息。所谓的&quot;链路状态&quot;,是指说明本路由与哪些路由器相邻及该链路的&quot;度量&quot;。对于OSPF算法,链路状态的&quot;度量&quot;主要用来表示费用、距离、时延、带宽\n3️⃣ 只有链路状态改变才会向所有路由器发送信息。\n典型协议:OSPF\nOSPF\n开放最短;路径优先协议(Open Shortest Path First)\nOSPF 除了具有链路状态路由算法的特点,还有以下特点:\n4️⃣OSPF 是网络层协议,他不使用 UDP 或者 TCP 而直接用 IP 数据报传送(IP 数据报首部的协议字段为 89)\n5️⃣OSPF 对不同的链路可根据 IP 分组的不同服务类型(TOS)而设置成不同的代价。因此,OSPF 对不同类型的业务可计算不同的路由,十分灵活\n6️⃣ 如果在同一个目的网络有多条代价相同的路径,那么可以将通信量分配给这几条路径。这称为多路径间的负载均衡\n7️⃣ 所有在 OSPF 路由器之间交换的分组都有鉴别功能,因而保证了仅在可信赖的路由之间交换链路状态信息\n8️⃣ 支持可变长度的子网划分和无分类编制 CIDR\n9️⃣ 每个链路状态都带上一个 32 位的序号,序号越大,状态越新\n路径向量路由协议\nBGP\n边界网关协议(Border Gateway Protocol, BGP) 是不同自治系统的路由器之间交换路由信息的协议。BGP 是应用层协议,它是基于 TCP 的。 默认为当前较新的版本 BGP-4。\nBGP 发言人 :\n每个 自治系统 ( Autonomous System ) 都要 选择一个路由器 , 当做本 自治系统 的发言人 , 该路由器 称为 “BGP 发言人” ; 该 BGP 发言人 路由器大多数情况 是之前说的 OSPF 协议 主干区域的自治系统边界路由器 ; ( 也有例外 )\nBGP 协议 简介 :\n① 交换对象 : 与 其它 自治系统 的 BGP 发言人 交换信息 ;\n② 交换信息 : 交换 网络可达性 信息 , 到达某个网络 , 所要经过的 自治系统 ;\n③ 交换周期 : 发生变化时 才更新 , 并且只 更新有变化的部分 ;\nBGP 协议信息交换过程\nBGP 交换的 网络可达性信息 , 就是到达某个网络 , 所要经过的 一系列的自治系统 ( Autonomous System ) ;\n当 BGP 发言人交换了网络可达性信息后 , 各个 BGP 发言人就可以根据采用的策略 , 从收到的路由信息中 , 找到到达指定 自治系统 ( Autonomous System ) 的 较好的路由 ; ( 注意不是最佳路由 )\n交换的信息 本质是一组完整的路径 ;\nBGP 协议的特点 :\n① 路由表内容 : BGP 协议支持 CIDR 无分类编址 , BGP 路由表项目内容是 : 网络前缀 , 下一跳路由 , 到达目的网络所要经过的自治系统序列 ;\n② 更新数据时机 : 在 BGP 刚启动时 , BGP 与 相邻 BGP 发言人 交换整个 BGP 路由表 , 之后只需要在发生变化时, 更新有变化的部分 ; 这样能节省资源开销 ;\n层次路由\n当网络规模扩大时,路由器的路由表成比例的增大,这不仅会消耗越来越多的路由器缓冲区空间,而且需要用更多的 CPU 时间来扫描路由表,用更多的带宽来交换路由状态信息.因此路由选择必须按照层次的方式进行\n因特网将整个互联网划分为许多较小的自治系统(注意一个自治系统包含很多个局域网),每个自治系统有权自主的决定本系统内应采用何种路由选择协议,如果两个自治系统之间需要通信,那么就需要一种在两个自治系统之间的协议来屏蔽这些差异,因此因特网把路由选择协议分为两大类:内部网关协议和外部网关协议\n具体示意图如下 👇\n\n✅内部网关协议(Interior Gateway Protocol, IGP)\n自治系统内部使用的路由选择协议(域内路由选择)\n典型协议:RIP、OSPF\nOSPF将一个自治系统(AS)再划分为若干区域(Area),每个路由器只知道如何将分组路由到自己所在区域的目标地址,对其他区域内的结构毫不知情\n\n✅外部网关协议(Exterior Gateway Protocol, EGP)\n自治系统间使用的路由选择协议(域间路由选择)\n典型协议:BGP\n具体示意图如下 👇\n\n\n\n\n\n\n\n\n\n\n分组的直接交付和间接交付\n✅直接交付:接收端的 IP 地址与发送方的 IP 地址同属一个子网\n✅间接交付:接收端的 IP 地址与发送方的 IP 地址不同属一个子网\nIPv4\nIPv4 即现在普遍使用的 IP 协议(版本 4).IP 协议定义数据传送的基本单元——IP 分组及其确切的数据结构\nIPv4 分组\n一个 IP 分组由首部和数据部分组成,首部前一部分的长度固定,共 20B,是所有 IP 分组所必有的,在首部固定部分的后面是一些可选字段,其长度可变\nIP 分组格式如下 👇\n\n\n\n\n\n\n\n\n\n\n🤔报文，数据报，分片，分组，帧的区别❓\n报文（message）：传输协议交给 ip 的数据称为报文；典型的报文包含一个传输层首部和应用程序数据；\n数据报（datagram）：在报文首部加上 ip 首部形成一个数据报；\n分片（fragment）：如果在选定网络中，数据报的长度太大，ip 就会把数据报分裂成几个分片，每个分片含有它自己的 ip 首部和一段原来数据报的数据；\n分组（packet）:提交给数据链路层进行传送时，一个 ip 分片或者一个很小的无需分片的 ip 数据报成为分组；\n帧（frame）:数据链路层在分组前面加上它自己的首部形成帧，并发送该帧；\nIP 首部的重要字段含义如下:\n\n\n✅ 版本。指 IP 协议的版本,目前广泛使用的版本为 4\n\n\n✅首部长度。占 4 位,可以表示的最大十进制数 15。以 32 位(4B)为单位,最大值为 60B(15×4B)\n\n\n✅总长度。占 16 位。指首部和数据之和的长度,单位为字节,因此数据报的最大长度为 216-1 = 65535B。以太网帧的最大传送单元(MTU)为 1500B,因此当一个 IP 数据报封装成帧时,数据报总长度(首部＋数据)一定不能超过下层数据链路层的 MTU\n\n\n✅ 标识。占 16 位。它是一个计数器,每产生一个数据报就+1,并赋值给标识字段。但他不是&quot;序号&quot;(因为 IP 是无连接的服务)。当一个数据报的长度超过网络的 MTU 时,必须分片,此时每个数据报片都复制一次标识号,以便能重装成原来的数据报\n\n\n标志。占 3 位,但只有低两位有效。标志字段的最低位为 MF,MF=1 表示后面还有分片,MF=0 表示最后一个分片。标志字段中间一位是 DF,只有当 DF=0 时才允许分片\n\n\n✅片偏移。占 13 位。它指出较长的分组在分片后,某片在原分组中的相对位置。片偏移以 8 个字节为偏移单位。除最后一个分片外,每个分片长度一定是 8B 的整数倍\n\n\n✅ 生存时间(TTL)。占 8 位。数据报在网络中可以通过的路由器数的最大值,标识分组在网络中的寿命,以确保分组不会永远在网络中循环。路由器在转发分组前,先把 TTL 减 1。若 TTL 被减为 0,则该分组必须被丢弃\n\n\n✅ 协议。占 8 位。指出此分组携带的数据使用的何种协议,即分组的数据部分应该上交给哪个协议进行处理,如 TCP、UDP 等。其中值 6 表示 TCP,值 17 表示 UDP\n\n\n✅ 首部校验和。占 16 位。首部校验和只校验分组的首部,而不校验数据部分。\n\n\n✅ 源地址字段。占 4B,标识发送方的 IP 地址\n\n\n✅ 目的地址字段。占 4B,标识接收方的 IP 地址\n\n\n\n\n\n\n\n\n\n\n\n关于长度的标记需要记住,需要熟悉 IP 数据报首部的各个字段的意义与功能,但不需要记忆 IP 数据报首部,正常情况下如果需要参考首部,题目都会直接给出\nIP 数据报分片\n一个数据报长度为4000B(固定首部长度)。现经过一个网络传送,但这此网络能够传送的数据最大长度为1500B。试问应当划分为几个短一点的数据报片?每个数据片段的数据字段长度、片偏移字段和MF标志应为何值?\n\n分析:\n1️⃣使用固定首部:IP数据报首部字节固定部分为20字节\n2️⃣源数据报中数据部分占4000-20 = 3980B\n3️⃣ 网络能传送的最大有效载荷为(即MTU的数据部分)1500 - 20 = 1480B\n4️⃣片偏移字段的长度单位为8B\n\n\n#应当划分为几个短一点的数据报片?\n3980/1480 = 2 余 1020B\n所以应该分为3个短一些的片\n\n\n#每个数据片段的数据字段长度?\n1480B 1480B 1020B\n\n\n#每个数据片段的片偏移字段的值?\n\n第一个 0\n第二个 1480/8 = 185\n第三个 (1480×2)/8 = 370\n\n#每个数据片段的MF标志的值?\n1 1 0\n修改 MTU 的数值后需要注意!!\n一个长4000B的IP数据报(固定首部长度)现经过一个网络传送,但这此网络能够传送的数据最大长度为800B。试问应当划分为几个短一点的数据报片?每个数据片段的数据字段长度、片偏移字段和MF标志应为何值\n\n分析:\n1️⃣使用固定首部:IP数据报首部字节固定部分为20字节\n2️⃣源数据报中数据部分占4000-20 = 3980B\n3️⃣ 网络能传送的最大有效载荷为(即MTU的数据部分)800 - 20 = 780B\n4️⃣片偏移字段的长度单位为8B,那么其数据部分必须为8的整数倍,由分析3所得的780B则无法满足,应修改为776B(8的整数倍中最接近780B的数)\n\n\n\n\n\n\n\n\n\n注意:MF=0 并不能确定是独立数据报还是分片得来的,只有当 MF=0 且偏移字段&gt;0 时,才能确定是分片的最后一个分片\nIPv4 与 NAT\nIP 地址\n每台主机所拥有的 32 位比特的全球标识\n格式为: 网络号+主机号\nIP 地址分类成了 5 种类型，分别是 A 类、B 类、C 类、D 类、E 类。\n\nIP 地址中有特殊用途,不用于主机的 IP 地址\n✅ 主机号全为 0 表示网络本身\n✅ 主机号全为 1 表示本网络的广播地址\n✅127.x.x.x 保留为回环自检地址,表示任意主机本身,目的地址为回环自检地址的 IP 报永远不会出现在任何网络上\n✅32 位全为 0 表示本网络的本主机(在 IPV4 中表示的是无效的目标地址，但是在服务器端它表示本机上的所有 IPV4 地址)\n✅ 全为 1 表示整个 TCP/IP 网络的广播地址,但由于路由器对广播域的隔离 255.255.255 等效于本网络中的广播地址\nNAT\n网络地址转换(Network Adress Translation)\n网络地址转换是指用通过将专用网络转换为公用网络从而隐藏内部管理的 IP 地址。它使整个专用网只需要一个全球 IP 地址就可与因特网连通,由于专用网本地 IP 是可重用的,所以 NAT 大大节省了 IP 地址的消耗,同时,它隐藏了内部网络结构,从而降低了内部网络受到攻击的风险\n以下是一些私有 IP 地址网段\n\n\n\n类型\n网段数\n备注\n\n\n\n\nA 类\n1\n10.x.x.x\n\n\nB 类\n16\n172.16.x.x~172.31.x.x\n\n\nC 类\n256\n192.168.x.x~192.255.x.x\n\n\n\nNAT 路由器\n使用 NAT 转换表\nNAT 转换表中存放着{全球 IP 地址:端口号}到{私有 IP 地址:端口号}的映射\n\n通过这种映射可以使多个私有 IP 映射到一个全球 IP\n\n\n\n\n\n\n\n\n\n🙋‍♂️ 普通路由器在转发 IP 数据报时,不改变其源 IP 地址和目的 IP 地址。而 NAT 路由器在转发 IP 数据报时,一定要更换其 IP 地址(转换源 IP 地址或目的 IP 地址)。普通路由器仅工作在网络层,而 NAT 路由器转发数据报时需要查看和转换传输层的端口号\n子网划分与子网掩码、CIDR\n子网划分\n将一个大的网络划分成几个较小的网络，而每一个网络都有其自己的子网地址\n划分子网的意义\n在了解子网划分这个问题，首先要明白划分子网到底有什么意义。大家都知道所谓广播传输，就是向本网段的所有节点都发送同样的数据包，这就势必要占用相当多的网络资源（因为每个广播数据包硬件设备都要对它进行分析），特别是带宽资源。然而最令人讨厌的就是在这些广播传输中对终端真正有用的只是所有广播接收用户中的一个。而且网络规模越大，广播数据包发送所占用的资源越多。明白以上这样一个事实后我们就知道划分子网的一下几方面意义：\n✅ 减少广播：因为广播数据包只能在同一网段中传输，网络规模小了，网络中用户少了，当然占用的资源也就少了。\n✅ 节省 IP 地址资源：对本身规模较大（200 个用户以上）的网络，划分子网 后，可用的 IP 地址是减少了，但是如果对于那些很小的企业网络来说，划分子网后，又可节省大量的 IP 地址资源。因为几个小网络可以共用一个大的网络地址范围，而且同样可以取到隔离的作用。有四个机房，每个机房 25 台机器，需要给这些机器配置 IP 地址和子网掩码。如果采用 4 个 C 类地址段，每个机房一个，然后在一一配置，一共浪费了（254-25）*4=916 个 IP 地址。\n✅ 安全性高：由于不同子网之间是不能直接通信的（但可通过路由器或网关进行），在网络形式不容乐观的今天，网络越小，安全性就相对越高。\n✅ 便于维护：一个大的网络要查找故障点是相当困难的，如果把网络规模缩小了，查找的范围也就小了，维护起来也更方便了。\n子网划分的基本思路\n✅ 子网划分纯属单位内部的事,单位对外仍表现为一个没有划分子网的网络\n✅ 从主机号借用若干比特位,作为子网号,当然主机号就减少了相应的比特位。三级 IP 地址的结构如下: IP 地址 = {&lt;网络号&gt;,&lt;子网号&gt;,&lt;主机号&gt;}\n✅ 凡是从其他网络发送给本单位网络,\n子网掩码\n为了告诉主机或路由器对 A、B、C 类网络进行了划分,使用子网掩码来表示源网络中子网号对主机号的借位\n子网掩码是一个与 IP 地址相对应的、长 32bit 的二进制串,1 对应 IP 地址及子网号,0 对应于主机号计算机只需要将 IP 地址和其对应的子网掩码逐位相与(逻辑AND运算),就可以得出对应子网的网络地址\n\n\n\n\n\n\n\n\n\n现在的因特网标准规定:所有的网络都必须使用子网掩码。如果一个网络未发生子网,就采用默认子网掩码。\nA、B、C 类地址的默认子网掩码为 255.0.0.0、255.255.0.0、255.255.255.0\n无分类编址 CIDR\n无分类域间路由选择 CIDR是在变长子网掩码的基础上提出的一种消除传统的 A、B、C 类网络划分,并且可以在软件的支持下实现超网构造的一种 IP 地址的划分方法\nCIDR 最主要的特点:\n✅CIDR 消除了传统的 A 类、B 类和 C 类地址以及划分子网的概念，因而可以更加有效地分配 IPv4 的地址空间。\n✅CIDR 使用各种长度的“网络前缀”(network-prefix)来代替分类地址中的网络号和子网号。\n✅IP 地址从三层编址（使用子网掩码）又回到了两层编址。\n✅CIDR 使用“斜线记法” ，它又称为 CIDR 记法，即在 IP 地址后面加上一个斜线“/”，然后写上网络前缀所占的位数（这个数值对应于三层编址中子网掩码中 1 的个数）。\n✅CIDR 把网络前缀都相同的连续的 IP 地址组成“CIDR 地址块”。\nCIDR 结构记法\nIP::=&#123;&lt;网络前缀>,&lt;主机号>&#125;\nCIDR 地址块:\n128.14.32.0/20 表示的地址块共有 212 个地址（因为斜线后面的 20 是网络前缀的位数，所以这个地址的主机号是 12 位）。这个地址块的起始地址是 128.14.32.0。在不需要指出地址块的起始地址时，也可将这样的地址块简称为“/20 地址块”。\n128.14.32.0/20 地址块的最小地址：128.14.32.0\n128.14.32.0/20 地址块的最大地址：128.14.47.255\n全 0 和全 1 的主机号地址一般不使用。举个栗子\n128.14.32.0/20 表示的地址（212 个地址）\n\n路由聚合(route aggregation)\n一个 CIDR 地址块可以表示很多地址，这种地址的聚合常称为路由聚合，它使得路由表中的一个项目可以表示很多个（例如上千个）原来传统分类地址的路由。路由聚合也称为构成超网(supernetting)。\nCIDR 地址块划分举例一个大学把 c 类地址分配给各个系\n\n这个 ISP （互联网服务提供商）共有 64 个 C 类网络。如果不采用 CIDR 技术，则在与该 ISP 的路由器交换路由信息的每一个路由器的路由表中，就需要有 64 个项目。但采用地址聚合后，只需用路由聚合后的 1 个项目 206.0.64.0/18 就能找到该 ISP。\n构成超网前缀长度不超过 23 位的 CIDR 地址块都包含了多个 C 类地址。这些 C 类地址合起来就构成了超网。网络前缀越短，其地址块所包含的地址数就越多。而在三层结构的 IP 地址中，划分子网是使网络前缀变长。\n最长前缀匹配(最佳匹配):\n使用 CIDR 时,查找路由表时应当匹配结果中选择最长网络前缀的路由\n原因：网络前缀越长，其地址块就越小，因而路由就越具体(more specific)越准确 。\n\n\n\n\n\n\n\n\n\n得到下一跳路由器的 IP 地址后,并不是直接将该地址填入待发送的数据报,而是将该 IP 地址转换为 MAC 地址(通过 ARP),将此 MAC 地址放到 MAC 帧的首部,然后根据这个 MAC 地址找到下一条路由器.在不同网络中传送时,MAC 帧的源地址和目的地址要发生变化,但是在网桥转发帧时,不改变帧的源地址,请注意区分\nARP、DHCP 与 ICMP\nARP\n地址解析协议 Address Rsolution Protocol\n无论网络层使用何种协议,在链路层传送数据帧时都必须使用 MAC 地址\n所以使用 ARP 来完成 IP → MAC 地址的映射\n每台主机都有一个 ARP 高速缓存\n主机 A 欲向某台主机 B 发送 IP 数据报,先在 ARP 高速缓存中查看有无主机 B 的 IP 地址,如果有,查出其 MAC 地址,将其 MAC 地址写入 MAC 帧的目标地址,如果没有则通过使用目的地址为: FF:FF:FF:FF:FF:FF 的帧来封装并广播 ARP 请求分组,使同一局域网的所有主机都收到此 ARP 请求,主机 B 收到 ARP 请求后向主机 A 发送 ARP 相应分组,分组中包含主机 B 的 IP 和 MAC 地址的映射,主机 A 收到 ARP 响应分组后,将其映射写入 ARP 缓存\n\n\n\n\n\n\n\n\n\n🙋‍♂️ARP 在 TCP/IP 中是网络层协议,在 OS 模型中是链路层协议,但是我的理解是其更应该是属于链路层和网络层协议中间的协议,因为其能看到 IP 地址,又能对 MAC 帧进行操作(修改其目的 MAC 地址)\nDHCP\n动态主机配置协议(Dynamic Host Conficuration Protocol),常用于给主机动态分配 IP 地址,它提供了即插即用的联网机制,该机制允许以太计算机加入新的网络和获取 IP 地址而不用手工参与.DHCP 是应用层协议,它是基于UDP的\nDHCP 工作原理如下:\n使用客户端/服务器模式\n需要 IP 的主机在启动时就向 DHCP 服务器广播发送报文,此时主机成为DHCP客户.本地网络上所有的主机都能接收到该发现报文,但只有DHCP服务器才能回应此报文,DHCP 服务器先在其数据库上查找该计算机的配置,若找到则返回找到的信息,若未找到,则从服务器的IP池中取一个地址分配给该计算机,DHCP 的回答报文称为提供报文\n\n\n\n\n\n\n\n\n\nDHCP 允许网络上配置多台 DHCP 服务器,当客户端发出&quot;DHCP 发现&quot;消息时可能会收到多个应答报文,客户端只会挑选其中一个,通常是最先到达的\nICMP\n网际控制信息协议(Internet Control Message Protocol)\n使用 ICMP 让主机或路由器报告差错和异常情况。ICMP 报文作为 IP 层数据报的数据,加上数据报的首部,组成 IP 数据报发送出去。ICMP是IP层协议。\nICMP 报文的种类有两种,即ICMP差错报文和ICMP询问报文\nICMP 差错报告报文分为 5 种类型\n\n\n终点不可达:当主机或路由器不能交付数据报时,向源终点发终点不可达\n\n\n源点抑制:当路由器或者主机拥塞而丢弃数据报时,就向源点发送源点抑制报文,使源点知道应当把数据报的发送速率放慢\n\n\n时间超过:当路由器收到生存时间为(TTL)为零的数据报时,除丢弃该数据报外,还要向源点发送时间超过报文。当终点在预先规定时间内不能收到一个数据报的全部数据报片时,就把已收到的数据报片全丢弃,并向源点发送时间超过报文\n\n\n参数问题:当路由或目的主机收到数据报首部中有的字段值不正确时,就丢弃该数据报,并向源点发送参数问题报文\n\n\n改变路由(重定向):路由器把改变路由报文发送给主机,让主机知道下次应将数据报发送给另外的路由器(可通过更好的路径)\n\n\n🚨 不应发送 ICMP 差错报告报文的有以下几种:\n\n\n对 ICMP 差错报告报文不再发送 ICMP 差错报告报文\n\n\n对第一个分片的数据报片的所有后续数据报片不再发送 ICMP 差错报告报文\n\n\n对有组播地址的数据报都不发送 ICMP 报告报文\n\n\n对具特殊地址(如 127.0.0.0 或 0.0.0.0)的数据报发送 ICMP 差错报告报文\n\n\nICMP 询问报文分 4 种类型:回送请求和回答报文、时间戳请求和回答报文、地址掩码请求和回答报文、路由器询问和通告报文 。最常用的是前两种\nICMP 最常见的应用是分组网间探测PING(用来测试两台主机之间的连通性,使用 ICMP 回送和请求报文)和Traceroute(路由追踪)(这是 UNIX 的命令,Windows 中是 Tracert,可以用来跟踪分组经过的路由,使用了 ICMP 时间时间超过报文)\n\n\n\n\n\n\n\n\n\n🙋‍♂️PING 工作在应用层,它直接使用网络层的 ICMP,而未使用传输层测 TCP 或 UDP。Traceroute 工作在网络层\nIPv6\n为了解决 IP 地址耗尽的措施有 3 种:\n\n\n采用 DIDR\n\n\n采用 NAT 以节省全球 IP 地址\n\n\n采用更大空间地址空间的新版本的 IPv6\n\n\nIPv6 地址的主要特点如下:\n\n\n从 32 位增大到 128 位\n\n\n拓展的地址层次结构\n\n\n灵活的首部格式\n\n\n改进的选项\n\n\n允许协议继续扩充\n\n\n支持即插即用(即自动配置)\n\n\n支持资源的预分配\n\n\nIPv6 只有在包的源节点才能分片,是端到端的,传输路径中的路由器不能分片,所以从一般意义上说,IPv6 不允许分片(不允许类似 IPv4 的路由分片)\n\n\nIPv4 首部长度必须是 8B 的整数倍,IPv4 是 4B 的整数倍\n\n\n增大了安全性。身份验证和保密功能是 IPv6 的关键特征\n\n\nIPv6 地址\nIPv6 数据报的目的地址可以是以下三种部分:\n\n\n单播。单播就是传统的点对点通信\n\n\n多播。多播是一点对多点的通信,分组被交付到一组计算机的每台计算机\n\n\n任播。这使 IPv6 增加的一种类型。任播的目的站是一组计算机,但数据报在交付时只交付其中一台计算机,通常是距离最近的一台计算机\n\n\nIPv6 地址的缩写\nIPv4 地址通常使用点分十进制表示法。如果 IPv6 也用这种表示法,那么地址书写起来将相当长,所以 IPv6 采用了冒号 16 进制表示法,即用每 4 位二进制数用一个 16 进制数表示,并用冒号将每 4 位 16 进制数用冒号分隔\n例👇\n4BF5:AA12:0216:FEBC:BA5F:039A:BE9A:2170\n每 16 位二进制我们将其称之为域\n当 16 位域的开头有一些 0,可以直接省略,但必须保留 1 个字符\n\n当有相连的 0 值域时,还可以进一步缩写,这些域可以用双冒号缩写\n\n\n\n\n\n\n\n\n\n\n🚨 双冒号表示法在一个地址中仅能出现一次,选择相邻数最多的 0 值域进行使用\nIPv4 向 IPv6 过渡可以采用的两种方法\n1️⃣双协议栈\n即一台设备上同时装有 IPv4 和 IPv6 的协议栈\n如果是路由器不同接口,可能分别配置了 IPv4 和 IPv6 地址,如果是计算机,则同时具有 IPv4 和 IPv6 地址\n2️⃣隧道技术\n将 IPv6 数据报封装到 IPv4 数据报的数据部分,使 IPv6 能在 IPv4 网络中传输\nIP 组播\nIP 数据报的三种传输方式\n单播：单播用于发送数据包到单个目的地，且每 发送一份单播报文都使用一个单播 IP 地址作为目的地址。是一种点对点传输方式。\n广播：广播是指发送数据包到同一广播域或子网内的所有设备的一种数据传输方式，是一种点对多点传输方式。\n组播（多播）：当网络中的某些用户需要特定数据时，组播数据发送者仅发送一次数据，借助组播路由协议为组播数据包建立组播分 发树，被传递的数据到达距离用户端尽可能近的节点后才开始复制和分发，是一种点对多点传输方式。\n单播和组播的比较\n单播在发送者和每一接收者之间需要单独的数据信道。组播提高了数据传送效率。减少了主干网出现拥塞的可能性。组播组中的主机可以是在同一个物理网络，也可以来自不同的物理网络（如果有组播路由器的支持=&gt;组播路由器：运行组播协议的路由器）。\n![af6f6abead684157a3871ca83a5c8b7a_无水印](计算机网络基础/af6f6abead684157a3871ca83a5c8b7a_无水印 (2).png)\nIP 组播地址\nIP 组播地址让源设备能够将分组发送给一组设备。属于多播组的设备将被分配一个组播组 IP 地址（一群共同需求主机的相同标识）。\n组播地址范围为 224.0.0.0 ～ 239.255.255.255（D 类地址），一个 D 类地址表示一个组播组。只能用作分组的目标地址。源地址总是为单播地址。\nIP 组播地址的特点： 1.组播数据报也是“尽最大努力交付”，不提供可靠交付，应用于 UDP。 2.对组播数据报不产生ICMP差错报文。 3.并非所有 D 类地址都可以作为组播地址\nIP 组播的分类\n组播可以分为两种:一种只在本局域网上进行硬件组播;另一种则在因特网的范围内进行组播。在因特网上进行组播的最后阶段，还是要把组播数据报在局域网上用硬件组播交付给组播组的所有成员。\nIANA(互联网地址指派机构)拥有的以太网组播地址范围是从 01-00-5E-00-00-00 到 01-00-5E-7F-FF-FF。不难看出,每个 MAC 地址种只有 23 位可以用作组做。这只能和 D 类 IP 地址中的 23 位有一一对应的关系\n下面是硬件组播映射关系👇\n\n\n\n\n\n\n\n\n\n\n🤔以太网组播 IP 地址 224.215.145.230 应该映射到的组播 MAC 地址是❓\n以太网组播地址块的范围是 01-00-5E-00-00-00~01-00-5E-7F-FF-FF，而且在每个地址中，只有后 23 位可用组播。这样，只能和 D 类 P 地址中的后 23 位有–一对应关系。D 类 P 地址可供分配的有 28 位,可见这 28 位中的前 5 位不能用来构成以太网硬件地址。215 的二进制为 11010111,其中，在映射过程中最高位为 0，因此 215.145.230 的二进制为 01010111.10010001.11100110，对应的十六进制数是 57-91-E6。\n所以是 01-00-5E-57-91-E6\nIGMP 协议与组播路由选择协议\nROUND 1：\n某主机要加入组播组时，该主机向组播组的组播地址发送一个 IGMP 报文，声明自己要称为该组的成员。本地组播路由器收到 IGMP 报文后，要利用组播路由选择协议把这组成员关系发给因特网上的其他组播路由器。\nROUND 2：本地组播路由器周期性探询本地局域网上的主机，以便知道这些主机是否还是组播组的成员。只要有一个主机对某个组响应，那么组播路由器就认为这个组是活跃的；如果经过几次探询后没有一个主机响应，组播路由器就认为本网络上的没有此组播组的主机，因此就不再把这组的成员关系发给其他的组播路由器。\n组播路由器知道的成员关系只是所连接的局域网中有无组播组的成员。\n\n移动 IP\n移动 IP 的概念\n移动 IP 技术是移动结点(计算机/服务器等)以固定的网络 IP 地址，实现跨越不同网段的漫游功能，并保证了基于网络 IP 的网络权限在漫游过程中不发生任何改变。\n基于 IPv4 的移动 IP 定义三种功能实体:移动结点、归属代理（也称本地代理）和外埠代理(也称外部代理)。归属代理和外埠代理又统称为移动代理。\n移动结点：具有永久 IP 地址的移动设备。\n归属代理（本地代理）：一个移动结点的永久“居所”称为归属网络，在归属网络中代表移动节点执行移动管理功能的实体叫做归属代理。\n永久地址（归属地址/主地址）：移动站点在归属网络中的原始地址。\n外部代理（外地代理）：在外部网络中帮助移动节点完成移动管理功能的实体称为外部代理。\n转交地址（辅地址）：可以是外部代理的地址或动态配置的一个地址。\n移动 P 技术的基本通信流程如下:\n\n\n移动结点在本地网时，按传统的 TCP/IP 方式进行通信（在本地网中有固有的地址)。\n\n\n移动结点漫游到一个外地网络时，仍然使用固定的 P 地址进行通信。为了能够收到通信对端发给它的 IP 分组，移动结点需要向本地代理注册当前的位置地址，这个位置地址就是转交地址（它可以是外部代理的地址或动态配置的一个地址)。\n\n\n本地代理接收来自转交地址的注册后，会构建一条通向转交地址的隧道，将截获的发给移动结点的 P 分组通过隧道送到转交地址处。\n\n\n在转交地址处解除隧道封装，恢复原始的 IP 分组，最后送到移动结点，这样移动结点在外网就能够收到这些发送给它的 IP 分组。\n\n\n移动结点在外网通过外网的路由器或外部代理向通信对端发送 IP 数据包。\n\n\n移动结点来到另一个外网时，只需向本地代理更新注册的转交地址，就可继续通信。\n\n\n移动结点回到本地网时，移动结点向本地代理注销转交地址，这时移动结点又将使用传统的 TCP/IP 方式进行通信。\n\n\n\n\n\n\n\n\n\n\n\n🙋‍♂️ 移动 P 为移动主机设置了两个 P 地址，即主地址和辅地址（转交地址)。移动主机在本地网时，使用的是主地址。当移动到另一个网络时，需要获得一个临时的辅地址，但此时主地址仍然不变。从外网移回本地网时，辅地址改变或撤销，而主地址仍然保持不变。\n网络层设备\n冲突域和广播域\n冲突域\n冲突域是指连接到同一物理介质上的所有结点的集合,这些结点之间存在介质争用现象,在 OSI 模型中,冲突域被视为第一层的概念,像中继器、集线器等简单无脑复制转发信号的第一层设备所链接的结点都属于一个冲突域,也就是说他们不能划分冲突域\n广播域\n广播域是指接收相同广播消息的结点集合。也就是说在该集合中任何一个节点发送一个广播帧,其他能收到这个帧的结点都被认为是该广播域的一部分。在 OSI 模型中,广播域被视为第二层概念,像第一层(集线器等)、第二层(交换机等)设备所连接的结点都属于同一个广播域\n通常所说的局域网(LAN)特指使用路由器分割的网络,也就是广播域\n传输层\n传输层对收到的报文进行差错检测(首部数据部分)网络层只检查 IP 数据报的首部,不检验数据部分\n传输层的寻址与端口\n端口的作用\n端口能让应用层的各种进程将其数据通过通过端口向下交付给传输层,以及让传输层应当将其报文段的数据通过端口交付给应用层相应进程\n端口是传输层的服务访问端口(Transport Service Access Point,TSAP)\n数据链路层的 SAP 是 MAC 地址\n网络层的 SAP 是 IP 地址\n传输层的 SAP 是端口\n端口号\n应用进程用过端口号进行标识,端口长度为16bit,能够表示 65536(216)个不同的端口号。端口号具有本地意义,即端口号只标识本计算机应用层各个进程,在因特网中不同计算机相同端口号是没有联系的。根据端口号范围,可将端口分为两类:\n🖥︎ 服务端使用的端口号\n\n\n熟知端口号:0~1023(IANA 将其指派给了 TCP/IP 最重要的一些应用程序)\n常用的熟知端口号\n\n\n\n应用程序\n熟知端口号\n\n\n\n\nFTP\n21\n\n\nTELNET\n23\n\n\nSMTP\n25\n\n\nDNS\n53\n\n\nTFTP\n69\n\n\nHTTP\n80\n\n\nSNMP\n161\n\n\nHTTPS\n443\n\n\n\n\n\n登记端口号:1024~49151(供没有使用熟知端口号的应用使用,必须在 IANA 登记,以防止重复)\n\n\n💻︎ 客户端使用的端口号\n49152~65535\n仅在客户进程运行时才动态选择,又称临时端口(短暂端口)\n套接字\n在网络中通过 IP 地址来标识区别不同的主机。通过端口号来标识和区分一台主机中不同的应用进程。端口号拼接到 IP 地址即构成套接字Socket。在网络中采用发送方和接受方的套接字来识别端点。套接字,实际上是一个通信端点,即:\n套接字Socket = (IP地址:端口号)\n它唯一地标识网络中一台主机和其上的一个应用(进程)\n无连接服务和面向连接服务\n无连接服务和面向连接服务\nTCP/IP 协议族在 IP 层之上使用了两个传输协议:TCP与UDP\nTCP 提供面向连接的服务,使用 TCP 的应用有:FTP(文件传输协议)、HTTP(超文本传输协议)、TELNET(远程登录)\nUDP 提供无连接的服务,使用 UDP 的应用有:TFTP(小文件传输协议)、DNS、SNMP和RTP(实时传输协议)\n\n\n\n\n\n\n\n\n\n🤔IP 数据报与 UDP 数据报的区别❓\nUDP 数据报是封装在 IP 数据报的数据部分进行传输的\n\n\n\n\n\n\n\n\n\n🤔TCP 和网络层虚电路的区别❓\nTCP 报文在传输层抽象的逻辑信道中传输,对路由器不可见;虚电路所经过的交换结点,都必须保存虚电路的状态信息,而网络层采用的虚电路方式则无法提供无连接的服务而传输层采用 TCP 不影响网络层提供无连接的服务\nUDP 协议\nUDP 仅在 IP 数据报服务之上增加了两个最基本的服务:复用/分用以及差错检测\nUDP 常用于传输较少数据的网络应用,如 DNS,SNMP。UDP 也常用于多媒体应用(如 IP 电话、实时视频会议、流媒体等),可靠数据可靠数据传输对其并不重要,但较大的延迟无法容忍\nUDP 的优点有以下 5 点:\n\n\nUDP 无须建立连接,因此 UDP 不会引入建立连接的时延\n\n\n无连接状态\n\n\n分组开销少,为 8B\n\n\nUDP 没有拥塞控制,因此网络中的拥塞不会影响主机的发送效率\n\n\nUDP 支持一对一、一对多、多对一的交互通信\n\n\nUDP 数据报\nUDP 是面向报文的,UDP 对应用层交下的报文添加首部后就交付给网络层,既不合并,也不拆分,接收方 UDP 对网络层上交的 UDP 数据报,去除首部,原封不动交付上层应用进程,&quot;报文&quot;是 UDP 数据报处理的最小单位,UDP的报文长度发送应用进程决定。\n以下为 UDP 首部格式👇\n\n各字段意义如下 👇\n\n\n源端口:需要对方回信时使用,不使用就全为 0\n\n\n目的端口:目的端口号。这在终点交付报文中必须使用到\n\n\n长度:UDP 数据报长度(首部+数据),其最小值为 8(仅有首部)\n\n\n校验和:检测 UDP 在传输中是否有错,有错就丢弃。该字段是可选的,当源主机不想计算校验和时,则直接令该字段全为 0\n\n\nUDP 校验\n在计算校验和时要在 UDP 首部临时添加一个 12B 的&quot;伪首部&quot;,计算完后移除,如果数据部分长度不是偶数位,则需要在数据部分尾部填入一个全零字节(计算后移除,不发送)\n\n检验和主要是基于反码求和运算:\n\n\n\n\n\n\n\n\n\n反码算数运算：两个数进行二进制反码求和的运算很简单。它的规则是从低位到高位逐列进行计算。0 和 0 相加是 0，0 和 1 相加是 1，1 和 1 相加是 0，但要产生一个进位 1，加到下一列。如果最高位相加后产生进位，则最后得到的结果要加 1。\n\nUDP 校验和的计算方法:\n发送方:\n1.将校验和字段置零。\n2.把所有比特位按 16-bit（2 字节）一组进行划分。\n3.把 2 中划分好的组进行向加，如果遇到进位，将进位值加到值的最低位上。举例：（用 16 进制表示）\n0xBB5E+0xFCED = 0x1 B84B, 可以看出在这个例子中结果有进位，所以将进位值 1 加到值的最低位上，得到结果是 0xB84C\n4.把所有的组相加到一起后，得到的结果是一个 16 位的数，将这个结果取反后则得到了校验码。\n接收方:\n\n\n将 4 个 16 比特的数（包含校验和）加起来，一定等于 1111 1111 1111 1111（相当于两个反码相加），这也是取反码做校验和的原因\n\n\n如果不等，校验和错误，传输出现问题\n\n\nTCP 协议\nTCP 是在不可靠的 IP 层之上实现的可靠的数据传输协议,它主要解决传输可靠、有序、无丢失和不重复的问题。\nTCP 的主要特点如下:\n\n\nTCP 是面向连接的传输层协议,TCP 连接时一条逻辑链路\n\n\n每条 TCP 连接只能有两个端点,每条 TCP 的连接只能是端到端的(进程对进程)\n\n\nTCP 提供全双工通信,允许通信双方的应用程序在任何时候都能发送数据。为此 TCP 连接的两端都设有发送缓存和接受缓存,用来临时存放双方通信的数据\n\n\n发送缓存用来存放以下数据:\n① 发送应用程序出纳送给发送方 TCP 准备发送的数据;\n② 发送方已发送但尚未收到确认的数据\n接收缓存用来存放以下数据:\n① 按序到达但尚未被接受应用程序读取的数据\n② 不按序到达的数据\n4) TCP是面向字节流的,虽然应用程序和TCP的交互是一次一个数据块(大小不等),但TCP把应用程序交下来的数据仅视为一连串的无结构的字节流\n4) TCP提供可靠交付的服务,保证传送的数据无差错,不丢失,不重复且有序\nTCP 报文段\n以下为 TCP 首部格式👇\n\nTCP 首部各字段意义如下:\n\n\n源端口和目的端口:各占 2B。端口是运输层与应用层的服务接口,运输层的复用和分用的功能都要靠端口实现\n\n\n序号:占 4B,范围是 0~223-1。因为 TCP 是面向字节流的(即 TCP 的传输时是逐个字节传送的),所以 TCP 连接传送的字节流中的每个字节都按顺序编号。序号字段的值指的是本报文段所发送的数据的第一个字节的序号\n\n\n确认号:占 4B,是期望收到对方下一个报文段的第一个数据字节的序号,若确认号为 N 则表明到序号 N-1 为止的所有数据都已正确收到\n\n\n数据偏移(首部长度):占 4 位。注意与IP 数据报分片的数据偏移进行区分,这里表示的是首部长度,即 TCP 报文段的数据起始处距离 TCP 报文段的起始处有多远。数据偏移以4B 为单位,而 4 位二进制最多能表示 15,所以 TCP 首部最大长度为 60B\n\n\n保留:占 6 位,保留为今后使用,但目前应置为 0\n\n\n紧急位 URG:当 URG = 1 时表明紧急指针字段有效。他告诉系统此报文中有紧急数据,应当尽快传送\n\n\n确认位 ACK:仅当 ACK = 1 时确认字段有效,ACK = 0 时确认号无效\n\n\n推送位 PUSH:接收方收到 PUSH = 1 的报文时应尽快交付给应用程序,而不用等到整个缓存满了再向上交付\n\n\n复位位 RST:RST = 1 时表明连接出现严重差错(如主机崩溃或其他原因)必须释放连接再重新建立连接\n\n\n同步位 SYN:SYN = 1 时表明这是一个请求连接或者连接接受报文当 SYN = 1 ACK =0 时表明是连接请求;SYN = 1 ACK = 1 表明同意建立连接\n\n\n终止位 FIN:用来释放一个连接,当 FIN = 1 时表示此报文的发送方数据已经发送完毕,并要求释放运输连接\n\n\n窗口:允许对方发送给的数据量\n\n\n校验和:要求将 TCP 报文首部加上一个 12B 的&quot;伪首部&quot;后再进行计算(只需要将 UDP 伪首部中的协议字段从17改为6,其他部分与 UDP 一样)\n\n\n紧急指针:占 2B。紧急指针在 URG = 1 时才有效,它指出在本报文段中紧急数据共有多少字节(紧急指针在报文段数据的最前面)\n\n\n选项:长度可变。TCP 最初之规定了一种选项,即最大报文长度(Maximum Segment Size, MSS)。MSS 是 TCP 报文段中的数据字段的最大长度(仅仅是数据字段)\n\n\n填充。这是为了使整个首部长度是 4B 的整数倍\n\n\nTCP 连接管理\nTCP 是面向连接的服务,因此每个 TCP 连接都有三个阶段:连接建立、数据传输、连接释放\nTCP 把连接作为最基本的抽象,每条 TCP 连接有两个端点,TCP 连接的端点不是主机,不是主机的 IP 地址,不是应用进程,也不是传输层的协议端口。TCP 连接的端口即为套接字(Socket)或插口。,每条 TCP 连接唯一地被通信的两个端点(即两个套接字)确定。\nTCP 连接的建立采用客户端/服务器模式(C/S 模式)。主动发起连接的应用进程称为客户(Client),而被动等待连接建立的应用进程称为服务器(Server)\nTCP 连接的建立\n连接的建立经历以下 3 个步骤,通常称为&quot;三次握手&quot;👇\n\n\n\n服务器进程准备好接受外来的连接，这通常是通过调用 socket，bind，listen 这三个函数来完成，我们称之为被动打开（passive open）。然后服务器进程就处于LISTEN状态，等待客户的连接请求，如有，则作出响应。\n\n\n客户通过调用 connect 发起主动打开（active open），向服务器发出连接请求报文段，请求中的首部的同步位 SYN = 1，同时选择一个初始序号 seq = x。TCP 规定，SYN报文段不能携带数据，但要消耗一个序号。这时，TCP 客户进入SYN-SEND（同步已发送）状态。\n\n\n服务器收到客户端连接请求后，必须确认（ACK）客户的 SYN 报文段。在确认报文段中，把 SYN 和 ACK 位都置为 1，确认号为ack = x + 1，同时也为自己选择一个初始序号seq = y。请注意，这个报文段也不能携带数据，但同样要消耗掉一个序号。这时，TCP 服务器进入SYN-RCVD（同步收到）状态。\n\n\n客户在收到服务器的确认后，还要向服务器进程给出确认。确认报文段的 ACK 置 1，确认号ack = y + 1，而自己的序号seq = x + 1。TCP 规定，这个报文段可以携带数据，也可以不携带数据，如果不携带数据，下一个数据报文段的序号仍是seq = x + 1。这时，TCP 连接已经建立，客户进入ESTABLISHED（已建立连接）状态。\n\n\n服务器收到客户的确认后，也进入ESTABLISHED状态。\n在上述的建立连接的过程中，前后发送了三个报文段，因此 TCP 建立连接的过程也称之为三次握手（three-way handshake）。\n\n\n\n\n\n\n\n\n\n\n\n🤔为什么需要三次握手?而不是 2 次❓\n为什么客户在收到服务器的确认后，还要向服务器发送一次确认呢？这主要是为了防止已失效的连接请求报文段突然又传送到了服务器，因而发生错误。考虑一种情况，客户发出连接请求后，但因连接请求报文丢失而未收到确认。于是客户再重传一次连接请求。后来收到了确认，建立了连接。数据传输完毕后，就释放了连接。客户共发送了两个连接请求报文段，其中第一个丢失，第二个到达了服务器。没有“已失效的连接请求报文段”。现假定一种异常情况。即客户发出的第一个连接请求报文段并没有丢失，而是在某些网络结点长时间滞留了，以致延误到连接释放以后的某个时间才到达服务器。本来这是一个早已失效的报文段，但服务器收到此失效的连接请求后，就误认为是客户又一次发出一次新的连接请求。于是就向客户发出确认报文段，同意建立连接。假定不采用三次握手，那么只要服务器发出确认，新的连接就建立了。由于现在客户端并没有发出建立连接的请求，因此不会理睬服务器的确认，也不会向服务器发送数据。但服务器却以为新的连接已经建立了，并一直等待客户发送数据。服务器的许多资源就这样白浪费了。采用三次握手的办法可以防止上述现象的发生。例如刚才的情况下，客户不会向服务器的确认发出确认，由于服务器收不到确认，就知道客户并没有要求建立连接。\n\n\n\n\n\n\n\n\n\n🚨 值得注意的是,服务器在第二次握手的时候就已经预先分配了资源,而客户端分配缓存资源的时间在第三次握手,这就使得服务器易受到SYN洪泛攻击\nTCP 连接的释放\n天下没有不散的筵席,TCP 也同样如此。参与 TCP 连接的两个进程中的任意一个都能终止该连接。TCP 连接释放的过程被称为&quot;四次挥手&quot;👇\n\n\n\nA 的应用进程先发出释放连接报文段，并停止发送数据，主动关闭 TCP 连接。A 把连接释放报文段首部 FIN 置 1，其序号为 seq = u。这时 A 进入FIN-WAIT-1（终止等待1）状态。\n\n\nB 收到连接释放报文段后即发出确认确认号为 ack = u + 1，而自己的序号为 seq = v。然后 B 就进入CLOSE-WAIT（关闭等待）状态。TCP 服务器进程这时应通知高层应用进程，因而从 A 到 B 这个方向的连接就释放了，这时的 TCP 连接处于半关闭状态，即 A 已经没有数据要发送了，但 B 若发送数据，A 仍接收。\n\n\nA 收到来自 B 的确认后，就进入FIN-WAIT-2（终止等待2）状态，等待 B 发出的连接释放报文段。\n\n\n若 B 已经没有要向 A 发送的数据，其应用进程就通知 TCP 释放 连接。这时 B 发出的连接释放报文段 FIN = 1，还必须重复上次已发送过的确认号 ack = u + 1。假定 B 的序号为 w（在半关闭期间 B 可能又发送了一些数据）。这时 B 就进入了LAST-ACK（最后确认）状态，等待 A 的确认。\n\n\nA 收到了的连接释放报文段后，必须对此发出确认。其确认号为 ack = w + 1，而自己的序号为 seq = u + 1。然后进入到TIME-WAIT（时间等待）状态。请注意，现在 TCP 连接还没有释放掉。必须经过时间等待计时器（TIME-WAIT timer）设置的时间 2MSL 后，A 才进入到 CLOSED 状态。时间 MSL 叫做最长报文段寿命（Maximum Segment Lifetime）。\n\n\nB 只要收到 A 发出的确认，就进入 CLOSED 状态。我们注意到，B 结束 TCP 连接的时间要比 A 早一些。由于释放 TCP 连接的过程需要发送四个报文段，因此释放连接的过程也称之为四次挥手。\n\n\n\n\n\n\n\n\n\n\n\n🙋‍♂️TIME_WAIT 状态\n上述释放连接的过程中，A 在 TIME-WAIT 状态必须等待 2MSL，才进入 CLOSED 状态，上面也提到，这个 MSL 是报文段的最长寿命。那么 MSL 的真实含义是什么呢？\nMSL 是任何 IP 数据报能够在网络中存活的最长时间。我们知道这个时间是有限的，因为每个数据报含有一个称为跳限（hop limit）的 8 位字段，它的最大值是 255，即最大为 255 跳。尽管这是一个跳数限制而不是真正的时间限制，我们仍然假设：具有最大跳限的数据报在网络中存在的时间不可能超过 MSL 秒。任何 TCP 实现都必须为 MSL 选择一个值。RFC 1122 的建议值为 2 分钟，对于现在的网络，MSL = 2 分钟可能太长了，故一些实现采用 30 秒的值，这意味着，TIME-WAIT 状态的持续时间在 1 分钟到 4 分钟之间。\n为什么客户在 TIME-WAIT 状态必须 2MSL 的时间呢？这有两个理由：\n1）可靠地实现 TCP 全双工连接的终止\n客户 A 最后一个 ACK 报文段可能丢失，这样服务器 B 处于 LAST-ACK 状态而收不到确认。接下来 B 会超时重传 FIN + ACK 报文段，而 A 就能在 2MSL 时间内收到这个重传的 FIN + ACK 报文段，并再重传一次确认，并重新启动 2MSL 计时器。最后，A 和 B 都正常进入 CLOSED 状态。如果 A 在发送完最后一个 ACK 报文段后立即释放连接，那么就无法收到 B 重传的 FIN + ACK 报文段，因而也不会再发送一次确认报文段，这样 B 就无法按照正常步骤进入 CLOSED 状态。\n2）防止“已失效的连接请求报文段”出现在本连接中\n客户 A 在发送完最后一个 ACK 报文段后，再经过时间 2MSL，就可以使本连接持续的时间内所产生的所有报文段都会网络中消失。这样就可以使下一个新的连接中不会出现这种旧的连接请求报文段。\n对于应用程序来说，什么情况下会出现大量 TIME_WAIT 的状态？\nTIME_WAIT 的出现是一般是客户主动关闭 TCP 连接而出现的，即出现在客户端机器，服务端机器一般不会出现 TIME_WAIT 状态。\nTCP 可靠传输\nTCP 的任务是在 IP 层的不可靠、尽力而为服务的基础上建立一种可靠数据传输服务。TCP 提供的可靠数据传输服务就是要保证接收方进程从缓冲区读出的字节流与发送方发出的字节流是完全一样的。TCP 使用了校验、序号、确认和重传机制来达到这个目的。\n其中校验机制与UDP 校验机制一致,只不过将其协议段从 17 改为 6\n序号\nTCP 首部的序号字段用来保证数据能有序提交给应用层，TCP 把数据看成一个无结构但是有序的字节流，而序号是建立在传送的字节流之上，而不是建立在报文段之上。TCP 连接中传送的数据流中的每一个字节都编上一个序号。序号字段的值则指的是本报文段所发送的数据的第一个字节的序号。\n确认\nTCP 首部的确认号是期望收到对方的下一个报文段的数据的第一个字节的序号。TCP 默认使用累计确认，即 TCP 只确认数据流中至第一个丢失字节为止的字节。例如，接收方 B 收到了发送方 A 发送的包含字节 0~2 和 6 ~7 的报文段。由于某些原因，B 还没有收到字节 3~5 的报文段，此时 B 仍在等待字节 3(和其后面的字节)，因此，B 到 A 的下一个报文段将确认号字段设置为 3。\n重传\n有两种事件会导致 TCP 对报文段进行重传：\n\n\n超时\n\n\nTCP 每发送一个报文设置一个计时器\n当计时器的时间高于加权平均往返时间 RTTs(随着 RRT 样本值的变化而变化)还未收到确认,就重传该报文\n\n\n冗余 ACK(冗余确认)\n\n\nTCP 规定当发送方收到对同一个报文段的 3 个冗余 ACK 时,就可以认为跟在这个确认报文段之后的报文段已经丢失\n每当比期望序号大的失序报文段到达时，发送一个冗余 ACK，指明下一个期待字节的序号。\n发送方已发送 1，2，3，4，5 报文段​ 接收方收到 1，返回给 1 的确认(确认号为 2 的第一个字节)​ 接收方收到 3，仍返回给 1 的确认(确认号为 2 的第一个字节)​ 接收方收到 4，仍返回给 1 的确认(确认号为 2 的第一个字节)​ 接收方收到 5，仍返回给 1 的确认(确认号为 2 的第一个字节)\n发送方收到 3 个对于报文段 1 的冗余 ACK——认为 2 报 文段丢失，重传 2 号报文段\nTCP 流量控制\n基于数据链路层所介绍的滑动窗口\n传输层和数据链路层的流量控制的区别是:\n1) 传输层是定义`端到端之间的流量控制`,数据链路层定义中间`两个相邻结点的流量控制`\n1) 传输层的窗口可以动态变化,数据链路层的滑动窗口协议的窗口大小不能动态变化\nTCP 的拥塞控制\n拥塞控制和流量控制的区别\n拥塞控制是让网络能够承受现有的网络负荷,是一个全局性的过程,涉及所有主机、路由器\n流量控制往往是点到点的通信量的控制,是一个端到端的访问\nTCP 的拥塞控制算法\n慢开始、拥塞避免、快重传、快恢复\nTCP 协议要求发送方维护两个窗口:\n\n\n接收窗口rwnd\n\n\n接收方根据目前接收缓存大小所许诺的的最新窗口值\n\n\n拥塞窗口cwnd\n\n\n发送方根据字节估算的网络拥塞程度而设置的窗口值\n发送窗口的上限值应取接收窗口 rwnd 和拥塞窗口 cwnd 中较小的一个即:\n发送MAX = min[rwnd,cwnd]\n慢开始\n思想:\n\n\n先令 cwnd = 1 (此处这里的 1 代表 1 个 MSS 的长度(最大报文段长度),窗口是以字节为单位的)\n\n\n每当过一个[RRT(往返时延)](###往返时延(RRT Round Trip Time))cwnd 的值翻倍\n\n\n一直到一个阈值 → 慢开始门限(ssthresh)\n\n\n然后进行拥塞避免算法\n\n\n拥塞避免算法\n思想:\n\n\n每过一个 RRT 就把 cwnd+1\n\n\n若网络出现拥塞(即未按时收到确认),就把慢开始门限(ssthresh)设置为出现拥塞时的 cwnd 的一半,然后将 cwnd 重新设置为 1,重新执行慢开始算法\n\n\n以下是拥塞避免和慢开始的流程图👇\ngraph TD\nA(开始) --> B[cwnd = 1]\nB --> C&#123;cwnd &lt; ssthresh&#125;\nC -- 是 --> D[慢开始: cwnd翻倍]\nD --> C\nC -- 否 --> E[拥塞避免: cwnd + 1]\nE --> F&#123;出现拥塞?&#125;\nF -- 是 --> G[ssthresh = cwnd / 2, cwnd = 1]\nG --> C\nF -- 否 --> E\n\n\n\n\n\n\n\n\n\n当 cwnd = ssthresh 既可以使用慢开始算法,又可以使用拥塞避免算法(通常使用)\n快重传和快恢复\n快重传(利用了冗余 ACK)\n当收到 3 个对同一个报文段的 ACK 确认,立即重传对方尚未收到的报文段,而不必等待那个报文段设置的重传计时器超时。快重传并非取消重传计时器,而是在某些情况下可更早地重传丢失的报文段\n\n\n\n\n\n\n\n\n\n🤔TCP 是使用的 GBN 还是 SR 选择重传❓\nTCP 使用累计确认,值看起来像是 GBN 的风格,但是正确收到但失序的报文并不会丢弃,而是缓存起来,TCP 至多一次重传一个报文段(即冗余 ACK 之后的报文段),而 GBN 需要重传错误报文段后的所有报文段,另外 TCP 提供一个 SACK 选项,即选择确认选项,而使用选择确认选项时,TCP 看起来就和 SR 非常相似。因此,TCP 的差错恢复机制可视为 GBN 和 SR 协议的混合体\n快恢复\n当网络拥塞发生时(发送方连续收到三个冗余 ACK 时),进行网络拥塞的处理后(将慢开始门限设置为此时发送方 cwnd 的一半),将 cwnd 设置为慢开始 sstresh 的值,然后执行拥塞避免算法,由于跳过了拥塞窗口 cwnd 从 1 起始的慢开始过程,所以被称为快恢复\n应用层\n网络应用模型\n客户/服务器模型\nClient/Server 模型(C/S 模型)中有一个总是打开的主机称为服务器,它服务于许多来自其他称为客户机的主机请求。\n最主要的特征:客户是服务请求方.服务器是服务提供方\n主要特点还有:\n\n\n网络各计算机地位不平等\n\n\n客户机之间不直接通信\n\n\n可拓展性不佳\n\n\n常见应用:web、文件传输协议(FTP)、远程登录和电子邮件\nP2P 模型\nP2P 网络是指在互联网中由对等结点组成的覆盖网络(Overlay Network),是一种动态的逻辑网络,它没有固定的客户和服务器划分,任意一对计算机(对等方)直接通信(显著特点)\nP2P 缺点:占用较多内存影响整机速度,经常进行 P2P 下载会对硬盘造成较大的损伤\n域名系统(DNS)\n域名系统(Domain Name System, DNS)用来把便于人们记忆具有特定含义的主机名转换为便于机器处理的 IP 地址。\nDNS 使用 C/S 模型,其协议运行在UDP之上,使用53号端口\n概念上可将 DNS 分为三个部分:层次域名空间、域名服务器和解析器\n层次域名空间\n层次域名空间结构如下 👇\n\n\n\n标号中的英文不区分大小写\n\n\n标号中除连字符(-)外不能使用其他标点符号\n\n\n每个标号不能超过 63 个字符,多标号组成的完整域名不超过 255 个字符\n\n\n级别最低的域名写最左边,级别最高的顶级域名写最右边\n\n\n顶级域名分为三类\n(Top Level Domain, TLD)\n\n\n国家(地名)顶级域名(nTLD):“.cn&quot;表示中国;”.us&quot;代表美国;&quot;.uk&quot;表示英国\n\n\n通用顶级域名(gTLD):常见的有&quot;.com&quot;→ 公司;“.net&quot;→ 网络服务机构;”.org&quot;→ 非盈利组织和&quot;.gov&quot;→ 国家或政府部门\n\n\n基础结构域名:这种顶级域名只有一个,即 arpa 用于反向域名解析(又称反向域名)\n\n\n\n域名服务器\nDNS 将域名地址解析成 IP 地址,其使用了大量的域名服务器并将它们以层次的方式组织,没有一台域名服务器有因特网上所有主机的映射,相反映射分布在所有 DNS 上,采用&quot;分布式&quot;设计的 DNS,是一个在因特网上实现分布式数据库的精彩范例\n总共四种类型的域名服务器:\n根域名服务器\n所有根域名服务器都知道所有的顶级域名服务器的 IP 地址\n本地域名服务器只要字节无法解析们都要首先求助于根域名服务器,通常它不直接把待查询的域名直接转换为 IP 地址,而是告诉本地域名服务器下一步应当找哪个顶级域名服务器进行查询\n\n\n\n\n\n\n\n\n\n🙋‍♂️ 因特网上有13个域名服务器(其实为 13 个 IP 地址,每个 IP 地址后都是一个冗余服务器的集群),中国没有根域名服务器(IPv4),只有根镜像域名服务器\n(我国已有 IPv6 根域名服务器)\n顶级域名服务器\n这些域名服务器管理在该顶级域名服务器注册的所有二级域名,收到 DNS 请求时,就给出相应的回答(可能是最后的结果,也可能是下一步应当查找的域名服务器的 IP)\n授权域名服务器\n每台主机都必须在授权域名服务器处登记。为了更可靠地工作,一台主机最好至少有两个授权域名服务器。实际上许多域名服务器同时充当本地域名服务器和授权域名服务器\n授权域名服务器总能将其管辖的主机名转换为该主机的 IP 地址\n\n\n\n\n\n\n\n\n\n🤔到底什么是授权域名服务器❓\n假设你有一家网上商店，网址是www.example.com。为了让人们能够访问你的网站，你需要注册一个域名，并将其映射到你的网站服务器的IP地址上。你选择了一个域名注册公司来注册你的域名，比如GoDaddy。注册完成后，你需要将域名服务器配置为GoDaddy的域名服务器。\n此时，GoDaddy 就是你的授权域名服务器。当有人在浏览器中输入www.example.com时，浏览器会向本地域名服务器发送一个查询请求，询问该网址对应的IP地址是什么。本地域名服务器可能不知道答案，因此会向更高级别的域名服务器发送查询请求，该请求最终会到达GoDaddy的域名服务器。\nGoDaddy 的域名服务器保存了你的域名信息，包括将www.example.com映射到哪个IP地址上。它会将这个信息返回给本地域名服务器，本地域名服务器再将其返回给浏览器，浏览器就可以通过该IP地址连接到你的网站了。\n因此，授权域名服务器的作用是确保每个域名的真实信息只能由授权的机构进行管理和修改，从而防止了恶意攻击和网络欺诈。\n本地域名服务器\n每个因特网服务提供者(ISP) 或一所大学甚至一所大学中的各个系,都可以拥有一个本地域名服务器,每当一台主机发出 DNS 请求时,这个报文就发送给该主机的本地域名服务器\n域名解析过程\n正向解析:把域名映射成 IP 地址\n反向解析:把 IP 地址映射成域名\n客户端要域名解析时,通过本机的 DNS 客户端构造一个 DNS 请求报文,以 UDP 数据报的方式发往本地域名服务器\n域名解析由两种方式:递归查询和递归与迭代相结合的查询:\n递归查询\n\n上图中 1-8 表示顺序\n(对根域名服务器造成的负载过大,实际中不使用)\n递归与迭代相结合的查询(实际使用)\n\n假定某客户机想获知域名为 y.abc.com 主机的 IP 地址，域名解析的过程（共使用 8 个 UDP 报文）如下：\n① 客户机向其本地域名服务器发出 DNS 请求报文\n② 本地域名服务器收到请求后，查询本地缓存，若没有该记录，则以 DNS 客户的身份向根域名服务器发出解析请求\n③ 根域名服务器收到请求后，判断该域名属于.com 域，将对应的顶级域名服务器 dns.com 的 IP 地址返回给本地域名服务器\n④ 本地域名服务器向顶级域名服务器 dns.com 发出解析请求报文\n⑤ 顶级域名服务器 dns.com 收到请求后，判断该域名属于 abc.com 域，因此将对应的授权域名服务器 dns.abc.com 的 IP 地址返回给本地域名服务器\n⑥ 本地域名服务器向授权域名服务器 dns.abc.com 发起解析请求报文\n⑦ 授权域名服务器 dns.abc.com 收到请求后，将查询结果返回给本地域名服务器\n⑧ 本地域名服务器将查询结果保存到本地缓存，同时返回给客户机\n为了提高 DNS 的查询效率，并减少因特网上的 DNS 查询报文数量，在域名服务器中广泛地使用了高速缓存。当一个 DNS 服务器接收到 DNS 查询结果时，它能将该 DNS 信息缓存在高速缓存中。 这样，当另一个相同的域名查询到达该 DNS 服务器时，该服务器就能够直接提供所要求的 IP 地址，而不需要再去向其他 DNS 服务器询问。 因为主机名和 IP 地址之间的映射不是永久的，所以 DNS 服务器将在一段时间后丢弃高速缓存中的信息。\n\n\n\n\n\n\n\n\n\n🙋‍♂️ 为保持高速缓存中的内容正确，域名服务器应为每项内容设置计时器，并处理超过合理时间的项（如每个项目只存放两天）。当权限域名服务器回答一个查询请求时，在响应中指明绑定有效存在的时间值。增加此时间值可减少网络开销，减少此时间值可以提高域名转换的准确性。\n文件传输协议(FTP)\nFTP 提供交互式的访问，允许客户指明文件的类型与格式，并允许文件具有存取权限。它屏蔽了各计算机系统的细节，因而适合于在异构网络中的任意计算机之间传送文件。\n  FTP 提供以下功能：\n  ① 提供不同种类主机系统（硬、软件体系等都可以不同）之间的文件传输能力\n  ② 以用户权限管理的方式提供用户对远程 FTP 服务器上的文件管理能力\n  ③ 以匿名 FTP 的方式提供公用文件共享的能力\nFTP 采用客户/服务器的工作方式，它使用 TCP 可靠的传输服务。 一个 FTP 服务器进程可同时为多个客户进程提供服务。FTP 的服务器进程由两大部分组成：一个主进程，负责接收新的请求；另外有若干从属进程，负责处理单个请求。其工作步骤如下：\n  ① 打开熟知端口 21（控制端口），使客户进程能够连接上\n  ② 等待客户进程发连接请求\n  ③ 启动从属进程来处理客户进程发来的请求。主进程与从属进程并发执行，从属进程对客户进程的请求处理完毕后即终止\n  ④ 回到等待状态，继续接收其他客户进程的请求\nFTP 服务器必须在整个会话期间保留用户的状态信息。特别是服务器必须把指定的用户账户与控制连接联系起来，服务器必须追踪用户在远程目录树上的当前位置。\n控制连接与数据连接\n控制连接\n服务器监听21 号端口，等待客户连接，建立在这个端口上的连接称为控制连接，控制连接用来传输控制信息（如连接请求、传送请求等），并且控制信息都以 7 位 ASCII 格式传送。FTP 客户发出的传送请求，通过控制连接发送给服务器端的控制进程，但控制连接并不用来传送文件。在传输文件时还可以使用控制连接（如客户在传输中途发一个中止传输的命令），因此控制连接在整个会话期间一直保持打开状态。\n数据连接\n服务器端的控制进程在接收到 FTP 客户发来的文件传输请求后，就创建“数据传送进程”和“数据连接”。数据连接用来连接客户端和服务器端的数据传送进程，数据传送进程实际完成文件的传送，在传送完毕后关闭“数据传送连接”并结束运行。\n   因为 FTP 使用了一个分离的控制连接，所以也称 FTP 的控制信息是带外（Out-of-band）传送的。使用 FTP 时，若要修改服务器上的文件，则需要先将此文件传送到本地主机，然后再将修改后的文件副本传送到原服务器。 网络文件系统（NFS）允许进程打开一个远程文件，并在该文件的某个特定位置开始读写数据。这样，NFS 可使用户复制一个大文件中的一个很小的片段，而不需要复制整个大文件。\n数据连接在每次数据传输完毕后就关闭\n数据连接有两种传输模式:\n主动模式 PORT\n登录成功后要读取数据时,客户端随机开放一个端口,并发送命令给服务器,服务器收到 PORT 命令和端口号后,通过 20 号端口和客户端提供的端口连接\n即==“服务器固定端口 20 连接到客户端端口”==\n\n\n\n\n\n\n\n\n\n🙋‍♂️ 匿名用户使用anonymous作为用户名\n被动模式 PASV\n客户端要读取数据时,发送 PASV 到服务器,服务器随机开放一个端口,并告知客户端,客户端再连接到服务器开放的端口进行数据传输\n电子邮件\n电子邮件系统的组成结构\n电子邮件是一种异步通信方式，通信时不需要双方同时在场。电子邮件把邮件发送到收件人使用的邮件服务器，并放在其中的收件人邮箱中，收件人可以随时上网到自己使用的邮件服务器进行读取。\n   一个电子邮件系统应具有下图所示的三个最主要的组成构件，即用户代理（User Agent）、邮件服务器和电子邮件使用的协议，如SMTP、POP3（或IMAP）等。\n\n用户代理（UA）：用户与电子邮件系统的接口。用户代理使用户能够通过一个很友好的接口发送和接收邮件，用户代理至少应当具有撰写、显示和邮件处理的能力。通常情况下，用户代理就是一个运行在 PC 上的程序，常见的有 Outlook、Foxmail 等\n邮件服务器：组成电子邮件系统的核心。邮件服务器的功能是发送和接收邮件，同时还要向发信人报告邮件传送的情况（已交付、被拒绝、丢失等）。邮件服务器采用客户/服务器方式工作，但它能够同时充当客户和服务器。例如，当邮件服务器 A 向邮件服务器 B 发送邮件时，A 就作为 SMTP 客户，而 B 是 SMTP 服务器；反之，当 B 向 A 发送邮件时，B 就是 SMTP 客户，而 A 就是 SMTP 服务器。\n邮件发送协议和读取协议：邮件发送协议用于用户代理向邮件服务器发送邮件或在邮件服务器之间发送邮件，通常使用的是 SMTP；邮件读取协议用于用户代理从邮件服务器读取邮件，如 POP3。 SMTP采用的是“推”（Push）的通信方式，即在用户代理向邮件服务器发送邮件及在邮件服务器之间发送邮件时，SMTP 客户端主动将邮件“推”送到 SMTP 服务器端。而POP3采用的是“拉”（Pull）的通信方式，即用户读取邮件时，用户代理向邮件服务器发出请求，“拉”取用户邮箱中的邮件。\n电子邮件格式与 MIME\n电子邮件格式\n一个电子邮件分为信封和内容两大部分，邮件内容又分为首部和主体两部分。RFC 822 规定了邮件的首部格式，而邮件的主体部分则让用户自由撰写。用户写好首部后，邮件系统自动地将信封所需的信息提取出来并写在信封上，用户不需要亲自填写信封上的信息。\n   邮件内容的首部包含一些首部行，每个首部行由一个关键字后跟冒号再后跟值组成。有些关键字是必需的，有些则是可选的。最重要的关键字是To:和Subject：。\n  To 是必需的关键字，后面填入一个或多个收件人的电子邮件地址。电子邮件地址的规定格式为：收件人邮箱名@邮箱所在主机的域名，如abc@test.com，其中收信人邮箱名即用户名，abc 在 test.com 这个邮件服务器上必须是唯一的。这也就保证了abc@test.com这个邮件地址在整个因特网上是唯一的。\n  Subject 是可选关键字，是邮件的主题，反映了邮件的主要内容\n   当然，还有一个必填的关键字是 From，但它通常由邮件系统自动填入。首部和主体之间用一个空行进行分割。典型的邮件内容如下：\nFrom:hoopdog@hust.edu.com\nTo:abc@test.com\nSubject:Say hello to Internet\n\nbalabalabala...\n...\n多用途网际邮件扩充（MIME）\n由于 SMTP 只能传送一定长度的 ASCII 码，许多其他非英语国家的文字就无法传送，且无法传送可执行文件及其他二进制对象，因此提出了多用途网络邮件扩充（Multipurpose Internet Mail Extensions,MIME）\n  MIME并未改动SMTP或取代它。MIME 的意图是继续使用目前的格式，但增加了邮件主体的结构，并定义了传送非 ASCII 码的编码规则。也就是说，MIME 邮件可在现有的电子邮件程序和协议下传送。MIME 与 SMTP 的关系如图：\n\nMIME 主要包括以下三部分内容：\n ①5 个新的邮件首部字段，包括 MIME 版本、内容描述、内容标识、内容传送编码和内容类型\n ② 定义了许多邮件内容的格式，对多媒体电子邮件的表示方法进行了标准化\n ③ 定义了传送编码，可对任何内容格式进行转换，而不会被邮件系统改变\nSMTP 和 POP3\nSMTP\n简单邮件传输协议（Simple Mail Transfer Protocol，SMTP）是一种提供可靠且有效的电子邮件传输的协议，它控制两个相互通信的 SMTP 进程交换信息。由于 SMTP 使用客户/服务器方式，因此负责发送邮件的 SMTP 进程就是 SMTP 客户，而负责接收邮件的 SMTP 进程就是 SMTP 服务器。SMTP 使用的是 TCP 连接，端口号为 25。 SMTP 通信有以下三个阶段：\n  （1）连接建立\n   发件人的邮件发送到发送方邮件服务器的邮件缓存中后，SMTP 客户就每隔一定时间对邮件缓存扫描一次。如发现有邮件，就使用 SMTP 的熟知端口号（25）与接收方邮件服务器的 SMTP 服务器建立 TCP 连接。连接建立后，接收方 SMTP 服务器发出 220 Service ready（服务就绪）。然后 SMTP 客户向 SMTP 服务器发送 HELO 命令，附上发送方的主机名。\n  SMTP 不使用中间邮件服务器。TCP 连接总是在发送方和接收方这两个邮件服务器之间直接建立，而不管它们相隔多远。接收方的邮件服务器因故障暂时不能建立连接时，发送方的邮件服务器只能等待一段时间后再次尝试连接。\n  （2）邮件传送\n   连接建立后，就可开始传送邮件。邮件的传送从 MAIL 命令开始，MAIL 命令后面有发件人的地址。如 MAIL FROM：hoopdog@hust.edu.cn。若 SMTP 服务器已准备好接收邮件，则回答 250 OK。接着 SMTP 客户端发送一个或多个 RCPT（收件人 recipient 的缩写）命令，格式为 RCPT TO：&lt;收件人地址&gt;。每发送一个 RCPT 命令，都应有相应的信息从 SMTP 服务器返回，如 250OK 或 550 No such user here（无此用户）\n  RCPT 命令的作用是，先弄清接收方系统是否已做好接收邮件的准备，然后才发送邮件，以便不至于发送了很长的邮件后才知道地址错误，进而避免浪费通信资源。\n   获得 OK 的回答后，客户端就使用 DATA 命令，表示要开始传输邮件的内容。正常情况下，SMTP 服务器回复信息是 354 Start mail input;end with &lt; CRIF &gt;.&lt; CRIF &gt;。&lt; CRIF &gt;表示回车换行。此时 SMTP 客户端就可开始传送邮件内容，并用&lt; CRIF &gt;.&lt; CRIF &gt;（两个回车，中间一个点）表示邮件内容的结束。\n  （3）连接释放\n   邮件发送完毕后，SMTP 客户应发送 QUIT 命令。SMTP 服务器返回的信息是 221（服务关闭），表示 SMTP 同意释放 TCP 连接。邮件传送的全部过程就此结束。\nPOP3 和 IMAP\n邮局协议（Post Office Protocol,POP）是一个非常简单但功能有限的邮件读取协议，现在使用的是它的第三个版本 POP3。POP3 采用的是“拉”（Pull）的通信方式，当用户读取邮件时，用户代理向邮件服务器发出请求，“拉”取用户邮箱中的邮件。\n  POP 也使用客户/服务器的工作方式，在传输层使用 TCP，端口号为 110。接收方的用户代理上必须运行 POP 客户程序，而接收方的邮件服务器上则运行 POP 服务器程序。POP 有两种工作方式：“下载并保留”和“下载并删除”。 在“下载并保留”方式下，用户从邮件服务器上读取邮件后，邮件依然会保存在邮件服务器上，用户可再次从服务器上读取该邮件；而使用“下载并删除”方式时，邮件一旦被读取，就在邮件服务器上被删除，用户不能再次从服务器上读取。\n   另一个邮件接收协议是因特网报文存取协议（IMAP），它比 POP 复杂得多，IMAP 为用户提供了创建文件夹、在不同文件夹之间移动邮件及在远程文件夹中查询邮件的命令，为此 IMAP 服务器维护了会话用户的状态信息。IMAP 的另一特性是允许用户代理只获取报文的某些部分，例如可以只读取一个报文的首部，或一个多部分 MIME 报文的一部分。这非常适用于低带宽的情况，用户可能并不想取回邮箱中的所有邮件，尤其是包含很多音频或视频的大邮件。\n目前有很多基于万维网的电子邮件，如 Hotmail、Gmail 等。这种电子邮件的特点是，用户浏览器与 Hotmail 或 Gmail 的邮件服务器之间的邮件发送或接收使用的是 HTTP，而仅在不同邮件服务器之间传送邮件时才使用 SMTP。\n万维网(www)\n万维网（World Wide Web，WWW）是一个资料空间,在这个空间中：一样有用的事物称为一种“资源”，并由一个全域“统一资源定位符”（URL）标识。这些资源通过超文本传输协议（HTTP）传送给使用者，而后者通过单击链接来获取资源。\n万维网的内核部分是由三个标准构成的：\n（1）统一资源定位符（URL）\n   负责标识万维网上的各种文档，并使每个文档在整个万维网的范围内具有唯一的标识符 URL。（2）超文本传输协议（HTTP）\n   一个应用层协议，它使用 TCP 连接进行可靠的传输， HTTP 是万维网客户程序和服务器程序之间交互所必须严格遵守的协议（3）超文本标记语言（HTML）\n   一种文档结构的标记语言，它使用一些约定的标记对页面上的各种信息（包括文字、声音、图像、视频等）、格式进行描述\nURL 是对可以从因特网上得到的资源的位置和访问方法的一种简洁表示。URL 相当于一个文件名在网络范围的扩展。\n  URL 的一般形式是：&lt;协议&gt;://&lt;主机&gt;:&lt;端口&gt;/&lt;路径&gt;\n  &lt;协议&gt;是指用什么协议来获取万维网文档,常见的协议有 http、ftp 等；&lt;主机&gt;是存放资源的主机在因特网中的域名，也可以是 IP 地址；&lt;端口&gt;和&lt;路径&gt;有时可以省略。\n超文本传输协议（HTTP）\nHTTP定义了浏览器（万维网客户进程）怎样向万维网服务器请求万维网文档，以及服务器怎样把文档传送给浏览器。 从层次的角度看，HTTP 是面向事务的（Transaction-oriented）应用层协议，它规定了在浏览器和服务器之间的请求和响应的格式与规则，是万维网上能够可靠地交换文件（包括文本、声音、图像等各种多媒体文件）的重要基础\n每个万维网站点都有一个服务器进程,他不断监听 TCP 的端口 80(HTTP 端口80,HTTPS 端口443)\nHTTP 采用 TCP 作为传输层协议，保证了数据的可靠传输。 HTTP 不必考虑数据在传输过程中被丢弃后又怎样被重传。但是，HTTP 本身是无连接的。 也就是说，虽然 HTTP 使用了 TCP 连接，但通信的双方在交换 HTTP 报文之前不需要先建立 HTTP 连接。\nHTTP 既可以使用非持久连接，也可以使用持久连接（HTTP/1.1支持）\n   对于非持久连接，每个网页元素对象（如 JPEG 图形、Flash 等）的传输都需要单独建立一个 TCP 连接。也就是说，请求一个万维网文档所需的时间是该文档的传输时间（与文档大小成正比）加上两倍往返时间 RTT（一个 RTT 用于 TCP 连接，另一个 RTT 用于请求和接收文档）\n\n\n\n\n\n\n\n\n\n🙋‍♂️ 所谓持久连接，是指万维网服务器在发送响应后仍然保持这条连接，使同一个客户和服务器可以继续在这条连接上传送后续的 HTTP 请求与响应报文。\n持久连接又分为非流水线和流水线两种方式。对于非流水线方式，客户在收到前一个响应后才能发出下一个请求。HTTP/1.1 的默认方式是使用流水线的持久连接。这种情况下，客户每遇到一个对象引用就立即发出一个请求，因而客户可以逐个地连续发出对各个引用对象的请求。如果所有的请求和响应都是连续发送的，那么所有引用的对象共计经历 1 个 RTT 延迟，而不是像非流水线方式那样，每个引用都必须有 1 个 RTT 延迟。\nHTTP 的报文结构\nHTTP 是面向文本的（Text-Oriented），因此报文中的每个字段都是一些 ASCII 码串，并且每个字段的长度都是不确定的。有两类 HTTP 报文：\n请求报文(resquest)：从客户向服务器发送的请求报文\n  响应报文(response)：从服务器到客户的回答\n请求和响应报文格式如下 👇\n\n总结:\n\n以下一图总结并回顾报文段、IP 数据报、MAC 帧的相关知识 👇\n\n拓展知识\n请求报文中几个常用方法\n\n\n\n方法\n意义\n\n\n\n\nGET\n请求读取由 URL 标识的信息\n\n\nHEAD\n请求读取由 URL 标识的信息的首部\n\n\nPOST\n给服务器添加信息(如注释)\n\n\nCONNECT\n用于代理服务器\n\n\nDELETE\n请求服务器删除指定数据\n\n\n\n响应报文中的状态码\n\n\n\n状态码\n名字\n意义\n\n\n\n\n100\nContinue\n继续\n\n\n101\nSwitching Protocols\n切换协议\n\n\n102\nProcessing\n处理中\n\n\n103\nEarly Hints\n早期提示\n\n\n200\nOK\n请求成功\n\n\n201\nCreated\n已创建\n\n\n202\nAccepted\n已接受\n\n\n203\nNon-Authoritative Information\n非官方信息\n\n\n204\nNo Content\n无内容\n\n\n205\nReset Content\n重置内容\n\n\n206\nPartial Content\n部分内容\n\n\n207\nMulti-Status\n多状态\n\n\n208\nAlready Reported\n已报告\n\n\n226\nIM Used\nIM 已使用\n\n\n300\nMultiple Choices\n多种选择\n\n\n301\nMoved Permanently\n永久重定向\n\n\n302\nFound\n找到\n\n\n303\nSee Other\n参见其他\n\n\n304\nNot Modified\n未修改\n\n\n305\nUse Proxy\n使用代理\n\n\n307\nTemporary Redirect\n临时重定向\n\n\n308\nPermanent Redirect\n永久重定向\n\n\n400\nBad Request\n错误的请求\n\n\n401\nUnauthorized\n未经授权\n\n\n402\nPayment Required\n需要付款\n\n\n403\nForbidden\n禁止访问\n\n\n404\nNot Found\n未找到\n\n\n405\nMethod Not Allowed\n方法不允许\n\n\n406\nNot Acceptable\n不可接受\n\n\n407\nProxy Authentication Required\n需要代理身份验证\n\n\n408\nRequest Timeout\n请求超时\n\n\n409\nConflict\n冲突\n\n\n410\nGone\n已删除\n\n\n411\nLength Required\n需要 Content-Length 头部\n\n\n412\nPrecondition Failed\n前提条件失败\n\n\n413\nPayload Too Large\n请求有效载荷过大\n\n\n414\nURI Too Long\n请求的 URI 过长\n\n\n415\nUnsupported Media Type\n不支持的媒体类型\n\n\n416\nRange Not Satisfiable\n范围不可满足\n\n\n417\nExpectation Failed\n预期失败\n\n\n418\nI’m a teapot\n我是一个茶壶\n\n\n421\nMisdirected Request\n被错导的请求\n\n\n422\nUnprocessable Entity\n无法处理的实体\n\n\n423\nLocked\n已锁定\n\n\n424\nFailed Dependency\n依赖关系失败\n\n\n425\nToo Early\n过早\n\n\n426\nUpgrade Required\n需要升级\n\n\n428\nPrecondition Required\n需要前提条件\n\n\n429\nToo Many Requests\n请求过多\n\n\n431\nRequest Header Fields Too Large\n请求头字段过大\n\n\n451\nUnavailable For Legal Reasons\n由于法律原因不可用\n\n\n500\nInternal Server Error\n服务器内部错误\n\n\n501\nNot Implemented\n未实现\n\n\n502\nBad Gateway\n错误的网关\n\n\n503\nService Unavailable\n服务不可用\n\n\n504\nGateway Timeout\n网关超时\n\n\n505\nHTTP Version Not Supported\n不支持的 HTTP 版本\n\n\n506\nVariant Also Negotiates\n变体协商也有问题\n\n\n507\nInsufficient Storage\n存储空间不足\n\n\n508\nLoop Detected\n检测到循环\n\n\n510\nNot Extended\n未扩展\n\n\n511\nNetwork Authentication Required\n需要网络认证\n\n\n\nHTTP 是无状态的协议,也就是说同一个客户端第二次访问同一个服务器上的页面,服务器的相应与第一次访问相同,因为服务器不记得曾经访问过这个客户,也不记得客户端的访问次数\n在实际应用中常使用 🍪cookie/token + 数据库的方式来跟踪用户活动\n客户端发送 http 请求,服务器接受 client 请求后建立一个session,并 sent 一个 http respone 到 client,这个 response head 中包含了一个set-cookie头部该头部包含sessionid\nset-cookie格式如下:\nset-cookie : value[; Expries : date][;Domain = domain][;Path = path][;Max-Age : value][;Secure ...]\nExpries:cookie 最长有效时间(时间戳),没有设置则表示这是一个会话期 cookie,当会话被关闭此时会话期 cookie 在彼时被移除\n\n\n\n\n\n\n\n\n\n🙋‍♂️ 在服务端渲染的页面,其 Expries 的时间戳是服务器时间\n而在客户端渲染的页面,其 Expries 的时间戳是客户端时间\nMax-Age:cookie 失效前需要经过的秒数,秒数为 0 或-1 会将 cookie 直接过期。Max-Age 的优先级比 Expries 更高\nDomain:指定 cookie 可以送达的主机名,没指定的话默认值为当前文档访问地址中的主机部分\nSecure:一个带有安全属性的 cookie(只有在请求使用 https 的时候才会被发送到服务端,以阻止中间人攻击)\nHttpOnly:用于阻止 JS 通过 Document.cookie 属性访问 cookie,其用来防范跨站攻击脚本 xss\nsamesite::允许一则 cookie 不随跨站请求一起被发送,这可以一定程度上防范跨站请求伪造攻击(CSRF)\nsamesite-value:\n1) strict:意味着浏览器只对同一站点发送请求,即请求来自设置cookie的站点(同域,同协议)\n1) Lax:cookie不会在跨站请求中被发送。如加载图像或frame的请求,但cookie在用户从外站导航到源站时cookie也将被发送,这是samesite未被设置时的默认行为\n1) None:浏览器在跨站和同站均会发送cookie,设置这一值的同时必须同时设置secure属性\n什么是跨站?什么是跨域?二者有何区别?\n跨域的定义并不是域名不同或者域不同,而是&quot;不同源&quot;\n同源的定义是协议、域名、端口号三者都相同的 URL\n\n具有相同协议、主机名、端口号的组合的网站被视为&quot;相同来源&quot;(same-origin)其他所有内容均视为&quot;跨域&quot;(cross-origin)\n站(site)\n站是指有效顶级域名(effective Top-LeveL Domain, eTLD)和其前面的二级域名的一个整体,即(eTLD+1)\n\n\n\n\n\n\n\n\n\n\neTLD 列表在 publicsuffix.org/list 上进行维护\n同站和跨站\n具有相同的 eTLD+1 的网端被视为同站(same-site)\n具有不同的 eTLD+1 的网端被视为跨站(cross-site)\n\n\n\n\n\n\n\n\n\n尽管同站忽略了协议(无协议的同站)在某些情况下必须严格区分协议,以防 HTTP 被用作弱通道,一些文档将同站更明确的定义为 schemeful same site(协议与 eTLD+1 都相同)\n即https://www.example与http😕/www.example.com视为跨站\n","slug":"计算机网络基础","date":"2023-07-17T16:30:34.000Z","categories_index":"计算机基础,计算机网络","tags_index":"计算机网络","author_index":"ND_LJQ"}]